[["index.html", "데이터 과학을 지탱하는 기본기 데이터 과학을 지탱하는 기본기", " 데이터 과학을 지탱하는 기본기 한국 알 사용자회 2022-05-12 데이터 과학을 지탱하는 기본기 사단법인 한국 알(R) 사용자회는 디지털 불평등 해소와 통계 대중화를 위해 2022년 설립되었습니다. 오픈 통계 패키지 개발을 비롯하여 최근에 데이터 사이언스 관련 교재도 함께 제작하여 발간하는 작업을 수행하고 있습니다. 그 첫번째 결과물로 John Fox 교수님이 개발한 설치형 오픈 통계 패키지 Rcmdr(Fox 2016) (Fox and Bouchet-Valat 2021) (Fox 2005) 를 신종화 님께서 한글화 및 문서화에 10년 넘게 기여해주신 한국알사용자회 저작권을 흔쾌히 허락해 주셔서 설치형 오픈 통계 패키지 - Rcmdr로 세상에 나왔습니다. 두번째 활동을 여기저기 산재되어 있던 시각화 관련 자료를 묶어 데이터 시각화(Data Visualization)를 전자책 형태로 공개하였고, 데이터 분석 관련 저술을 이어 진행하게 되었습니다. 데이터 분석 언어 R에 관한 지식을 신속히 습득하여 독자들이 갖고 있는 문제에 접목시키고자 하시는 분은 한국 알(R) 사용자회에서 번역하여 공개한 R 신병훈련소(Bootcamp) 과정을 추천드립니다. “데이터 과학을 지탱하는 기본기” 저작을 위해 소프트웨어/데이터 카펜트리(Software/Data Carpentry)의 원작내용을 번역(Wilson 2022)하고 필요한 경우 한국에서 고급 데이터 분석작업을 수행하기 위해 저자들의 경험을 녹여 제작한 출판물임을 밝혀둡니다. “데이터 과학을 지탱하는 기본기” 저작물을 비롯한 한국 알(R) 사용자회 저작물은 크리에이티브 커먼즈 저작자표시-비영리-동일조건 변경 허락 (BY-NC-SA) 라이선스를 준용하고 있습니다. 관련 문의와 연락이 필요한 경우 한국 알(R) 사용자회 admin@r2bit.com 대표전자우편으로 연락주세요. 후원계좌 디지털 불평등 해소를 위해 제작중인 오픈 통계패키지 개발과 고품질 콘텐츠 제작에 큰 힘이 됩니다. 하나은행 448-910057-06204 사단법인 한국알사용자회 참고문헌 "],["shell-intro.html", "1 . 쉘(Shell) 소개 1.1 배경 1.2 쉘(Shell) 1.3 어떻게 생겼을까? 1.4 ls 와 플래그 의미 파악 1.5 어려운가요? 1.6 유연성과 자동화 1.7 Nelle 파이프라인 - 문제", " 1 . 쉘(Shell) 소개 1.1 배경 상위 수준에서 컴퓨터는 네가지 일을 수행한다: 프로그램 실행 데이터 저장 컴퓨터간 상호 의사소통 사람과 상호작용 마지막 작업을 뇌-컴퓨터 연결, 음성 인터페이스를 포함한 다양한 많은 방식으로 수행하고 있지만 아직은 초보적인 수준이어서, 대부분은 WIMP((Window) 윈도우, (Icon)아이콘, (Mouse)마우스, (Pointer)포인터)를 사용한다. 1980년대까지 이러한 기술은 보편적이지 않았지만, 기술의 뿌리는 1960년대 Doug Engelbart의 작업에 있고, “The Mother of All Demos”로 불리는 것에서 볼 수 있다. 조금 더 멀리 거슬러 올라가면, 초기 컴퓨터와 상호작용하는 유일한 방법은 와이어로 다시 연결하는 것이다. 하지만, 중간에 1950년에서 1980년 사이 대부분의 사람들이 라인 프린터(line printer)를 사용했다. 이런 장치는 표준 키보드에 있는 문자, 숫자, 특수부호의 입력과 출력만 허용해서, 프로그래밍 언어와 인터페이스는 이러한 제약사항에서 설계됐다. 여전히 전통적인 화면, 마우수, 터치패드, 키보드를 사용하지만 터치 인터페이스와 음성 인터페이스가 보편화되고 있다. 이런 종류의 인터페이스를 지금 대부분의 사람들이 사용하는 그래픽 사용자 인터페이스(GUI, graphical user interface)과 구별하기 위해서 명령-라인 인터페이스(CLI, command-line interface)라고 한다. CLI의 핵심은 읽기-평가-출력(REPL,read-evaluate-print loop)이다: 사용자가 명령어를 타이핑하고 엔터(enter)/반환(return)키를 입력하면, 컴퓨터가 읽고, 실행하고, 결과를 출력한다. 그러고 나면, 사용자는 다른 명령를 타이핑하는 것을 로그 오프해서 시스템을 빠져 나갈때까지 계속한다. GUI는 WIMP((Window) 윈도우, (Icon)아이콘, (Mouse)마우스, (Pointer)포인터)로 구성되는데 배우기 쉽고, 단순 작업에 대해서는 환상적이다. “클릭”하게 되면 명령이 “내가 원하는 작업을 수행해”라고 손쉽게 컴퓨터에 통역된다. 하지만, 이런 마술은 단순한 작업을 수행하고, 정확하게 이러한 유형의 작업을 수행할 수 있는 프로그램에 불과하다. 만약 복잡하고, 특정 목적에 부합되는 훨씬 묵직한 작업을 컴퓨터에 내리고자 한다고 해서, 난해하거나 어렵거나할 필요는 없고, 단지 명령 어휘가 필요하고 이를 사용하는데 필요한 단순한 문법만 필요로 한다. 쉘이 이런 기능을 제공한다 - 단순한 언어로 이를 사용하는데 명령-라인 인터페이스가 필요하다. 명령라인 인터페이스의 심장은 읽기-평가-출력(REPL,read-evaluate-print loop)이다. REPL로 불리는 이유는 쉘에 명령어를 타이핑하고 Return를 치게되면 컴퓨터가 명령어를 읽어들이고 나서, 평가(혹은 실행)하고 출력결과를 화면에 뿌린다. 또 다른 명령어를 입력할 때까지 대기하는 루푸를 반복하게 되서 그렇다. 상기 묘사가 마치 사용자가 직접 명령어를 컴퓨터에 보내고, 컴퓨터는 사용자에게 직접적으로 출력을 보내는 것처럼 들린다. 사실 중간에 명령 쉘(command shell)로 불리는 프로그램이 있다. 사용자가 타이핑하는 것은 쉘로 간다. 쉘은 무슨 명령어를 수행할지 파악해서 컴퓨터에게 수행하도록 지시한다. 쉘을 조개(shell)로 불리는데 이유는 운영체제를 감싸서, 복잡성 일부를 숨겨서 운영체제와 더 단순하게 상호작용하게 만든다. 1.2 쉘(Shell) 쉘(Shell)은 다른 것과 마찬가지로 프로그램이다. 조금 특별한 것은 자신이 연산을 수행하기 보다 다른 프로그램을 실행한다는 것이다. 가장 보편적인 유닉스 쉘(Unix Shell)은 Bash(Bourne Again SHell)다. Stephen Bourne이 작성한 쉘에서 나와서 그렇게 불리우고 — 프로그래머 사이에 재치로 통한다. Bash는 대부분의 유닉스 컴퓨터에 기본으로 장착되는 쉘이고, 윈도우용으로 유닉스스런 도구로 제공되는 패키지 대부분에도 적용된다. Bash나 다른 쉘을 사용하는 것이 마우스를 사용하는 것보다 프로그래밍 작성하는 느낌이 난다. 명령어는 간략해서 (흔히 단지 2~3자리 문자다), 명령어는 자주 암호스럽고, 출력은 그래프같이 시각적인 것보다 텍스트줄로 쭉 뿌려진다. 다른 한편으로, 쉘을 사용하여 좀더 강력한 방식으로 현존하는 도구를 단지 키보드 입력값 몇개를 조합해서 대용량의 데이터를 자동적으로 처리할 수 있는 파이프라인을 구축할 수 있게 한다. 추가로, 명령 라인은 종종 멀리 떨어진 컴퓨터 혹은 슈퍼컴퓨터와 상호작용하는 가장 쉬운 방법이다. 고성능 컴퓨팅 시스템에 포함된 다양한 특화된 도구와 자원을 실행하는데 쉘과 친숙성이 거의 필연적이다. 클러스트 컴퓨팅과 클라우드 컴퓨팅이 과학 데이터 클런칭(scientific data cruching)이 점점 대중화됨에 따라 원격 컴퓨터를 구동하는 것이 필수적인 기술이 되어가고 있다. 여기서 다뤄지는 명령-라인 기술에 기반해서 광범위한 과학적 질문과 컴퓨터적 도전과제를 처리할 수 있다. 1.3 어떻게 생겼을까? 전형적인 쉘 윈도우는 다음과 같다: bash-3.2$ bash-3.2$ ls -F / Applications/ System/ Library/ Users/ Network/ Volumes/ bash-3.2$ 첫번째 줄은 프롬프트(prompt)만 보여주고 있고, 쉘이 입력준비가 되었다는 것을 나타낸다. 프롬프트로 다른 텍스트를 지정할 수도 있다. 가장 중요한 것: 명령어를 타이핑할 때, 프롬프트를 타이핑하지 말고, 인식되거나 수행할 수 있는 명령어만 타이핑한다. 예제 두번째 줄에서 타이핑한 ls -F / 부분이 전형적인 구조를 보여주고 있다: 명령어(command), 플래그(flags) (선택옵션(options) 혹은 스위치(switches)) 그리고 인자(argument). 플래그는 대쉬(-) 혹은 더블 대쉬(--)로 시작하는데 명령어의 행동에 변화를 준다. 인자는 명령어에 작업할 대상을 일러준다(예를 들어, 파일명과 디렉토리). 종종 플래그를 매개변수(parameter)라고도 부른다. 명령어를 플래그 한개 이상, 인자도 한개 이상 사용하기도 한다: 하지만, 명령어가 항상 인자 혹은 플래그를 요구하지는 않는다. 상기 예제의 두번째 줄에서, 명령어는 ls, 플래그는 -F, 인자는 /이 된다. 각각은 공백으로 뚜렸하게 구분된다: 만약 ls 와 -F 사이 공백을 빼먹게 되면 쉘은 ls-F 명령어를 찾게 되는데, 존재하지 않는 명령어다. 또한, 대문자도 문제가 될 수 있다: LS 명령어와 ls 명령어는 다르다. 다음으로 명령어가 생성한 출력결과를 살펴보자. 이번 경우에 / 폴더에 위치한 파일 목록을 출력하고 있다. 금일 해당 출력결과가 무엇을 의미하는지 다룰 예정이다. 맥OS를 사용하시는 참석자분들은 이번 출력결과를 이미 인지하고 있을지도 모른다. 마지막으로, 쉘은 프롬프트를 출력하고 다음 명령어가 타이핑되도록 대기모드로 바뀐다. 이번 학습예제에서 프롬프트가 $이 된다. 명령어를 PS1='$ ' 타이핑하게 되면 동일하게 프롬프트를 맞출 수 있다. 하지만, 본인 취향에 맞추어 프롬프트를 둘 수도 있다 - 흔히 프롬프트에 사용자명과 디렉토리 현재 위치정보를 포함하기도 하다. 쉘 윈도우를 열고, ls -F / 명령어를 직접 타이핑한다. (공백과 대문자가 중요함으로 잊지 말자.) 원하는 경우 프롬프트도 변경해도 좋다. 1.4 ls 와 플래그 의미 파악 모든 쉘 명령어는 컴퓨터 어딘가에 저장된 프로그램으로, 쉘은 명령어를 검색해서 찾을 장소를 목록으로 이미 가지고 있다. (명령목록은 PATH로 불리는 변수(variable)에 기록되어 있지만, 이 개념을 나중에 다룰 것이라 현재로서는 그다지 중요하지는 않다.) 명령어, 플래그, 인자가 공백으로 구분된다는 점을 다시 상기하자. REPL(읽기-평가-출력(read-evaluate-print) 루프)를 좀더 살펴보자. “평가(evaluate)” 단계는 두가지 부분으로 구성됨에 주목한다: 타이핑한 것을 읽어들인다(이번 예제에서 ls -F /) 쉘은 공백을 사용해서 명령어로 입력된 것을 명령어, 플래그, 인자로 쪼갠다. 평가(Evaluate): ls 라는 프로그램을 찾는다. 찾은 프로그램을 실행하고 프로그램이 인식하고 해석한 플래그와 인자를 전달한다. 프로그램 실행 결과를 출력한다. 그리고 나서, 프롬프트를 출력하고 또다른 명령어를 입력받도록 대기한다. Command not found 오류 쉘이 타이핑한 명령어 이름을 갖는 프로그램을 찾을 수 없는 경우, 다음과 같은 오류 메시지가 출력된다: $ ls-F -bash: ls-F: command not found 일반적으로 명령어를 잘못 타이핑했다는 의미가 된다 - 이 경우, ls 와 -F 사이 공백을 빼먹어서 그렇다. 즉, ls -F와 같이 명령을 전달하면 의도한 바가 기계에 정확히 전달된다. 1.5 어려운가요? GUI와 비교하여 컴퓨터와 상호작용하는데 있어 어려운 모형이고 학습하는데 노력과 시간이 다소 소요도니다. GUI는 선택지를 보여주고, 사용자가 선택지중에서 선택하는 하는 것이다. 명령라인 인터페이스(CLI)로 선택지가 명령어와 패러미터의 조합으로 표현된다. 사용자에게 제시되는 것이 아니라서 새로운 언어의 어휘를 학습하듯이 일부 학습이 필요하다. 명령어의 일부만 배우게 되면 정말 도움이 많이 되고, 핵심적인 명령어를 다뤄보자. 1.6 유연성과 자동화 쉘문법(Grammar of Shell)은 기존 도구를 조합해서 강력한 파이프라인을 구축하도록 해서 방대한 데이터를 자동화하여 다룰 수 있다. 명령 순서는 스크립트(script)로 작성하여 작업흐름의 재현가능성을 향상시켜서 쉽게 반복이 가능하도록 한다. 추가로, 명령 라인은 종종 멀리 떨어진 컴퓨터 혹은 슈퍼컴퓨터와 상호작용하는 가장 쉬운 방법이다. 고성능 컴퓨팅 시스템에 포함된 다양한 특화된 도구와 자원을 실행하는데 쉘과 친숙성이 거의 필연적이다. 클러스트 컴퓨팅과 클라우드 컴퓨팅이 과학 데이터 클런칭(scientific data cruching)이 점점 대중화됨에 따라 원격 컴퓨터를 구동하는 것이 필수적인 기술이 되어가고 있다. 여기서 다뤄지는 명령-라인 기술에 기반해서 광범위한 과학적 질문과 컴퓨터적 도전과제를 처리할 수 있다. 1.7 Nelle 파이프라인 - 문제 해양 생물학자 넬 니모(Nell Nemo) 박사가 방금전 6개월간 북태평양 소용돌이꼴 조사를 마치고 방금 귀환했다. 태평양 거대 쓰레기 지대에서 젤리같은 해양생물을 표본주출했다. 총 합쳐서 1,520개 시료가 있고 다음 작업이 필요하다: 서로 다른 300개 단백질의 상대적인 함유량을 측정하는 분석기계로 시료를 시험한다. 한 시료에 대한 컴퓨터 출력결과는 각 단백질에 대해 한 줄 파일형식으로 표현된다. goostat으로 명명된 그녀의 지도교수가 작성한 프로그램을 사용하여 각 단백질에 대한 통계량을 계산한다. 다른 대학원 학생중 한명이 작성한 goodiff로 명명된 프로그램을 사용해서, 각 단백질에 대한 통계량과 다른 단백질에 대해 상응하는 통계량을 비교한다. 결과를 작성한다. 그녀의 지도교수는 이달 말까지 이 작업을 정말로 마무리해서, 논문이 다음번 Aquatic Goo Letters 저널 특별판에 게재되기를 희망한다. 각 시료를 분석장비가 처리하는데 약 반시간 정도 소요된다. 좋은 소식은 각 시료를 준비하는데는 단지 2분만 소요된다. 연구실에 병렬로 사용할 수 있는 분석장비 8대가 있어서, 이 단계는 약 2주정도만 소요될 것이다. 나쁜 소식은 goostat, goodiff를 수작업으로 실행한다면, 파일이름 입력하고 “OK” 버튼을 45,150번 눌려야 된다는 사실이다 (goostat 300회 더하기 goodiff 300×299/2). 매번 30초씩 가정하면 2주 이상 소요될 것이다. 논문 마감일을 놓칠 수도 있지만, 이 모든 명령어를 올바르게 입력할 가능성은 거의 0 에 가깝다. 다음 수업 몇개는 대신에 그녀가 무엇을 해야되는지 탐색한다. 좀더 구체적으로, 처리하는 파이프라인 중간에 반복되는 작업을 자동화하는데 쉘 명령어(command shell)를 어떻게 사용하는지 설명해서, 논문을 쓰는 동안에 컴퓨터가 하루에 24시간 작업한다. 덤으로 중간 처리작업 파이프라인을 완성하면, 더 많은 데이터를 얻을 때마다 다시 재사용할 수 있게 된다. "],["shell-filedir.html", "2 . 파일과 폴더 넘나들기 2.1 도움말 얻기 2.2 cd 디렉토리 변경 2.3 상대/절대 경로 2.4 Nelle 파이프라인: 파일 구성", " 2 . 파일과 폴더 넘나들기 파일과 디렉토리 관리를 담당하고 있는 운영체제 부분을 파일 시스템(file system)이라고 한다. 파일 시스템은 데이터를 정보를 담고 있는 파일과 파일 혹은 다른 디렉토리를 담고 있는 디렉토리(혹은 “폴더”“)로 조직화한다. 파일과 디렉토리를 생성, 검사, 이름 바꾸기, 삭제하는데 명령어 몇개가 자주 사용된다. 명령어를 살펴보기 위해, 쉘 윈도우를 연다: 먼저, pwd 명령어를 사용해서 위치를 찾아낸다; pwd는 “print working directory”를 의미한다. 디렉토리는 장소(place) 같다 - 쉘을 사용할 때마다 정확하게 한 장소에 위치하게 되는데, 이를 현재 작업 디렉토리(current working directory)라고 부른다. 명령어 대부분은 현재 작업 디렉토리에 파일을 읽고 쓰는 작업을 “이곳(here)”에 수행한다. 그래서 명령어를 실행하기 전에 현재 위치가 어디인지 파악하는 것이 중요하다. pwd 명령어를 숳애하게 되면 현재 위치를 다음과 같이 보여주게 된다: $ pwd /Users/nelle 다음에서, 컴퓨터의 응답은 /Users/nelle으로 넬(Nelle)의 홈 디렉토리(home directory)다: 홈 디렉토리(Home Directory) 변종 홈 디렉토리 경로는 운영체제마다 다르게 보인다. 리눅스에서 /home/nelle 처럼 보이고, 윈도우에서는 C:\\Documents and Settings\\nelle, C:\\Users\\nelle와 유사하게 보인다. (윈도우 버젼마다 다소 차이가 있을 수 있음에 주목한다.) 다음 예제부터, 맥OS 출력결과를 기본설정으로 사용할 것이다; 리눅스와 윈도우 출력결과에 다소 차이가 날 수 있지만, 전반적으로 유사하다. “홈 디렉토리(home directory)”를 이해하기 위해서, 파일 시스템이 전체적으로 어떻게 구성되었는지 살펴보자. 최상단에 다른 모든 것을 담고 있는 루트 디렉토리(root directory)가 있다. 슬래쉬 / 문자로 나타내고, /users/nelle에서 맨 앞에 슬래쉬이기도 하다. Nelle 과학자 컴퓨터의 파일시스템을 사례로 살펴보자. 시연을 통해서 유사한 방식으로 (하지만 정확하게 동일하지는 않지만) 본인 컴퓨터 파일시스템을 탐색하는 명령어를 학습하게 된다. 넬 과학자 컴퓨터의 파일 시스템은 다음과 같다: 파일 시스템 최상단에 다른 모든 것을 담고 있는 루트 디렉토리(root directory)가 있다. 슬래쉬 / 문자로 나타내고, /users/nelle에서 맨 앞에 슬래쉬이기도 하다. 홈 디렉토리 안쪽에 몇가지 다른 디렉토리가 있다: bin (몇몇 내장 프로그램이 저장된 디렉토리), data (여러가지 데이터 파일이 저장된 디렉토리), Users (사용자의 개인 디렉토리가 저장된 디렉토리), tmp (장기간 저장될 필요가 없는 임시 파일을 위한 디렉토리), 등등: 현재 작업 디렉토리 /Users/nelle는 /Users 내부에 저장되어 있다는 것을 알고 있는데, 이유는 /Users가 이름 처음 부분이기 때문에 알 수 있다. 마찬가지로 /Users는 루트 디렉토리 내부에 저장되어 있다는 것을 알 수 있는데, 이름이 /으로 시작되기 때문이다. 슬래쉬(Slashes) 슬래쉬 / 문자는 두가지 의미가 있는 것에 주목한다. 파일 혹은 디렉토리 이름 앞에 나타날 때, 루트 디렉토리를 지칭하게 되고, 이름 가운데 나타날 때, 단순히 구분자 역할을 수행한다. /Users 하단에서 Nelle 과학자 컴퓨터 계정과, 랩실 동료 미이라(Mummy)와 늑대인간(Wolfman) 디렉토리를 볼 수 있다. 홈 디렉토리 미이라(Mummy) 파일은 /Users/imhotep 디렉토리에 저장되어 있고, 늑대인가(Wolfman)의 파일은 /Users/larry 디렉토리에 저장되어 있고 /Users/nelle 디렉토리에 nelle의 정보가 저장되어 있는데, 이것이 왜 nelle이 디렉토리 이름의 마지막 부분인 이유다. 일반적으로 명령 프롬프트를 열게 되면, 처음 시작하는 곳이 본인 계정 홈 디렉토리가 된다. 본인 파일시스템에 담긴 내용물을 파악하는데 사용하는 명령어를 학습해 보자. (Nelle의 홈 디렉토리에 무엇이 있는지 ls 명령어를 실행해서 살펴보자.) ls는 “목록보기(listing)”를 나타낸다: $ ls Applications Documents Library Music Public Desktop Downloads Movies Pictures (다시 한번, 본인 컴퓨터 운영체제와 파일시스템을 취향에 따라 바꿨는지에 따라 출력결과는 다소 다를 수 있다.) ls는 알파벳 순서로 깔끔하게 열로 정렬하여 현재 디렉토리에 있는 파일과 디렉토리 이름을 출력한다. 플래그(flag) -F(스위치(switch) 혹은 옵션(option)으로도 불린다)를 추가하여 출력을 좀더 이해하기 좋게 출력괄를 생성할 수도 있다. ls으로 하여금 디렉토리 이름 뒤에 /을 추가하게 일러준다: 끝에 붙은 /은 디렉토리라는 것을 지칭한다. 설정에 따라 달라지도록 파일이냐 디렉토리냐에 따라 다른 색상을 입힐 수도 있다. 앞선 학습에서 ls -F 명령어를 사용한 것을 상기한다. $ ls -F Applications/ Documents/ Library/ Music/ Public/ Desktop/ Downloads/ Movies/ Pictures/ 2.1 도움말 얻기 ls 명령어에 딸린 플래그가 많다. 일반적으로 명령어와 수반되는 플래그 사용법을 파악하는 방식이 두개 있다: --help 플래그를 명령어에 다음과 같이 전달하는 방법: $ ls --help man 명령어로 다음과 같이 매뉴얼을 읽는 방법: $ man ls 본인 컴퓨터 환경에 따라 상기 방법 중 하나만 동작(man 혹은 --help)할 수도 있다. 아래에서 두가지 방법 모두 살펴보자. 2.1.1 --help 플래그 배쉬 내부에서 동작하도록 작성된 배쉬 명령어와 프로그램은 --help 플래그를 지원해서 명령어 혹은 프로그램을 사용하는 방식에 대한 더 많은 정보를 볼 수 있게 해 준다. $ ls --help Usage: ls [OPTION]... [FILE]... List information about the FILEs (the current directory by default). Sort entries alphabetically if none of -cftuvSUX nor --sort is specified. Mandatory arguments to long options are mandatory for short options too. -a, --all do not ignore entries starting with . -A, --almost-all do not list implied . and .. --author with -l, print the author of each file -b, --escape print C-style escapes for nongraphic characters --block-size=SIZE scale sizes by SIZE before printing them; e.g., &#39;--block-size=M&#39; prints sizes in units of 1,048,576 bytes; see SIZE format below -B, --ignore-backups do not list implied entries ending with ~ -c with -lt: sort by, and show, ctime (time of last modification of file status information); with -l: show ctime and sort by name; otherwise: sort by ctime, newest first ... 중략 -X sort alphabetically by entry extension -Z, --context print any security context of each file -1 list one file per line. Avoid &#39;\\n&#39; with -q or -b --help display this help and exit --version output version information and exit The SIZE argument is an integer and optional unit (example: 10K is 10*1024). Units are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000). Using color to distinguish file types is disabled both by default and with --color=never. With --color=auto, ls emits color codes only when standard output is connected to a terminal. The LS_COLORS environment variable can change the settings. Use the dircolors command to set it. Exit status: 0 if OK, 1 if minor problems (e.g., cannot access subdirectory), 2 if serious trouble (e.g., cannot access command-line argument). GNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt; Full documentation at: &lt;http://www.gnu.org/software/coreutils/ls&gt; or available locally via: info &#39;(coreutils) ls invocation&#39; 지원되지 않는 명령-라인 선택옵션 지원되지 않는 선택옵션(플래그)를 사용하게 되면, ls를 비롯한 다른 프로그램은 다음과 같은 오류 메시지를 일반적으로 출력하게 된다: $ ls -j ls: invalid option -- &#39;j&#39; Try &#39;ls --help&#39; for more information. 2.1.2 man 명령어 ls에 대해 배울 수 있는 다른 방식은 다음 명령어를 타이핑하는 것이다. $ man ls 상기 명령어를 실행하게 되면 ls 명령어와 선택 옵션에 대해 기술된 페이지로 탈바꿈하게 된다. 만약 운이 좋은 경우 상용법에 대한 예제도 포함되어 있다. man 페이지를 살펴보는 방법은 행단위로 이동하는데 ↑, ↓을 사용하거나 전체 페이지 단위로 건너뛰거나 아래 페이지로 이동할 경우 B, Spacebar을 사용한다. man 페이지에서 단어나 문자를 찾는 경우 / 다음에 검색할 문자 혹은 단어를 타이핑하면 된다. man 페이지에서 빠져 나오고자 종료(quit)하고자 한다면 Q을 누른다. 웹상의 매뉴얼 페이지 물론 명령어에 대한 도움말에 접근하는 세번째 방식이 있다: 웹브라우저를 통해서 인터넷을 검색하는 것이다. 인터넷 검색을 이용할 때, 검색쿼리에 unix man page 문구를 포함할 경우 연관된 정보를 찾는데 도움이 될 수 있다. GNU도 GNU 핵심 유틸리티(core GNU utilities)이 포함된 매뉴얼을 제공하고 있는데 이번 학습에 소개된 많은 명령어를 망라하고 있다. 더많은 ls 플래그 탐색 -l, -h 플래그를 붙여 ls 명령어를 수행하게 되면 출력결과는 어떻게 나올까? 출력결과의 일부는 이번 학습에서 다루지 않는 속성(property)에 대한 것으로 파일 권한과 파일 소유에 대한 것이다. 그럼에도 불구하고 나머지는 유용할 것이다. ls와 사용되는 -l 플래그는 long을 축약한 것으로 파일/디렉토리 명칭 뿐만 아니라 파일 크기, 최종 변경 시간 같은 부가정보가 출력된다. -h 플래그는 “human readable” 사람이 읽기 편한 형태로 파일크기를 지정한다. 예를 들어, 5369 대신에 5.3K이 화면에 출력된다. 재귀적으로 시간순으로 목록 출력 ls -R 명령어는 디렉토리에 담긴 내용을 재귀적으로 화면에 출력한다; 즉, 각 단계별로 하위 디렉토리, 하위-하위 디렉토리 내용을 확면에 출력한다. ls -t 명령어는 마지막 변경된 시점순으로 가장 최근에 변경된 파일 혹은 디렉토리를 화면에 정렬해서 출력한다. ls -R -t 명령어는 어떤 순서로 화면엘 출력할까? 힌트: ls -l 명령어를 사용해서 시간도장(timestamp)을 볼 수 있도록 전체 목록을 화면에 출력한다. 각 디렉토리의 파일/디렉토리가 가장 마지막 시간 변경순으로 정렬되어 출력된다. 여기서 홈 디렉토리가 하위 디렉토리(sub-directories)가 포함된것을 알 수 있다. 슬래쉬(/)가 붙지 않는 명칭을 갖는 것은 것은 평범한 파일(file)이다. ls 와 -F 사이에 공백이 있는 것에 주목한다: 공백이 없다면 쉘은 존재하지 않는 ls-F 명령어를 실행시키려 한다고 간주한다. ls 명령어를 사용해서 다른 디렉토리에 들어 있는 파일과 디렉토리를 살펴볼 수 있다. ls -F Desktop 명령어를 실행해서 바탕화면 Desktop 디렉토리에 담긴 것을 살펴보자. 즉, ls 명령어는 -F 플래그, 그리고 인자(argument) Desktop으로 구성된다. Desktop 인자는 ls로 하여금 현재 작업 디렉토리가 아닌 바탕화면 디렉토리 내용을 출력하도록 지정하는 역할을 수행한다: $ ls -F Desktop data-shell/ 작업한 출력결과는 웹사이트에서 다운로드 받아 압축을 풀어 작업하여 생성한 data-shell 디렉토리와 본인 바탕화면에 저장된 모든 파일과 하위디렉토리가 출력되어야 한다. 2.2 cd 디렉토리 변경 지금 확인했듯이, 배쉬 쉘은 파일을 계층적 파일 시스템으로 구성한다는 아이디어에 강력히 의존하고 있다. 이런 방식으로 계층적으로 파일과 디렉토리를 구조화하게 되면 본인 작업을 추적하는데 도움이 된다: 책상위에 출력한 논문 수백개를 쌓아놓은 것는 것이 가능하듯이, 홈 디렉토리에 파일 수백개를 저장하는 것도 가능하다. 하지만, 이런 접근법은 자멸하는 전략이나 마찬가지다. data-shell 디렉토리가 바탕화면(Desktop)에 위치하는 것을 확인했으니, 다음 두가지를 수행할 수 있다. 먼저, data-shell 디렉토리에 담긴 것을 살펴보자; 디렉토리 이름에 ls를 전달해서 앞서 확인된 동일한 전략을 사용하자: $ ls -F Desktop/data-shell creatures/ molecules/ notes.txt solar.pdf data/ north-pacific-gyre/ pizza.cfg writing/ 둘째로, 다른 디렉토리로 위치를 실제로 바꿀 수 있다. 그렇게 하면 더이상 홈 디렉토리에 있지는 않게 된다. 작업 디렉토리를 변경하기 위해서 cd 다음에 디렉토리 이름을 사용한다. cd는 “change directory”의 두문어다. 하지만 약간 오해의 소지가 있다: 명령어 자체가 디렉토리를 변경하지는 않고, 단지 사용자가 어느 디렉토리에 있는지에 대한 쉘의 생각만 바꾼다. 앞서 확인한 data 디렉토리로 이동해 보자. 다음 명령어를 쭉 이어서 실행하게 되면 목적지에 도달할 수 있다: $ cd Desktop $ cd data-shell $ cd data 상기 명령어는 홈 디렉토리에 바탕화면(Desktop) 디렉토리로 이동하고 나서, data-shell 디렉토리로 이동하고 나서, data 디렉토리에 이동하게 된다. cd 명령어는 아무것도 출력하지는 않지만, pwd 명령어를 실행하게 되면 /Users/nelle/Desktop/data-shell/data 위치한 것을 확인하게 된다. 인자 없이 ls 명령어를 실행하게 되면, /Users/nelle/Desktop/data-shell/data 디렉토리 파일과 디렉토리를 출력하게 되는데 이유는 지금 있는 위치이기 때문이다: $ pwd /Users/nelle/Desktop/data-shell/data $ ls -F amino-acids.txt elements/ pdb/ salmon.txt animals.txt morse.txt planets.txt sunspot.txt 이제 디렉토리 나무를 타서 아래로 내려가는 방법을 익혔다. 하지만 어떻게 하면 위로 올라갈 수 있을까? 다음 명령어를 시도해보자: $ cd data-shell -bash: cd: data-shell: No such file or directory 하지만, 오류 발생! 이유가 뭘까? 지금까지 방법으로 cd 명령어는 현재 디렉토리 내부에 하위 디렉토리만 볼 수 있다. 현재 디렉토리에서 상위 디렉토리를 볼 수 있는 다른 방법이 있다; 가장 단순한 것부터 시작해보자. 쉘에서 한단계 위 디렉토리로 이동할 수 있는 단축키가 존재하는데 다음과 같이 생겼다: $ cd .. ..은 특별한 디렉토리명인데 “현재 디렉토리를 포함하는 디렉토리”, 좀더 간결하게 표현하면 현재 디렉토리의 부모를 의미한다. 물론, cd .. 명령어를 실행하고 나서 pwd을 실행하게 되면 /Users/nelle/Desktop/data-shell로 되돌아 간다: $ pwd /Users/nelle/Desktop/data-shell 단순히 ls 명령어를 실행하게 되면 특수 디렉토리 ..이 화면에 출력되지는 않는다. .. 디렉토리를 출력하려면 ls 명령어와 -a 플래그를 사용한다: $ ls -F -a ./ .bash_profile data/ north-pacific-gyre/ pizza.cfg thesis/ ../ creatures/ molecules/ notes.txt solar.pdf writing/ -a은 “show all”의 축약으로 모두 보여주기를 의미한다; ls로 하여금 ..와 같은 .로 시작하는 파일과 디렉토리명도 화면에 출력하게 강제한다. (/Users/nelle 디렉토리에 위치한다면, /Users 디렉토리를 지칭) .도 또다른 특별한 디렉토리로, “현재 작업 디렉토리(current working directory)”를 의미한다. 중복되어 불필요해 보일 수 있지만, 곧 .에 대한 사용법을 학습할 것이다. 대부분의 명령라인 도구에서 플래그 다수룰 조합해서 플래그 사이 공백없이 단일 -로 사용함에 주목한다: ls -F -a은 ls -Fa와 동일하다. 다른 숨은 파일들 숨은 .., . 디렉토리에 더해서, .bash_profile 파일도 봤을 것이다. .bash_profile 파일에는 쉘 환경설정 정보가 담겨져 있다. .으로 시작하는 다른 파일과 디렉토리를 봤을 수도 있다. 이런 파일은 본인 컴퓨터의 다른 프로그램에서 환경설정을 하기 위해서 사용되는 파일과 디렉토리라고 보면 된다. . 접두어를 사용해서 ls 명령어를 사용할 때 이러한 환경설정 파일들이 터미널을 난잡하게 만드는 것을 방지하는 기능을 수행한다. 직교(Orthogonality) 특수 이름 .과 ..는 ls에만 속하는 것이 아니고; 모든 프로그램에서 같은 방식으로 해석된다. 예를 들어, /Users/nelle/data 디렉토리에 있을 때, ls .. 명령어는 /Users/nelle의 목록을 보여줄 것이다. 어떻게 조합되든 상관없이 동일한 의미를 가지게 될 때, 프로그래머는 이를 직교(orthogonal)한다고 부른다. 직교 시스템은 사람들이 훨씬 배우기 쉬운데, 이유는 기억하고 추적할 특수 사례와 예외가 더 적기 때문이다. 2.3 상대/절대 경로 컴퓨터에 파일시스템을 돌아다니는데 기본 명령어는 pwd, ls, cd을 들 수 있다. 지금까지 사용했던 했던 방식을 벗어난 사례를 살펴보자. 프롬프트에서 cd 명령어를 디렉토리를 특정하지 않고 실행시키면 어떻게 될까? $ cd 상기 명령어 실행 결과를 어떻게 확인할 수 있을까? pwd 명령어가 정답을 제시한다! $ pwd /Users/nelle 어떤 플래그도 없는 cd 명령어는 홈디렉토리로 이동시킨다. 파일시스템에서 방향을 잃었을 경우 큰 도움이 된다. data 디렉토리로 되돌아가자. 앞서 명령어 세개를 동원했지만 한방에 해당 디렉토리를 명세해서 바로 이동할 수 있다. $ cd Desktop/data-shell/data pwd 와 ls -F 명령어를 실행해서 올바른 자리로 돌아왔는지 확인하자. data 디렉토리에서 한단계 위로 올라가려고 하면 cd .. 명령어를 사용했다. 현재 디렉토리 위치에 관계없이 특정 디렉토리로 이동할 수 있는 다른 방식도 있다. 지금까지 디렉토리명을 명세할 때 상대경로(relative paths)를 사용했다. ls 혹은 cd와 같은 명령어와 상대 경로를 사용할 때는 시스템이 파일시스템의 루트 위치(/)에서 차근차근 찾기보다 해당 위치를 현재 위치를 찾아 명령을 실행시킨다. 하지만, / 슬래쉬로 표현되는 루트 디렉토리에서 전체 경로를 추가한 절대경로(absolute path)로 명세하는 것도 가능하다. / 슬래쉬는 컴퓨터가 루트 디렉토리에서 경로를 탐색하도록 지시한다. 따라서, 명령어를 실행할 때 현재 디렉토리 위치에 관계없이 정확한 특정 디렉토리를 항상 명세하게 된다. 절대경로를 사용하면 파일 시스템에 어느 위치에서든 있던 관계없이 data-shell 디렉토리로 이동할 수 있다. 절대경로를 찾기 쉬운 방법은 pwd 명령어를 사용해서 필요한 디렉토리 정보를 추출하고 이를 활용해서 data-shell 디렉토리로 이동한다. $ pwd /Users/nelle/Desktop/data-shell/data $ cd /Users/nelle/Desktop/data-shell pwd와 ls -F 명령어를 실행하게 되면 원하던 디렉토로리 제대로 이동되었는지 확인이 가능하다. 단축(Shortcuts) 두개 더 쉘을 ~ (틸드) 문자를 경로의 시작으로 해석해서 “현재 사용자 홈 디렉토리”를 의미하게 된다. 예를 들어, Nelle의 홈 디렉토리가 /Users/nelle이라면, ~/data은 /Users/nelle/data와 동치가 된다. 경로명에 첫 문자로 있을 때만 이것이 동작한다: here/there/~/elsewhere이 here/there/Users/nelle/elsewhere이 되는 것은 아니다. 따라서, cd ~을 홈 디렉토리로 변경하는데 사용한다. 또 다룩 단축은 대쉬(-) 문자다. cd는 - 문자를 지금 있는 이전 디렉토리로 변역한다. 이 방법이 전체 경로를 기억하고 있다가 타이핑하는 것보다 더 빠르다. 이를 통해 디렉토리를 앞뒤로 매우 효율적으로 이동하게 된다. cd .. 와 cd - 명령어 사이 차이점은 전자(cd ..)는 위로, 후자(cd -)는 아래로 이동하게 위치를 바꾸는 역할을 수행한다. TV 리모컨의 이전 채널 기능으로 생각하면 편하다. 동일 작업을 수행하는 수많은 방법 - 절대 경로 vs. 상대 경로 /home/amanda/data/ 디렉토리에서 시작할 때, Amanda가 홈디렉토리인 /home/amanda로 돌아가도록 사용할 수 있는 명령어를 아래에서 선택하시요. cd . cd / cd /home/amanda cd ../.. cd ~ cd home cd ~/data/.. cd cd .. 해답 풀이 1. No: .은 현재 디렉토리를 나타냄. 2. No: /는 루트 디렉토리를 나타냄. 3. No: Amanda 홈 디렉토리른 /Users/amanda임. 4. No: ../..은 두 단계 거슬러 올라간다; 즉, /Users에 도달함. 5. Yes: ~은 사용자 홈 디렉토리를 나타남; 이 경우 /Users/amanda이 됨. 6. No: 현재 디렉토리 내부에 home 디렉토리가 존재하는 경우 home 디렉토리로 이동하게 됨. 7. Yes: 불필요하게 복잡하지만, 정답이 맞음. 8. Yes: 사용자 홈 디렉토리로 이동할 수 있는 단축키를 사용함. 9. Yes: 한 단계 위로 이동. 상대경로 해결 만약 pwd 명령어를 쳤을 때, 화면에 /Users/thing이 출력된다면, ls -F ../backup은 무엇을 출력할까요? ../backup: No such file or directory 2012-12-01 2013-01-08 2013-01-27 2012-12-01/ 2013-01-08/ 2013-01-27/ original/ pnas_final/ pnas_sub/ 도전과제 질문 파일 시스템 해답 풀이 No: backup in /Users 디렉토리 내부에 backup 디렉토리가 있다. No: Users/thing/backup 디렉토리에 담긴 것을 출력한다. 하지만 ..으로 한 단계 상위 레벨 위를 찾도록 요청했다. No: 이전 해답을 참조한다. Yes: ../backup/ 은 /Users/backup/을 지칭한다. ls 독해 능력 상기 그림(도전과제 질문에 사용되는 파일 시스템)에 나온 디렉토리 구조를 상정한다. 만약 pwd 명령어를 쳤을 때 화면에 /Users/backup이 출력되고, -r 인자는 ls 명령어가 역순으로 화면에 출력하게 한다면, 어떤 명령어가 다음을 화면에 출력할까요? pnas_sub/ pnas_final/ original/ 1. `ls pwd` 2. `ls -r -F` 3. `ls -r -F /Users/backup` 4. 위 #2 혹은 #3, 하지만, #1은 아님. 해답풀이 1. No: pwd 는 디렉토리 명칭이 아님. 2. Yes: 디렉토리 인자가 없는 ls 명령어는 현재 디렉토리의 파일과 디렉토리를 화면에 출력함. 3. Yes: 절대 경로를 명시적으로 사용. 4. Correct: 상기 해설 참조. 2.4 Nelle 파이프라인: 파일 구성 파일과 디렉토리에 대해서 알았으니, Nelle은 단백질 분석기가 생성하는 파일을 구성할 준비를 마쳤다. 우선 north-pacific-gyre 디렉토리를 생성해서 데이터가 어디에서 왔는지를 상기하도록 한다. 2012-07-03 디렉토리를 생성해서 시료 처리를 시작한 날짜를 명기했다. Nelle은 conference-paper와 revised-results같은 이름을 사용하곤 했다. 하지만, 몇년이 지난 후에 이해하기 어렵다는 것을 발견했다. (마지막 지푸라기는 revised-revised-results-3 디렉토리를 본인이 생성했다는 것을 발견했을 때였다.) 출력결과 정렬 Nelle은 월과 일에 0을 앞에 붙여 디렉토리를 “년-월-일(year-month-day)” 방식으로 이름지었다. 왜냐하면 쉘이 알파벳 순으로 파일과 디렉토리 이름을 화면에 출력하기 때문이다. 만약 월이름을 사용한다면, 12월(December)이 7월(July) 앞에 위치할 것이다: 만약 앞에 0을 붙이지 않으면 11월이 7월 앞에 올 것이다. 각각의 물리적 시료는 “NENE01729A”처럼 10자리 중복되지 않는 ID로 연구실 관례에 따라 표식을 붙였다. 시료의 장소, 시간, 깊이, 그리고 다른 특징을 기록하기 위해서 수집 기록에 사용된 것과 동일하다. 그래서 이를 각 파일 이름으로 사용하기로 결정했다. 분석기 출력값이 텍스트 형식이기 때문에 NENE01729A.txt, NENE01812A.txt, … 같이 확장자를 붙였다. 총 1,520개 파일 모두 동일한 디렉토리에 저장되었다. 이제 data-shell 현재 작업 디렉토리에서 Nelle은 다음 명령어를 사용해서, 무슨 파일이 있는지 확인할 수 있다: $ ls north-pacific-gyre/2012-07-03/ 엄청나게 많은 타이핑이지만 탭 자동완성(tab completion)을 통해 쉘에게 많은 일을 시킬 수도 있다. 만약 다음과 같이 타이핑하고: $ ls nor 그리고 나서 탭(키보드에 탭 키)을 누르면, 자동으로 쉘이 디렉토리 이름을 자동완성 시켜준다: $ ls north-pacific-gyre/ 탭을 다시 누르면, Bash가 명령문에 2012-07-03/을 추가하는데, 왜냐하면 유일하게 가능한 자동완성조건이기 때문이다. 한번더 탭을 누려면 아무것도 수행하지 않는다. 왜냐하면 1520가지 경우의 수가 있기 때문이다; 탭을 두번 누르면 모든 파일 목록을 가져온다. 이것을 탭 자동완성(tab completion)이라고 부르고, 앞으로도 다른 많은 툴에서도 많이 볼 것이다. "],["shell-create.html", "3 . 파일과 디렉토리 작업 3.1 파일과 디렉토리를 위한 좋은 명칭 3.2 파일과 폴더 이동 3.3 다수 파일과 폴더 작업", " 3 . 파일과 디렉토리 작업 이제는 어떻게 파일과 디렉토리를 살펴보는지 알게 되었지만, 우선, 어떻게 파일과 디렉토리를 생성할 수 있을까요? 바탕화면(Desktop) data-shell 디렉토리로 돌아가서 ls -F 명령어를 사용하여 무엇을 담고 있는지 살펴봅시다: $ pwd /Users/nelle/Desktop/data-shell $ ls -F creatures/ data/ molecules/ north-pacific-gyre/ notes.txt pizza.cfg solar.pdf writing/ 명령어 mkdir thesis을 사용하여 새 디렉토리 thesis를 생성합시다 (출력되는 것은 아무것도 없습니다.): $ mkdir thesis 이름에서 유추를 할 수도, 하지 못할 수도 있지만, mkdir은 “make directory(디렉토리 생성하기)”를 의미한다. thesis는 상대 경로여서(즉, 앞에 슬래쉬가 없음), 새로운 디렉토리는 현재 작업 디렉토리 아래 만들어진다: $ ls -F creatures/ data/ molecules/ north-pacific-gyre/ notes.txt pizza.cfg solar.pdf thesis/ writing/ 동일한 작업을 수행하는 두가지 방법 쉘을 사용해서 디렉토리를 생성하는 것이나 파일 탐색기를 사용하는 것과 별반 차이가 없다. 운영체제 그래픽 파일 탐색기를 사용해서 현재 디렉토리를 열게 되면, thesis 디렉토리가 마찬가지로 나타난다. 파일과 상호작용하는 두가지 다른 방식이 존재하지만, 파일과 디렉토리는 동일하다. 3.1 파일과 디렉토리를 위한 좋은 명칭 명령라인으로 작업할 때, 복잡하고 어려운 파일과 디렉토리는 삶을 질을 현격히 저하시킨다. 다음에 파일 명칭에 대한 유용한 팁이 몇개 있다. 공백(whitespaces)을 사용하지 마라 공백은 이름을 의미있게 할 수도 있지만, 공백이 명령라인 인터페이스에서 인자를 구별하는데 사용되기에, 파일과 디렉토리 명에서는 피하는 것이 상책이다. 공백 대신에 - 혹은 _ 문자를 사용한다. 대쉬(-)로 명칭을 시작하지 않는다. 명령어가 -으로 시작되는 명칭을 선택옵션으로 처리하기 때문이다. 명칭에 문자, 숫자, . (마침표), - (대쉬) and _ (밑줄)을 고수한다. 명령라인 인터페이스에서 다른 많은 문자는 특별한 의미를 갖는다. 학습을 진행하면서 이들 중 일부를 배울 것이다. 일부 특수 문자는 명령어가 기대했던 대로 동작하지 못하게 하거나, 심한 경우 데이터 유실을 야기할 수도 있다. 공백을 포함하거나 알파벳이 아닌 문자를 갖는 파일명이나 디렉토리명을 굳이 지정할 필요가 있다면, 인용부호(\"\")로 파일명이나 디렉토리명을 감싸야 한다. thesis 디렉토리를 방금 생성했기에 내부에는 아무것도 없다: $ ls -F thesis cd 명령어를 사용하여 thesis로 작업 디렉토리를 변경하자. Nano 텍스트 편집기를 실행해서 draft.txt 파일을 생성하자: $ cd thesis $ nano draft.txt 어떤 편집기가 좋을까요? “nano가 텍스트 편집기다”라고 말할 때, 정말 “텍스트”만 의미한다. 즉, 일반 문자 데이터만 작업할 수 있고, 표, 이미지, 혹은 다른 형태의 인간 친화적 미디어는 작업할 수 없다. nano를 워크샵에서 사용하는데 이유는 거의 누구나 훈련없이 사용할 수 있기 때문이다. 하지만, 실제 작업에는 좀더 강력한 편집기 사용을 추천한다. 유닉스 시스템 계열(맥 OS X, 리눅스)에서 많은 프로그래머는 Emacs 혹은 Vim을 사용하거나, (둘다 완전히 비직관적이만, 심지어 유닉스 표준이기도 하다) 혹은 그래픽 편집기로 Gedit를 사용한다. 윈도우에서는 Notepad++를 사용하는 것도 좋다. 윈도우에는 메모장(notepad)이라고 불리는 자체 내장 편집기도 있는데 nano 편집기와 마찬가지로 명령라인에서 바로 불러 실행될 수 있다. 어떤 편집기를 사용하든, 파일을 검색하고 저장하는 것을 알 필요가 있다. 쉘에서 편집기를 시작하면, (아마도) 현재 작업 디렉토리가 디폴트 시작 위치가 된다. 컴퓨터 시작 메뉴에서 시작한다면, 대신에 바탕화면(Desktop) 혹은 문서 디렉토리에 파일을 저장하고 싶을지도 모른다. “다른 이름으로 저장하기(Save As …)”로 다른 디렉토리로 이동하여 작업 디렉토리를 변경하여 파일을 저장할 수도 있다. 텍스트 몇 줄을 타이핑하고, 컨트롤+O (Control-O, Ctrl 혹은 콘트롤 키보드를 누르면서 O 를 누름)를 눌러서 데이터를 디스크에 쓰면 저장된다: (저장하고자 하는 파일명을 입력하도록 독촉받게 되면 draft.txt 기본디폴트로 설정된 것을 받아들이고 엔터키를 친다.) Nano in Action 파일이 저장되면, 컨트롤+X (Ctrl-X, Control-X)를 사용하여 편집기를 끝내고 쉘로 돌아간다. Control, Ctrl, ^ Key 컨트롤 키를 줄여서 “Ctrl” 키라고도 부른다. 컨트롤 키를 기술하는 몇가지 방식이 있다. 예를 들어, “컨트롤 키를 누룬다”, “컨트롤 키를 누르면서 X 키를 친다”라는 표현은 다음 중 하나로 기술된다: Control-X Control+X Ctrl-X Ctrl+X ^X C-x nano 편집기에서 화면 하단에 ^G Get Help ^O WriteOut을 볼 수 있다. Control-G를 눌러 도움말을 얻고, Control-O를 눌러 파일을 저장한다는 의미를 갖는다. nano는 화면에 어떤 출력도 뿌려주지 않고 끝내지만, ls 명령어를 사용하여 draft.txt 파일이 생성된 것을 확인할 수 있다: $ ls draft.txt 파일을 생성하는 다른 방법 nano 편집기를 사용해서 텍스트 파일을 생성하는 방법을 살펴봤다. 홈 디렉토리에서 다음 명령어를 실행해 보자: $ cd # 홈 디렉토리로 이동하기 $ touch my_file.txt touch 명령어는 어떤 작업을 수행하는가? GUI 파일 탐색기를 사용해서 본인 홈 디렉토리를 살펴보게 되면, 파일이 생성된 것이 보이는가? ls -l 명령어를 사용해서 파일을 살펴보자. my_file.txt 파일은 얼마나 큰가? 이런 방식으로 파일을 언제 생성하면 좋을까? 실행결과 및 해석 touch 명령어가 홈 디렉토리에 ‘my_file.txt’ 파일을 새로 생성시킨다. 터미널로 현재 홈 디렉토리에 있는 경우, ls 를 타이핑하게 되면 새로 생성된 파일을 확인할 수 있다. GUI 파일 탐색기로도 ‘my_file.txt’ 파일을 볼 수 있다. ‘ls -l’ 명령어로 파일을 조사하게 되면, ‘my_file.txt’ 파일크기가 0kb 임에 주목한다. 다른 말로 표현하면, 데이터가 아무 것도 없다는 의미가 된다. 텍스트 편집기로 ‘my_file.txt’ 파일을 열게 되면, 텅 비어 있다. 일부 프로그램은 그 자체로 출력 파일을 생성하지 않지만, 빈 파일이 이미 생성되어 있는 것을 요구조건으로 하는 경우가 있다. 프로그램이 실행되면, 출력결과를 채울 수 있는 파일이 존재하는지 검색한다. 이런 프로그램에게 touch 명령어는 빈 텍스트 파일을 효율적으로 생성할 수 있는 메커니즘을 제공한다는 점에서 유용하다. data-shell 디렉토리로 돌아가서, 생성한 초안을 제거해서 thesis 디렉토리를 깔끔하게 정리하자: $ cd thesis $ rm draft.txt 상기 명령어는 파일을 제거한다(rm은 “remove”를 줄인 것이다.) ls 명령어를 다시 실행하게 되면, 출력결과는 아무 것도 없게 되는데 파일이 사라진 것을 확인시켜준다: $ ls 삭제는 영원하다 유닉스에는 삭제된 파일을 복구할 수 있는 휴지통이 없다. (하지만, 유닉스에 기반한 대부분의 그래픽 인터페이스는 휴지통 기능이 있다) 파일을 삭제하면 파일시스템의 관리대상에서 빠져서 디스트 저장공간이 다시 재사용되게 한다. 삭제된 파일을 찾아 되살리는 도구가 존재하지만, 어느 상황에서나 동작한다는 보장은 없다. 왜냐하면 파일이 저장되었던 공간을 컴퓨터가 바로 재사용할지 모르기 때문이다. 파일을 다시 생성하고 나서, cd ..를 사용하여 /Users/nelle/Desktop/data-shell 상위 디렉토리로 이동해보자: $ pwd /Users/nelle/Desktop/data-shell/thesis $ nano draft.txt $ ls draft.txt $ cd .. rm thesis을 사용하여 전체 thesis 디렉토리를 제거하려고 하면 오류 메시지가 생긴다: $ rm thesis rm: cannot remove `thesis&#39;: Is a directory rm 명령어는 파일에만 동작하고 디렉토리에는 동작하지 않기 때문에 오류가 발생한다. thesis 디렉토리를 제거하려면, draft.txt 파일도 삭제해야 한다. rm 명령어에 재귀(recursive) 선택옵션을 사용해서 삭제 작업을 수행할 수 있다: $ rm -r thesis rm 안전하게 사용하기 rm -i thesis/quotations.txt 타이핑하면 무슨 일이 일어날까? rm 명령어를 사용할 때 왜 이러한 보호장치가 필요할까? $ rm: remove regular file &#39;thesis/quotations.txt&#39;? -i 선택옵션은 삭제하기 전에 삭제를 확인하게 해준다. 유닉스 쉘에는 휴지통이 없어서, 삭제되는 모든 파일은 영원히 사라진다. -i 플래그를 사용하게 되면, 삭제를 원하는 파일만 삭제되는지 점검할 수 있는 기회를 갖게된다. 큰 힘에는 큰 책임이 따른다(With Great Power Comes Great Responsibility) 디렉토리에 먼저 파일을 제거하고, 그리고 나서 디렉토리를 제거하는 방식은 지루하고 시간이 많이 걸린다. 대신에 -r 옵션을 가진 rm 명령어를 사용할 수 있다. -r 플래그 옵션은 “recursive(재귀적)”을 나타낸다. $ rm -r thesis 디렉토리에 모든 것을 삭제하고 나서 디렉토리 자체도 삭제한다. 만약 디렉토리가 하위 디렉토리를 가지고 있다면, rm -r은 하위 디렉토리에도 같은 작업을 반복한다. 매우 편리하지만, 부주위하게 사용되면 피해가 엄청날 수 있다. 디렉톨리 파일을 재귀적으로 제거하는 것은 매우 위험할 수 있다. 삭제되는 것에 염려가 된다면, rm 명령어에 -i 인터랙티브 플래그를 추가해서 삭제단계마다 확인을 하고 삭제하는 것도 가능하다. $ rm -r -i thesis rm: descend into directory ‘thesis’? y rm: remove regular file ‘thesis/draft.txt’? y rm: remove directory ‘thesis’? y 상기 명령어는 thesis 디렉토리 내부 모든 것을 삭제하고 나서 thesis 디렉토리도 삭제하는데 삭제단계별로 확인 절차를 거친다. 다시 한번 디렉토리와 파일을 생성하자. 이번에는 thesis/draft.txt 파일경로로 바로 nano를 실행함을 주목하자. 이전에는 thesis디렉토리로 가서 draft.txt이름으로 nano를 실행했다. $ pwd /Users/nelle/Desktop/data-shell $ mkdir thesis $ nano thesis/draft.txt $ ls thesis draft.txt 3.2 파일과 폴더 이동 draft.txt가 특별한 정보를 제공하는 이름이 아니어서 mv를 사용하여 파일 이름을 변경하자. mv는 “move”의 줄임말이다: $ mv thesis/draft.txt thesis/quotes.txt 첫번째 매개변수는 mv 명령어에게 이동하려는 대상을, 두번째 매개변수는 어디로 이동되는지를 나타낸다. 이번 경우에는 thesis/draft.txt 파일을 thesis/quotes.txt으로 이동한다. 이렇게 파일을 이동하는 것이 파일 이름을 바꾸는 것과 동일한 효과를 가진다. 아니나 다를까, ls 명령어를 사용하여 확인하면 thesis 디렉토리에는 이제 quotes.txt 파일만 있음을 확인할 수 있다: $ ls thesis quotes.txt 목표 파일명을 명세할 때 주의를 기울일 필요가 있다. 왜냐하면, mv 명령어는 동일 명칭을 갖는 어떤 기존 파일도 아주 조용히 덮어 써버리는 재주가 있어 데이터 유실에 이르게 된다. 부가적인 옵션 플래그, mv -i (즉 mv --interactive)를 사용해서 덮어쓰기 전에 사용자가 확인하도록 mv 명령어를 활용할 수도 있다. 일관성을 갖고 있어서, mv는 디렉토리에도 동작한다 — 별도 mvdir 명령어는 없다. quotes.txt 파일을 현재 작업 디렉토리로 이동합시다. mv를 다시 사용한다. 하지만 이번에는 두번째 매개변수로 디렉토리 이름을 사용해서 파일이름을 바꾸지 않고, 새로운 장소에 놓는다. (이것이 왜 명령어가 “move(이동)”으로 불리는 이유다.) 이번 경우에 사용되는 디렉토리 이름은 앞에서 언급한 특수 디렉토리 이름 . 이다. $ mv thesis/quotes.txt . 과거에 있던 디렉토리에서 파일을 현재 작업 디렉토리로 옮긴 효과가 나타난다. ls 명령어가 thesis 디렉토리가 비였음을 보여준다: $ ls thesis 더 나아가, ls 명령어를 인자로 파일 이름 혹은 디렉토리 이름과 함께 사용하면, 그 해당 파일 혹은 디렉토리만 화면에 보여준다. 이렇게 사용하면, quotes.txt 파일이 현재 작업 디렉토리에 있음을 볼 수 있다: $ ls quotes.txt quotes.txt 현재 폴더로 이동하기 다음 명령어를 실행한 후에, 정훈이는 sucrose.dat, maltose.dat 파일을 잘못된 폴더에 넣은 것을 인지하게 되었다: $ ls -F analyzed/ raw/ $ ls -F analyzed fructose.dat glucose.dat maltose.dat sucrose.dat $ cd raw/ 해당 파일을 현재 디렉토리(즉, 현재 사용자가 위치한 폴더)로 이동시키도록 아래 빈칸을 채우시오: $ mv ___/sucrose.dat ___/maltose.dat ___ $ mv ../analyzed/sucrose.dat ../analyzed/maltose.dat . .. 디렉토리는 부모 디렉토리(즉, 현재 디렉토리에서 상위 디렉토리를 지칭) . 디렉토리는 현재 디렉토리를 지칭함을 상기한다. cp 명령어는 mv 명령어와 거의 동일하게 동작한다. 차이점은 이동하는 대신에 복사한다는 점이다. 인자로 경로를 두개 갖는 ls 명령어로 제대로 작업을 했는지 확인할 수 있다. 대부분의 유닉스 명령어와 마찬가지로, ls 명령어로 한번 경로 다수를 전달할 수도 있다: $ cp quotes.txt thesis/quotations.txt $ ls quotes.txt thesis/quotations.txt quotes.txt thesis/quotations.txt 복사를 제대로 수행했는지 증명하기 위해서, 현재 작업 디렉토리에 있는 quotes.txt 파일을 삭제하고 나서, 다시 동일한 ls 명령어를 실행한다. $ rm quotes.txt $ ls quotes.txt thesis/quotations.txt ls: cannot access quotes.txt: No such file or directory thesis/quotations.txt 이번에는 현재 디렉토리에서 quotes.txt 파일은 찾을 수 없지만, 삭제하지 않은 thesis 폴더의 복사본은 찾아서 보여준다. 파일명이 뭐가 중요해? Nelle의 파일 이름이 “무엇.무엇”으로 된 것을 알아챘을 것이다. 이번 학습에서, 항상 .txt 확장자를 사용했다. 이것은 단지 관례다: 파일 이름을 mythesis 혹은 원하는 무엇이든지 작명할 수 있다. 하지만, 대부분의 사람들은 두 부분으로 구분된 이름을 사용하여 사람이나 프로그램이 다른 유형의 파일임을 구분하도록 돕는다. 이름에 나온 두번째 부분을 파일 확장자(filename extension)라고 부르고, 파일에 어떤 유형의 데이터가 담고 있는지 나타낸다. .txt 확장자는 텍스트 파일임을, .pdf는 PDF 문서임을, .cfg 확장자는 어떤 프로그램에 대한 구성정보를 담고 있는 형상관리 파일임을 내고, .png 확장자는 PNG 이미지 등등을 나타낸다. 단지 관습이기는 하지만 중요하다. 파일은 바이트(byte) 정보를 담고 있다: PDF 문서, 이미지, 등에 대해서 규칙에 따라 바이트를 해석하는 것은 사람과 작성된 프로그램에 맡겨졌다. whale.mp3처럼 고래 PNG 이미지 이름을 갖는 파일을 고래 노래의 음성파일로 변환하는 마술은 없다. 설사 누군가 두번 클릭할 때, 운영체제가 음악 재생기로 열어 실행할 수는 있지만 동작은 되지 않을 것이다. 파일 이름 바꾸기 데이터를 분석하는데 필요한 통계 검정 목록을 담고 있는 .txt 파일을 현재 디렉토리에 생성했다고 가정하자; 파일명은 statstics.txt. 파일을 생성하고 저장한 후에 곰곰히 생각해 보니 파일명 철자가 틀린 것을 알게 되었다! 틀린 철자를 바로잡고자 하는데, 다음 중 어떤 명령어를 사용해야 하는가? 1. cp statstics.txt statistics.txt 2. mv statstics.txt statistics.txt 3. mv statstics.txt . 4. cp statstics.txt . 해답 1. No. 철자오류가 수정된 파일이 생성되지만, 철자가 틀린 파일도 디렉토리에 여전히 존재하기 때문에 삭제작업이 필요하다. 2. Yes, 이 명령어를 통해서 파일명을 고칠 수 있다. 3. No, 마침표(.)는 파일을 이동할 디렉토리를 나타내지 새로운 파일명을 제시하고 있지는 않고 있다; 동일한 파일명은 생성될 수 없다. 4. No, 마침표(.)는 파일을 복사할 디렉토리를 나타내지 새로운 파일명을 제시하고 있지는 않고 있다; 동일한 파일명은 생성될 수 없다. 이동과 복사 아래 보여진 일련의 명령문에 뒤에 ls명령어의 출력값은 무엇일까요? $ pwd /Users/jamie/data $ ls proteins.dat $ mkdir recombine $ mv proteins.dat recombine/ $ cp recombine/proteins.dat ../proteins-saved.dat $ ls proteins-saved.dat recombine recombine proteins.dat recombine proteins-saved.dat 해답 /Users/jamie/data 디렉토리에서 출발해서, recombine 이름의 디렉토리를 새로 생성한다. 두번째 행은 proteins.dat 파일을 새로 만든 폴더 recombine으로 이동(mv) 시킨다. 세번째 행은 방금전에 이동한 파일에 대한 사본을 생성시킨다. 여기서 조금 까다로운 점은 파일이 복사되는 디렉토리다. .. 이 의미하는 바가 “한단계 위로 이동”하라는 의미라서, 복사되는 파일은 이제 /Users/jamie 디렉토리에 위치하게 됨을 상기한다. .. 이 의미하는 바는 복사되는 파일 위치에 대한 것이 아니라 현재 작업 디렉토리에 대한 것으로 해석됨에 유의한다. 그래서, 그래서, ls 명령어를 사용해서 보여지게 되는 것은 (/Users/jamie/data에 있기 때문에) recombine 폴더가 된다. No, 상기 해설을 참조한다. proteins-saved.dat 데이터는 /Users/jamie 폴더에 위치한다. Yes No, 상기 해설을 참조한다. proteins.dat 데이터는 /Users/jamie/data/recombine 폴더에 위치한다. No, 상기 해설을 참조한다. proteins-saved.dat 데이터는 /Users/jamie 폴더에 위치한다. 3.3 다수 파일과 폴더 작업 다수 파일을 복사하기 이번 연습문제에서는 data-shell/data 디렉토리에서 명령어를 테스트한다. 아래 예제에서, 파일명 다수와 디렉토리명이 주어졌을 떄 cp 명령어는 어떤 작업을 수행하는가? $ mkdir backup $ cp amino-acids.txt animals.txt backup/ 아래 예제에서, 3개 혹은 그 이상의 파일명이 주어졌을 때 cp 명령어는 어떤 작업을 수행하는가? $ ls -F amino-acids.txt animals.txt backup/ elements/ morse.txt pdb/ planets.txt salmon.txt sunspot.txt $ cp amino-acids.txt animals.txt morse.txt 해답 하나이상 파일명 다음에 디렉토리명이 주어지게 되면(즉, 목적지 디렉토리는 마지막 인자에 위치해야 한다.), cp 명령어는 파일을 해당 디렉토리에 복사한다. 연달아 파일명이 세게 주어지면, cp 명령어는 오류를 던지는데 이유는 마지막 인자로 디렉토리를 기대했기 때문이다. cp: target ‘morse.txt’ is not a directory 와일드 카드(Wildcards) *는 와일드카드(wildcard)다. 와일드카드는 0 혹은 그 이상의 문자와 매칭되서, *.pdb은 ethane.pdb, propane.pdb 등등에 매칭한다. 반면에, p*.pdb은 propane.pdb와 pentane.pdb만 매칭하는데, 맨 앞에 ’p’로 시작되는 파일명만 일치하기만 하면 되기 때문이다. ?도 또한 와일드카드지만 단지 단일 문자만 매칭한다. 이것이 의미하는 바는 p?.pdb은 pi.pdb 혹은 p5.pdb을 매칭하지만 (molecules 디렉토리에 두 파일이 있다면), propane.pdb은 매칭하지 않는다. 한번에 원하는 수만큼 와일드카드를 사용할 수 있다. 예를 들어, p*.p?*는 ‘p’로 시작하고’.’과 ‘p’, 그리고 최소 한자의 이상의 문자로 끝나는 임의의 문자열을 매칭한다고 표현할 수 있는데 ‘?’이 한 문자를 매칭해야하고 마지막’*‘은 끝에 임의의 문자숫자와 매칭할 수 있기 때문이다. 그래서 p*.p?*은 preferred.practice과 심지어 p.pi도 매칭한다(첫번째’*‘은 어떤 문자도 매칭할 수가 없음). 하지만 quality.practice은 매칭할 수 없는데 이유는 ’p’로 시작하지 않고, preferred.p도 매칭할 수 없는데 ’p’ 다음에 최소 하나의 문자가 필요한데 없기 때문이다. 쉘이 와일드카드를 봤을 때, 요청된 명령문을 시작하기 전에 와일드카드를 확장하여 매칭할 파일 이름 목록을 생성한다. 예외로, 와일드카드 표현식이 어떤 파일과도 매칭되지 않게되면, 배수는 명령어에 인자로 표현식을 있는 그대로 전달한다. 예를 들어, molecules 디렉토리(.pdb 확장자로 끝나는 파일만 모여있다.)에 ls *.pdf을 타이핑하게 되면, *.pdf으로 불리는 파일이 없다고 오류 메시지를 출력한다. 하지만, 일반적으로 wc과 ls 명령어는 와일드카드 표현식과 매칭되는 파일명 목록을 보게 되고 와일드카드 자체가 아니다. 다른 프로그램은 아니지만, 쉘은 와일드카드를 확장한 것을 다룬다는 점에서 직교 설계(orthogonal design)의 또 다른 사례로 볼 수 있다. 와일드카드 추가 문제 정훈이는 미세조정(calibration), 원본 데이터(dataset), 데이터 설명 데이터를 디렉토리에 보관하고 있다: 2015-10-23-calibration.txt 2015-10-23-dataset1.txt 2015-10-23-dataset2.txt 2015-10-23-dataset_overview.txt 2015-10-26-calibration.txt 2015-10-26-dataset1.txt 2015-10-26-dataset2.txt 2015-10-26-dataset_overview.txt 2015-11-23-calibration.txt 2015-11-23-dataset1.txt 2015-11-23-dataset2.txt 2015-11-23-dataset_overview.txt 또 다른 견학여행을 떠나기 전에, 정훈이는 데이터를 백업하고 일부 데이터를 랩실 동료 기민에게 보내고자 한다. 정훈이는 백업과 전송 작업을 위해서 다음 명령어를 사용한다: $ cp *dataset* /backup/datasets $ cp ____calibration____ /backup/calibration $ cp 2015-____-____ ~/send_to_bob/all_november_files/ $ cp ____ ~/send_to_bob/all_datasets_created_on_a_23rd/ 정훈이가 빈칸을 채우도록 도움을 주세요. &gt; 해답 &gt; &gt; &gt; $ cp *calibration.txt /backup/calibration &gt; $ cp 2015-11-* ~/send_to_bob/all_november_files/ &gt; $ cp *-23-dataset* ~send_to_bob/all_datasets_created_on_a_23rd/ &gt; 디렉토리와 파일 조직화 정훈이가 프로젝트 작업을 하고 있는데, 작업 파일이 그다지 잘 조직적으로 정리되어 있지 않음을 알게 되었다: $ ls -F analyzed/ fructose.dat raw/ sucrose.dat fructose.dat 와 sucrose.dat 파일은 자료분석 결과 산출된 출력결과를 담고 있다. 이번 학습에서 배운 어떤 명령어를 실행해야, 아래 명령어를 실행했을 때 다음에 보여지는 출력을 생성할까요? $ ls -F analyzed/ raw/ $ ls analyzed fructose.dat sucrose.dat 해답 mv *.dat analyzed 정훈이는 analyzed 디렉토리에 fructose.dat, sucrose.dat 파일을 이동시킬 필요가 있다. 쉘에서 현재 디렉토리에서 *.dat 와일드카드가 .dat 확장자를 갖는 모든 파일을 매칭한다. mv 명령어가 .dat 확장자를 갖는 파일을 analyzed 디렉토리로 이동시킨다. 폴더 구조를 복사하지만, 파일을 복사하지 말자. 새로운 실험을 시작해 보자. 데이터 파일 없이 이전 실험에게 만들었던 파일 구조만 복제하자. 그렇게 하면 새로운 데이터를 쉽게 추가할 수 있게 된다. ‘2016-05-18-data’ 디렉토리에 data 폴더로 raw와 processed가 있는데, 각자 데이터 파일이 담겨있다. 목적은 2016-05-18-data 폴더를 2016-05-20-data 폴더로 복사하는 것인데 복사된 폴더에는 모든 데이터 파일을 제거해야 된다. 다음 명령어 집합 중 어떤 명령어 집합이 상기 목적을 달성할까요? 다른 명령어 집합은 무슨 작업을 수행하는 것일가? $ cp -r 2016-05-18-data/ 2016-05-20-data/ $ rm 2016-05-20-data/raw/* $ rm 2016-05-20-data/processed/* $ rm 2016-05-20-data/raw/* $ rm 2016-05-20-data/processed/* $ cp -r 2016-05-18-data/ 2016-5-20-data/ $ cp -r 2016-05-18-data/ 2016-05-20-data/ $ rm -r -i 2016-05-20-data/ 해답 첫번째 명령어들이 해당 목적을 달성한다. 먼저 재귀적으로 데이터 폴더를 복사한다. 그리고 나서 rm 명령어 두번 사용해서 복사한 디렉토리의 모든 파일을 제거한다. 쉘은 * 와일드카드로 매칭되는 모든 파일과 하위디렉토리를 확장하도록 한다. 두번째 명령어들은 순서가 잘못되었다: 복사하지 않는 파일을 샂게하고 나서 재귀 복사 명령어로 디렉토리를 복사했다. 세번째 명령어도 목적을 달성하는데, 시간이 다소 소요된다: 첫번째 명령어가 디렉토리를 재귀적으로 복사하지만, 두번째 명령어는 인터랙티브하게 각 파일과 디렉토리에 대한 확인하는 과정을 거쳐 삭제를 하게 되어 시간이 추가로 소요된다. "],["pipe-filter.html", "4 . 파이프와 필터 4.1 Nelle 파이프라인: 파일 확인하기", " 4 . 파이프와 필터 몇가지 기초 유닉스 명령어를 배웠기 때문에, 마침내 쉘의 가장 강령한 기능을 살펴볼 수 있게 되었다: 새로운 방식으로 기존에 존재하던 프로그램을 쉽게 조합해 낼 수 있게 한다. 간단한 유기분자 설명을 하는 6개 파일을 담고 있는 molecules(분자)라는 디렉토리에서 시작한다. .pdb 파일 확장자는 단백질 데이터 은행 (Protein Data Bank) 형식으로, 분자의 각 원자 형식과 위치를 표시하는 간단한 텍스트 형식으로 되어 있다. $ ls molecules cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb 명령어 cd로 해당 디렉토리로 가서 wc *.pdb 명령어를 실행한다. wc 명령어는 “word count”의 축약어로 파일의 라인 수, 단어수, 문자수를 개수한다. (왼쪽에서 오른쪽 순서로) *.pdb에서 *은 0 혹은 더 많이 일치하는 문자를 매칭한다. 그래서 쉘은 *.pdb을 통해 .pdb 전체 리스트 목록을 반환한다: $ cd molecules $ wc *.pdb 20 156 1158 cubane.pdb 12 84 622 ethane.pdb 9 57 422 methane.pdb 30 246 1828 octane.pdb 21 165 1226 pentane.pdb 15 111 825 propane.pdb 107 819 6081 total wc 대신에 wc -l을 실행하면, 출력결과는 파일마다 행수만을 보여준다: $ wc -l *.pdb 20 cubane.pdb 12 ethane.pdb 9 methane.pdb 30 octane.pdb 21 pentane.pdb 15 propane.pdb 107 total 단어 숫자만을 얻기 위해서 -w, 문자 숫자만을 얻기 위해서 -c을 사용할 수 있다. 파일 중에서 어느 파일이 가장 짧을까요? 단지 6개의 파일이 있기 때문에 질문에 답하기는 쉬울 것이다. 하지만 만약에 6000 파일이 있다면 어떨까요? 해결에 이르는 첫번째 단계로 다음 명령을 실행한다: $ wc -l *.pdb &gt; lengths.txt &gt; 기호는 쉘로 하여금 화면에 처리 결과를 뿌리는 대신에 파일로 방향변경(redirect)하게 한다. 만약 파일이 존재하지 않으면 파일을 생성하고 파일이 존재하면 파일에 내용을 덮어쓰기 한다. 조용하게 덮어쓰기 하기 때문에 자료가 유실될 수 있어서 주의가 요구된다. (이것이 왜 화면에 출력결과가 없는 이유다. wc가 출력하는 모든 것은 lengths.txt 파일에 대신 들어간다.) ls lengths.txt 을 통해 파일이 존재하는 것을 확인한다: $ ls lengths.txt lengths.txt cat lengths.txt을 사용해서 화면으로 lengths.txt의 내용을 보낼 수 있다. cat은 “concatenate”를 줄인 것이고 하나씩 하나씩 파일의 내용을 출력한다. 이번 사례에는 단지 파일이 하나만 있어서, cat 명령어는 단지 한 파일이 담고 있는 내용만 보여준다: $ cat lengths.txt 20 cubane.pdb 12 ethane.pdb 9 methane.pdb 30 octane.pdb 21 pentane.pdb 15 propane.pdb 107 total 페이지 단위 출력결과 살펴보기 이번 학습에서 편리성과 일관성을 위해서 cat 명령어를 계속 사용한다. 하지만, 파일 전체를 화면에 쭉 뿌린다는 면에서 단점이 있다. 실무적으로 less 명령어가 더 유용한데 $ less lengths.txt와 같이 사용한다. 파일을 화면 단위로 출력한다. 아래로 내려가려면 스페이스바를 누르고, 뒤로 돌아가려면 b를 누르면 되고, 빠져 나가려면 q를 누른다. 이제 sort 명령어를 사용해서 파일 내용을 정렬합니다. sort -n 명령어는 어떤 작업을 수행할까? 다음 파일 행을 포함하고 있는 파일에 sort 명령어를 실행하면: 10 2 19 22 6 출력결과는 다음과 같다: 10 19 2 22 6 동일한 입력에 대해서 sort -n을 실행하면, 대신에 다음 결과를 얻게 된다: 2 6 10 19 22 인수 -n이 왜 이런 효과를 가지는지 설명하세요. 해답 -n 플래그는 알파벳 정렬이 아닌, 숫자 정렬하도록 명세한다. -n 플래그를 사용해서 알파벳 대신에 숫자 방식으로 정렬할 것을 지정할 수 있다. 이 명령어는 파일 자체를 변경하지 않고 대신에 정렬된 결과를 화면으로 보낸다: $ sort -n lengths.txt 9 methane.pdb 12 ethane.pdb 15 propane.pdb 20 cubane.pdb 21 pentane.pdb 30 octane.pdb 107 total &gt; lengths.txt을 사용해서 wc 실행결과를 lengths.txt에 넣었듯이, 명령문 다음에 &gt; sorted-lengths.txt을 넣음으로서, 임시 파일이름인 sorted-lengths.txt에 정렬된 목록 정보를 담을 수 있다. 이것을 실행한 다음에, 또 다른 head 명령어를 실행해서 sorted-lengths.txt에서 첫 몇 행을 뽑아낼 수 있다: $ sort -n lengths.txt &gt; sorted-lengths.txt $ head -n 1 sorted-lengths.txt 9 methane.pdb head에 -n 1 매개변수를 사용해서 파일의 첫번째 행만이 필요하다고 지정한다. -n 20은 처음 20개 행만을 지정한다. sorted-lengths.txt이 가장 작은 것에서부터 큰 것으로 정렬된 파일 길이 정보를 담고 있어서, head의 출력 결과는 가장 짧은 행을 가진 파일이 되어야만 된다. 동일한 파일에 방향변경하기 명령어 출력결과를 방향변경하는데 동일한 파일에 보내는 것은 매우 나쁜 아이디어다. 예를 들어: $ sort -n lengths.txt &gt; lengths.txt 위와 같이 작업하게 되면 틀린 결과를 얻을 수 있을 뿐만 아니라 경우에 따라서는 lengths.txt 파일 내용을 잃어버릴 수도 있다. &gt;&gt;은 무엇을 의미하는가? &gt; 사용법을 살펴봤지만, 유사한 연산자로 &gt;&gt;도 있는데 다소 다른 방식으로 동작한다. 문자열을 출력하는 echo 명령어를 사용해서, 두 연산자 차이를 밝혀내는데 아래 명령어를 테스트 한다: $ echo hello &gt; testfile01.txt $ echo hello &gt;&gt; testfile02.txt 힌트: 각 명령문을 연속해서 두번 실행하고 나서, 출력결과로 나온 파일을 면밀히 조사한다. &gt; 해답 &gt; &gt; &gt; 연산자를 갖는 첫번째 예제에서 문자열 “hello”는 testfile01.txt 파일에 저장된다. &gt; 하지만, 매번 명령어를 실행할 때마다 파일에 덮어쓰기를 한다. &gt; &gt; 두번째 예제에서 &gt;&gt; 연산자도 마찬가지로 “hello”를 파일에 저장(이 경우 testfile02.txt)하는 것을 알 수 있다. &gt; We see from the second example that the &gt;&gt; operator also writes “hello” to a file &gt; 하지만, 파일이 이미 존재하는 경우(즉, 두번째 명령어를 실행하게 되면) 파일에 문자열을 덧붙인다. {: .solution} 데이터 덧붙이기 head 명령어는 이미 만나봤다. 파일 시작하는 몇줄을 화면에 출력하는 역할을 수행한다. tail 명령어도 유사하지만, 반대로 파일 마지막 몇줄을 화면에 출력하는 역할을 수행한다. data-shell/data/animals.txt 파일을 생각해 보자. 다음 명령어를 실행하게 되면 animalsUpd.txt 파일에 저장될 내용이 어떤 것일지 아래에서 정답을 고르세요: $ head -n 3 animals.txt &gt; animalsUpd.txt $ tail -n 2 animals.txt &gt;&gt; animalsUpd.txt animals.txt 파일 첫 3줄. animals.txt 파일 마지막 2줄. animals.txt 파일의 첫 3줄과 마지막 2줄. animals.txt 파일의 두번째 세번째 줄. 해답 정답은 3. 1번이 정답이 되려면, head 명령어만 실행한다. 2번이 정답이 되려면, tail 명령어만 실행한다. 4번이 정답이 되려면, head -3 animals.txt | tail -2 &gt;&gt; animalsUpd.txt 명령어를 실행해서 head 출력결과를 파이프에 넣어 tail -2를 실행해야 한다. 이것이 혼란스럽다면, 좋은 친구네요: wc, sort, head 명령어 각각이 무엇을 수행하는지 이해해도, 중간에 산출되는 파일에 무슨 일이 진행되고 있는지 따라가기는 쉽지 않다. sort와 head을 함께 실행해서 이해하기 훨씬 쉽게 만들 수 있다: $ sort -n lengths.txt | head -n 1 9 methane.pdb 두 명령문 사이의 수직 막대를 파이프(pipe)라고 부른다. 수직막대는 쉘에게 왼편 명령문의 출력결과를 오른쪽 명령문의 입력값으로 사용된다는 뜻을 전달한다. 컴퓨터는 필요하면 임시 파일을 생성하거나, 한 프로그램에서 주기억장치의 다른 프로그램으로 데이터를 복사하거나, 혹은 완전히 다른 작업을 수행할 수도 있다; 사용자는 알 필요도 없고 관심을 가질 이유도 없다. 어떤 것도 파이프를 연속적으로 사슬로 엮어 사용하는 것을 막을 수는 없다. 즉, 예를 들어 또 다른 파이프를 사용해서 wc의 출력결과를 sort에 바로 보내고 나서, 다시 처리 결과를 head에 보낸다. wc 출력결과를 sort로 보내는데 파이프를 사용했다: $ wc -l *.pdb | sort -n 9 methane.pdb 12 ethane.pdb 15 propane.pdb 20 cubane.pdb 21 pentane.pdb 30 octane.pdb 107 total 또 다른 파이프를 사용해서 wc의 출력결과를 sort에 바로 보내고 나서, 다시 처리 결과를 head로 보내게 되면 전체 파이프라인은 다음과 같이 된다: $ wc -l *.pdb | sort -n | head -n 1 9 methane.pdb 이것이 정확하게 수학자가 log(3x) 같은 중첩함수를 사용하는 것과 같다. “log(3x)은 x에 3을 곱하고 로그를 취하는 것과 같다.” 이번 경우는, *.pdb의 행수를 세어서 정렬해서 첫부분만 계산하는 것이 된다. 명령문을 파이프로 연결하기 현재 작업 디렉토리에, 최소 행수를 갖는 파일을 세개 찾고자 한다. 아래 열거된 어떤 명령어 중 어떤 것이 원하는 파일 3개를 찾아줄까? wc -l * &gt; sort -n &gt; head -n 3 wc -l * | sort -n | head -n 1-3 wc -l * | head -n 3 | sort -n wc -l * | sort -n | head -n 3 해답 해답은 4. 파이프 문자 |을 사용해서 이 프로세스 표준출력을 다른 프로세스 표준입력으로 넣어준다. &gt; 기호는 표준입력을 파일로 방향변경할 때 사용한다. data-shell/molecules 디렉토리에서도 시도해 보라! 파이프를 생성할 때 뒤에서 실질적으로 일어나는 일은 다음과 같다. 컴퓨터가 한 프로그램(어떤 프로그램도 동일)을 실행할 때 프로그램에 대한 소프트웨어와 현재 상태 정보를 담기 위해서 주기억장치 메모리에 프로세스(process)를 생성한다. 모든 프로세스는 표준 입력(standard input)이라는 입력 채널을 가지고 있다. (여기서 이름이 너무 기억하기 좋아서 놀랄지도 모른다. 하지만 걱정하지 마세요. 대부분의 유닉스 프로그래머는 “stdin”이라고 부른다). 또한 모든 프로세스는 표준 출력(standard output)(혹은 “stdout”)이라고 불리는 기본디폴트 출력 채널도 있다. 이 채널이 일반적으로 오류 혹은 진단 메시지 용도로 사용되어서 터미널로 오류 메시지를 받으면서도 그 와중에 프로그램 출력값이 또다른 프로그램에 파이프되어 들어가는 것이 가능하게 한다. 쉘은 실질적으로 또다른 프로그램이다. 정상적인 상황에서 사용자가 키보드로 무엇을 타이핑하는 모든 것은 표준 입력으로 쉘에 보내지고, 표준 출력에서 만들어지는 무엇이든지 화면에 출력된다. 쉘에게 프로그램을 실행하게 할때, 새로운 프로게스를 생성하고, 임시로 키보드에 타이핑하는 무엇이든지 그 프로세스의 표준 입력으로 보내지고, 프로세스는 표준 출력을 무엇이든 화면에 전송한다. wc -l *.pdb &gt; lengths을 실행할 때 여기서 일어나는 것을 설명하면 다음과 같다. wc 프로그램을 실행할 새로운 프로세스를 생성하라고 쉘이 컴퓨터에 지시한다. 파일이름을 인자로 제공했기 때문에 표준입력 대신 wc는 인자에서 입력값을 읽어온다. &gt;을 사용해서 출력값을 파일로 방향변경 했기했기 때문에, 쉘은 프로세스의 표준 출력결과를 파일에 연결한다. wc -l *.pdb | sort -n을 실행한다면, 쉘은 프로세스 두개를 생성한다. (파이프 프로세스 각각에 대해서 하나씩) 그래서 wc과 sort은 동시에 실행된다. wc의 표준출력은 직접적으로 sort의 표준 입력으로 들어간다; &gt;같은 방향변경이 없기 때문에 sort의 출력은 화면으로 나가게 된다. wc -l *.pdb | sort -n | head -1을 실행하면, 파일에서 wc에서 sort로, sort에서 head을 통해 화면으로 나가게 되는 데이터 흐름을 가진 프로세스 3개가 있게 된다. 방향변경과 파이프 이 간단한 아이디어가 왜 유닉스가 그토록 성공적이었는지를 보여준다. 다른 많은 작업을 수행하는 거대한 프로그램을 생성하는 대신에, 유닉스 프로그래머는 각자가 한가지 작업만을 잘 수행하는 간단한 도구를 많이 생성하는데 집중하고, 서로간에 유기적으로 잘 작동하게 만든다. 이러한 프로그래밍 모델을 파이프와 필터(pipes and filters)라고 부른다; 파이프는 이미 살펴봤고, 필터(filter)는 wc, sort같은 프로그램으로 입력 스트림을 출력 스트림으로 변환하는 것이다. 거의 모든 표준 유닉스 도구는 이런 방식으로 동작한다: 별도로 언급되지 않는다면, 표준 입력에서 읽고, 읽은 것을 가지고 무언가를 수행하고 표준출력에 쓴다. 중요한 점은 표준입력에서 텍스트 행을 읽고, 표준 출력에 텍스트 행을 쓰는 임의 프로그램은 이런 방식으로 동작하는 모든 다른 프로그램과 조합될 수 있다는 것이다. 여러분도 여러분이 작성한 프로그램을 이러한 방식으로 작성할 수 있어야 하고 작성해야 한다. 그래서 여러분과 다른 사람들이 이러한 프로그램을 파이프에 넣어서 생태계 전체 힘을 배가할 수 있다. 입력 방향변경 프로그램의 출력 결과 방향변경을 위해서 &gt;을 사용하는 것과 마찬가지로, &lt;을 사용해서 입력을 되돌릴 수도 있다. 즉, 표준입력 대신에 파일로부터 읽어 들일 수 있다. 예를 들어, wc ammonia.pdb 와 같이 작성하는 대신에, wc &lt; ammonia.pdb 작성할 수 있다. 첫째 사례는, wc는 무슨 파일을 여는지를 명령 라인의 매개변수에서 얻는다. 두번째 사례는, wc에 명령 라인 매개변수가 없다. 그래서 표준 입력에서 읽지만, 쉘에게 ammonia.pdb의 내용을 wc에 표준 입력으로 보내라고 했다. &lt; 기호이 의미하는 것은 무엇인가? (다운로드 예제 데이터를 갖고 있는 최상위) data-shell 디렉토리로 작업 디렉토리를 변경한다. 다음 두 명령어 차이는 무엇인가? $ wc -l notes.txt $ wc -l &lt; notes.txt 해답 &lt; 기호는 입력을 방향변경을 해서 명령어로 전달한다. 상기 예제 모두에서, 쉘은 입력에서 wc 명령어를 통해 행수를 반환한다. 첫번째 예제에서, 입력은 notes.txt 파일이고, 파일명이 wc 명령어로부터 출력으로 주어지게 된다. 두번째 예제로부터, notes.txt 파일 내용이 표준입력으로 방향변경을 통해 보내지게 된다. 이것은 마치 프롬프트에서 파일 콘텐츠를 타이핑하는 것과 같다. 따라서, 파일명이 출력에 주어지지 않는다 - 단지 행번호만 주어진다. 다음과 같이 타이핑해보자: $ wc -l this is a test Ctrl-D # Ctrl-D를 타이핑하게 되면 쉘이 입력을 마무리한 것을 알게 전달하는 역할을 한다. 3 ``` uniq가 왜 인접한 중복 행만을 단지 제거한다고 생각합니까? 명령문 uniq는 입력으로부터 인접한 중복된 행을 제거한다. 예를 들어, salmon.txt 파일에 다음이 포함되었다면, coho coho steelhead coho steelhead steelhead data-shell/data 디렉토리의 uniq salmon.txt 명령문 실행은 다음을 출력한다. coho steelhead coho steelhead uniq가 왜 인접한 중복 행만을 단지 제거한다고 생각합니까? (힌트: 매우 큰 파일을 생각해보세요.) 모든 중복된 행을 제거하기 위해, 파이프로 다른 어떤 명령어를 조합할 수 있을까요? &gt; 해답 &gt; &gt; &gt; $ sort salmon.txt | uniq &gt; 파이프 독해능력 data-shell/data 폴더에 animals.txt로 불리는 파일은 다음 데이터를 포함한다 2012-11-05,deer 2012-11-05,rabbit 2012-11-05,raccoon 2012-11-06,rabbit 2012-11-06,deer 2012-11-06,fox 2012-11-07,rabbit 2012-11-07,bear 다음 아래 파이프라인에 각 파이프를 통과하고, 마지막 방향변경을 마친 텍스트는 무엇이 될까요? $ cat animals.txt | head -n 5 | tail -n 3 | sort -r &gt; final.txt 힌트: 명령어를 한번에 하나씩 작성해서 파이프라인을 구축한 뒤에 이해한 것이 맞는지 시험한다. 해답 head 명령어는 animals.txt 파일에서 첫 5 행을 추출한다. 그리고 나서, tail 명령어로 이전 5 행에서 마지막 3 행을 추출된다. sort -r 명령어는 역순으로 정렬을 시키게 된다. 마지막으로 출력결과는 final.txt 파일에 방향변경하여 화면이 아닌 파일로 보내진다. 파일에 저장된 내용은 cat final.txt 명령어를 실행하면 확인이 가능하다. 파일에는 다음 내용이 저장되어야 한다: 2012-11-06,rabbit 2012-11-06,deer 2012-11-05,raccoon 파이프 구성하기 이전 연습문제에 사용된 animals.txt 파일을 가지고 다음 명령어를 실행한다: $ cut -d , -f 2 animals.txt 콤마를 구분자로 각 행을 쪼개려고 하면 -d 플래그를 사용하고, -f 플래그는 각행의 두번째 필드를 지정하게 되서 출력결과는 다음과 같다: deer rabbit raccoon rabbit deer fox rabbit bear 파일에 담겨 있는 동물이 무엇인지를 알아내려면, 다른 어떤 명령어가 파이프라인에 추가되어야 하나요? (동물 이름에 어떠한 중복도 없어야 합니다.) 해답 $ cut -d , -f 2 animals.txt | sort | uniq {: .language-bash} 파이프 선택? animals.txt 파일은 아래 형식으로 586줄로 구성되어 있다: 2012-11-05,deer 2012-11-05,rabbit 2012-11-05,raccoon 2012-11-06,rabbit ... data-shell/data/ 현재 디렉토리로 가정하고, 다음 중 어떤 명령어가 동물 종류별로 전체 출현 빈도수를 나타내는 표를 작성하는데 사용하면 좋을까요? grep {deer, rabbit, raccoon, deer, fox, bear} animals.txt | wc -l sort animals.txt | uniq -c sort -t, -k2,2 animals.txt | uniq -c cut -d, -f 2 animals.txt | uniq -c cut -d, -f 2 animals.txt | sort | uniq -c cut -d, -f 2 animals.txt | sort | uniq -c | wc -l 해답 정답은 5. 정답을 이해하는데 어려움이 있으면, (data-shell/data 디렉토리에 위치한 것을 확인한 후) 명령어 전체를 실행하거나, 파이프라인 일부를 실행해 본다. 4.1 Nelle 파이프라인: 파일 확인하기 앞에서 설명한 것처럼 Nelle은 분석기를 통해 시료를 시험해서 17개 파일을 north-pacific-gyre/2012-07-03 디렉토리에 생성했다. 빠르게 건전성 확인하기 위해, 홈디렉토리에서 시작해서, 다음과 같이 타이핑한다: $ cd north-pacific-gyre/2012-07-03 $ wc -l *.txt 결과는 다음과 같은 18 행이 출력된다: 300 NENE01729A.txt 300 NENE01729B.txt 300 NENE01736A.txt 300 NENE01751A.txt 300 NENE01751B.txt 300 NENE01812A.txt ... ... 이번에는 다음과 같이 타이핑한다: $ wc -l *.txt | sort -n | head -n 5 240 NENE02018B.txt 300 NENE01729A.txt 300 NENE01729B.txt 300 NENE01736A.txt 300 NENE01751A.txt 이런, 파일중에 하나가 다른 것보다 60행이 짧다. 다시 돌아가서 확인하면, 월요일 아침 8:00 시각에 분석을 수행한 것을 알고 있다 — 아마도 누군가 주말에 기계를 사용했고, 다시 재설정하는 것을 깜빡 잊었을 것이다. 시료를 다시 시험하기 전에 파일중에 너무 큰 데이터가 있는지를 확인한다: $ wc -l *.txt | sort -n | tail -n 5 300 NENE02040B.txt 300 NENE02040Z.txt 300 NENE02043A.txt 300 NENE02043B.txt 5040 total 숫자는 예뻐 보인다 — 하지만 끝에서 세번째 줄에 ‘Z’는 무엇일까? 모든 시료는 ’A’ 혹은 ’B’로 표시되어야 한다. 시험실 관례로 ’Z’는 결측치가 있는 시료를 표식하기 위해 사용된다. 더 많은 결측 시료를 찾기 위해, 다음과 같이 타이핑한다: $ ls *Z.txt NENE01971Z.txt NENE02040Z.txt 노트북의 로그 이력을 확인할 때, 상기 샘플 각각에 대해 깊이(depth) 정보에 대해서 기록된 것이 없었다. 다른 방법으로 정보를 더 수집하기에는 너무 늦어서, 분석에서 두 파일을 제외하기로 했다. rm 명령어를 사용하여 삭제할 수 있지만, 향후에 깊이(depth)정보가 관련없는 다른 분석을 실시할 수도 있다. 그래서 와일드 카드 표현식 *[AB].txt을 사용하여 파일을 조심해서 선택하기로 한다. 언제나 그렇듯이, ’*’는 임의 숫자의 문자를 매칭한다. [AB] 표현식은 ’A’혹은 ’B’를 매칭해서 Nelle이 가지고 있는 유효한 데이터 파일 모두를 매칭한다. 와일드카드 표현식(Wildcard Expressions) 와일드카드 표현식은 매우 복잡할 수 있지만, 종종 다소 장황할 수 있는 비용을 지불하고 간단한 구문만 사용해서 작성하기도 한다. data-shell/north-pacific-gyre/2012-07-03 디렉토리를 생각해 보자: *[AB].txt 와일드카드 표현식은 A.txt 혹은 B.txt으로 끝나는 모든 파일을 매칭시킨다. 이 와일드카드 표현식을 잊었다고 상상해보자: [] 구문을 사용하지 않는 기본 와일드드카드 표현식으로 동일하게 파일을 매칭할 수 있을까? 힌트: 표현식이 하나 이상 필요할 수도 있다. [] 구문을 사용하지 않고 작성한 표현식은 동일한 파일을 매칭한다. 두 출력결과의 작은 차이점은 무엇인가? 최초 와일드카드 표현식은 오류가 나지 않는데 어떤 상황에서 본인 표현식은 오류 메시지를 출력하는가? 해답 1. $ ls *A.txt $ ls *B.txt 새로운 명령어에서 나온 출력결과는 명령어가 두개라 구분된다. The output from the new commands is separated because there are two commands. A.txt로 끝나는 파일이 없거나 B.txt로 끝나는 파일이 없는 경우 그렇다. 불필요한 파일 제거하기 저장공간을 절약하고자 중간 처리된 데이터 파일을 삭제하고 원본 파일과 처리 스크립트만 보관했으면 한다고 가정하자. 원본 파일은 .dat으로 끝나고, 처리된 파일은 .txt으로 끝난다. 다음 중 어떤 명령어가 처리과정에서 생긴 중간 모든 파일을 삭제하게 하는가? 1. rm ?.txt 2. rm *.txt 3. rm * .txt 4. rm *.* 해답 1. 한문자 .txt 파일을 제거한다. 2. 정답 3. * 기호로 인해 현재 디렉토리 모든 파일과 디렉토리를 매칭시킨다. 그래서 * 기호로 매칭되는 모든 것과 추가로 .txt 파일도 삭제한다. 4. *.* 기호는 임의 확장자를 갖는 모든 파일을 매칭시킨다. 따라서 *.* 기호는 모든 파일을 삭제한다. "],["shell-loop.html", "5 . 루프(Loops) 5.1 Nelle의 파이프라인: 많은 파일 처리하기", " 5 . 루프(Loops) 반복적으로 명령어를 실행하게 함으로써 자동화를 통해서 루프는 생산성 향상에 핵심이 된다. 와일드카드와 탭 자동완성과 유사하게, 루프를 사용하면 타이핑 상당량(타이핑 실수)을 줄일 수 있다. 와일드카드와 탭 자동완성은 타이핑을 (타이핑 실수를) 줄이는 두가지 방법이다. 또다른 것은 쉘이 반복해서 특정 작업을 수행하게 하는 것이다. basilisk.dat, unicorn.dat 등으로 이름 붙여진 게놈 데이터 파일이 수백개 있다고 가정하자. 이번 예제에서, 단지 두개 예제 파일만 있는 creatures 디렉토리를 사용할 것이지만 동일한 원칙은 훨씬 더 많은 파일에 즉시 적용될 수 있다. 디렉토리에 있는 파일을 변경하고 싶지만, 원본 파일을 original-basilisk.dat와 original-unicorn.dat으로 이름을 변경해서 저장한다. 하지만 다음 명령어를 사용할 수 없다: $ cp *.dat original-*.dat 왜냐하면 상기 두 파일 경우에 전개가 다음과 같이 될 것이기 때문이다: $ cp basilisk.dat unicorn.dat original-*.dat 상기 명령어는 파일을 백업하지 않고 대신에 오류가 발생된다: cp: target `original-*.dat&#39; is not a directory cp 명령어는 입력값 두개 이상을 받을 때 이런 문제가 발생한다. 이런 상황이 발생할 때, 마지막 입력값을 디렉토리로 예상해서 모든 파일을 해당 디렉토리로 넘긴다. creatures 디렉토리에는 original-*.dat 라고 이름 붙은 하위 디렉토리가 없기 때문에, 오류가 생긴다. 대신에, 리스트에서 한번에 연산작업을 하나씩 수행하는 루프(loop)를 사용할 수 있다. 교대로 각 파일에 대해 첫 3줄을 화면에 출력하는 단순한 예제가 다음에 나와 있다: $ for filename in basilisk.dat unicorn.dat &gt; do &gt; head -n 3 $filename # 루프 내부에 들여쓰기는 가독성에 도움을 준다. &gt; done COMMON NAME: basilisk CLASSIFICATION: basiliscus vulgaris UPDATED: 1745-05-02 COMMON NAME: unicorn CLASSIFICATION: equus monoceros UPDATED: 1738-11-24 for 루프 내부에 코드 들여쓰기 for 루프 내부의 코드를 들여쓰는 것이 일반적인 관행이다. 들여쓰는 유일한 목적은 코드를 더 읽기 쉽게 하는 것 밖에 없다 – for 루프를 실행하는데는 꼭 필요하지는 않다. 쉘이 키워드 for를 보게 되면, 쉘은 리스트에 있는 각각에 대해 명령문 하나(혹은 명령문 집합)을 반복할 것이라는 것을 알게 된다. 루프를 반복할 때마다(iteration 이라고도 한다), 현재 작업하고 있는 파일 이름은 filename으로 불리는 변수(variable)에 할당된다. 리스트의 다음 원소로 넘어가기 전에 루프 내부 명령어가 실행된다. 루프 내부에서, 변수 이름 앞에 $ 기호를 붙여 변수 값을 얻는다: $ 기호는 쉘 해석기가 변수명을 텍스트나 외부 명령어가 아닌 변수로 처리해서 값을 해당 위치에 치환하도록 지시한다. 이번 경우에 리스트는 파일이름이 두개다: basilisk.dat, unicorn.dat. 매번 루프가 돌 때마다 파일명을 filename 변수에 할당하고 head 명령어를 실행시킨다. 즉, 루프가 첫번째 돌 때 $filename 은 basilisk.dat이 된다. 쉘 해석기는 basilisk.dat 파일에 head 명령어를 실행시켜서 basilisk.dat 파일의 첫 3줄을 화면에 출력시킨다. 두번째 반복에서, $filename은 unicorn.dat이 된다. 이번에는 쉘이 head 명령어를 unicorn.dat 파일에 적용시켜 unicorn.dat 파일 첫 3줄을 화면에 출력시킨다. 리스트에 원소가 두개라서, 쉘은 for 루프를 빠져나온다. 변수명을 분명히 구분하는데, 중괄호 내부에 변수명을 넣어서 변수로 사용하는 것도 가능하다: $filename 은 ${filename}와 동치지만, ${file}name와는 다르다. 이 표기법을 다른 사람 프로그램에서 찾아볼 수 있다. 루프 내부의 변수 이번 예제는 data-shell/molecules 디렉토리를 가정한다. ls 명령어를 던지면 출력결과는 다음과 같다: cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb 다음 코드의 출력결과는 어떻게 나오는가? $ for datafile in *.pdb &gt; do &gt; ls *.pdb &gt; done 이제 다음 코드의 출력결과는 무엇인가? $ for datafile in *.pdb &gt; do &gt; ls $datafile &gt; done 왜 상기 두 루프 실행결과는 다를까? 해답 첫번째 코드 블록은 루프를 돌릴 때마다 동일한 출력결과를 출력한다. 배쉬는 루프 몸통 내부 와일드카드 *.pdb을 확장해서 .pdb로 끝나는 모든 파일을 매칭시킨다. 확장된 루프는 다음과 같이 생겼다: $ for datafile in cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb &gt; do &gt; ls cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb &gt; done cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb 두번째 코드 블록은 루프를 돌 때마다 다른 파일을 출력한다. datafile 파일 변수값이 $datafile을 통해 평가되고 ls 명령어를 사용해서 파일 목록을 출력하게 된다. cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb 프롬프트 따라가기 루프안에서 타이핑을 할 때, 쉘 프롬프트가 $에서 &gt;으로 바뀐다. 두번째 프롬프트는, &gt;, 온전한 명령문 타이핑이 끝마치지 않았음을 상기시키려고 다르게 표기된다. 세미콜론 ; 을 사용해서 두 명령어로 구성된 문장을 단일 명령줄로 단순화한다. 동일한 기호, 하지만 다른 의미 쉘 프롬프트로 &gt; 기호가 사용되는 것을 확인했지만, &gt; 기호는 출력결과를 방향변경(redirect) 하는데도 사용된다. 유사하게 $ 기호를 쉘 프롬프트로 사용했지만, 앞에서 살펴봤듯이, 쉘로 하여금 변수값을 추출하는데도 사용된다. 쉘이 &gt; 혹은 $ 기호를 출력하게 되면, 사용자가 뭔가 타이핑하길 기대하고 있다는 것으로 해당 기호는 프롬프트를 의미한다. 사용자 본인이 &gt; 혹은 $ 기호를 타이핑하게 되면, 출력결과를 방향변경하거나 변수 값을 끄집어내는 지시를 쉘에 전달하게 된다. data-shell/creatures 디렉토리의 예제로 돌아가자. 사람 코드를 읽는 독자에게 목적을 좀더 명확히 하기 위해서 루프의 변수명을 filename로 했다. 쉘 자체는 변수명이 어떻게 작명되든지 문제삼지 않는다. 만약 루프를 다음과 같이 작성하거나: $ for x in basilisk.dat unicorn.dat &gt; do &gt; head -n 3 $x &gt; done 혹은: $ for temperature in basilisk.dat unicorn.dat &gt; do &gt; head -n 3 $temperature &gt; done 둘다 정확하게 동일하게 동작한다. 이렇게는 절대 하지 마세요. 사람이 프로그램을 이해할 수 있을 때만 프로그램이 유용하기 때문에, (x같은) 의미없는 이름이나, (temperature같은) 오해를 줄 수 있는 이름은 오해를 불러일으켜서 독자가 생각하기에 당연히 프로그램이 수행해야 할 작업을 프로그램이 수행하지 못하게 할 가능성을 높인다. 파일 집합 제한걸기 data-shell/molecules 디렉토리에서 다음 루프를 실행하게 되면 출력결과는 어떻게 될까? $ for filename in c* &gt; do &gt; ls $filename &gt; done 어떤 파일도 출력되지 않는다. 모든 파일이 출력된다. cubane.pdb, octane.pdb, pentane.pdb 파일만 출력된다. cubane.pdb 파일만 출력된다. 해답 정답은 4. 와일드카드 * 문자는 0 혹은 그 이상 문자를 매칭하게 된다. 따라서, 문자 c로 시작하는 문자 다음에 0 혹은 그 이상 문자를 갖는 모든 파일이 매칭된다. 대신에 다음 명령어를 사용하면 출력결과는 어떻게 달라지나? $ for filename in *c* &gt; do &gt; ls $filename &gt; done 동일한 파일이 출력된다. 이번에는 모든 파일이 출력된다. 이번에는 어떤 파일도 출력되지 않는다. cubane.pdb 와 octane.pdb 파일이 출력된다. octane.pdb 파일만 출력된다. 해답 정답은 4. 와일드카드 * 문자는 0 혹은 그 이상 문자를 매칭하게 된다. 따라서, c 앞에 0 혹은 그 이상 문자가 올 수 있고, c 문자 다음에 0 혹은 그 이상 문자가 모두 매칭된다. data-shell/creatures 디렉토리에서 예제를 계속해서 학습해보자. 다음에 좀더 복잡한 루프가 있다: $ for filename in *.dat &gt; do &gt; echo $filename &gt; head -n 100 $filename | tail -n 20 &gt; done 쉘이 *.dat을 전개해서 쉘이 처리할 파일 리스트를 생성한다. 그리고 나서 루프 몸통(loop body) 부분이 파일 각각에 대해 명령어 두개를 실행한다. 첫 명령어 echo는 명령 라인 매개변수를 표준 출력으로 화면에 뿌려준다. 예를 들어: $ echo hello there 상기 명령은 다음과 같이 출력된다: hello there 이 사례에서, 쉘이 파일 이름으로 $filename을 전개했기 때문에, echo $filename은 단지 파일 이름만 화면에 출력한다. 다음과 같이 작성할 수 없다는 것에 주의한다: $ for filename in *.dat &gt; do &gt; $filename &gt; head -n 100 $filename | tail -n 20 &gt; done 왜냐하면, $filename이 basilisk.dat으로 전개될 때 루프 처음에 쉘이 프로그램으로 인식한 basilisk.dat를 실행하려고 하기 때문이다. 마지막으로, head와 tail 조합은 어떤 파일이 처리되든 81-100줄만 선택해서 화면에 뿌려준다. (파일이 적어도 100줄로 되었음을 가정) ::: {#shell-loop-space .rmdcaution} 파일, 디렉토리, 변수 등 이름에 공백 공백(whitespace)을 사용해서 루프를 돌릴 때 리스트의 각 원소를 구별했다. 리스트 원소중 일부가 공백을 갖는 경우, 해당 원소를 인용부호로 감싸서 사용해야 된다. 데이터 파일이 다음과 같은 이름으로 되었다고 가정하자: red dragon.dat purple unicorn.dat 다음을 사용하여 파일을 처리하려고 한다면: $ for filename in &quot;red dragon.dat&quot; &quot;purple unicorn.dat&quot; &gt; do &gt; head -n 100 &quot;$filename&quot; | tail -n 3 &gt; done 파일명에 공백(혹은 다른 특수 문자)를 회피하는 것이 더 단순하다. 상기 파일은 존재하지 않는다. 그래서 상기 코드를 실행하게 되면, head 명령어는 파일을 찾을 수가 없어서 예상되는 파일명을 보여주는 오류 메시지가 반환된다: head: cannot open ‘red dragon.dat’ for reading: No such file or directory head: cannot open ‘purple unicorn.dat’ for reading: No such file or directory 상기 루프 내부 $filename 파일명 주위 인용부호를 제거하고 공백 효과를 살펴보자. creatures 디렉토리에서 코드를 실행시키게 되면 unicorn.dat 파일에 대한 결과를 루프 명령어 실행 결과를 얻게 됨에 주목한다: head: cannot open ‘red’ for reading: No such file or directory head: cannot open ‘dragon.dat’ for reading: No such file or directory head: cannot open ‘purple’ for reading: No such file or directory CGGTACCGAA AAGGGTCGCG CAAGTGTTCC 원래 파일 복사문제로 되돌아가서, 다음 루프를 사용해서 문제를 해결해 보자: $ for filename in *.dat &gt; do &gt; cp $filename original-$filename &gt; done 상기 루프는 cp 명령문을 각 파일이름에 대해 실행한다. 처음에 $filename이 basilisk.dat로 전개될 때, 쉘은 다음을 실행한다: cp basilisk.dat original-basilisk.dat 두번째에는 명령문은 다음과 같다: cp unicorn.dat original-unicorn.dat cp 명령어는 아무런 출력결과도 만들어내지 않기 때문에, 루프가 제대로 돌아가는지 확인하기 어렵다. echo로 명령문 앞에 위치시킴으로써, 명령문 각각이 제대로 동작되고 있는 확인하는 것이 가능하다. 다음 도표를 통해서 스크립트가 동작할 때 어떤 작업이 수행하고 있는지 상술하고 있다. 또한 echo 명령어를 사려깊이 사용하는 것이 어떻게 훌륭한 디버깅 기술이 되는지도 보여주고 있다. For Loop in Action 5.1 Nelle의 파이프라인: 많은 파일 처리하기 Nelle은 이제 goostats 프로그램(논문 지도교수가 작성한 쉘 스크립트)을 사용해서 데이터 파일을 처리할 준비가 되었다. goostats 프로그램은 표본추출 단백질 파일에서 통계량을 산출하는데 인자를 두개 받는다: 입력파일 (원본 데이터를 포함) 출력파일 (산출된 통계량을 저장) 아직 쉘을 어떻게 사용하는지 학습단계에 있기 때문에, 단계별로 요구되는 명령어를 차근히 작성하기로 마음먹었다. 첫번째 단계는 적합한 파일을 선택했는지를 확인하는 것이다 — ‘Z’가 아닌 ’A’ 혹은 ’B’로 파일이름이 끝나는 것이 적합한 파일이라는 것을 명심한다. 홈 디렉토리에서 시작해서, 박사과정 Nelle이 다음과 같이 타이핑한다: $ cd north-pacific-gyre/2012-07-03 $ for datafile in NENE*[AB].txt &gt; do &gt; echo $datafile &gt; done NENE01729A.txt NENE01729B.txt NENE01736A.txt ... NENE02043A.txt NENE02043B.txt 다음 단계는 goostats 분석 프로그램이 생성할 파일이름을 무엇으로 할지 결정하는 것이다. “stats”을 각 입력 파일에 접두어로 붙이는 것이 간단해 보여서, 루프를 변경해서 작업을 수행하도록 한다: $ for datafile in NENE*[AB].txt &gt; do &gt; echo $datafile stats-$datafile &gt; done NENE01729A.txt stats-NENE01729A.txt NENE01729B.txt stats-NENE01729B.txt NENE01736A.txt stats-NENE01736A.txt ... NENE02043A.txt stats-NENE02043A.txt NENE02043B.txt stats-NENE02043B.txt goostats을 아직 실행하지는 않았지만, 이제 확신할 수 있는 것은 올바른 파일을 선택해서, 올바른 출력 파일이름을 생성할 수 있다는 점이다. 명령어를 반복적으로 타이핑하는 것은 귀찮은 일이지만, 더 걱정이 되는 것은 Nelle이 타이핑 실수를 하는 것이다. 그래서 루프를 다시 입력하는 대신에 위쪽 화살표를 누른다. 위쪽 화살표에 반응해서 컴퓨터 쉘은 한줄에 전체 루프를 다시 보여준다. (스크립트 각 부분이 구분되는데 세미콜론이 사용됨): $ for datafile in NENE*[AB].txt; do echo $datafile stats-$datafile; done 왼쪽 화살표 키를 사용해서, Nelle은 echo명령어를 bash goostats으로 변경하고 백업한다: $ for datafile in NENE*[AB].txt; do bash goostats $datafile stats-$datafile; done 엔터키를 누를 때, 쉘은 수정된 명령어를 실행한다. 하지만, 어떤 것도 일어나지 않는 것처럼 보인다 — 출력이 아무것도 없다. 잠시뒤에 Nelle은 작성한 스크립트가 화면에 아무것도 출력하지 않아서, 실행되고 있는지, 얼마나 빨리 실행되는지에 대한 정보가 없다는 것을 깨닫는다. 컨트롤+C(Control-C)를 눌러서 작업을 종료하고, 반복할 명령문을 위쪽 화살표로 선택하고, 편집해서 다음과 같이 작성한다: $ for datafile in NENE*[AB].txt; do echo $datafile; bash goostats $datafile stats-$datafile; done 시작과 끝 쉘에 ^A, 콘트롤+A(Control-A, Ctrl-a)를 타이핑해서 해당 라인 처음으로 가고, ^E (Ctrl-e, Control-E)를 쳐서 라인의 끝으로 이동한다. 이번에 프로그램을 실행하면, 매 5초간격으로 한줄을 출력한다: NENE01729A.txt NENE01729B.txt NENE01736A.txt ... 1518 곱하기 5초를 60으로 나누면, 작성한 스크립트를 실행하는데 약 2시간 정도 소요된다고 볼 수 있다. 마지막 점검으로, 또다른 터미널 윈도우를 열어서, north-pacific-gyre/2012-07-03 디렉토리로 가서, cat stats-NENE01729B.txt을 사용해서 출력파일 중 하나를 면밀히 조사한다. 출력결과가 좋아보인다. 그래서 커피를 마시고 그동안 밀린 논문을 읽기로 한다. 역사(history)를 아는 사람은 반복할 수 있다. 앞선 작업을 반복하는 또다른 방법은 history 명령어를 사용하는 것이다. 실행된 마지막 수백개 명령어 리스트를 얻고 나서, 이들 명령어 중 하나를 반복실행하기 위해서 !123(“123”은 명령 숫자로 교체된다.)을 사용한다. 예를 들어 Nelle이 다음과 같이 타이핑한다면: $ history | tail -n 5 456 ls -l NENE0*.txt 457 rm stats-NENE01729B.txt.txt 458 bash goostats NENE01729B.txt stats-NENE01729B.txt 459 ls -l NENE0*.txt 460 history 그리고 나서, 단순히 !458을 타이핑함으로써, NENE01729B.txt 파일에 goostats을 다시 실행할 수 있게 된다. 다른 이력(history) 명령어 이력(history)에 접근하는 단축 명령어가 다수 존재한다. Ctrl-R 탄축키는 “reverse-i-search” 이력 검색모드로 입력한 텍스트와 매칭되는 가장 최슨 명령어를 이력에서 찾아서 제시한다. Ctrl-R 단축키를 한번 혹은 그 이상 누르게 되면 그 이전 매칭을 검색해 준다. !! 명령어는 바로 직전 명령어를 불러온다. (키보드 윗화살표를 사용하는 것보다 더 편리할수도 편리하지 않을 수도 있다.) !$ 명령어는 마지막 명령문의 마지막 단어를 불러온다. 기대했던 것보다 훨씬 유용할 수 있다: bash goostats NENE01729B.txt stats-NENE01729B.txt 명령문을 실행한 후에 less !$을 타이핑하게 되면 stats-NENE01729B.txt 파일을 찾아준다. 키보드 위화살표를 눌러 명령라인을 편집하는 것보다 훨씬 빠르다. 루프 내부에서 파일에 저장하기 - 1부 data-shell/molecules 디렉토리에 있다고 가정하자. 다음 루프의 효과는 무엇인가? $ for alkanes in *.pdb &gt; do &gt; echo $alkanes &gt; cat $alkanes &gt; alkanes.pdb &gt; done fructose.dat, glucose.dat, sucrose.dat을 출력하고, sucrose.dat에서 나온 텍스트를 xylose.dat에 저장된다. fructose.dat, glucose.dat, sucrose.dat을 출력하고, 모든 파일 3개에서 나온 텍스트를 합쳐 xylose.dat에 저장된다. fructose.dat, glucose.dat, sucrose.dat, xylose.dat을 출력하고, sucrose.dat에서 나온 텍스트를 xylose.dat에 저장된다. 위 어느 것도 아니다. 해답 1. 순차적으로 각 파일의 텍스트가 alkanes.pdb 파일에 기록된다. 하지만, 루프가 매번 반복될 때마다 파일에 덮어쓰기가 수행되어서 마지막 alkanes.pdb 파일 텍스트만 alkanes.pdb 파일에 기록된다. 루프 내부에서 파일에 저장하기 - 2부 이번에도 data-shell/molecules 디렉토리에 있다고 가정하고, 다음 루프 실행 출력결과는 무엇일까? $ for datafile in *.pdb &gt; do &gt; cat $datafile &gt;&gt; all.pdb &gt; done cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb 파일에 나온 모든 모든 텍스트가 하나로 붙여져서 all.pdb 파일에 저장된다. ethane.pdb 파일에 나온 텍스트만 all.pdb 파일에 저장된다. cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb, propane.pdb 파일에서 나온 모든 텍스트가 하나로 풑여져서 all.pdb 파일에 저장된다. cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb, propane.pdb 파일에서 나온 모든 텍스트가 화면에 출력되고 all.pdb 파일에 저장된다. 해답 정답은 3. 명령어 실행 출력결과를 방향변경하여 덮었는 것이 아니라 &gt;&gt; 기호는 파일에 덧붙인다. cat 명령어에서 나온 출력결과가 파일로 방향변경되어 어떤 출력결과도 화면에 출력되지는 않는다. 시운전(Dry Run) 루프는 한번에 많은 작업을 수행하는 방식이다 — 만약 잘못된 것이 있다면, 한번에 실수를 대단히 많이 범하게 된다. 루프가 수행하는 작업을 점검하는 한 방법이 실제로 루프를 돌리는 대신에 echo 명령어를 사용하는 것이다. 실제로 명령어를 실행하지 않고, 다음 루프가 실행할 명령어를 머릿속으로 미리보고자 한다고 가정한다: $ for file in *.pdb &gt; do &gt; analyze $file &gt; analyzed-$file &gt; done 아래 두 루프 사이에 차이는 무엇이고, 어느 것을 시운전으로 실행하고 싶은가? # Version 1 $ for file in *.pdb &gt; do &gt; echo analyze $file &gt; analyzed-$file &gt; done # Version 2 $ for file in *.pdb &gt; do &gt; echo &quot;analyze $file &gt; analyzed-$file&quot; &gt; done 해답 두번째 버젼을 실행하면 좋을 것이다. 달러 기호로 접두명을 주었기 때문에 루프 변수를 확장해서 인용부호로 감싼 모든 것을 화면에 출력한다. 첫번째 버전은 echo analyze $file 명령을 수행해서 analyzed-$file 파일로 출력결과를 방향변경하여 저장시킨다. 따라서 파일이 쭉 자동생성된다:analyzed-cubane.pdb, analyzed-ethane.pdb … 두가지 버젼을 직접 실행해보고 출력결과를 살펴보자! analyzed-*.pdb 파일을 열어서 파일에 기록된 내용도 살펴본다. 중첩루프(Nested Loops) 다른 화합물과 다른 온도를 갖는 조합을 해서, 각 반응율 상수를 측정하는 실험을 조직하도록 이에 상응하는 디렉토리 구조를 갖추고자 한다. 다음 코드 실행결과는 어떻게 될까? $ for species in cubane ethane methane &gt; do &gt; for temperature in 25 30 37 40 &gt; do &gt; mkdir $species-$temperature &gt; done &gt; done 해답 중첩 루프(루프 내부에 루프가 포함됨)를 생성하게 된다. 외부 루프에 각 화학물이, 내부 루프(중첩된 루프)에 온도 조건을 반복하게 되서, 화학물과 온도를 조합한 새로운 디렉토리가 쭉 생성된다. 직접 코드를 실행해서 어떤 디렉토리가 생성되는지 확인한다! "],["shell-script.html", "6 . 쉘 스크립트 6.1 Nelle 파이프라인: 스크립트 생성하기", " 6 . 쉘 스크립트 마침내 쉘을 그토록 강력한 프로그래밍 환경으로 탈바꾼할 준비가 되었다. 자주 반복적으로 사용되는 명령어들을 파일에 저장시키고 나서, 단 하나의 명령어를 타이핑함으써 나중에 이 모든 연산 작업작업을 다시 재실행할 수 있다. 역사적 이유로 파일에 저장된 명령어 꾸러미를 통상 쉘 스크립트(shell script)라고 부르지만, 실수로 그렇게 부르는 것은 아니다: 실제로 작은 프로그램이다. molecules/ 디렉토리로 돌아가서 middle.sh 파일에 다음 행을 추가하게 되면 쉘스크립트가 된다: $ cd molecules $ nano middle.sh nano middle.sh 명령어는 middle.sh 파일을 텍스트 편집기 “nano”로 열게 한다. (편집기 프로그램은 쉘 내부에서 실행된다.) middle.sh 파일이 존재하지 않는 경우, middle.sh 파일을 생성시킨다. 텍스트 편집기를 사용해서 직접 파일을 편집한다 – 단순히 다음 행을 삽입시킨다: head -n 15 octane.pdb | tail -n 5 앞서 작성한 파이프에 변형이다: octane.pdb 파일에서 11-15 행을 선택한다. 기억할 것은 명령어로서 실행하지 않고: 명령어를 파일에 적어 넣는다는 것이다. 그리고 나서 나노 편집기에서 Ctrl-O를 눌러 파일을 저장하고, 나노 편집기에서 Ctrl-X를 눌러 텍스트 편집기를 빠져나온다. molecules 디렉토리에 middle.sh 파일이 포함되어 있는지 확인한다. Once we have saved the file, we can ask the shell to execute the commands it contains. Our shell is called bash, so we run the following command: 파일을 저장하면, 쉘로 하여금 파일에 담긴 명령어를 실행하도록 한다. 지금 쉘은 bash라서, 다음과 같이 다음 명령어를 실행시킨다: $ bash middle.sh ATOM 9 H 1 -4.502 0.681 0.785 1.00 0.00 ATOM 10 H 1 -5.254 -0.243 -0.537 1.00 0.00 ATOM 11 H 1 -4.357 1.252 -0.895 1.00 0.00 ATOM 12 H 1 -3.009 -0.741 -1.467 1.00 0.00 ATOM 13 H 1 -3.172 -1.337 0.206 1.00 0.00 아니나 다를까, 스크립트의 출력은 정확하게 파이프라인을 직접적으로 실행한 것과 동일하다. 텍스트 vs. 텍스트가 아닌 것 아무거나 종종 마이크로소프트 워드 혹은 리브르오피스 Writer 프로그램을 “텍스트 편집기”라고 부른다. 하지만, 프로그래밍을 할때 조금더 주의를 기울일 필요가 있다. 기본 디폴트로, 마이크로소프트 워드는 .docx 파일을 사용해서 텍스트를 저장할 뿐만 아니라, 글꼴, 제목, 등등의 서식 정보도 함께 저장한다. 이런 추가 정보는 문자로 저장되지 않아서, head 같은 도구에게는 무의미하다: head 같은 도구는 입력 파일에 문자, 숫자, 표준 컴퓨터 키보드 특수문자만이 포함되어 있는 것을 예상한다. 따라서, 프로그램을 편집할 때, 일반 텍스트 편집기를 사용하거나, 혹은 일반 텍스트로 파일을 저장하도록 주의한다. 만약 임의 파일의 행을 선택하고자 한다면 어떨까요? 파일명을 바꾸기 위해서 매번 middle.sh을 편집할 수 있지만, 단순히 명령어를 다시 타이핑하는 것보다 아마 시간이 더 걸릴 것이다. 대신에 middle.sh을 편집해서 좀더 다양한 기능을 제공하도록 만들어보자: $ nano middle.sh 나노 편집기로 octane.pdb을 $1으로 불리는 특수 변수로 변경하자: head -n 15 &quot;$1&quot; | tail -n 5 쉘 스크립트 내부에서, $1은 “명령라인의 첫 파일 이름(혹은 다른 인자)”을 의미한다. 이제 스크립트를 다음과 같이 바꿔 실행해 보자: $ bash middle.sh octane.pdb ATOM 9 H 1 -4.502 0.681 0.785 1.00 0.00 ATOM 10 H 1 -5.254 -0.243 -0.537 1.00 0.00 ATOM 11 H 1 -4.357 1.252 -0.895 1.00 0.00 ATOM 12 H 1 -3.009 -0.741 -1.467 1.00 0.00 ATOM 13 H 1 -3.172 -1.337 0.206 1.00 0.00 혹은 다음과 같이 다른 파일에 대해 스크립트 프로그램을 실행해 보자: $ bash middle.sh pentane.pdb ATOM 9 H 1 1.324 0.350 -1.332 1.00 0.00 ATOM 10 H 1 1.271 1.378 0.122 1.00 0.00 ATOM 11 H 1 -0.074 -0.384 1.288 1.00 0.00 ATOM 12 H 1 -0.048 -1.362 -0.205 1.00 0.00 ATOM 13 H 1 -1.183 0.500 -1.412 1.00 0.00 인자 주위를 이중 인용부호로 감싸기 파일명에 공백이 포함된 경우 루프 변수 내부에 이중 인용부호로 감싼 것과 동일한 사유로, 파일명에 공백이 포함된 경우 이중 인용부호로 $1을 감싼다. 하지만, 매번 줄 범위를 조정할 때마다 여전히 middle.sh 파일을 편집할 필요가 있다. 이 문제를 특수 변수 $2 와 $3 을 사용해서 고쳐보자: head, tail 명령어에 해당 줄수를 출력하도록 인자로 넘긴다. $ nano middle.sh head -n &quot;$2&quot; &quot;$1&quot; | tail -n &quot;$3&quot; 이제 다음을 실행시킨다: $ bash middle.sh pentane.pdb 15 5 ATOM 9 H 1 1.324 0.350 -1.332 1.00 0.00 ATOM 10 H 1 1.271 1.378 0.122 1.00 0.00 ATOM 11 H 1 -0.074 -0.384 1.288 1.00 0.00 ATOM 12 H 1 -0.048 -1.362 -0.205 1.00 0.00 ATOM 13 H 1 -1.183 0.500 -1.412 1.00 0.00 명령문의 인자를 변경함으로써 스크립트 동작을 바꿀 수 있게 된다: $ bash middle.sh pentane.pdb 20 5 ATOM 14 H 1 -1.259 1.420 0.112 1.00 0.00 ATOM 15 H 1 -2.608 -0.407 1.130 1.00 0.00 ATOM 16 H 1 -2.540 -1.303 -0.404 1.00 0.00 ATOM 17 H 1 -3.393 0.254 -0.321 1.00 0.00 TER 18 1 제대로 동작하지만, middle.sh 쉘스크립트를 읽는 다른 사람은 잠시 시간을 들여, 스크립트가 무엇을 수행하는지 알아내야 할지 모른다. 스크립트를 상단에 주석(comments)을 추가해서 좀더 낫게 만들 수 있다: $ nano middle.sh # Select lines from the middle of a file. # Usage: bash middle.sh filename end_line num_lines head -n &quot;$2&quot; &quot;$1&quot; | tail -n &quot;$3&quot; 주석은 #문자로 시작하고 해당 행 끝까지 주석으로 처리된다. 컴퓨터는 주석을 무시하지만, 사람들이(미래의 본인 자신도 포함) 스크립트를 이해하고 사용하는데 정말 귀중한 존재다. 유일한 단점은 스크립트를 변경할 때마다, 주석이 여전히 유효한지 확인해야 된다는 점이다: 잘못된 방향으로 독자를 오도하게 만드는 설명은 아무것도 없는 것보다 더 나쁘다. 만약 많은 파일을 단 하나 파이프라인으로 처리하고자 한다면 어떨까? 예를 들어, .pdb 파일을 길이 순으로 정렬하려면, 다음과 같이 타이핑한다: $ wc -l *.pdb | sort -n wc -l은 파일에 행갯수를 출력하고(wc는 ’word count’로 -l 플래그를 추가하면 ’count lines’의미가 됨을 상기한다), sort -n은 숫자순으로 파일의 행갯수를 정렬한다. 파일에 담을 수 있지만, 현재 디렉토리에 .pdb 파일만을 정렬한다. 다른 유형의 파일에 대한 정렬된 목록을 얻으려고 한다면, 스크립트에 이 모든 파일명을 얻는 방법이 필요하다. $1, $2 등등은 사용할 수 없는데, 이유는 얼마나 많은 파일이 있는지를 예단할 수 없기 때문이다. 대신에, 특수 변수 $@을 사용한다. $@은 “쉘 스크립트 모든 명령-라인 인자”를 의미한다. 공백을 포함한 매개변수를 처리하려면 이중 인용부호로 $@을 감싸두어야 된다. (\"$@\"은 \"$1\" \"$2\" … 와 동치다). 예제가 다음에 있다: $ nano sorted.sh # Sort filenames by their length. # Usage: bash sorted.sh one_or_more_filenames wc -l &quot;$@&quot; | sort -n 실행방법과 실행결과는 다음과 같다. $ bash sorted.sh *.pdb ../creatures/*.dat 9 methane.pdb 12 ethane.pdb 15 propane.pdb 20 cubane.pdb 21 pentane.pdb 30 octane.pdb 163 ../creatures/basilisk.dat 163 ../creatures/unicorn.dat 유일무이한 개체 목록으로 나열 정훈이는 데이터 파일 수백개를 갖고 있는데, 각각은 다음과 같은 형식을 가지고 있다: 2013-11-05,deer,5 2013-11-05,rabbit,22 2013-11-05,raccoon,7 2013-11-06,rabbit,19 2013-11-06,deer,2 2013-11-06,fox,1 2013-11-07,rabbit,18 2013-11-07,bear,1 data-shell/data/animal-counts/animals.txt 파일을 대상으로 예제를 작성한다. 임의 파일이름을 명령-라인 인자로 갖는 species.sh 이름의 쉘 스크립트를 작성하라. cut, sort, uniq를 사용해서 각각의 파일별로 나오는 유일무이한 개체에 대한 목록을 화면에 출력하세요. 해답 # csv 파일에 유일무이한 개체를 찾는 스크립트로 개체는 두번째 데이터 필드가 된다. # 스크립트는 명령라인 인자로 모든 파일명을 인자로 받는다. # 모든 파일에 대해 루프를 돌려 반복한다. for file in $@ do echo “Unique species in $file:” # 개체명을 추출한다. cut -d , -f 2 $file | sort | uniq done ``` 왜 쉘 스크립트가 어떤 작업도 수행하지 않을까? 스크립트가 아주 많은 파일을 처리하고 했지만, 어떠한 파일 이름도 부여하지 않는다면 무슨 일이 발생할까? 예를 들어, 만약 다음과 같이 타이핑한다면 어떻게 될까요?: $ bash sorted.sh 하지만 *.dat (혹은 다른 어떤 것)를 타이핑하지 않는다면 어떨까요? 이 경우 $@은 아무 것도 전개하지 않아서, 스크립트 내부의 파이프라인은 사실상 다음과 같다: $ wc -l | sort -n 어떠한 파일이름도 주지 않아서, wc은 표준 입력을 처리하려 한다고 가정한다. 그래서, 단지 앉아서 사용자가 인터랙티브하게 어떤 데이터를 전달해주길 대기하고만 있게 된다. 하지만, 밖에서 보면 사용자에게 보이는 것은 스크립트가 거기 앉아서 정지한 것처럼 보인다: 스크립트가 아무 일도 수행하지 않는 것처럼 보인다. 유용한 무언가를 수행하는 일련의 명령어를 방금 실행했다고 가정하자 — 예를 들어, 논문에 사용될 그래프를 스크립트가 생성. 필요하면 나중에 그래프를 다시 생성할 필요가 있어서, 파일에 명령어를 저장하고자 한다. 명령문을 다시 타이핑(그리고 잠재적으로 잘못 타이핑할 수도 있다)하는 대신에, 다음과 같이 할 수도 있다: $ history | tail -n 5 &gt; redo-figure-3.sh redo-figure-3.sh 파일은 이제 다음을 담고 있다: 297 bash goostats NENE01729B.txt stats-NENE01729B.txt 298 bash goodiff stats-NENE01729B.txt /data/validated/01729.txt &gt; 01729-differences.txt 299 cut -d &#39;,&#39; -f 2-3 01729-differences.txt &gt; 01729-time-series.txt 300 ygraph --format scatter --color bw --borders none 01729-time-series.txt figure-3.png 301 history | tail -n 5 &gt; redo-figure-3.sh 명령어의 일련 번호를 제거하고, history 명령어를 포함한 마지막 행을 지우는 작업을 편집기에서 한동안 작업한 후에, 그림을 어떻게 생성시켰는지에 관한 정말 정확한 기록을 갖게 되었다. 왜 명령어를 실행하기 전에 history에 명령어를 기록할까? 다음 명령어를 실행시키게 되면: $ history | tail -n 5 &gt; recent.sh 파일에 마지막 명령어는 history 명령 그자체다; 즉 쉘이 실제로 명령어를 실행하기 전에 명령 로그에 먼저 history를 추가했다. 실제로 항상 쉘은 명령어를 실행시키기 전에 로그에 명령어를 기록한다. 왜 이런 동작을 쉘이 한다고 생각하는가? 해답 만약 명령어가 죽던가 멈추게 되면, 어떤 명령어에서 문제가 발생했는지 파악하는 것이 유용할 수 있다. 명령어가 실행된 후에 기록하게 되면, 크래쉬(crash)가 발생된 마지막 명령어에 대한 기록이 없게 된다. 실무에서, 대부분의 사람들은 쉘 프롬프트에서 몇번 명령어를 실행해서 올바르게 수행되는지를 확인한 다음, 재사용을 위해 파일에 저장한다. 이런 유형의 작업은 데이터와 작업흐름(workflow)에서 발견한 것을 history를 호출해서 재사용할 수 있게 하고, 출력을 깔끔하게 하기 위해 약간의 편집을 하고 나서, 쉘 스크립트로 저장하는 흐름을 탄다. 6.1 Nelle 파이프라인: 스크립트 생성하기 Nelle의 지도교수는 모든 분석결과가 재현가능해야 된다는 고집을 갖고 있다. 모든 분석 단계를 담아내는 가장 쉬운 방법은 스크립트에 있다. 편집기를 열어서 다음과 같이 작성한다: # 데이터 파일별로 통계량 계산. for datafile in &quot;$@&quot; do echo $datafile bash goostats $datafile stats-$datafile done do-stats.sh 이름으로된 파일에 저장해서, 다음과 같이 타이핑해서 첫번째 단계 분석을 다시 실행할 수 있게 되었다: $ bash do-stats.sh NENE*[AB].txt 또한 다음과 같이도 할 수 있다: $ bash do-stats.sh NENE*[AB].txt | wc -l 그렇게 해서 출력은 처리된 파일 이름이 아니라 처리된 파일의 숫자만 출력된다. Nelle의 스크립트에서 주목할 한가지는 스크립트를 실행하는 사람이 무슨 파일을 처리할지를 결정하게 하는 것이다. 스크립트를 다음과 같이 작성할 수 있다: # Site A, Site B 데이터 파일에 대한 통계량 계산 for datafile in NENE*[AB].txt do echo $datafile bash goostats $datafile stats-$datafile done 장점은 이 스크립트는 항상 올바른 파일만을 선택한다: ‘Z’파일을 제거했는지 기억할 필요가 없다. 단점은 항상 이 파일만을 선택한다는 것이다 — 모든 파일(’Z’를 포함하는 파일), 혹은 남극 동료가 생성한 ’G’, ‘H’ 파일에 대해서 스크립트를 편집하지 않고는 실행할 수 없다. 좀더 모험적이라면, 스크립트를 변경해서 명령-라인 매개변수를 검증해서 만약 어떠한 매개변수도 제공되지 않았다면 NENE*[AB].txt을 사용하도록 바꿀수도 있다. 물론, 이런 접근법은 유연성과 복잡성 사이에 서로 대립되는 요소 사이의 균형, 즉 트레이드오프(trade-off)를 야기한다. 쉘 스크립트의 변수 molecules 디렉토리에서, 다음 명령어를 포함하는 script.sh라는 쉘스크립트가 있다고 가정한다: head -n $2 $1 tail -n $3 $1 molecules 디렉토리에서 다음 명령어를 타이핑한다: bash script.sh &#39;*.pdb&#39; 1 1 다음 출력물 결과 중 어떤 결과가 나올 것으로 예상하나요? 1. molecules 디렉토리에 있는 *.pdb 확장자를 갖는 각 파일의 첫번줄과 마지막줄 사이 모든 줄을 출력. 2. molecules 디렉토리에 있는 *.pdb 확장자를 갖는 각 파일의 첫번줄과 마지막 줄을 출력. 3. molecules 디렉토리에 있는 각 파일의 첫번째와 마지막 줄을 출력. 4. *.pdb 를 감싸는 인용부호로 오류가 발생. 해답 정답은 2. 특수 변수 $1, $2, $3은 스크립트에 명령라인 인수를 나타낸다. 따라서 실행되는 명령어는 다음과 같다: $ head -n 1 cubane.pdb ethane.pdb octane.pdb pentane.pdb propane.pdb $ tail -n 1 cubane.pdb ethane.pdb octane.pdb pentane.pdb propane.pdb 인용부호로 감싸져서 쉘이 '*.pdb'을 명령라인에서 확장하지 않는다. 이를 테면, 스크립트의 첫번째 인자는 '*.pdb'으로 전달되어 스크립트 내부에서 확장되어 head와 tail 명령어를 실행시키게 된다. 주어진 확장자 내에서 가장 긴 파일을 찾아낸다 인자로 디렉토리 이름과 파일이름 확장자를 갖는 longest.sh이름의 쉘 스크립트를 작성해서, 그 디렉토리에서 해당 확장자를 가지는 파일 중에 가장 긴 줄을 가진 파일이름을 화면에 출력하세요. 예를 들어, 다음은 $ bash longest.sh /tmp/data pdb /tmp/data 디렉토리에 .pdb 확장자를 가진 파일 중에 가장 긴 줄을 가진 파일이름을 화면에 출력한다. 해답 # 쉘 스크립트는 다음 두 인자를 갖는다: # 1. 디렉토리명 # 2. 파일 확장자 # 해당 디렉토리에서 파일 확장자와 매칭되는 가장 길이가 긴 파일명을 출력한다. wc -l $1/*.$2 | sort -n | tail -n 2 | head -n 1 스크립트 독해 능력 이번 문제에 대해, 다시 한번 data-shell/molecules 디렉토리에 있다고 가정한다. 지금까지 생성한 파일에 추가해서 디렉토리에는 .pdb 파일이 많다. 만약 다음 행을 담고 있는 스크립트로 bash example.sh *.dat을 실행할 때, example.sh 이름의 스크립트가 무엇을 수행하는지 설명하세요: # 스크립트 1 echo *.* # 스크립트 2 for filename in $1 $2 $3 do cat $filename done # 스크립트 3 echo $@.pdb 해답 스크립트 1은 파일명에 구두점(.)이 포함된 모든 파일을 출력한다. 스크립트 2는 파일 확장자가 매칭되는 첫 3 파일의 내용을 화면에 출력시킨다. 쉘이 인자를 example.sh 스크립트에 전달하기 전에 와일드카드를 확장시킨다. 스크립트 3은 .pdb로 끝나는 스크립트의 모든 인자(즉, 모든 .pdb 파일)를 화면에 출력시킨다. cubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb.pdb 스크립트 디버깅 Nelle 컴퓨터 north-pacific-gyre/2012-07-03 디렉토리의 do-errors.sh 파일에 다음과 같은 스크립트가 저장되었다고 가정하자. # Calculate stats for data files. for datafile in &quot;$@&quot; do echo $datfile bash goostats $datafile stats-$datafile done 다음을 실행하게 되면: $ bash do-errors.sh NENE*[AB].txt 출력결과는 아무 것도 없다. 원인을 파악하고자 -x 선택옵션을 사용해서 스크립트를 재실행시킨다: bash -x do-errors.sh NENE*[AB].txt 보여지는 출력결과는 무엇인가? 몇번째 행에서 오류가 발생했는가? &gt; 해답 &gt; -x 플래그를 사용하면 디버그 모드에서 bash를 실행시키게 된다. &gt; 각 명령어를 행단위로 실행시키고 출력결과를 보여주는데, 오류를 특정하는데 도움이 된다. &gt; 이번 예제에서 echo 명령어는 아무 것도 출력하지 않는 것을 볼 수 있다. &gt; 루프 변수명의 철자가 잘못 타이핑 되어 있다. &gt; datfile 변수가 존재하지 않아서 빈 문자열이 반환되었다. "],["shell-find.html", "7 . 파일, 문자, 디렉토리 등 찾기", " 7 . 파일, 문자, 디렉토리 등 찾기 “구글(Google)”을 “검색”을 의미하는 동사로 많은 분들이 사용하는 것처럼 유닉스 프로그래머는 “grep”을 동일하게 사용한다. grep은 “global/regular expression/print(전역/정규표현식/출력)”의 축약어로 초기 유닉스 편집기에서 일반적인 일련의 연산작업을 뜻한다. 매우 유용한 명령-라인 프로그램 이름이기도 하다. grep은 패턴과 매칭되는 파일의 행을 찾아 화면에 뿌려준다. 예제 파일로, Salon 잡지 1988년 경쟁부문에서 하이쿠(haiku, 일본의 전통 단시) 3개를 담고 있는 파일을 사용례로 활용할 것이다. 이 예제 파일을 갖는 “writing” 하위 디렉토리에서 작업을 할 것이다: $ cd $ cd Desktop/data-shell/writing $ cat haiku.txt The Tao that is seen Is not the true Tao, until You bring fresh toner. With searching comes loss and the presence of absence: &quot;My Thesis&quot; not found. Yesterday it worked Today it is not working Software is like that. 영원히 혹은 5년 원본 하이쿠에 링크를 걸지 않았는데 이유는 Salon 사이트에 더 이상 보이는 것 같지 않아서다. Jeff Rothenberg가 말했듯이, “디지털 정보는 어느 것이 먼저 오든 영원한 영속성을 가지거나 혹은 5년이다.” 운이 좋은 경우 인기 콘텐트는 종종 백업된다. 단어 “not”을 포함하는 행을 찾아 봅시다: $ grep not haiku.txt Is not the true Tao, until &quot;My Thesis&quot; not found Today it is not working 여기서 not이 찾고자 하는 패턴이다. grep 명령어는 파일을 뒤져 지정된 패턴과 매칭되는 것을 찾아낸다. 명령어를 사용하려면 grep을 타이핑하고 나서, 찾고자 하는 패턴을 지정하고 나서 검색하고자 하는 파일명(혹은 파일 다수)를 지정하면 된다. 출력값으로 “not”을 포함하는 파일에 행이 3개 있다. 다른 패턴을 시도해 보자. 이번에는 “The”이다. $ grep The haiku.txt The Tao that is seen &quot;My Thesis&quot; not found. 이번에는 문자 “The”를 포함한 행이 두줄 출력되었다. 하지만, 더 큰 단어 안에 포함된 단어(“Thesis”)도 함께 출력된다. grep명령어에 -w 옵션을 주면, 단어 경계로 매칭을 제한해서, “day” 단어만을 가진 행만이 화면에 출력된다. 매칭을 “The” 단어 자체만 포함하는 행만 매칭시키려면, grep명령어에 -w 옵션을 주게 되면, 단어 경계로 매칭을 제한시킨다. $ grep -w The haiku.txt The Tao that is seen “단어 경계”는 행의 시작과 끝이 포함됨에 주의한다. 그래서 공백으로 감싼 단어는 해당사항이 없게 된다. 때때로, 단어 하나가 아닌, 문구를 찾고자 하는 경우도 있다. 인용부호 내부에 문구를 넣어 grep으로 작업하는 것이 편하다. $ grep -w &quot;is not&quot; haiku.txt Today it is not working 지금까지 단일 단어 주위를 인용부호로 감쌀 필요가 없다는 것을 알고 있다. 하지만, 단어 다수를 검색할 때 인용부호를 사용하는 것이 유용하다. 이렇게 하면, 검색어(term) 혹은 검색 문구(phrase)와 검색 대상이 되는 파일 사이를 더 쉽게 구별하는데 도움을 준다. 나머지 예제에서는 인용부호를 사용한다. 또다른 유용한 옵션은 -n으로, 매칭되는 행에 번호를 붙여 출력한다: $ grep -n &quot;it&quot; haiku.txt 5:With searching comes loss 9:Yesterday it worked 10:Today it is not working 상기에서 5, 9, 10번째 행이 문자 “it”를 포함함을 확인할 수 있다. 다른 유닉스 명령어와 마찬자기로 옵션(즉, 플래그)을 조합할 수 있다. 단어 “the”를 포함하는 행을 찾아보자. “the”를 포함하는 행을 찾는 -w 옵션과 매칭되는 행에 번호를 붙이는 -n을 조합할 수 있다: $ grep -n -w &quot;the&quot; haiku.txt 2:Is not the true Tao, until 6:and the presence of absence: 이제 -i 옵션을 사용해서 대소분자 구분없이 매칭한다: $ grep -n -w -i &quot;the&quot; haiku.txt 1:The Tao that is seen 2:Is not the true Tao, until 6:and the presence of absence: 이제, -v 옵션을 사용해서 뒤집어서 역으로 매칭을 한다. 즉, 단어 “the”를 포함하지 않는 행을 출력결과로 한다. $ grep -n -w -v &quot;the&quot; haiku.txt 1:The Tao that is seen 3:You bring fresh toner. 4: 5:With searching comes loss 7:&quot;My Thesis&quot; not found. 8: 9:Yesterday it worked 10:Today it is not working 11:Software is like that. grep 명령어는 옵션이 많다. grep 명령어에 대한 도움을 찾으려면, 다음 명령어를 타이핑한다: $ grep --help Usage: grep [OPTION]... PATTERN [FILE]... Search for PATTERN in each FILE or standard input. PATTERN is, by default, a basic regular expression (BRE). Example: grep -i &#39;hello world&#39; menu.h main.c Regexp selection and interpretation: -E, --extended-regexp PATTERN is an extended regular expression (ERE) -F, --fixed-strings PATTERN is a set of newline-separated fixed strings -G, --basic-regexp PATTERN is a basic regular expression (BRE) -P, --perl-regexp PATTERN is a Perl regular expression -e, --regexp=PATTERN use PATTERN for matching -f, --file=FILE obtain PATTERN from FILE -i, --ignore-case ignore case distinctions -w, --word-regexp force PATTERN to match only whole words -x, --line-regexp force PATTERN to match only whole lines -z, --null-data a data line ends in 0 byte, not newline Miscellaneous: ... ... ... grep 사용 다음중 어떤 명령어가 다음 결과를 만들어낼까요? and the presence of absence: grep \"of\" haiku.txt grep -E \"of\" haiku.txt grep -w \"of\" haiku.txt grep -i \"of\" haiku.txt 해답 정답은 3번. -w 플래그는 온전한 단어만 매칭되는 것을 찾기 때문이다. 와일드카드(Wildcards) grep의 진정한 힘은 옵션에서 나오지 않고; 패턴에 와일드카드를 포함할 수 있다는 사실에서 나온다. (기술적 명칭은 정규 표현식(regular expressions)이고, “grep” 명령어의 “re”가 정규표현식을 나타낸다.) 정규 표현식은 복잡하기도 하지만 강력하기도 하다. 복잡한 검색을 하고자 한다면, 소프트웨어 카펜트리 웹사이트에서 수업내용을 볼 수 있다. 맛보기로, 다음과 같이 두번째 위치에 ’o’를 포함한 행을 찾을 수 있다: $ grep -E &#39;^.o&#39; haiku.txt You bring fresh toner. Today it is not working Software is like that. -E 플래그를 사용해서 인용부호 안에 패턴을 넣어서 쉘이 해석하는 것을 방지한다. (예를 들어, 패턴에 ‘*’이 포함된다면, grep을 실행되기 전에 쉘이 먼저 전개하려 할 것이다.) 패턴에서’^‘은 행의 시작에 매칭을 고정시키는 역할을 한다.’.’은 한 문자만 매칭하고(쉘의 ’?’과 마찬가지로), ’o’는 실제 영문 ’o’와 매칭된다. 개체(species) 추적하기 정훈이는 한 디렉토리에 수백개 데이터 파일이 있는데, 형태는 다음과 같다: 2013-11-05,deer,5 2013-11-05,rabbit,22 2013-11-05,raccoon,7 2013-11-06,rabbit,19 2013-11-06,deer,2 명령라인에서 첫번째 인자로 개체(species), 두번째 인자로 디렉토리를 인자로 받는 쉘스크립트를 작성하고자 한다. 스크립트는 일자별로 관측된 개체수를 담아 species.txt 라는 파일로 저장하면 된다. 2013-11-05,22 2013-11-06,19 스크립트를 작성하는데 다음에 나온 명령어를 적절한 순서로 파이프에 연결시키면 된다: cut -d : -f 2 &gt; | grep -w $1 -r $2 | $1.txt cut -d , -f 1,3 힌트: man grep 명령어를 사용해서 디렉토리에서 재귀적으로 텍스트를 grep하는지 찾아본다. man cut 명령어를 사용해서 한줄에 필드 하나 이상을 선택하는 방법을 살펴본다. data-shell/data/animal-counts/animals.txt 파일이 예제 파일로 제공되고 있다: &gt; 해답 &gt; &gt; &gt; grep -w $1 -r $2 | cut -d : -f 2 | cut -d , -f 1,3 &gt; $1.txt &gt; &gt; &gt; 상기 쉘 스크립트를 다음과 같이 호출하면 된다: &gt; &gt; &gt; $ bash count-species.sh bear . &gt; 작은 아낙네(Little Women) Louisa May Alcott가 지은 작은 아낙네(Little Women)를 친구과 함께 읽고 논쟁중이다. 책에는 Jo, Meg, Beth, Amy 네자매가 나온다. 친구가 Jo가 가장 많이 언급되었다고 생각한다. 하지만, 나는 Amy라고 확신한다. 운좋게도, 소설의 전체 텍스트를 담고 있는 LittleWomen.txt 파일이 있다(data-shell/writing/data/LittleWomen.txt). for 루프를 사용해서, 네자매 각각이 얼마나 언급되었는지 횟수를 개수할 수 있을까? 힌트: 한가지 해결책은 grep, wc, | 명령어를 동원하는 것이지만, 다른 해결책으로 grep 옵션을 활용하는 것도 있다. There is often more than one way to solve a programming task, so a particular solution is usually chosen based on a combination of yielding the correct result, elegance, readability, and speed. 프로그래밍 문제를 푸는 방식은 한가지 이상 존재한다. 따라서, 올바른 결과를 도출해야 하고, 우아하고(elegance), 가독성이 좋고(readability), 속도를 다 함께 고려하여 선택한다. 해답 for sis in Jo Meg Beth Amy do echo $sis: grep -ow $sis LittleWomen.txt | wc -l done 또다른 해법으로, 다소 떨어지는 해답은 다음과 같다: for sis in Jo Meg Beth Amy do echo $sis: grep -ocw $sis LittleWomen.txt done 이 해답이 다소 뒤떨어지는 이유는 grep -c는 매칭되는 행 숫자만 출력하기 때문이다. 행마다 매칭되는 것이 하나 이상 되는 경우, 이 방법으로 매칭되는 전체 갯수는 낮아질 수 있기 때문이다. grep이 파일의 행을 찾는 반면에, find 명령어는 파일 자체를 검색한다. 다시, find 명령어는 정말 옵션이 많다; 가장 간단한 것이 어떻게 동작하는지 시연하기 위해, 다음과 같은 디렉토리 구조를 사용할 것이다. Find 찾기 예제 파일 구조 Nelle의 writing 디렉토리는 haiku.txt로 불리는 파일 하나와, 하위 디렉토리 4개를 포함한다. thesis 디렉토리는 슬프게고 아무것도 담겨있지 않는 빈 파일 empty-draft.md만 있고, data 디렉토리는 LittleWomen.txt, one.txt과 two.txt 총 파일 3개를 포함하고, tools 디렉토리는 format과 stats 프로그램을 포함하고, oldtool 파일을 담고 있는 old 하위 디렉토리로 구성되어 있다. 첫 명령어로, find .을 실행하자. $ find . . ./data ./data/one.txt ./data/LittleWomen.txt ./data/two.txt ./tools ./tools/format ./tools/old ./tools/old/oldtool ./tools/stats ./haiku.txt ./thesis ./thesis/empty-draft.md 항상 그렇듯이, . 자체가 의미하는 바는 현재 작업 디렉토리로, 검색을 시작하는 디렉토리가 된다. find 출력결과로 현재 작업 디렉토리 아래 있는 모든 파일, 그리고 디렉토리명이 나온다. 출력결과가 쓸모없어 보이지만, find 명령어에 선택옵션이 많아서 출력결과를 필터할 수 있다. 이번 학습에서는 그중 일부만 다뤄볼 것이다. 첫번째 선택옵션은 -type d로 “디렉토리인 것들”을 의미한다. 아니나 다를까, find의 출력에는 (.을 포함해서) 디렉토리 5개가 나온다. $ find . -type d ./ ./data ./thesis ./tools ./tools/old find 명령어가 찾는 객체가 특별한 순서를 갖고 출력되는 것이 아님에 주목한다. -type d에서 -type f로 옵션을 변경하면, 대신에 모든 파일 목록이 나온다: $ find . -type f ./haiku.txt ./tools/stats ./tools/old/oldtool ./tools/format ./thesis/empty-draft.md ./data/one.txt ./data/LittleWomen.txt ./data/two.txt 이제 이름으로 매칭을 하자: $ find . -name *.txt ./haiku.txt 모든 텍스트 파일을 찾기를 기대하지만, 단지 ./haiku.txt만을 화면에 출력한다. 문제는 명령문을 실행하기 전에, *같은 와일드카드 문자를 쉘이 전개하는 것이다. 현재 디렉토리에서 *.txt을 전개하면 haiku.txt이 되기 때문에, 실제 실행하는 명령어는 다음과 같다: $ find . -name haiku.txt find 명령어는 사용자가 요청한 것만 수행한다; 사용자는 방금전에 잘못된 것을 요청했다. 사용자가 원하는 것을 얻기 위해서, grep을 가지고 작업했던 것을 수행하자. 단일 인용부호에 *.txt을 넣어서 쉘이 와일드카드 *을 전개하지 못하게 한다. 이런 방식으로, find 명령어는 확장된 파일명 haiku.txt이 아닌, 실제로 *.txt 패턴을 얻는다: $ find . -name &#39;*.txt&#39; ./data/one.txt ./data/LittleWomen.txt ./data/two.txt ./haiku.txt 목록(Listing) vs. 찾기(Finding) 올바른 옵션이 주어진 상태에서, ls와 find 명령어를 사용해서 비슷한 작업을 수행하도록 만들 수 있다. 하지만, 정상 상태에서 ls는 가능한 모든 것을 목록으로 출력하는 반면에, find는 어떤 특성을 가진 것을 검색하고 보여준다는 점에서 차이가 난다. 앞에서 언급했듯이, 명령-라인(command-line)의 힘은 도구를 조합하는데 있다. 파이프로 어떻게 조합하는지를 살펴봤고; 또 다른 기술을 살펴보자. 방금 보았듯이, find . -name '*.txt' 명령어는 현재 디렉토리 및 하위 디렉토리에 있는 모든 텍스트 파일 목록을 보여준다. 어떻게 하면 wc -l 명령어와 조합해서 모든 파일의 행을 개수할 수 있을까? 가장 간단한 방법은 $() 내부에 find 명령어를 위치시키는 것이다: $ wc -l $(find . -name &#39;*.txt&#39;) 11 ./haiku.txt 300 ./data/two.txt 21022 ./data/LittleWomen.txt 70 ./data/one.txt 21403 total 쉘이 상기 명령어를 실행할 때, 처음 수행하는 것은 $() 내부를 무엇이든 실행시키는 것이다. 그리고 나서 $() 표현식을 명령어의 출력 결과로 대체한다. find의 출력 결과가 파일 이름 4개, 즉, ./data/one.txt, ./data/LittleWomen.txt, ./data/two.txt, ./haiku.txt라서, 쉘은 다음과 같이 명령문을 구성하게 된다: $ wc -l ./data/one.txt ./data/LittleWomen.txt ./data/two.txt ./haiku.txt 상기 명령문이 사용자가 원하는 것이다. 이러한 확장이 *과 ? 같은 와일드카드로 확장할 때, 정확하게 쉘이 수행하는 것이다. 하지만 자신의 “와일드카드”로 사용자가 원하는 임의 명령어를 사용해보자. find와 grep을 함께 사용하는 것이 일반적이다. 먼저 find가 패턴을 매칭하는 파일을 찾고; 둘째로 grep이 또 다른 패턴과 매칭되는 파일 내부 행을 찾는다. 예제로 다음에 현재 부모 디렉토리에서 모든 .pdb 파일에 “FE” 문자열을 검색해서, 철(FE) 원자를 포함하는 PDB파일을 찾을 찾을 수 있다: $ grep &quot;FE&quot; $(find .. -name &#39;*.pdb&#39;) ../data/pdb/heme.pdb:ATOM 25 FE 1 -0.924 0.535 -0.518 매칭후 빼내기 grep 명령어의 -v 옵션은 패턴 매칭을 반전시킨다. 패턴과 매칭하지 않는 행만 출력시킨다. 다음 명령어 중에서 어느 것이 /data 폴더에 s.txt로 끝나는 (예로, animals.txt 혹은 planets.txt), 하지만 net 단어는 포함하지 않게 모든 파일을 찾아낼까요? 정답을 생각해냈다면, data-shell 디렉토리에서 다음 명령어를 시도해본다. find data -name '*s.txt' | grep -v net find data -name *s.txt | grep -v net grep -v \"temp\" $(find data -name '*s.txt') None of the above. 해답 정답은 1. 매칭 표현식을 인용부호로 감싸서 쉘이 전개하는 것을 방지시킨 상태로 find 명령어에 전개시킨다. 2번은 틀렸는데, 이유는 쉘이 find 명령어에 와일드카드를 전달하는 대신에 *s.txt 을 전개하기 때문이다. 3번은 틀렸는데, 이유는 파일명을 찾는 대신에 “temp”와 매칭되지 않는 행을 갖는 파일을 검색하기 때문이다. 바이너리 파일(Binary File) 텍스트 파일에 존재하는 것을 찾는 것에만 배타적으로 집중했다. 데이터가 만약 이미지로, 데이터베이스로, 혹은 다른 형식으로 저장되어 있다면 어떨까? 한가지 선택사항은 grep 같은 툴을 확장해서 텍스트가 아닌 형식도 다루게 한다. 이 접근법은 발생하지도 않았고, 아마도 그러지 않을 것이다. 왜냐하면 지원할 형식이 너무나도 많은 존재하기 때문이다. 두번째 선택지는 데이터를 텍스트로 변환하거나, 데이터에서 텍스트같은 비트를 추출하는 것이다. 아마도 가장 흔한 접근법이 (정보를 추출하기 위해서) 각 데이터 형식마다 도구 하나만 개발하면 되기 때문이다. 한편으로, 이 접근법은 간단한 것을 쉽게 할 수 있게 한다. 부정적인 면으로 보면, 복잡한 것은 일반적으로 불가능하다. 예를 들어, grep을 이리 저리 사용해서 이미지 파일에서 X와 Y 크기를 추출하는 프로그램을 작성하기는 쉽다. 하지만, 공식을 담고 있는 엑셀 같은 스프레드쉬트 셀에서 값을 찾아내는 것을 어떻게 작성할까? 세번째 선택지는 쉘과 텍스트 처리가 모두 한계를 가지고 있다는 것을 인지하고, 대신에 (R 혹은 파이썬 같은) 프로그램 언어를 사용하는 것이다. 이러한 시점이 왔을 때 쉘에서 너무 고생하지 마세요: R 혹은 파이썬을 포함한 많은 프로그래밍 언어가 많은 아이디어를 여기에서 가져왔다. 모방은 또한 칭찬의 가장 충심어린 형태이기도 하다. 유닉스 쉘은 지금 사용하는 대부분의 사람보다 나이가 많다. 그토록 오랫동안 생존한 이유는 지금까지 만들어진 가장 생산성이 높은 프로그래밍 환경 중 하나 혹은 아마도 가장 생산성 높은 프로그래밍 환경이기 때문이다. 구문이 암호스러울 수도 있지만, 숙달한 사람은 다양한 명령어를 대화하듯이 실험하고 나서, 본인 작업을 자동화하는데 학습한 것을 사용한다. 그래픽 사용자 인터페이스(GUI)가 처음에는 더 좋을 수 있지만, 여전히 쉘이 최강이다. 화이트헤드(Alfred North Whitehead) 박사가 1911년 썼듯이 “문명은 생각없이 수행할 수 있는 중요한 작업의 수를 확장함으써 발전한다. (Civilization advances by extending the number of important operations which we can perform without thinking about them.)” find 파이프라인 독해 능력 다음 쉘 스크립트에 대해서 무슨 것을 수행하는지 짧은 설명문을 작성하세요. wc -l $(find . -name &#39;*.dat&#39;) | sort -n 해답 현재 디렉토리에서 .dat 확장자를 갖는 모든 파일을 찾아내시오. 파일 각각이 담고 있는 행을 개수한다. 앞선 단계에서 나온 출력결과를 숫자로 인식해서 정렬시킨다. 다른 특성을 갖는 파일 찾아내기 find 명령어에 “test”로 알려진 다른 기준을 제시해서 특정 속성을 갖는 파일을 지정할 수 있다. 예를 들어, 파일 생성시간, 파일 크기, 파일권한, 파일소유. man find 명령어를 사용해서 이를 살펴보고 나서, 지난 24시간 이내 ahmed 사용자가 변경시킨 모든 파일을 찾는 명령어를 적성한다. 힌트 1: -type, -mtime, -user 플래그 세개를 모두 사용해야 한다. 힌트 2: -mtime 값을 음수를 지정해야 된다 — 왜일까? 해답 Nelle의 홈이 작업 디렉토리라고 가정하고, 다음 명령어를 타이핑한다: $ find ./ -type f -mtime -1 -user ahmed "],["git.html", "8 . 자동화된 버젼제어", " 8 . 자동화된 버젼제어 누군가 무엇을 했는지, 언제 했는지를 추적하기 위해서, 버젼제어를 어떻게 사용할 수 있는지 탐색해보자. 다른 사람과 협업을 하지 않더라도, 자동화된 버젼제어가 다음 상황보다 훨씬 더 낫다: 이전에 상기와 같은 상황에 처했었다: 같은 문서에 대해서 거의 동일한 다수 버젼을 관리하는 것은 우스워 보인다. 일부 워드프로세서가 이런 상황을 좀더 잘 처리하도록 하는 기능이 있다. 예를 들어, 마이크로소프트 워드 “변경사항 추적(Track Changes)” 혹은 구글 닥스(Google Docs)의 버젼 이력이 그것이다. 버젼제어 시슽메은 문서의 기본 버젼으로 시작하고 나서, 각 단계마다 변경한 이력을 저장한다. 테이프로 생각하면 쉽다: 테이프를 되감으면, 문서 시작한 지점으로 가고, 각 변경사항을 다시 돌리면 가장 최근 버젼이 된다. 변경사항이 순차적으로 저장된다. 변경사항을 문서 그자체로부터 떨어진 것으로 생각하면, 동일 기반 문서에 다른 변경사항을 “재생(playback)”하고, 다른 문서 버젼을 관리하는 것으로 간주할 수 있다. 예를 들어, 사용자 두명이 같은 문서에 독립적인 변경 작업을 수행할 수 있다. 다른 버전이 저장될 수도 있다. 만약 충돌나지 않으면, 심지어 동일 문서에서 두가지 변경사항을 작업할 수도 있다. 버전 다수가 병합될 수도 있다. 버젼제어 시스템은 사용자를 대신해서 변경사항을 기록하고, 파일 버젼을 생성하고 파일병합하는데 유용한 도구다. 버젼제어 시스템은 어떤 변경사항을 다음 버젼에 반영(커밋(commit))으로 불림)할지 결정하는 할 수 있게 하고, 커밋에 관한 유용한 메타정보를 보관한다. 특정 프로젝트와 프로젝트 메타정보에 대한 완전한 커밋이력은 저장소(repository)에 보관된다. 저장소는 협업하는 여러 동료 컴퓨터에 걸쳐 동기화될 수 있다. 버젼제어 시스템의 오랜 역사 자동화된 버젼제어 시스템이 새로운 것은 전혀 아니다. 1980년부터 RCS, CVS, Subversion 같은 도구가 존재했고, 많은 대기업에서 사용되고 있다. 하지만, 다양한 기능의 한계로 인해서 이들 중 다수는 이제 레거시 시스템(legacy system)으로 간주된다. 최근에 등장한 도구 Git과 Mercurial은 분산(distributed) 기능을 제공한다. 저장소를 굳이 중앙 서버에 둘 필요가 없다는 의미다. 이러한 최신 시스템에는 동시간에 동일한 파일에 다수 저작자가 작업하는 것을 가능하게 하는 강력한 병합(merge) 도구도 내장하고 있다. 논문 작성 논문을 작성하면서 정말 멋진 문단을 초안을 작성했지만, 나중에 망치게 되었다고 상상해 보자. 어떻게 정말 멋진 맺음말 버전이 포함된 문서를 되살릴 수 있을까? 가능하기도 할까? 공저자가 5명이라고 상상해보자. 공저자가 논문에 반영한 변경사항과 코멘트를 어떻게 관리할 수 있을까? 마이크로소프트 워드나 리브레오피스 Writer를 사용하는 경우, Track Changes 옵션을 사용해서 변경한 것을 반영하게 되면 어떻게 될까? 이러한 변경사항에 대한 이력은 갖고 있는가? "],["git-setup.html", "9 . Git 구축 및 설정", " 9 . Git 구축 및 설정 처음 Git를 새로운 컴퓨터에 사용할 때, 몇가지 설정이 필요하다. 다음에 Git을 시작할 때, 설정해야 되는 몇가지 사례가 나와있다: 이름과 전자우편 주소 선호하는 텍스트 편집기 선정 전역(즉, 모든 프로젝트)으로 이런 설정을 할지 여부 명령라인에서 Git 명령어는 다음과 같이 작성된다; git verb options, 즉, git 동사 선택옵션. verb 가 실제로 수행하고자 하는 명령어가 되고, options는 verb에 필요할지도 모르는 추가 선택옵션 정보가 된다. 다음에 Dracula가 새로 구입한 노트북에 환경설정하는 방법이 나와있다: $ git config --global user.name &quot;Vlad Dracula&quot; $ git config --global user.email &quot;vlad@tran.sylvan.ia&quot; Dracula 대신에 본인 이름과 본인 전자우편 주소를 사용합니다. 사용자명과 전자우편 주소는 후속 Git 활동과 연관된다. 이것이 의미하는 바는 GitHub, BitBucket, GitLab, 혹은 Git 호스트 서버에 푸쉬하는 어떤 변경사항도 사용자명과 전자우편 주소를 담게되는 것을 의미한다. 줄마침(Line Endings) 다른 키보트 타이핑과 마찬가지로, 키보드로 Return를 치게 되면, 컴퓨터는 엔터값을 문자로 인코딩한다. 줄마침을 표현하기 위해서 운영체제마다 별도 문자를 사용한다. (개행 혹은 줄중단, 영어로 newline 혹은 line breaks를 들어봤을 수도 있다.) Git이 파일을 비교하는데 이러한 문자를 사용하기 때문에, 운영체제가 다른 컴퓨텅에서 파일을 편집할 때 예기치 않은 이슈가 발생될 수 있다. 이 문제는 금번 학습 범위를 넘어서는 것이지만, on this GitHub page 웹페이지에서 좀더 자세한 정보를 얻을 수 있다. Git에서 줄마침을 인식하고 인코딩하는 방식을 변경하려면, git config에 core.autocrlf 명령을 사용한다. 권장되는 설정은 다음과 같다: 맥OS와 리눅스: $ git config --global core.autocrlf input 윈도우: $ git config --global core.autocrlf true 이번 학습에서, GitHub을 사용하게 되는데, 사용되는 전자우편주소는 GitHub 계정을 설정할 때 사용하는 것과 같은 것이 되어야 한다. 만약, 개인정보에 대해 걱정이 된다면, GitHub’s instructions for keeping your email address private을 참조한다. GitHub에서 사적인 개인 전자우편주소를 선택하기로 했다면, user.email에 동일한 전자우편주소를 사용한다. 즉, username을 GitHub의 설정된 것으로 바꿔놓아 username@users.noreply.github.com게 된다. 나중에 git config 명령어를 사용해서 전자우편 주소를 변경할 수 있다. Dracula도 자신이 선호하는 텍스트 편집기를 설정해야 하는데, 다음 표를 참조한다: 편집기 환경설정 명령어 Atom $ git config --global core.editor \"atom --wait\" nano $ git config --global core.editor \"nano -w\" BBEdit (Mac, with command line tools) $ git config --global core.editor \"bbedit -w\" Sublime Text (Mac) $ git config --global core.editor \"/Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl -n -w\" Sublime Text (Win, 32-bit install) $ git config --global core.editor \"'c:/program files (x86)/sublime text 3/sublime_text.exe' -w\" Sublime Text (Win, 64-bit install) $ git config --global core.editor \"'c:/program files/sublime text 3/sublime_text.exe' -w\" Notepad++ (Win, 32-bit install) $ git config --global core.editor \"'c:/program files (x86)/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\" Notepad++ (Win, 64-bit install) $ git config --global core.editor \"'c:/program files/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\" Kate (Linux) $ git config --global core.editor \"kate\" Gedit (Linux) $ git config --global core.editor \"gedit --wait --new-window\" Scratch (Linux) $ git config --global core.editor \"scratch-text-editor\" Emacs $ git config --global core.editor \"emacs\" Vim $ git config --global core.editor \"vim\" 원할 때마다 Git에 사용할 텍스트 편집기 환경설정을 다시 할 수 있다. Vim 나가기 다수 프로그램에서 Vim이 기본설정된 편집기다. Vim을 예전에 사용한 적이 없고, 변경사항을 저장하지 않고 세션을 빠져나가고자 한다면, Esc 다음에, :q!를 타이핑하고 나서 Return를 친다. 변경사항을 저장하고 나가려면, Esc 다음에, :wq를 타이핑하고 Return을 친다. 앞서 실행한 상기 명령어는 한번만 실행하면 된다: --global 플래그는 Git으로 하여금 해당 컴퓨터에 본인 계정의 모든 프로젝트에 환경설정한 것을 사용하도록 한다. 본인이 설정한 환경설정 내용은 언제라도 다음 명령어를 입력하여 확인할 수 있다: $ git config --list 원하는 만큼 환경설정을 바꿀 수도 있다: 편집기를 바꾸거나 전자우편주소를 갱신할 때 동일한 명령어를 사용하면 된다. 프록시(Proxy) 일부 네트워크에서 proxy를 사용할 필요가 있다. 이런 경우, Git에게 프록시에 대해 일러줘야 한다: $ git config --global http.proxy proxy-url $ git config --global https.proxy proxy-url 프록시를 비활성화 하는 경우, 다음 명령어를 사용한다. $ git config --global --unset http.proxy $ git config --global --unset https.proxy Git 도움말과 매뉴얼 항상 기억할 것은 git 명령어를 잊은 경우, -h 선택옵션을 주어 명령어 목록을 볼 수 있고, --help를 사용해서 Git 매뉴얼도 이용할 수 있다: $ git config -h $ git config --help "],["git-create.html", "10 . 저장소 생성", " 10 . 저장소 생성 Git 환경설정이 완료되면, Git를 사용할 수 있다. 행성 착륙선을 화성에 보낼 수 있는지 조사를 하고 있는 늑대인간과 드라큘라 이야기를 계속해서 진행해 보자. motivatingexample 먼저 바탕화면(Desktop)에 작업할 디렉토리를 생성하고, 생성한 디렉토리로 이동하자: $ cd ~/Desktop $ mkdir planets $ cd planets 그리고 나서, planets을 저장소(repository)로 만든다 — 저장소는 Git이 파일에 대한 버젼정보를 저장하는 장소다: $ git init git init 명령어가 서브디렉토리(subdirectory)와 파일을 담고 있는 저장소를 생성하는데 주목한다 — planets 저장소 내부에 중첩된 별도 저장소를 생성할 필요는 없다. 또한, planets 디렉토리를 생성하고 저장소로 초기화하는 것은 완전히 서로 다른 과정이다. ls를 사용해서 디렉토리 내용을 살펴보면, 변한 것이 아무것도 없는 것처럼 보인다: $ ls 하지만, 모든 것을 보여주는 -a 플래그를 추가하면, Git은 planets 디렉토리 내부에 .git 로 불리는 숨겨진 디렉토리를 생성한 것을 볼 수 있다: $ ls -a . .. .git Git은 .git이라는 특별한 하위 디렉토리에 프로젝트에 대한 정보를 저장한다. 여기에는 프로젝트 디렉토리 내부에 위치한 모든 파일과 서브 디렉토리가 포함된다. 만약 .git를 삭제하면, 프로젝트 이력을 모두 잃어버리게 된다. 모든 것이 제대로 설정되었는지를 확인을 하려면, Git에게 다음과 같이 프로젝트 상태를 확인 명령어를 던진다: $ git status # On branch master # # Initial commit # nothing to commit (create/copy files and use &quot;git add&quot; to track) 다른 git 버전을 사용할 경우, 출력 결과물이 다소 다를 수도 있다. Git 저장소를 생성할 장소 (이미 생성한 프로젝트) 행성에 대한 정보를 추적하면서, 드라큘라는 달에 관한 정보도 추적하고자 한다. plantes 프로젝트와 관련된, 새로운 프로젝트 moons 를 시작한다. 늑대인간의 걱정에 불구하고, Git 저장소 내부에 또다른 Git 저장소를 생성하려고 다음 순서로 명령어를 입력해 나간다: $ cd ~/Desktop # 바탕화면 디렉토리로 되돌아 간다. $ cd planets # planets 디렉토리로 들어간다. $ ls -a # planets 디렉토리에 .git 서브 디렉토리가 있는지 확인한다. $ mkdir moons # planets/moons 서브 디렉토릴르 생성한다. $ cd moons # moons 서브 디렉토리로 이동한다. $ git init # Git 저장소를 moons 하위디렉토리에 생성한다. $ ls -a # 새로운 Git 저장소가 .git 하위 디렉토리에 있는지 확인한다. moons 서브 디렉토리에 저장된 파일을 추적하기 위해 moons 디렉토리 안에서 git init 명령을 실행해야 할까? 해답 아니다. moons 서브 디렉토리에 Git 저장소를 만들 필요는 없다. 왜냐하면, planets 저장소가 이미 모든 파일, 서브 디렉토리, planets 디렉토리 아래 서브 디렉토리 파일 모두를 추적하기 때문이다. 따라서, 달에 관한 모든 정보를 추정하는데, 드랴큘라는 planets 디렉토리 아래 moons 서브 디렉토리를 추가하는 것으로 충분하다. 추가적으로, 만약 Git 저장소가 중첩(nested)되면, Git 저장소는 서로 방해할 수 있다: 바깥 저장소가 내부 저장소 버전관리를 하게 된다. 따라서, 별도 디렉토리에 서로 다른 신규 Git 저장소를 생성하는게 최선이다. 디렉토리에 저장소가 서로 충돌하지 않도록 하려면, git status 출력물을 점검하면 된다. 만약, 다음과 같은 출력물이 생성되게 되면 신규 저장소를 생성하는 것이 권장된다: $ git status fatal: Not a git repository (or any of the parent directories): .git git init 실수 올바르게 고치기 늑대인간은 드라큘라에게 중첩된 저장소가 중복되어 불필요한 이유와 함께 향후 혼란을 야기할 수 있는 이유를 설명했다. 드라큘라는 중첩된 저장소를 제거하고자 한다. moons 서브 디렉토리에 마지막으로 날린 git init 명령어 실행취소를 어떻게 할 수 있을까? 해답 – 주의해서 사용바람! 이러한 사소한 실수를 원복하고자, 드라큘라는 planets 디렉토리에서 다음 명령어를 실행하여 .git 디렉토리를 제거하기만 하면 된다: $ rm -rf moons/.git 하지만, 주의한다! 디렉토리를 잘못 타이핑하게 되면, 보관해야하는 프로젝트 정보를 담고 있는 Git 이력 전체가 날아가게 된다. 따라서, pwd 명령어를 사용해서 현재 작업 디렉토리를 항상 확인한다. "],["git-change.html", "11 . 변경사항 추적", " 11 . 변경사항 추적 먼저 디렉토리 위치가 맞는 확인하자. planets 디렉토리에 위치해야 한다. $ pwd /home/vlad/Desktop/planets moons 디렉토리에 여전히 있다면, planets 디렉토로리 되돌아간다. $ pwd /home/vlad/Desktop/planets/moons $ cd .. 전진기지로서 화성의 적합성에 관한 기록을 담고 있는 mars.txt 파일을 생성한다. (파일 편집을 위해서 nano 편집기를 사용한다; 원하는 어떤 편집기를 사용해도 된다. 특히, 앞에서 전역으로 설정한 core.editor일 필요는 없다. 하지만, 파일을 새로 생성하거나 편집할 때 배쉬 명령어는 사용자가 선택한 편집기에 의존하게 된다.(nano일 필요는 없다.) 텍스트 편집기에 대한 환기로, The Unix Shell의 “Which Editor?” 부분을 참고한다. $ nano mars.txt mars.txt 파일에 다음 텍스트를 타이핑한다: Cold and dry, but everything is my favorite color mars.txt 파일은 이제 한 줄을 포함하게 되어서, 다음 명령어로 내용을 확인할 수 있다: $ ls mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color 다시 한번 프로젝트의 상태를 확인하고자 하면, 새로운 파일이 인지되었다고 Git이 일러준다: $ git status On branch master Initial commit Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) mars.txt nothing added to commit but untracked files present (use &quot;git add&quot; to track) “untracked files” 메시지가 의미하는 것은 Git가 추적하고 있지 않는 파일 하나가 디렉토리에 있다는 것이다. git add를 사용해서 Git에게 추적관리하라고 일러준다: $ git add mars.txt 그리고 나서, 올바르게 처리되었는지 확인한다: $ git status On branch master Initial commit Changes to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: mars.txt 이제 Git은 mars.txt 파일을 추적할 것이라는 것을 알고 있지만, 커밋으로 아직 저장소에는 어떤 변경사항도 기록되지 않았다. 이를 위해서 명령어 하나 더 실행할 필요가 있다: $ git commit -m &quot;Start notes on Mars as a base&quot; [master (root-commit) f22b25e] Start notes on Mars as a base 1 file changed, 1 insertion(+) create mode 100644 mars.txt git commit을 실행할 때, Git은 git add를 사용해서 저장하려고 하는 모든 대상을 받아서 .git 디렉토리 내부에 영구적으로 사본을 저장한다. 이 영구 사본을 커밋(commit) (혹은 수정(revision))이라고 하고, 짧은 식별자는 f22b25e이다. (여러분의 커밋번호의 짧은 식별자는 다를 수 있다.) -m (“message”를 위미) 플래그를 사용해서 나중에 무엇을 왜 했는지 기억에 도움이 될 수 있는 주석을 기록한다. -m옵션 없이 git commit을 실행하면, Git는 nano(혹은 처음에 core.editor에서 설정한 다른 편집기)를 실행해서 좀더 긴 메시지를 작성할 수 있다. 좋은 커밋 메시지(Good commit messages) 작성은 커밋으로 만들어진 간략한 (영문자 기준 50문자 이하) 변경사항 요약으로 시작된다. 일반적으로 메시지는 완전한 문장이 되어야 한다. 예를 들어, “If applied, this commit will” . 만약 좀더 상세한 사항을 남기려면, 요약줄 사이에 빈줄을 추가하고 추가적인 내역을 적는다. 추가되는 공간에 왜 변경을 하는지 사유를 남기고, 어떤 영향을 미치는지도 기록한다. 이제 git status를 시작하면: $ git status On branch master nothing to commit, working directory clean 모든 것이 최신 상태라고 보여준다. 최근에 작업한 것을 알고자 한다면, git log를 사용해서 프로젝트 이력을 보여주도록 Git에게 명령어를 보낸다: $ git log commit f22b25e3233b4645dabd0d81e651fe074bd8e73b Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 09:51:46 2013 -0400 Start notes on Mars as a base git log는 시간 역순으로 저장소의 모든 변경사항을 나열한다. 각 수정사항 목록은 전체 커밋 식별자(앞서 git commit 명령어로 출력한 짧은 문자와 동일하게 시작), 수정한 사람, 언제 생성되었는지, 커밋을 생성할 때 Git에 남긴 로그 메시지가 포함된다. 내가 작성한 변경사항은 어디있나? 이 시점에서 ls 명령어를 다시 실행하면, mars.txt 파일만 덩그러니 보게 된다. 왜냐하면, Git이 앞에서 언급한 .git 특수 디렉토리에 파일 변경 이력 정보를 저장했기 때문이다. 그래서 파일 시스템이 뒤죽박죽되지 않게 된다. (따라서, 옛 버젼을 실수로 편집하거나 삭제할 수 없다.) 이제 드라큘라가 이 파일에 정보를 더 추가했다고 가정하자. (다시 한번 nano편집기로 편집하고 나서 cat으로 파일 내용을 살펴본다. 다른 편집기를 사용할 수도 있고, cat으로 파일 내용을 꼭 볼 필요도 없다.) $ nano mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman git status를 실행하면, Git이 이미 알고 있는 파일이 변경되었다고 일러준다: $ git status On branch master Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: mars.txt no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 마지막 줄이 중요한 문구다: “no changes added to commit”. mars.txt 파일을 변경했지만, 아직 Git에게는 변경을 사항을 저장하려고 하거나 (git add로 수행), 저장소에 저장하라고 (git commit로 수행) 일러주지도 않았다. 이제 행동에 나서보자. 저장하기 전에 변경사항을 항상 검토하는 것은 좋은 습관이다. git diff를 사용해서 작업 내용을 두번 검증한다. git diff는 현재 파일의 상태와 가장 최근에 저장된 버젼의 차이를 보여준다: $ git diff diff --git a/mars.txt b/mars.txt index df0654a..315bf3a 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,2 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman 출력 결과가 암호같은데 이유는 한 파일이 주어졌을 때 다른 파일 하나를 어떻게 재구성하는지를 일러주는 patch와 편집기 같은 도구를 위한 일련의 명령어라서 그렇다. 만약 해당 내역을 조각내서 쪼개다면: 첫번째 행은 Git이 신규 파일과 옛 버젼 파일을 비교하는 유닉스 diff 명령어와 유사한 출력결과를 생성하고 있다. 두번째 행은 정확하게 Git이 파일 어느 버젼을 비교하는지 일러준다; df0654a와 315bf3a은 해당 버젼에 대해서 중복되지 않게 컴퓨터가 생성한 표식이다. 세번째와 네번째 행은 변경되는 파일 명칭을 다시한번 보여주고 있다. 나머지 행이 가장 흥미롭다. 실제 차이가 나는 것과 어느 행에서 발생했는지 보여준다. 특히 첫번째 열의 + 기호는 어디서 행이 추가 되었는지 보여준다. 변경사항 검토후에, 변경사항을 커밋(commit)하자. $ git commit -m &quot;Add concerns about effects of Mars&#39; moons on Wolfman&quot; $ git status On branch master Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: mars.txt no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 이럴 수가, git add을 먼저 하지 않아서 Git이 커밋을 할 수 없다. 고쳐봅시다: $ git add mars.txt $ git commit -m &quot;Add concerns about effects of Mars&#39; moons on Wolfman&quot; [master 34961b1] Add concerns about effects of Mars&#39; moons on Wolfman 1 file changed, 1 insertion(+) 실제로 무엇을 커밋하기 전에 커밋하고자하는 파일을 먼저 추가하라고 Git이 주문하는데, 이유는 한번에 모든것을 커밋하지 싶지 않을 수도 있기 때문이다. 예를 들어, 작성하고 있는 논문에 지도교수 논문을 일부 인용하여 추가한다고 가정하자. 논문 중간에 인용되는 추가부분과 상응되는 참고문헌을 커밋하고는 싶지만, 결론 부분을 커밋하고는 싶지 않다. (아직 결론이 완성되지 않았다.) 이런 점을 고려해서, Git은 특별한 준비 영역(staging)이 있어서 현재 변경부분(change set)을 추가는 했으나 아직 커밋하지 않는 것을 준비 영역에서 추적하고 있다. 준비 영역(Staging area) 프로젝트 기간 동안에 걸쳐 발생된 변경사항에 대해 스냅사진을 찍는 것으로 Git을 바라보면, git add 명령어는 무엇이 스냅사진(준비영역에 놓는 것)에 들어갈지 명세하고, git commit 명령어는 실제로 스탭사진을 찍는 것이다. 만약 git commit을 타이핑할 때 준비된 어떤 것도 없다면, Git이 git commit -a 혹은 git commit --all 명령어 사용을 재촉한다. 사진을 찍으려고 모두 모이세요 하는 것과 같다. 하지만, 준비영역에 추가할 것을 명시적으로 하는 것이 항상 좋다. 왜냐하면 커밋을 했는데 잊은 것이 있을 수도 있기 때문이다. (스냅사진으로 돌아가서, -a 옵션을 사용했기 때문에 스냅사진에 들어갈 항목을 불완전하게 작성했을 수도 있다!) 수작업으로 준비영역에 올리거나, 원하는 것보다 많은 것을 올렸다면 “git undo commit”을 찾아보라. Git 준비(Staging) 영역 파일 변경사항을 편집기에서 준비 영역으로, 그리고 장기 저장소로 옮기는 것을 살펴보자. 먼저, 파일에 행 하나를 더 추가한다: $ nano mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity $ git diff diff --git a/mars.txt b/mars.txt index 315bf3a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1,2 +1,3 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity 지금까지 좋다. 파일의 끝에 행을 하나 추가했다(첫 열에 +이 보인다). 이제, 준비영역에 변경 사항을 놓고, git diff 명령어가 보고하는 것을 살펴보자: $ git add mars.txt $ git diff 출력결과가 없다. Git이 일러줄 수 있는 것은 영구히 저장되는 것과 현재 디렉토리에 작업하고 있는 것에 차이가 없다는 것이다. 하지만, 다음과 같이 명령어를 친다면: $ git diff --staged diff --git a/mars.txt b/mars.txt index 315bf3a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1,2 +1,3 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity 마지막으로 커밋된 변경사항과 준비 영역(Staging)에 있는 것과 차이를 보여준다. 변경사항을 저장하자: $ git commit -m &quot;Discuss concerns about Mars&#39; climate for Mummy&quot; [master 005937f] Discuss concerns about Mars&#39; climate for Mummy 1 file changed, 1 insertion(+) 현재 상태를 확인하자: $ git status On branch master nothing to commit, working directory clean 그리고 지금까지 작업한 이력을 살펴보자: $ git log commit 005937fbe2a98fb83f0ade869025dc2636b4dad5 Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:14:07 2013 -0400 Discuss concerns about Mars&#39; climate for Mummy commit 34961b159c27df3b475cfe4415d94a6d1fcd064d Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:07:21 2013 -0400 Add concerns about effects of Mars&#39; moons on Wolfman commit f22b25e3233b4645dabd0d81e651fe074bd8e73b Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 09:51:46 2013 -0400 Start notes on Mars as a base 단어 단위 차이분석(Word-based diffing) 경우에 따라서는 줄단위로 텍스트 차이 분석이 너무 자세하지 않을 수도 있다. git diff 명령어에 --color-words 선택옵션이 유용할 수 있는데 이유는 색상을 사용해서 변경된 단어를 강조해서 표시해 주기 때문이다. 로그 페이지별 보기 화면에 git log 출력결과가 너무 긴 경우, git에 화면 크기에 맞춰 페이지 단위로 쪼개주는 프로그램이 제공된다. 페이지별 쪼개보기(“pager”)가 호출되면, 화면 마지막 줄에 프롬프트 대신에 :이 나타난다. 페이저(pager)에서 나오려면, Q를 타이핑한다. 다음 페이지로 이동하려면, Spacebar를 타이핑한다. 전체 페이지에서 특정 단어를 검색하려면, / 타이핑하고, and 특정단어를 검색하는 검색어를 타이핑한다. 검색에 매칭되는 단어를 따라가려면 N을 타이핑한다. 로그 크기 제한걸기 git log가 전체 터미널 화면을 접수하는 것을 피하려면, -N 선택옵션을 적용해서 Git이 화면에 출력하는 커밋 숫자에 제한을 건다. 여기서 -N은 보고자 하는 커밋 갯수가 된다. 예를 들어 가장 마지막 커밋만 보려고 한다면 다음과 같이 타이핑한다: $ git log -1 commit 005937fbe2a98fb83f0ade869025dc2636b4dad5 Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:14:07 2013 -0400 Discuss concerns about Mars&#39; climate for Mummy --oneline 선택옵션을 사용해서 출력되는 로그 메시지 크기를 줄일 수도 있다: $ git log --oneline * 005937f Discuss concerns about Mars&#39; climate for Mummy * 34961b1 Add concerns about effects of Mars&#39; moons on Wolfman * f22b25e Start notes on Mars as a base --oneline 선택옵션과 다른 선택옵션을 조합할 수도 있다. 유용한 조합 사례로 다음이 있다: $ git log --oneline --graph --all --decorate * 005937f Discuss concerns about Mars&#39; climate for Mummy (HEAD, master) * 34961b1 Add concerns about effects of Mars&#39; moons on Wolfman * f22b25e Start notes on Mars as a base 디렉토리 Git에서 디렉토리에 관해서 알아두면 좋을 두가지 사실. Git은 그 자체로 디렉토리를 추적하지 않고, 디렉토리에 담긴 파일만 추적한다. 믿지 못하겠다면, 직접 다음과 같이 시도해 본다: $ mkdir directory $ git status $ git add directory $ git status 새로 생성된 directory 이름을 갖는 디렉토리가 git add 명령어로 명시적으로 추가했음에도 불구하고 untracked files 목록에 나오지 않고 있다. 이런 이유로 인해서 가끔 .gitkeep 파일을 보게 된다. .gitignore와 달리, 특별하지는 않고 유일한 목적은 디렉토리를 만들어 내어 Git이 저장소에 추가하도록 하는 역할만 수행한다. 사실 원하는 이름으로 파일명을 붙일 수 있다. Git 저장소에 디렉토리를 생성하고 파일로 채워넣으면, 다음과 같이 디렉토리의 모든 파일을 추가할 수 있다: git add &lt;directory-with-files&gt; 요약하면, 변경사항을 저장소에 추가하고자 할 때, 먼저 변경된 파일을 준비 영역(Staging)에 git add 명령어로 추가하고 나서, 준비 영역의 변경사항을 저장소에 git commit 명령어로 최종 커밋한다: Git 커밋(Commit) 작업흐름 커밋 메시지 고르기 다음 중 어떤 커밋 메시지가 mars.txt 파일의 마지막 커밋으로 가장 적절할까요? 1. “Changes” 2. “Added line ‘But the Mummy will appreciate the lack of humidity’ to mars.txt” 3. “Discuss effects of Mars’ climate on the Mummy” 해답 1번은 충분히 기술되어 있지 못하고 커밋 목적이 불확실하다; 2번은 “git diff” 명령어를 사용한 것과 불필요하게 중복된다; 3번이 좋다: 짧고, 기술이 잘되어 있고, 피할 수 없게 명백하다(imperative). Git에 변경사항 커밋하기 다음 중 어떤 명령어가 로컬 Git 저장소에 myfile.txt 파일 변경사항을 저장시키는걸까? $ git commit -m &quot;my recent changes&quot; $ git init myfile.txt $ git commit -m &quot;my recent changes&quot; $ git add myfile.txt $ git commit -m &quot;my recent changes&quot; $ git commit -m myfile.txt &quot;my recent changes&quot; 해답 파일이 이미 준비영역(staging)에 올라온 경우만 커밋이 생성된다. 신규 저장소를 생성하게 된다. 정답: 파일을 준비영역에 추가하고 나서, 커밋하게 된다. myfile.txt 파일에 “my recent changes” 메시지를 갖는 커밋을 생성한다. 파일 다수를 커밋 준비영역(staging area)은 스냅샷 한번에 원하는 만큼 파일을 변경사항을 담아 낼 수 있다. 1. mars.txt 파일에 전진기지로 생각하는 금성(Venus)를 고려하고 있다는 결정을 담은 텍스트를 추가한다. 2. venus.txt 파일을 새로 생성해서 본인과 친구들에게 금성에 관한 첫생각을 담아낸다. 3. 파일 두개에 변경사항을 준비영역에 추가하고 커밋한다. 해답 먼저, mars.txt, venus.txt 파일에 변경사항을 기록한다: $ nano mars.txt $ cat mars.txt Maybe I should start with a base on Venus. $ nano venus.txt $ cat venus.txt Venus is a nice planet and I definitely should consider it as a base. 준비영역에 파일 두개를 추가한다. 한줄로 추가작업을 수행할 수 있다: $ git add mars.txt venus.txt 혹은 명령어를 다수 타이핑하면 된다: $ git add mars.txt $ git add venus.txt 이제 파일을 커밋할 준비가 되었다. git status를 사용해서 확인하면, 커밋을 할 준비가 되었다: $ git commit -m &quot;Write plans to start a base on Venus&quot; [master cc127c2] Write plans to start a base on Venus 2 files changed, 2 insertions(+) create mode 100644 venus.txt bio 저장소 bio라는 새로운 Git 저장소를 본인 로컬 컴퓨터에 생성한다. me.txt라는 파일로 본인에 대한 3줄 이력서를 작성한다. 변경사항을 커밋한다. 그리고 나서 한줄을 바꾸고, 네번째 줄을 추가하고 나서, 원래 상태와 갱신된 상태의 차이를 화면에 출력한다. 해답 필요하다면, planets 폴더에서 빠져나온다: $ cd .. bio 폴더를 새로 생성하고 bio 폴더로 이동한다: $ mkdir bio $ cd bio git 명령어로 초기화한다: $ git init nano 혹은 선호하는 편집기를 사용해서 me.txt 파일에 본인 일대기를 작성한다. 파일을 추가하고 나서, 저장소에 커밋한다: $ git add me.txt $ git commit -m&#39;Adding biography file&#39; 기술된 것(한줄 변경하고, 4번째 줄을 추가한다)처럼 파일을 변경한다. 원본 상태와 수정된 상태를 git diff 명령어를 사용해서 화면에 출력한다: $ git diff me.txt 저자(Author)와 커미터(Committer) 매번 커밋을 할 때마다, Git은 이름을 두번 저장한다. 본인 이름이 저자(Author)와 커미터(Committer)로 기록된다. 마지막 커밋에 추가 정보를 Git에게 요구하면 확인이 가능하다: $ git log --format=full 커밋할 때, 저자를 다른 누군가로 바꿀 수 있다: $ git commit --author=&quot;Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;&quot; 커밋을 두개 생성한다: 하나는 --author 옵션을 갖는 것으로 저자로 동료이름을 반영한다. git log와 git log --format=full 명령어를 실행한다. 이런 방식이 동료와 협업하는 방식이 될 수도 있겠다고는 생각이 될 수 있다. 해법 $ git add me.txt $ git commit -m &quot;Update Vlad&#39;s bio.&quot; --author=&quot;Frank N. Stein &lt;franky@monster.com&gt;&quot; [master 4162a51] Update Vlad&#39;s bio. Author: Frank N. Stein &lt;franky@monster.com&gt; 1 file changed, 2 insertions(+), 2 deletions(-) $ git log --format=full commit 4162a51b273ba799a9d395dd70c45d96dba4e2ff Author: Frank N. Stein &lt;franky@monster.com&gt; Commit: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Update Vlad&#39;s bio. commit aaa3271e5e26f75f11892718e83a3e2743fab8ea Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Commit: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Vlad&#39;s initial bio. "],["git-history.html", "12 . 이력 탐색", " 12 . 이력 탐색 앞선 학습에서 살펴봤듯이, 식별자로 커밋을 조회할 수 있다. HEAD 식별자를 사용해서 작업 디렉토리의 가장 최근 커밋을 조회할 수 있다. mars.txt 파일에 한번에 한줄씩 추가했다. 따라서, 눈으로 봐도 진행사항을 쉽게 추적할 수 있다. HEAD를 사용해서 추적작업을 수행해보자. 시작전에 mars.txt 파일에 변경을 가해보자. $ nano mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity An ill-considered change 이제, 변경된 사항을 살펴보자. $ git diff HEAD mars.txt diff --git a/mars.txt b/mars.txt index b36abfd..0848c8d 100644 --- a/mars.txt +++ b/mars.txt @@ -1,3 +1,4 @@ Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity +An ill-considered change. HEAD만 빼면, 앞서 살펴본 것과 동일하다. 이러한 접근법의 정말 좋은 점은 이전 커밋을 조회살 수 있다는 점이다. ~1(“~”은 “틸드(tilde)”, 발음기호 [til-duh])을 추가해서 HEAD 이전 첫번째 커밋을 조회할 수 있다. $ git diff HEAD~1 mars.txt git diff 명령어를 사용해서 이전 커밋과 차이난 점을 보고자 한다면, HEAD~1, HEAD~2 표기법을 사용해서 조회를 쉽게 할 수 있다: $ git diff HEAD~2 mars.txt diff --git a/mars.txt b/mars.txt index df0654a..b36abfd 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change git show를 사용해서도 커밋 메시지 분만 아니라 이전 커밋과 변경사항을 보여준다. git diff는 작업 디렉토리와 커밋 사이 차이나는 부분을 보여준다. $ git show HEAD~2 mars.txt commit 34961b159c27df3b475cfe4415d94a6d1fcd064d Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt; Date: Thu Aug 22 10:07:21 2013 -0400 Start notes on Mars as a base diff --git a/mars.txt b/mars.txt new file mode 100644 index 0000000..df0654a --- /dev/null +++ b/mars.txt @@ -0,0 +1 @@ +Cold and dry, but everything is my favorite color 이런 방식으로, 연쇄 커밋 사슬을 구성할 수 있다. 가장 최근 사슬의 끝값은 HEAD로 조회된다; ~ 표기법을 사용하여 이전 커밋을 조회할 수 있다. 그래서 HEAD~1(“head 마이너스 1”으로 읽는다.)은 “바로 앞선 커밋”을 의미하고, HEAD~123은 지금 있는 위치에서 123번째 이전 수정으로 간다는 의미가 된다. 커밋된 것을 git log 명령어로 화면에 뿌려주는 숫자와 문자로 구성된 긴 문자열을 사용하여 조회할 수도 있다. 변경사항에 대해서 중복되지 않는 ID로 “중복되지 않는(unique)”의 의미는 정말 유일하다는 의미다: 특정 컴퓨터에 있는 임의 파일 집합에 대한 모든 변경사항은 중복되지 않는 40-문자 식별자가 붙어있다. 첫번째 커밋은 ID로 f22b25e3233b4645dabd0d81e651fe074bd8e73b 이 주어졌다. 그래서 다음과 같이 시도하자: $ git diff f22b25e3233b4645dabd0d81e651fe074bd8e73b mars.txt diff --git a/mars.txt b/mars.txt index df0654a..93a3e13 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change 올바든 정답이지만, 난수 40-문자로 된 문자열을 타이핑하는 것은 매우 귀찮은 일이다. 그래서 Git 앞의 몇개 문자만으로도 사용할 수 있게 했다: $ git diff f22b25e mars.txt diff --git a/mars.txt b/mars.txt index df0654a..93a3e13 100644 --- a/mars.txt +++ b/mars.txt @@ -1 +1,4 @@ Cold and dry, but everything is my favorite color +The two moons may be a problem for Wolfman +But the Mummy will appreciate the lack of humidity +An ill-considered change 좋았어요! 파일에 변경사항을 저장할 수 있고 변경된 것을 확인할 수 있다. 어떻게 옛 버젼 파일을 되살릴 수 있을까? 우연히 파일을 덮어썼다고 가정하자: $ nano mars.txt $ cat mars.txt We will need to manufacture our own oxygen 이제 git status를 통해서 파일이 변경되었다고 하지만, 변경사항은 아직 준비영역(Staging area)에 옮겨지지 않은 것으로 확인된다: $ git status On branch master Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: mars.txt no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) git checkout 명령어를 사용해서 과거에 있던 상태로 파일을 돌려 놓을 수 있다: $ git checkout HEAD mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity 이름에서 유추할 수 있듯이, git checkout 명령어는 파일 옛 버젼을 확인하고 갖고 나간다. 즉, 되살린다. 이 경우 HEAD에 기록된 가장 최근에 저장된 파일 버젼을 되살린다. 좀더 오래된 버젼을 되살리고자 한다면, 대신에 커밋 식별자를 사용한다: $ git checkout f22b25e mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color $ git status # On branch master Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) # Changes not staged for commit: # (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) # (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) # # modified: mars.txt # no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 변경사항은 준비영역에 머물러 있는 것에 주목한다. 다시, git checkout 명령어를 사용해서 이전버젼으로 되돌아 간다: $ git checkout HEAD mars.txt 헤드(HEAD)를 잃지 말자 f22b25e 커밋 상태로 mars.txt 파일을 되돌리는데 앞서 다음 명령어를 사용했다. $ git checkout f22b25e mars.txt 하지만 주의하자! checkout 명령어는 다른 중요한 기능을 갖고 있고 만약 타이핑에 오류가 있다면 의도를 Git이 오해할 수 있다. 예를들어, 앞선 명령에서 mars.txt를 빼먹게 되면… $ git checkout f22b25e Note: checking out &#39;f22b25e&#39;. You are in &#39;detached HEAD&#39; state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b &lt;new-branch-name&gt; HEAD is now at f22b25e Start notes on Mars as a base “detached HEAD”는 “보기는 하지만 건드리지는 마시오”와 같다. 따나서 현재 상태에서 어떤 변경도 만들지 말아야한다. 저장소 지난 상태를 살펴본 후에 git checkout master 명령어로 HEAD를 다시 붙힌다. 실행 취소를 하는 변경을 하기 *전에** 저장소 상태를 확인하는 커밋 번호를 사용해야 한다는 것을 기억하는 것이 중요하다. 흔한 실수는 커밋 번호를 사용하는 것이다. 아래 예제에서는 커밋 번호가 f22b25e인 가장 최신 커밋(HEAD~1) 앞의 상태로 다시 되돌리고자 한다: Git Checkout 그래서, 모두 한군데 놓아보자: https://figshare.com/articles/How_Git_works_a_cartoon/1328266 흔한 사례 단순화 git status 출력결과를 주의깊이 읽게 되면, 힌트가 포함된 것을 볼 수 있다. (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) 출력결과가 언급하는 바는, 버전 식별자 없이 git checkout 명령어를 실행하게 되면 HEAD에 저장된 상태로 파일을 원복시킨다. 더블 대쉬 --가 필요한 경우는 명령어 자체로부터 복구회야 되는 파일명을 구별할 때다: 없는 경우, 커밋 식별자에 Git은 파일명을 사용한다. 파일이 하나씩 하나씩 옛 상태로 되돌린다는 사실이 사람들이 작업을 조직하는 방식에 변화를 주는 경향이 있다. 모든 것이 하나의 큰 문서로 되어있다면, 나중에 결론부분에 변경사항을 실행취소하지 않고, 소개부분에 변경을 다시 되돌리기가 쉽지 않다(하지만 불가능하지는 않다). 다른 한편으로 만약 소개부분과 결론부분이 다른 파일에 저장되어 있다면, 시간 앞뒤로 이동하기가 훨씬 쉽다. 파일 이전 버젼 복구하기 정훈이가 몇주동안 작업한 파이썬 스크립트에 변경을 했고, 오늘 아침 정훈이가 작업한 변경사항이 스크립트를 “망가 먹어서” 더이상 실행이 되지 않는다. 복도 없이, 버그를 고치는데 1시간 이상 소모했다… 다행스럽게도, Git을 사용한 프로젝트 버젼을 추적하고 있었다! 다음 아래 명령어 중 어떤 것이 data_cruncher.py로 불리는 파이썬 스크립트 가장 최근 버젼을 복구하게 할까요? $ git checkout HEAD $ git checkout HEAD data_cruncher.py $ git checkout HEAD~1 data_cruncher.py $ git checkout &lt;unique ID of last commit&gt; data_cruncher.py Both 2 and 4 커밋 되돌리기(Reverting a Commit) 정훈이는 동료와 함께 파이썬 코드를 협업해서 작성하고 있다. 그룹 저장소에 마지막으로 커밋한 것이 잘못된 것을 알게 되서, 실행취소하여 원복하고자 한다. 정훈이는 실행취소를 올바르게 해서 그룹저장소를 사용하는 모든 구성원이 제대로된 변경사항을 가지고 작업을 계속하길 원한다. git revert [잘못된 커밋 ID] 명령어는 정훈이가 이전에 잘못 커밋했던 작업에 대해 실행취소하는 커밋을 새로 생성시킨다. 따라서, git revert는 git checkout [커밋 ID]와 다른데 이유는 checkout이 그룹 저장소에 커밋되지 않는 로컬 변경사항에 대해서 적용된다는 점에서 차이가 난다. 정훈이가 git revert를 사용할 올바른 절차와 설명이 아래에 나와있다. 빠진 명령어가 무엇일까? `________ # 커밋 ID를 찾을 수 있도록 Git 프로젝트 이력을 살펴본다. ID를 복사한다. (ID의 첫 문자 몇개만 사용한다. 예를 들어, 0b1d055). git revert [커밋 ID] 새로운 커밋 메시지를 타이핑한다. 저장하고 종료한다. 작업흐름과 이력 이해하기 다음 마지막 명령의 출력결과는 무엇일까? $ cd planets $ echo &quot;Venus is beautiful and full of love&quot; &gt; venus.txt $ git add venus.txt $ echo &quot;Venus is too hot to be suitable as a base&quot; &gt;&gt; venus.txt $ git commit -m &quot;Comment on Venus as an unsuitable base&quot; $ git checkout HEAD venus.txt $ cat venus.txt #this will print the contents of venus.txt to the screen Venus is too hot to be suitable as a base Venus is beautiful and full of love Venus is beautiful and full of love Venus is too hot to be suitable as a base Error because you have changed venus.txt without committing the changes 해법 정답은 2. 왜냐하면, git add venus.txt가 Venus is too hot to be suitable as a base 행을 추가하기 전에만 적용된다. git checkout이 실행될 때 반영이 되지 않아서 그렇다. git commit 명령어에 -a 플래그를 사용하게 되면 이런 손실을 막을 수 있다. git diff 이해 확인하기 git diff HEAD~3 mars.txt 명령어를 고려해 보자. 이 명령어를 실행하게 되면 실행결과로 예상하는 바를 말해보세요. 명령어를 실행하게 되면 어떤 일이 발생하는가? 그리고 이유는 무엇인가? 또 다른 명령어 git diff [ID] mars.txt를 시도해 보자. 여기서, [ID]를 가장 최근 커밋 식별자로 치환한다. 무슨 일이 생길까? 그리고 실제로 생긴 일은 무엇인가? 준비 단계 변경사항(Staged Changes) 제거하기 git checkout 명령어를 통해서 준비영역으로 올라오지 않은 변경사항이 있을 대, 이전 커밋을 복구할 수 있었다. 하지만, git checkout은 준비영역에 올라왔지만, 커밋되지 않는 변경사항에 대해서도 동작한다. mars.txt 파일에 변경사항을 만들고, 변경사항을 추가하고 나서, git checkout 명령어를 사용하게 되면 변경사항이 사라졌는지 살펴보자. 변경 이력 탐색과 요약 변경 이력 탐색은 Git에 있어 중요한 부분 중의 하나로, 특히 커밋이 수개월 전에 이뤄졌다면, 올바른 커밋 ID를 찾는 것이 종종 크나큰 도전과제가 된다. planets 프로젝트가 50 파일 이상으로 구성되었다고 상상해 보자. mars.txt 파일에 특정 텍스트가 변경된 커밋을 찾고자 한다. git log를 타이핑하게 되면 매우 긴 목록이 출력된다. 어떻게 하면 검색범위를 좁힐 수 있을까? git diff 명령어가 특정 파일만 탐색할 수 있단느 점을 상기하자. 예를 들어, git diff mars.txt. 이 문제에 유사한 아이디어를 적용해 보자. $ git log mars.txt 불행하게도 커밋 메시지 일부는 매우 애매모호하다. 예를 들어, update files. 어떻게 하면 파일을 잘 검색할 수 있을까? git diff, git log 명령어 모두 매우 유용하다. 두 명령어 모두 변경이력의 다른 부분을 요약해준다. 둘을 조합하는 것은 가능할까? 다음 명령어를 실행해 보자: $ git log --patch mars.txt 엄청 긴 출력 목록이 나타난다. 각 커밋마다 커밋 메시지와 차이가 쭉 출력된다. 질문: 다음 명령어는 무슨 작업을 수행할까요? $ git log --patch HEAD~3 *.txt "],["git-ignore.html", "13 . 추적대상에서 제외", " 13 . 추적대상에서 제외 만약 Git가 추적하기 않았으면 하는 파일이 있다면 어떨까요? 편집기에서 자동 생성되는 백업파일 혹은 자료 분석 중에 생성되는 중간 임시 파일이 좋은 예가 된다. 몇개 마루타 더미(dummy) 파일을 생성하자: $ mkdir results $ touch a.dat b.dat c.dat results/a.out results/b.out 그려면 Git은 다음을 보여준다: $ git status On branch master Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) a.dat b.dat c.dat results/ nothing added to commit but untracked files present (use &quot;git add&quot; to track) 벼젼 제어 아래 이런 파일을 놓는 것은 디스크 공간 낭비다. 더 좋은 않는 것은, 이런 파일을 모두 관리목록에 넣는 것이 실제적으로 중요한 변경사항을 관리하는데 집중하지 못하게 한다는 것이다. 그래서 Git에게 중요하지 않는 이런 파일을 무시하게 일러준다. .gitignore라는 프로젝트 루트 디렉토리에 파일을 생성해서 무시할 것을 명기함으로써 해당작업을 수행한다: $ nano .gitignore $ cat .gitignore *.dat results/ 상기 패턴은 .dat 확장자를 갖는 임의 파일과 results 디렉토리에 있는 모든 것을 무시한다. (하지만, 이들 파일 중 일부가 이미 추적되고 있다면, Git은 계속 추적한다.) .gitignore 파일을 생성하자마자, git status 출력결과는 훨씬 깨끗해졌다: $ git status On branch master Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) .gitignore nothing added to commit but untracked files present (use &quot;git add&quot; to track) 이제 Git가 알아차리는 유일한 것은 새로 생성된 .gitignore 파일이 된다. 우리는 이들 파일을 추적하여 관리하지 않는다고 생각할 수도 있지만, 우리와 저장소를 공유하고 있는 다른 모든 사람도 우리가 추적관리하지 않는 동일한 것을 무시하고 싶을 것이다. .gitignore 를 추가하고 커밋하자: $ git add .gitignore $ git commit -m &quot;Ignore data files and the results folder.&quot; $ git status # On branch master nothing to commit, working directory clean 보너스로, .gitignore는 실수로 추적하고 싶지 않는 파일이 저장소에 추가되는 것을 피할 수 있게 돕는다: $ git add a.dat The following paths are ignored by one of your .gitignore files: a.dat Use -f if you really want to add them. 만약 .gitignore 설정에 우선해서 파일을 추가하려면, git add -f를 사용해서 강제로 Git에 파일을 추가할 수 있다. 예를 들어, git add -f a.dat. 추적관리되지 않는 파일의 상태를 항상 보려면 다음을 사용한다: $ git status --ignored On branch master Ignored files: (use &quot;git add -f &lt;file&gt;...&quot; to include in what will be committed) a.dat b.dat c.dat results/ nothing to commit, working directory clean 중첩된 파일 추적하지 않기 디렉토리 구조가 다음과 같다: results/data results/plots 어떻게 하면 results/plots 만 추적하지 않을 수 있을까? results/data 디렉토리는 추적한다. 해답 대부분의 프로그래밍 이슈와 마찬가지로, 이 문제를 해결하는 몇가지 방식이 있다. results/plots 디렉토리 콘텐츠만 추적하지 않기로 한다면, .gitignore 파일에 /plots/ 폴더만 추적하지 않도록 다음과 같이 .gitignore 파일을 변경하면 된다: results/plots/ 대신에 /results/ 디렉토리에 모든 것을 추적하지 않지만, results/data만 추적하고자 한다면, results/ 폴더를 .gitignore 파일에 추가하고 results/data/ 폴더에 대해서 예외를 생성한다. 다음 도전과제가 이런 유형의 해법을 다루게 된다. 종종 ** 패턴이 사용하기 수월한데, 다수 디렉토리와 매칭을 지원한다. 예를 들어, **/results/plots/*은 루트 디렉토리에 results/plots 디렉토리를 추정하기 않게 도니다. 특정 파일만 포함시키기 final.data 파일만 제외하고 모든 .data 파일은 추적하지 않고자 하면 어떻게 하면 될까? 힌트: ! (느낌표 연산자) 부호가 수행하는 작업을 알아본다. 해법 .gitignore 파일에 다음 두 줄을 추가한다: *.data # 모든 data 파일을 추적하지 않는다. !final.data # final.data 파일만 예외로 한다. 느낌표 연산자가 앞서 제외된 항목을 포함시키게 한다. 디렉토리에 모든 파일 추적하지 않기 디렉토리 구조가 다음과 같다: results/data/position/gps/a.data results/data/position/gps/b.data results/data/position/gps/c.data results/data/position/gps/info.txt results/plots result/data/position/gps 디렉토리에 모든 .data 파일을 추적하지 않도록 .gitignore 파일에 규칙을 작성하는데 가장 짧은 규칙은 무엇일까? info.txt 파일은 추적하자. 해답 results/data/position/gps 디렉토리에 .data로 끝나는 모든 파일은 results/data/position/gps/*.data 규칙으로 매칭된다. results/data/position/gps/info.txt 파일은 확장자가 달라서 계속 추적된다. 적용 규칙 순서 .gitignore 파일에 다음 내용이 담겨있다: *.data !*.data 적용 결과는 어떻게 될까? 해답 ! 연산자는 이전에 정의된 추적제외 패턴을 부정한다. .gitignore파일에서 !*.data 규칙은 앞서 추적에서 제외한 .data 모든 파일 추적제외를 부정한다. 따라서, 어떤 것도 추적제외되지 않고, .data 파일 모두가 추적된다. 로그 파일 스크립트를 작성해서 log_01, log_02, log_03 형태의 중간 로그 파일이 많이 생성되었다. 로그 파일을 보관하고자 하지만, git으로 추적하고 싶지는 않다. log_01, log_02 … 형태 모든 파일을 추적 제외하는 .gitignore 규칙을 하나 작성한다. log_01 형태 마루타 파일을 생성해서 “추적제외 패턴”을 테스트한다. 종국에 log_01 파일이 매우 중요하는 것을 알게 되어서 .gitignore 파일을 변경하지 않고 추적되게 추가한다. 추적하기를 원하지 않지만, .gitignore를 통해서 추적제외할 수 있는 파일이 어떤 유형이 있는지 주변 동료와 상의하자. 해답 log_* 혹은 log* 규칙을 .gitignore 파일에 추가한다. git add -f log_01 명령어를 사용해서 log_01 파일에 대한 추적을 수행한다. "],["git-github.html", "14 . GitHub 원격작업", " 14 . GitHub 원격작업 버젼 제어(version control)는 다른 사람과 협업할 때 진정으로 다가온다. 우리는 이미 버젼 제어를 위해 필요한 작업 대부분을 수행했다; 한가지 빠진 것은 한 저장소에서 다른 저장소로 변경사항을 복사하는 것이다. Git 같은 시스템은 임의 두 저장소 사이에 작업을 옮길 수 있는 기능을 제공한다. 하지만, 실무에서 다른 사람의 노트북이나 PC보다는 중앙 허브에 웹 방식으로 하나의 원본을 두고 사용하는 것이 가장 쉽다. 대부분의 프로그래머는 프로그램 마스터 원본을 GitHub, BitBucket, GitLab 호스팅 서비스에 두고 사용한다; 이번 학습 마지막 부분에서 이러한 접근법의 장점과 단점을 살펴본다. 세상 사람들과 현재 프로젝트에서 변경한 사항을 공유하는 것에서부터 시작해보자. GitHub에 로그인하고 나서, 우측 상단 아이콘을 클릭해서 planets 이름으로 신규 저장소를 생성한다: (1단계) GitHub 저장소 생성 저장소 이름을 “planets”으로 만들고 “Create Repostiory”를 클릭한다: (2단계) GitHub 저장소 생성 저장소가 생성되자 마자, GitHub는 URL을 가진 페이지와 로컬 저장소 환경설정 방법에 대한 정보를 화면에 출력한다: (3단계) GitHub 저장소 생성 다음 명령어가 실제로 GitHub 서버에서 자동으로 수행된 것이다: $ mkdir planets $ cd planets $ git init mars.txt 파일을 추가하고 커밋한 이전 학습을 상기한다면, 로컬 저장소는 다음과 같이 도식적으로 표현할 수 있다: Git 준비영역(Staging) 로컬 저장소 이제 저장소가 두개로 늘어서, 도식적으로 표현하면 다음과 같다: 신선한 신규 GitHub 저장소 현재 로컬 저장소는 여전히 mars.txt 파일에 대한 이전 작업정보를 담고 있다. 하지만, GitHub의 원격 저장소에는 아직 어떠한 파일도 담고 있지는 않다: 다음 단계는 두 저장소를 연결하는 것이다. 로컬 저장소를 위해서 GitHub 저장소를 원격(remote)으로 만들어 두 저장소를 연결한다. GitHub의 저장소 홈페이지에 식별하는데 필요한 문자열이 포함되어 있다: GitHub 저장소 URL 발견장소 SSH에서 HTTPS로 프로토콜(protocol)을 변경하려면 ‘HTTPS’ 링크를 클릭한다. HTTPS vs. SSH 부가적인 설정이 필요하지 않아서 여기서는 HTTPS를 사용한다. 워크샵 후에 SSH 접근 설정을 원할지도 모른다. SSH 접근이 좀더 안전하다. GitHub, Atlassian/BitBucket, GitLab의 훌륭한 지도서 중 하나를 따라하는 것도 좋다. GitLab은 온라인 동영상도 제공한다. GitHub 저장소 URL 변경 웹 브라우져에서 URL을 복사하고 나서, 로컬 컴퓨터 planets 저장소로 가서 다음 명령어를 실행한다: $ git remote add origin https://github.com/vlad/planets.git Make sure to use the URL for your repository rather than Vlad’s: the only difference should be your username instead of vlad. Vlad가 아니고 여러분 저장소의 URL을 사용했는지 확인한다: 유일한 차이점은 vlad 대신에 여러분의 사용자이름(username)이다. git remote -v 실행해서 명령어가 제대로 작동했는지 확인한다: $ git remote -v origin https://github.com/vlad/planets.git (push) origin https://github.com/vlad/planets.git (fetch) origin 이름이 원격 저장소에 대한 로컬 별명이다. 원한다면 다른 명칭을 사용할 수도 있지만, origin 이름이 가장 일반적인 선택이다. 별명이 origin으로 설정되면, 다음 명령어가 변경사항을 로컬 저장소에서 GitHub 원격 저장소로 밀어 넣어 푸쉬(push)한다: $ git push origin master Counting objects: 9, done. Delta compression using up to 4 threads. Compressing objects: 100% (6/6), done. Writing objects: 100% (9/9), 821 bytes, done. Total 9 (delta 2), reused 0 (delta 0) To https://github.com/vlad/planets * [new branch] master -&gt; master Branch master set up to track remote branch master from origin. 프록시(Proxy) 만약 연결된 네트워크가 프록시를 사용한다면, “Could not resolve hostname” 오류 메시지로 인해서 마지막 명령어가 실패할 가능성이 있다. 이 문제를 해결하기 위해서, 프록시에 대한 정보를 Git에 전달할 필요가 있다: $ git config --global http.proxy http://user:password@proxy.url $ git config --global https.proxy http://user:password@proxy.url 프록시를 사용하지 않는 또다른 네트워크에 연결될 때, Git에게 프록시 기능을 사용하지 않도록 다음 명령어를 사용하여 일러준다: $ git config --global --unset http.proxy $ git config --global --unset https.proxy 비밀번호 관리자(password manager) 운영체제 위에 비밀번호 관리자(password manager)가 설정되어 있다면, 사용자이름(username)과 비밀번호(passord)가 필요로 할 때, git push 명령어가 이를 사용하려 한다. “Git Bash on Windows”를 사용하면 기본 디폴트 행동이다. 관리자 비밀번호를 사용하는 대신에, 터미널에서 사용자이름과 비밀번호를 입력하려면, git push를 실행하기 전에 터미널에서 다음과 같이 타이핑한다: $ unset SSH_ASKPASS git uses SSH_ASKPASS for all credential entry에도 불구하고, SSH나 HTTPS를 경유하여 Git을 사용하든 SSH_ASKPASS을 설정하고 싶지 않을 수도 있다. ~/.bashrc 파일 하단에 unset SSH_ASKPASS을 추가해서 Git으로 하여금 사용자명과 비밀번호를 사용하도록 기본설정으로 둘 수도 있다. 이제 로컬 저장소와 원격 저장소는 다음과 같은 상태가 된다: 첫번째 푸쉬(Push) 다음 GitHub 저장소 ‘-u’ 플래그(flag) Git 문서에서 git push과 함께 사용되는 -u 옵션을 볼 수 있다. git branch 명령어에 대한 --set-upstream-to 옵션과 동의어에 해당되는 옵션이다. 원격 브랜치를 현재 브랜치와 연결시키는데 사용된다. 그래서 git pull 명령어가 아무런 인자없이 사용될 수 있다. 원격 저장소가 설정되면, git push -u origin master 명령어만 실행시키면 연결작업이 완료된다. 또한, 원격 저장소에서 로컬 저장소로 변경사항을 풀(pull)해서 가져올 수도 있다: $ git pull origin master From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD Already up-to-date. 이 경우 가져오기 하는 풀(pull)은 아무런 결과가 없는데, 이유는 두 저장소가 이미 동기화가 되어서다. 하지만, 만약 누군가 GitHub 저장소에 변경사항을 푸쉬했다면, 상기 명령어는 변경된 사항을 로컬 저장소로 다운로드한다. GitHub GUI GitHub 웹사이트에서 planets 저장소를 찾아간다. Code 탭아래 “XX commits”(“XX”는 숫자) 텍스트를 클릭한다. 각 커밋 우측의 버튼 세개 여기 저기 둘러보고, 클릭해 본다. 버튼을 눌러서 어떤 정보를 모을 수 있거나 탐색할 수 있는가? 쉘에서 동일한 정보를 어떻게 얻을 수 있을까? 해답 (클립보드 그림을 갖는) 가장 좌측 버튼은 클립보드에 커밋 식별자 전체를 복사한다. 쉘에서 git log 명령어가 각 커밋에 대한 전체 커밋 식별자를 보여준다. 중간 버튼을 클릭하게 되면, 특정 커밋으로 변경한 내용 전체를 확인할 수 있다. 녹색 음영선은 추가를 붉은색 음영선은 삭제를 의미한다. 쉘에서 동일한 작업을 git diff로 할 수 있다. 특히, git diff ID1..ID2(ID1와 ID2은 커밋 식별자다) 명령어(즉, git diff a3bf1e5..041e637)는 두 커밋 사이 차이를 보여준다. 가장 우측 버튼은 커밋 당시에 저장소 모든 파일을 보여준다. 쉘로 이런 작업을 수행하려면, 해당 시점의 저장소를 checkout 해야 한다. 쉘에서 git checkout ID(여기서 ID는 살펴보려고 하는 커밋 식별자) 명령어를 실행하면 된다. checkout 하게 되면, 나중에 저장소를 올바른 상태로 되돌려 놓아야 된다는 것을 기억해야 됩니다. GitHub 시간도장(Timestamp) GitHub에 원격저장소를 생성하라. 로컬 저장소의 콘텐츠를 원격 저장소로 푸쉬하라. 로컬 저장소에 변경사항을 만들고, 변경사항을 푸쉬하라. 방금 생성한 GitHub 저장소로 가서 GitHub 변경사항에 대한 시간도장(timestamps)을 살펴본다. GitHub이 시간정보를 어떻게 기록하는가? 왜 그런가? 해답 GitHub은 시간도장을 사람이 읽기 쉬운 형태로 표시한다(즉, “22 hours ago” 혹은 “three weeks ago”). 하지만, 시간도장을 이리저리 살펴보면, 파일의 마지막 변경이 발생된 정확한 시간을 볼 수 있다. 푸쉬(Push) vs. 커밋(Commit) 이번 학습에서, “git push” 명령어를 소개했다. “git push” 명령어가 “git commit” 명령어와 어떻게 다른가? 해답 변경 사항을 푸쉬하면, 로컬에서 변경한 사항을 원격 저장소와 상호협의하여 최신 상태로 갱신한다. (흔히 다른 사람 변경시킨 것을 공유하는 것도 이에 해당된다.) 커밋은 로컬 저장소만 갱신한다는 점에서 차이가 난다. 원격 설정 고치기 원격 URL에 오탈자가 발생되는 일이 실무에서 흔히 발생된다. 이번 연습문제는 이런 유형의 이슈를 어떻게 고칠 수 있느냐에 대한 것이다. 먼저 잘못된 URL을 원격(remote)에 추가하면서 시작해 보자. git remote add broken https://github.com/this/url/is/invalid git remote로 추가할 때 오류를 받았나요? 원격 URL을 적법한지 확인해 주는 명령어를 생각해 낼 수 있나요? URL을 어떻게 수정할 수 있을까요? (팁: git remote -h를 사용한다.) 이번 연습문제를 수행한 다음에 원격(remote)를 지워버리는 것을 잊지말자. 해답 원격(remote)를 추가할 때 어떤 오류 메시지도 볼 수 없다. (원격 remote 를 추가하는 것은 Git에게 알려주기만 할 뿐 아직 사용하지는 않았기 때문이다.) git push 명령어를 사용하자마자, 오류 메시지를 보게 된다. git remote set-url 명령어를 통해서 잘못된 원격 URL을 바꿔 문제를 해결하게 된다. GitHub 라이선스와 README 파일 이번 학습에서 GitHub에 원격 저장소를 생성하는 방법을 학습했다. 하지만, GitHub 저장소를 초기화할 때 README.md 혹은 라이선스 파일을 추가하지 않았다. 로컬 저장소와 원격 저장소를 연결시킬 때 두 파일을 갖게 되면 무슨 일이 발생될 것으로 생각하십니까? 해답 이런 경우, 관련없는 이력때문에 병합 충돌(merge conflict)이 발생된다. GitHub에서 README.md 파일을 생성시키고 원격 저장소에서 커밋작업을 수행한다. 로컬 저장소로 원격 저장소를 풀(pull)로 땡겨오면, Git이 origin과 공유되지 않는 이력을 탐지하고 병합(merge)를 거부해 버린다. $ git pull origin master From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD * [new branch] master -&gt; origin/master fatal: refusing to merge unrelated histories --allow-unrelated-histories 옵션으로 두 저장소를 강제로 병합(merge)시킬 수 있다. 이런 옵션을 사용할 때 주의한다. 병합하기 전에 로컬저장소와 원격저장소의 콘텐츠를 면밀히 조사한다. $ git pull --allow-unrelated-histories origin master From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD Merge made by the &#39;recursive&#39; strategy. README.md | 1 + 1 file changed, 1 insertion(+) create mode 100644 README.md "],["git-collab.html", "15 . 협업 (Collaborating)", " 15 . 협업 (Collaborating) 다음 단계로, 짝을 이룬다. 한 사람이 “소유자”(연습을 시작하는데 사용될 GitHub 저장소 주인)가 되고, 다른 사람이 “협력자”(소유자 저장소를 복제해서 변경을 하는 사람)가 된다. 목표는 협력자가 변경사항을 소유자 저장소에 추가하는 것이다. 말미에는 역할을 바꿔서 두 사람 모두 소유자와 협력자의 역할을 수행한다. 혼자 훈련하기 혼자 힘으로 이번 학습을 쭉 진행해 왔다면, 두번째 터미널을 열어서 계속 진행할 수 있다.&gt; 두번째 윈도우가 여러분의 협력자를 나타내고, 다른 컴퓨터에서 작업하고 있는 것으로 볼 수 있다. GitHub 접근권한을 다른 사람에게 줄 필요가 없어졌다. 왜냐하면 두 ‘파트너’ 모두 여러분이기 때문이다. 소유자가 협력자에게 접근권한을 부여할 필요가 있다. GitHub에서 오른쪽에 ‘setting’ 버튼을 클릭해서 협력자(Collaborators)를 선택하고, 파트너 이름을 입력한다. GitHub에 협업자(Collaborators) 추가 소유자 저장소에 접근 권한이 부여되면, 협력자(Collaborator)는 https://github.com/notifications으로 이동한다. 그곳에서 소유자 저장소의 접근을 받아들이면 된다. 다음으로 협력자(Collaborator)는 소유자 저장소 사본을 본인 컴퓨터로 내려받는다. 이런 작업을 “저장소 복제(cloning a repo)”라고 부른다. 소유자의 저장소를 본인 바탕화면(Desktop) 폴더에 클론하려면, 협력자는 다음 명령어를 입력한다: $ git clone https://github.com/vlad/planets.git ~/Desktop/vlad-planets ’vlad’를 소유자 사용자이름(저장소를 소유하고 있는 사람)으로 바꾼다. 저장소 클론한 후 모습 앞서 작업했던 것과 정확하게 동일한 방식으로, 협력자는 이제 소유자의 저장소 클론에서 변경을 마음대로 할 수 있다: $ cd ~/Desktop/vlad-planets $ nano pluto.txt $ cat pluto.txt It is so a planet! $ git add pluto.txt $ git commit -m &quot;Add notes about Pluto&quot; 1 file changed, 1 insertion(+) create mode 100644 pluto.txt 그리고 나서, 변경사항을 GitHub의 소유자 저장소로 푸쉬한다: $ git push origin master Counting objects: 4, done. Delta compression using up to 4 threads. Compressing objects: 100% (2/2), done. Writing objects: 100% (3/3), 306 bytes, done. Total 3 (delta 0), reused 0 (delta 0) To https://github.com/vlad/planets.git 9272da5..29aba7c master -&gt; master 주목할 점은 origin 이라는 원격 저장소를 생성할 필요는 없다: 저장소를 복제(clone)할때 Git이 자동으로 origin 이름을 붙여준다. (수작업으로 원격 설정을 할 때, 앞에서 왜 origin 이름을 사용한 것이 현명한 선택인 이유다.) 이제 GitHub 웹사이트에서 소유자 저장소를 살펴본다(아마도 웹브라우져 다시 고치기를 수행할 필요가 있을 수 있다.) 협력자가 신규 커밋을 한 것을 확인할 수 있다. 소유자 로컬 컴퓨터로 GitHub 원본 저장소의 변경사항을 다운로드하려면, 소유자는 다음과 같이 입력한다: $ git pull origin master remote: Counting objects: 4, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 3 (delta 0) Unpacking objects: 100% (3/3), done. From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD Updating 9272da5..29aba7c Fast-forward pluto.txt | 1 + 1 file changed, 1 insertion(+) create mode 100644 pluto.txt 이제 저장소 3개 (소유자 로컬 저장소, 협력자 로컬 저장소, GitHub의 소유자 저장소) 모두 동기화 되었다. 기본적인 협업 작업흐름 실무에서 협업하는 저장소의 가장 최신 버전을 갖도록 확인하고 확인하는 것이 좋다. 어떤 변경을 가하기 전에 git pull 명령어를 먼저 실행해야 한다. 기본적인 협업 작업흐름은 다음과 같다. git pull origin master 명령어로 본인 로컬 저장소를 최신상태로 갱신한다. 변경 작업을 수행하고 git add 명령어로 준비단계(staging area)로 보낸다. git commit -m 명령어로 변경사항을 커밋한다. GitHub에 git push origin master 명령어로 변경사항을 업로드한다. 상당한 변경사항을 포함한 단 한번의 커밋보다 작은 변화를 준 커밋을 많이 하는 것이 좋다: 작은 커밋이 가독성도 좋고 리뷰하기도 더 편하다. 역할을 바꾸고 반복한다. 역할을 바꿔서 전체 과정을 반복한다. 변경사항 리뷰 협력자에게 어떤 정보도 주지않고 소유자가 저장소에 커밋을 푸쉬했다. 협력자는 명령라인으로 무엇이 변경되었는지 어떻게 알 수 있을까요? 해답 명령라인에서 협력자는 로컬 저장소에 원격 저장소 변경사항을 git fetch origin master 명려어를 사용해서 가져올 수 있다. 하지만, 그 자체로 병합(merge)되는 것은 아니다. git diff master origin/master 명령어를 실행해서, 협력자는 터미널에 변경사항을 확인할 수 있다. GitHub에서도 협력자는 포크된 저장소로 가서 “This branch is 1 commit behind Our-Repository:master.” 메시지를 볼 수 있다. Compare 아이콘과 링크가 걸려있다. Compare 페이지에서 협력자는 base fork를 본인 저장소로 변경하고 나서, “compare across forks” 위에 링크를 클릭한다. 마지막으로 head fork를 주 저장소로 변경한다. 이 작업을 하게 되면 차이가 나는 모든 커밋을 볼 수 있게 된다. GitHub에서 변경사항 주석(comment)달기 협력자는 소유자가 변경한 한 줄에 대해 질문을 가질 수 있고, 일부 제안사항도 있다. GitHub으로 커밋 차이에 대해 주석을 다는 것도 가능하다. 파란색 주석 아이콘(comment icon)을 클릭하면 주석 윈도우(comment window)을 열 수 있다. 협력자는 GitHub 인터페이스를 사용해서 코멘트와 제안을 남길 수 있다. 버전 이력, 백업, 그리고 버전 제어 일부 백업 소프트웨어는 파일 버전에 대한 이력을 기록하고 있다. 도한, 특정 버전을 복구하는 기능도 제공하고 있다. 이러한 기능이 버전 제어와 어떻게 다른가? 버전제어, Git, GitHub을 사용하는 좋은 점은 무엇인가? "],["git-conflict.html", "16 . 충돌 (Conflicts)", " 16 . 충돌 (Conflicts) 사람들이 병렬로 작업을 할 수 있게 됨에 따라, 누군가 다른 사람 작업영역에 발을 들여 넣을 가능성이 생겼다. 혼자서 작업할 경우에도 이런 현상이 발생한다: 소프트웨어 개발을 개인 노트북과 연구실 서버에서 작업한다면, 각 작업본에 다른 변경사항을 만들 수 있다. 버젼 제어(version control)가 겹치는 변경사항을 해결(resolve)하는 툴을 제공함으로서, 이러한 충돌(conflicts)을 관리할 수 있게 돕는다. 충돌을 어떻게 해소할 수 있는지 확인하기 위해서, 먼저 파일을 하나 생성하자. mars.txt 파일은 현재 두 협업하는 사람의 planets 저장소 사본에서는 다음과 같이 보인다: $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity 파트너 사본에만 한 줄을 추가하자: $ nano mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity This line added to Wolfman&#39;s copy 그리고 나서, 변경사항을 GitHub에 푸쉬하자: $ git add mars.txt $ git commit -m &quot;Add a line in our home copy&quot; [master 5ae9631] Add a line in our home copy 1 file changed, 1 insertion(+) $ git push origin master Counting objects: 5, done. Delta compression using up to 4 threads. Compressing objects: 100% (3/3), done. Writing objects: 100% (3/3), 352 bytes, done. Total 3 (delta 1), reused 0 (delta 0) To https://github.com/vlad/planets 29aba7c..dabb4c8 master -&gt; master 이제 또다른 파트너가 GitHub에서 갱신(update)하지 않고, 본인 사본에 다른 변경사항을 작업한다: $ nano mars.txt $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity We added a different line in the other copy 로컬 저장소에 변경사항을 커밋할 수 있다: $ git add mars.txt $ git commit -m &quot;Add a line in my copy&quot; [master 07ebc69] Add a line in my copy 1 file changed, 1 insertion(+) 하지만, Git이 GitHub에는 푸쉬할 수 없게 한다: $ git push origin master To https://github.com/vlad/planets.git ! [rejected] master -&gt; master (non-fast-forward) error: failed to push some refs to &#39;https://github.com/vlad/planets.git&#39; hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Merge the remote changes (e.g. &#39;git pull&#39;) hint: before pushing again. hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. 충돌하는 변경사항 Git이 푸쉬를 거절한다. 이유는 로컬 브랜로 반영되지 않는 신규 업데이터트가 원격 저장소에 있음을 Git이 탐지했기 때문이다. 즉, 본인이 작업한 변경사항이 다른 사람이 작업한 변경사항과 중첩되는 것을 Git이 탐지해서, 앞에서 작업한 것을 뭉개지 않도록 정지시킨다. 이제 해야될 작업은 GitHub에서 변경사항을 풀(Pull)해서 가져오고, 현재 작업중인 작업본과 병합(merge)해서 푸쉬한다. 풀(Pull)부터 시작하자: $ git pull origin master remote: Counting objects: 5, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 1), reused 3 (delta 1) Unpacking objects: 100% (3/3), done. From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD Auto-merging mars.txt CONFLICT (content): Merge conflict in mars.txt Automatic merge failed; fix conflicts and then commit the result. git pull 명령어는 로컬 저장소를 갱신할 때 원격 저장소에 이미 반영된 변경사항을 포함시키도록 한다. 원격 저장소 브랜치에서 변경사항을 가져온(fetch) 후에, 로컬 저장소 사본의 변경사항이 원격 저장소 사본과 겹치는 것을 탐지해냈다. 따라서, 앞서 작업한 것이 뭉개지지 않도록 서로 다른 두 버젼의 병합(merge)을 승인하지 않고 거절한 것이다. 해당 파일에 충돌나는 부분을 다음과 같이 표식해 놓는다: $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD We added a different line in the other copy ======= This line added to Wolfman&#39;s copy &gt;&gt;&gt;&gt;&gt;&gt;&gt; dabb4c8c450e8475aee9b14b4383acc99f42af1d &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD으로 시작되는 부분에 본인 변경사항이 나와있다. Git이 자동으로 =======을 넣어서 충돌나는 변경사항 사이에 구분자로 넣고, &gt;&gt;&gt;&gt;&gt;&gt;&gt;기호는 GitHub에서 다운로드된 파일 내용의 마지막을 표시한다. (&gt;&gt;&gt;&gt;&gt;&gt;&gt; 표시자 다음에 문자와 숫자로 구성된 문자열로 방금 다운로드한 커밋번호도 식별자로 제시한다.) 파일을 편집해서 표시자/구분자를 제거하고 변경사항을 일치하는 것은 전적으로 여러분에게 달려있다. 원하는 무엇이든지 할 수 있다: 예를 들어, 로컬 저장소의 변경사항을 반영하든, 원격 저장소의 변경사항을 반영하든, 로컬과 원격 저장소의 내용을 대체하는 새로운 것을 작성하든, 혹은 변경사항을 완전히 제거하는 것도 가능하다. 로컬과 원격 모두 교체해서 다음과 같이 파일이 보이도록 하자: $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity We removed the conflict on this line 병합을 마무리하기 위해서, 병합으로 생성된 변경사항을 mars.txt 파일에 추가하고 커밋한다: $ git add mars.txt $ git status On branch master All conflicts fixed but you are still merging. (use &quot;git commit&quot; to conclude merge) Changes to be committed: modified: mars.txt $ git commit -m &quot;Merge changes from GitHub&quot; [master 2abf2b1] Merge changes from GitHub 이제 변경사항을 GitHub에 푸쉬할 수 있다: $ git push origin master Counting objects: 10, done. Delta compression using up to 4 threads. Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 697 bytes, done. Total 6 (delta 2), reused 0 (delta 0) To https://github.com/vlad/planets.git dabb4c8..2abf2b1 master -&gt; master Git이 병합하면서 수행한 것을 모두 추적하고 있어서, 수작업으로 다시 고칠 필요는 없다. 처음 변경사항을 만든 협력자 프로그래머가 다시 풀하게 되면: $ git pull origin master remote: Counting objects: 10, done. remote: Compressing objects: 100% (4/4), done. remote: Total 6 (delta 2), reused 6 (delta 2) Unpacking objects: 100% (6/6), done. From https://github.com/vlad/planets * branch master -&gt; FETCH_HEAD Updating dabb4c8..2abf2b1 Fast-forward mars.txt | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) 병합된 파일을 얻게 된다: $ cat mars.txt Cold and dry, but everything is my favorite color The two moons may be a problem for Wolfman But the Mummy will appreciate the lack of humidity We removed the conflict on this line 다시 병합할 필요는 없는데, 다른 누군가 작업을 했다는 것을 Git가 알기 때문이다. 충돌을 해소하는 Git 기능은 매우 유용하지만, 충돌해소에는 시간과 노력이 수반되고, 충돌이 올바르게 해소되지 않게 되면 오류가 스며들게 된다. 프로젝트 와중에 상당량의 충돌을 해소하는데 시간을 쓰고 있다고 생각되면, 충돌을 줄일 수 있는 기술적인 접근법도 고려해보는 것이 좋겠다. 좀더 자주 upstream을 풀(Pull)하기, 특히 신규 작업을 시작하기 전이라면 더욱 그렇다. 작업을 구별하기 위해서 토픽 브랜치를 사용해서, 작업을 완료하면 마스터(master) 브랜치에 병합시킨다. 좀더 작게 원자수준 커밋을 한다. 논리적으로 적절하다면, 큰 파일을 좀더 작은 것으로 쪼갠다. 그렇게 함으로써 두 저작자가 동시에 동일한 파일을 변경하는 것을 줄일 수 있을 듯 싶다. 프로젝트 관리 전략으로 충돌(conflicts)을 최소화할 수도 있다: 동료 협력자와 누가 어떤 분야에 책임이 있는지 명확히 한다. 동료 협력자와 작업순서를 협의해서, 동일한 라인에 변경사항이 있을 수 있는 작업이 동시에 작업되지 않게 시간차를 둔다. 충돌이 문체변동(탭 vs 2 공백) 때문이라면, 프로젝트 관례를 수립하고, 코딩 스타일 도구(htmltidy, perltidy, rubocop 등)를 사용해서 필요한 경우 강제한다. 본인이 생성한 충돌 해소하기 강사가 생성한 저장소를 복제하세요. 저장소에 새 파일을 추가하고, 기존 파일을 변경하세요. (강사가 변경할 기존 파일이 어느 것인지 알려줄 것이다.) 강사의 말에 따라 충돌을 생성하는 연습을 위해서, 저장소에서 변경사항을 가져오도록 풀(Pull)하세요. 그리고 충돌을 해소하고 해결해 보세요. 텍스트 파일이 아닌 충돌 버젼 제어 저장소의 이미지 파일이나 혹은 다른 텍스트가 아닌 파일에서 충돌이 발생할 때, Git는 무엇을 하나요? 해답 먼저 시도해 보자. 드라큘라가 화성 표면에서 사진을 찍어 mars.jpg로 저장했다고 가정한다. 화성 이미지 파일이 없다면 다음과 같이 더미 바이너리 파일을 생성할 수도 있다. $ head --bytes 1024 /dev/urandom &gt; mars.jpg $ ls -lh mars.jpg -rw-r--r-- 1 vlad 57095 1.0K Mar 8 20:24 mars.jpg ls 명령어를 사용해서 파일 크기가 1 킬로바이트임이 확인된다. /dev/urandom 특수 파일에서 불러온 임의 바이트로 꽉 차있다. 이제, 드라큘라가 mars.jpg 파일을 본인 저장소에 저장한다고 상정한다: $ git add mars.jpg $ git commit -m &quot;Add picture of Martian surface&quot; [master 8e4115c] Add picture of Martian surface 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 mars.jpg 늑대인간도 비슷한 시점에 유사한 사진을 추가했다고 가정한다. 늑대인간의 사진은 화성하늘 사진인데, 이름도 mars.jpg로 동일하다. 드라큘라가 푸쉬하게 되면 유사한 메시지를 받게 된다: $ git push origin master To https://github.com/vlad/planets.git ! [rejected] master -&gt; master (fetch first) error: failed to push some refs to &#39;https://github.com/vlad/planets.git&#39; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &#39;git pull ...&#39;) before pushing again. hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. 풀을 먼저한 뒤에 충돌나는 것을 해소한다는 것을 학습했다: $ git pull origin master 이미지나 기타 바이너리 파일에 충돌이 생길 때, Git은 다음과 같은 메시지를 출력한다: $ git pull origin master remote: Counting objects: 3, done. remote: Compressing objects: 100% (3/3), done. remote: Total 3 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (3/3), done. From https://github.com/vlad/planets.git * branch master -&gt; FETCH_HEAD 6a67967..439dc8c master -&gt; origin/master warning: Cannot merge binary files: mars.jpg (HEAD vs. 439dc8c08869c342438f6dc4a2b615b05b93c76e) Auto-merging mars.jpg CONFLICT (add/add): Merge conflict in mars.jpg Automatic merge failed; fix conflicts and then commit the result. 이번에도 충돌 메시지가 mars.txt에 나온 것과 거의 동일하다. 하지만, 중요한 추가 라인 한줄이 있다: warning: Cannot merge binary files: mars.jpg (HEAD vs. 439dc8c08869c342438f6dc4a2b615b05b93c76e) Git은 자동으로 텍스트 파일에 했던 것처럼 이미지 파일에 충돌지점 표식을 끼워넣을 수 없다. 그래서 이미지 파일을 편집하는 대신에, 간직하고자 하는 버전을 쳇아웃(checkout)하고 나서 해당 버전을 추가(add)하고 커밋한다. 중요한 라인에, mars.jpg 두가지 버전에 대해서 커밋 식별자(commit identifier)를 Git이 제시하고 있다. 현재 작업 버젼은 HEAD이고, 늑대인간 작업버전은 439dc8c0...이다. 본인 작업버젼을 사용하고자 하면, git checkout 명령어를 사용한다: $ git checkout HEAD mars.jpg $ git add mars.jpg $ git commit -m &quot;Use image of surface instead of sky&quot; [master 21032c3] Use image of surface instead of sky 대신에 늑대인간 버젼을 사용하려고 하면, git checkout 명령어를 늑대인간 439dc8c0 커밋 식별자와 함께 사용하면 된다: $ git checkout 439dc8c0 mars.jpg $ git add mars.jpg $ git commit -m &quot;Use image of sky instead of surface&quot; [master da21b34] Use image of sky instead of surface 이미지 모두 보관할 수도 있다. 동일한 이미지명으로 보관할 수는 없다는 것이 중요하다. 순차적으로 각 버젼을 쳇아웃(checkout)하고 나서 이미지명을 변경한다. 그리고 나서 이름을 변경한 버젼을 추가한다. 먼저, 각 이미지를 쳇아웃하고 이름을 변경하자: $ git checkout HEAD mars.jpg $ git mv mars.jpg mars-surface.jpg $ git checkout 439dc8c0 mars.jpg $ mv mars.jpg mars-sky.jpg 그리고 나서, mars.jpg 이전 파일을 삭제하고 신규 파일 두개를 추가한다: $ git rm mars.jpg $ git add mars-surface.jpg $ git add mars-sky.jpg $ git commit -m &quot;Use two images: surface and sky&quot; [master 94ae08c] Use two images: surface and sky 2 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 mars-sky.jpg rename mars.jpg =&gt; mars-surface.jpg (100%) 이제 화성 이미지 파일 두개가 저장소에서 확인되지만 mars.jpg 파일은 더이상 존재하지 않는다. 일반적인 작업 시간 원격 Git 저장소를 활용하여 공동 프로젝트로 작업하는 컴퓨터 앞에 않아있다. 작업시간동안에 다음 동작을 취하지만, 작업순서는 다르다: 변경한다(make change): numbers.txt 텍스트 파일에 숫자 100을 추가. 원격 저장소 갱신시키기(Update remote): 로컬 저장소와 매칭되어 동기화시킴. 축하하기(Celebrate): 맥주로 성공을 자축함. 로컬 저장소 갱신시키기(Update local): 원격 저장소와 매칭되어 동기화시킴. 변경사항 준비영역으로 보내기(Stage change): 커밋대상으로 추가하기. 변경사항(Commit change): 로컬 저장소에 커밋하기 어떤 순서로 작업을 수행해야 충돌이 날 가능성을 최소화할 수 있을까? 아래표 action 칼럼에 순서대로 상기 명령어를 적어 본다. 작업 순서를 정했으면, command 칼럼에 대응되는 명령어를 적어본다. 일부 단계를 시작하는데 도움이 되도록 채워져 있다. order action . . . . . . . . . . command . . . . . . . . . . 1 2 echo 100 &gt;&gt; numbers.txt 3 4 5 6 Celebrate! AFK 해답 order action . . . . . . command . . . . . . . . . . . . . . . . . . . 1 Update local git pull origin master 2 Make changes echo 100 &gt;&gt; numbers.txt 3 Stage changes git add numbers.txt 4 Commit changes git commit -m \"Add 100 to numbers.txt\" 5 Update remote git push origin master 6 Celebrate! AFK "],["git-open.html", "17 . 공개 과학 (Open Science)", " 17 . 공개 과학 (Open Science) “공개(open)”의 반대는 “폐쇄(closed)”가 아니다. (The opposite of “open” isn’t “closed”.) “공개(open)”의 반대는 “망한(broken)” 것이다. (The opposite of “open” is “broken”.) 정보의 자유 공유는 과학에서 이상적일지 모르지만, 현실은 좀더 복잡하다. 현재, 보통 실무사례는 다음과 같다: 과학자가 데이터를 수집하고 학과에 가끔 백업되는 컴퓨터에 저장한다. 데이터를 분석하기 위해서 작은 프로그램을 작성하고 수정한다. (프로그램도 연구원의 로컬 노트북에 저장된다.) 적당한 분석 결과가 생성되자 마자, 작성해서 논문을 제출한다. 데이터를 논문에 포함할 수도 있다. (점점 많은 저널이 데이터를 요구한다.) 하지만, 아마도 프로그램 코드는 포함하지 않을 것이다. 시간이 흐른다. 저널에서는 연구원 분야의 익명으로된 소수의 사람들에게서 받아 검토(review)결과를 보낸다. 검토 결과를 충족하도록 논문을 수정한다. 수정하는 동안에 앞서 작성한 프로그램, 스크립트를 변경해서 다시 제출한다. 좀더 많은 시간이 흐른다. 종국에 논문이 출판된다. 논문에 데이터 온라인 사본 링크를 포함할 수도 있다. 하지만, 논문은 유료로 돈을 내야만 접근가능하다는 장벽(paywall)에 막혀있다: 개인 혹은 기관 접근 권한을 가진 사람만이 논문을 읽을 수 있다. 하지만, 점점 더 많은 과학자들에게, 프로세스는 다음과 같다: 과학자가 수집한 데이터가 수집되는 즉시, figshare 혹은 Zenodo같은 공개 접근 저장소에 저장된다. 그리고 디지털 객체 식별자(Digital Object Identifier, DOI)가 부여된다. 혹은 데이터를 이미 게시하고 Dryad에 저장한다. 과학자가 작업물을 보관할 저장소를 GitHub에 생성한다. 분석작업을 수행하면서, 스크립트의 변경사항을 (아마도 몇몇 산출 결과도 포함해서) 저장소에 푸쉬한다. 논문을 위한 저장소를 다목적으로 사용한다; 이 저장소가 다른 동료 과학자와 협업하는 허브가 된다. 논문 상태에 만족할 정도로 진행되면, arXiv 혹은 다른 사전 출력 서비스에 게시하고, 다른 동료 과학자를 초대해서 피드백을 받는다. 피드백에 기초해서 저널에 논문을 마지막으로 제출하기 전 몇번의 수정사항을 게시할 수도 있다. 출판된 논문은 사전출판논문, 코드, 그리고 데이터 저장소의 링크를 포함한다. 그렇게 함으로써 다른 과학자가 본인 연구의 시작점으로 삼아서 연구를 쉽게 연결해서 수행할 수 있게 된다. 이러한 공개 연구 모형은 발견을 가속시킨다. 연구 작업이 더 많이 공개될수록, 더 많이 인용되고 재사용된다(the more widely it is cited and re-used). 하지만, 이런 방식으로 작업하고 연구하고자 하는 사람들은 실무에서 “공개(open)”가 정확하게 의미하는 바에 대해서 몇가지 결정을 내릴 필요가 있다. 공개 과학(Open Science)에 관한 다른 측면에 대해서 이 책을 참고한다. 이것이 버젼 제어(version control)를 가르치는 (많은) 이유 중의 하나다. 버젼제어가 꾸준히 사용될 때, 컴퓨터 작업에 대한 공유가능한 전자연구노트로 활동함으로써 “방법”에 대한 질문에 답을 한다: 누가 언제 무엇을 했는지를 포함해서, 작업에 대한 개념적 단계가 문서화된다. 모든 단계는 (커밋 ID)식별자로 도장이 찍힌다. 식별자는 의도와 목적을 갖는 중복되지 않고 유일하다. 정당성(rationale), 아이디어, 다른 지적 작업에 대한 문서화를 이것에서 파생된 변경사항과 묶을 수 있다. 중복되지 않고 유일하며 복구가능한 방식으로 컴퓨터 작업 결과물을 얻어서 연구에 사용할 것을 조회할 수 있다. Git같은 분산된 버젼제어 시스템으로, 버젼제어 저장소는 영속성을 쉽게 얻을 수 있고, 전체 이력을 담아낼 수 있다. 코드를 인용가능하게 만들기 버젼제어 저장소에 올라온 모든 것(데이터, 코드, 논문 등)은 인용가능한 객체로 변환시킬 수 있다. lesson 12: 인용(Citation)에서 인용하는 방법에 대해서 학습하게 된다. 내 작업을 어떻게 재현가능하게 만들 수 있을까? 연구실 동료중 한명에게 논문에 나온 내용과 웹으로만 최근에 본인이 성취한 결과를 재현할 수 있는지 물어본다. 동료 결과물 중 하나에 대해서도 같은 작업을 수행해 본다. 그리고 나서, 일하고 있는 연구실에 나온 결과물에 대해서도 시도를 해본다. 적절한 데이터 저장소를 찾는 방법? 2~3분정도 인터넷을 검색하고 앞에서 언급된 데이터 저장소를 조사해 본다: Figshare, Zenodo, Dryad. 전공분야에 따라, 본인 전공분야별로 잘 알려진 저장소가 도움이 될 수 있다. Nature에서 추천한 데이터 저장소도 유용할 수 있다. 주변 동료와 현재 작업에 사용하고 있는 데이터 저장소에 대해서 토론해 보고, 이유도 설명해 보자. "],["git-licensing.html", "18 . 라이선싱 (Licensing) 18.1 소프트웨어 라이선스 18.2 콘텐츠 라이선스", " 18 . 라이선싱 (Licensing) 18.1 소프트웨어 라이선스 소스코드, 원고, 다른 창의적 저작물을 갖는 저장소가 공개될 때, 저장소 기반 디렉토리에 LICENSE 혹은 LICENSE.txt 파일을 포함해서 콘텐츠가 어떤 라이선스로 이용가능한지를 명확히 기술해야된다. 이유는 소스코드가 창의적 저작물로서, 자동적으로 지적재산(따라서 저작권)보호에 대상에 부합되기 때문이다. 자유로이 이용가능한 것으로 보여지거나, 명시적으로 광고되는 코드는 그런 보호를 유예하지 않는다. 따라서, 라이선스 문장이 없는 코드를 (재)사용하는 누구나 스스로 위험에 처하게 된다. 왜냐하면 소프트웨어 코드 저자가 항상 일방향으로 재사용을 불법화할 수 있기 때문이다. 즉, 저작권 소유자가 당신을 저작권법 위반으로 고소할 수 있다. 라이선스는 그렇지 않다면 보유하지 못할 권리를 다른 사람(라이선스 허여자, licensee)에게 부여함으로써 이 문제를 해결한다. 어떤 조건아래서 무슨 권리가 부여될지는 라이선스마다 다소 차이가 난다. 독점적 라이선스와 대조하여, Open Source Initiative에서 공인된 오픈 라이선스(open licences)는 최소한 다음에 나온 권리를 모두 부여한다. 이런 권리를 오픈 소스 정의(Open Source Definition)로 부른다.: 소스코드는 제약없이 이용가능하고, 사용되고, 재배포될 수 있다. 종합 배포의 일부로서도 포함된다. 변형 혹은 다른 파생 저작물도 허락되고, 또한 재배포될 수 있다. 이런 권리를 누가 받느냐의 질문이 차별의 조건이 되지 않는다. 예를 들어 상업적 혹은 학술적처럼 노력 분야에 의해서가 아님도 포함된다. 특히, 지금까지 라이선스 몇개가 인기를 얻고 있는데, choosealicense.com 웹사이트에서 본인 상황에 적합한 일반적인 라이선스를 선택하는데 도움이 된다. 주요한 고려사항에는 다음이 포함된다: 특허권을 주장하고자 하는가? 파생 저작물을 배포하는데 다른 사람도 소스코드를 배포하도록 강제할 것인가? 라이선싱하는 콘텐트가 소스코드인가? 이왕이면 소스코드도 라이선스할 것인가? 적절한 라이선스를 가장 잘 선택하는 것이 상당히 많은 가능한 조합이 있어 주눅이 들 수도 있다. 실무에서, 일부 라이선스만 지금까지 가장 인기가 있고, 다음이 그 범주에 포함된다: GNU 일반공중 라이선스 (GPL), MIT 라이선스, BSD 라이선스, 아파치 라이선스, 버젼 2.0. GPL은 다른 대부분의 공개소스 라이선스와 다른데, 전염성이 있는(infective) 특징이 있다: 코드의 수정된 버젼을 배포하는 누구나 혹은 GPL 코드를 포함한 어느 것이든지, 자신의 코드도 동일하게 자유로이 공개가능하게 만들어야 한다. 흔히 사용되는 라이선서를 선택하는 것이 기여자나 사용자의 삶을 편하게 한다. 왜냐하면, 기여자나 사용자 모두 해당 라이선스에 친숙해서 사용할 때 상당한 양의 전문용어를 꼼꼼히 살펴볼 필요가 없기 때문이다. Open Source Initiative와 Free Software Foundation 모두 좋은 선택이 될 수 있는 라이선스 목록을 유지관리하고 있다. 코드를 작성하는 과학자 관점에서 라이선싱과 라이선싱 선택지에 대한 전반적인 정보를 이 기사를 통해서 살펴볼 수 있다. 결국 가장 중요한 것은 라이선스가 무엇인지에 대해 분명한 문장이 있는지와 라이선스가 OSI와 FSF에서 승인되고 이미 검증된 것인지 여부다. 또한, 저장소에 공개된 것이 아닐지라도, 처음부터 최선으로 라이선스를 선택해야 된다. 결정을 미루는 것은 나중에 더 복잡하게 된다. 왜냐하면, 매번 새로운 협력자가 기여하기 시작하면, 협력자도 저작권을 갖게된다. 따라서, 라이선스를 고르자 마자, 승인을 득해야할 필요가 있기 때문이다. 본인이 오픈 라이선스를 사용할 수 있나요? 여러분이 작성하고 있는 소프트웨어에 오픈소스 소프트웨어 라이선스를 적용할 수 있는지 알아본다. 여러분이 라이선스 적용을 일방적으로 할 수 있는가? 혹은 여러분의 기관이나 조직의 다른 사람에게서 허락이 필요한가? 만약 그렇다면 누굴까? 본인은 어떤 라이선스를 이미 승인했나요? (금번 워크샵을 포함해서) 매일 사용하는 대다수 소프트웨어는 오픈-소스 소프트웨어로 출시되었다. 아래 목록 혹은 본인이 직접 고른 GitHub 사이트에서 프로젝트를 하나 고른다. 라이선스를 찾아(보통 LICENSE 혹은 COPYING 이름이 붙은 파일)보고, 소프트웨어 사용을 어떻게 제약하는지 살펴보자. 이번 세션에서 논의된 라이선스 중 하나인가? 차이점은 어떻게 나는가? Git, 소스코드 관리 도구 CPython, 파이썬 언어 구현 Jupyter, 웹기반 파이썬 노트북 프로젝트 EtherPad, 실시간 협업 편집기 18.2 콘텐츠 라이선스 만약 저장소 콘텐츠가 소프트웨어가 아닌 데이터, 창의적 저작물(매뉴얼, 기술 보고서, 원고) 같은 연구제품이 포함되면, 소프트웨어를 위해 설계된 라이선스 대부분은 적합하지는 못하다. 데이터: 대부분 국가사법권에서 데이터 유형 대부분은 자연에 대한 사실로 간주된다. 그럼으로, 저작권 보호를 받을 자격이 없다.(단, 아마도 사진과 의료영상정보 등은 예외) 따라서, 저작자 표시로 사회적 혹은 학자적 기대치를 알리려고, 저작권을 정의로 주장하는 방식으로 라이선스를 사용하는 것은 단지 법적으로 혼탁한 상황만 조장할 뿐이다. 크리에이티브 커먼즈 제로(Creative Commons Zero, CC0) 처럼 공중도메인 권리포기를 지지하는 법적 표시를 분명히 하는 것이 더 낫다. Dryad 데이터 저장소는 사실 이를 요구하고 있다. 창의적 저작물(Creative works): 매뉴얼, 보고서, 원고, 기타 창의적 저작물은 지적재산 보호 대상이 된다. 따라서 소프트웨어와 마찬가지로 자동으로 저작권으로 보호된다. 크리에이티브 커먼즈(Creative Commons) 조직이 기본 제약사항 4개를 조합해서 라이선스 집합을 마련했다: 저작자 표시(Attribution): 파생 저작물에 대해서 최초 저작자의 이름, 출처 등의 정보를 반드시 표시해야 한다. 변경 금지(No Derivative): 저작물을 복사할 수도 있으나 저작물을 변경 혹은 저작물을 이용하여 2차적 저작물로 제작을 금한다. 동일조건변경허락(Share Alike): 2차적 저작물을 제작할 수 있으나, 2차적 저작물은 원래 저작물과 동일한 라이선스를 적용한다. 비영리(Noncommercial): 저작물을 영리 목적으로 사용할 수 없음. 영리 목적을 위해서는 별도의 계약이 필요하다. 출처표시 (CC-BY)와 동일조건변경허락(CC-BY-SA) 라이선스만이 “오픈 라이선스”로 간주된다. 소프트웨어 카펜트리는 가능하면 폭넓게 재사용될 수 있도록 수업자료에 대해서는 CC-BY, 코드에는 MIT 라이선스를 사용한다. 다시 한번, 가장 중요한 것은 프로젝트 루트 디렉토리에 있는 LICENSE 파일에 라이선스가 무엇인지 분명하게 언급한다. 본인 프로젝트를 참조하는 방법을 기술하는데 CITATION 혹은 CITATION.txt 파일을 포함할 수도 있다. 소프트웨어 카펜트리 사례는 다음과 같다: To reference Software Carpentry in publications, please cite both of the following: Greg Wilson: &quot;Software Carpentry: Lessons Learned&quot;. arXiv:1307.5448, July 2013. @online{wilson-software-carpentry-2013, author = {Greg Wilson}, title = {Software Carpentry: Lessons Learned}, version = {1}, date = {2013-07-20}, eprinttype = {arxiv}, eprint = {1307.5448} } "],["git-hosting.html", "19 . 호스팅 (Hosting)", " 19 . 호스팅 (Hosting) 저작물이나 작업을 공개하고자 하는 그룹에서 가지는 두번째 큰 질문은 코드와 데이터를 어디에 호스팅할지 정하는 것이다. 방법중 하나는 연구실, 학과, 혹은 대학이 서버를 제공하여 계정관리와 백업 등등을 관리하는 것이다. 주된 장점은 누가 무엇을 소유하는지 명확하다. 특히 민감한 정보(예를 들어, 사람에 대한 실험정보 혹은 특허 출원에 사용될 수도 있는 정보)가 있다면 중요하다. 큰 단점은 서비스 제공 비용과 수명이다: 데이터를 수집하는데 10년을 보낸 과학자가 지금부터 10년 후에도 여전히 이용가능하기를 원하지만, 학교 인프라를 지원하는 대부분의 연구기금의 수명이 턱없이 짧다. 또다른 선택지는 도메인을 구입하고 호스팅하는데 ISP(인터넷 서비스 제공자, Internet service provider)에 비용을 지불한다. 이 접근법은 개인이나 그룹에게 좀더 많은 제어권을 주고 학교나 기관을 바꿀 때 생기는 문제도 비켜갈 수 있다. 하지만, 위나 아래 선택지보다 초기 설정하는데 더 많은 시간과 노력이 요구된다. 세번째 선택지는 GitHub, BitBucket, 혹은 SourceForge 같은 공개 호스팅 서비스를 채용하는 것이다. 웹 인터페이스를 통해서 저장소 코드를 생성하고, 보고, 편집할 수 있게 한다. 이러한 서비스는 이슈추적, 위키 페이지, 이메일 통보, 코드 리뷰를 포함한 커뮤니케이션과 프로젝트 관리 도구도 제공한다. 이러한 서비스는 규모의 경제와 네트워크 효과로 모두 이익을 볼 수 있다: 즉, 동일한 표준을 갖는 작은 많은 서비스를 실행하는 것보다 큰 서비스 하나를 실행하는 것이 더 쉽다. 또한, 사람들이 협업하기도 더 쉽다. 대중적인 서비스를 사용하면 이미 동일한 서비스를 사용하는 커뮤니티와 본인 프로젝트를 연결하는데 도움이 된다. 예로서, 소프트웨어 카펜트리는 GitHub에 있어서, 해당 페이지에 대한 소스코드를 찾아볼 수 있다. GitHub 계정을 갖는 누구나 해당 페이지에 변경사항을 제안할 수 있다. GitHub 저장소에서 Zenodo에 릴리스(release)를 연결하면 DOI를 부여할 수도 있다. 예를 들어, 10.5281/zenodo.57467이 “Git 소개”에 대해 주조된 DOI다. 규모가 크고 잘 정립된 서비스를 사용하는 것이 빠르게 강력한 도구의 장점을 흡수하는데 도움을 줄 수도 있다. 지속적 통합(Continuous integration, CI)이 그런 도구 중 하나로 자동으로 소프트웨어 빌드를 돌리고 코드가 커밋되거나 풀요청이 제출될 때마다 실행된다. 온라인 호스팅 서비스와 CI를 직접 통합이 의미하는 바는, 어떤 풀요청에도 해당 정보가 존재해서 코드 완결성과 품질 표준을 유지하는데 도움을 준다. 여전히 CI가 자가 구축한 호스팅 상황에도 이용가능하지만, 온라인 서비스 사용과 연계되면 초기설정과 유지보수 업무를 줄일 수 있다. 더욱이, 이러한 도구가 오픈소스 프로젝트에 무료로 제공되기도 한다. 사설 저장소에 대해서만 비용 일부를 지불하고 이용가능하다. 제도적 장벽 (Institutional Barriers) 공유가 과학에는 이상적이지만, 많은 기관에서 공유에 제약을 가한다. 예를 들어 잠재적으로 특허가능한 지적재산을 보호하는데 말이다. 만약 여러분이 그런 제약과 마주한다면, 특정 프로젝트 혹은 도메인에 예외를 요청하거나, 제도 혁파를 통해서 더 공개된 과학을 지지하도록 좀더 앞서 나가는데 근본적인 동기에 관해 질의하는 것이 더 생산적일 수 있다. 본인 작업을 공개할 수 있을까? 본인 작업을 공개 저장소에 공개할 수 있는지 알아보자. 공개 작업을 일방적으로 할 수 있을까? 혹은 속한 조직의 누군가로부터 허락이 필요한가? 만약 그렇다면 조직의 누굴까? 본인 작업을 어디에 공개할 수 있을까? 본인 논문, 데이터, 소프트웨어를 공유하려면 이용가능한 저장소가 소속기관에 갖추어져 있는가? 소속기관 저장소는 arXiV, figshare, GitHub or GitLab와 같은 데이터 저장소 서비스와 비교하여 어떤 차이점이 있는가? "],["git-korean.html", "20 . Git 추가설정 20.1 로컬 PC와 SSH 키(Key) 연결 20.2 SSH 공개키/비밀키 생성 1 20.3 첫 커밋(commit) 20.4 비밀번호 입력없이 푸쉬(push) 2", " 20 . Git 추가설정 20.1 로컬 PC와 SSH 키(Key) 연결 GitHub에 저장소(repository)를 만들고 여러 PC에서 작업을 진행할 경우 GitHub에 인증작업을 거쳐 진행하는 것이 여러모로 편리하다. 그중 하나의 방식이 공개키(public key)를 GitHub에 등록시켜 작업을 하는 것이 여기에 포함된다. 먼저 윈도우를 사용할 경우 Git for windows를 다운로드 받아 설치한다. ssh-keygen 명령어로 공개키/비밀키를 생성한다. 생성된 공개키를 GitHub 계정에 등록시킨다. 20.2 SSH 공개키/비밀키 생성 1 SSH 공개키/비밀키를 생성시키고 이를 GitHub 홈페이지에 등록한다. 먼저 ssh-keygen 명령어에 매개변수 인자를 넣고 GitHub 전자우편주소도 함께 지정한다. $ ssh-keygen -t rsa -C “your_email@example.com” ssh-keygen 명령어로 생성된 키를 GitHub에 등록한다. 우측상단 [Settings] → [SSH and GPG keys] → [New SSH key] [New SSH key]를 클릭하게 되면 Title, Key를 넣는 입력부분이 보인다. Title에 식별가능한 이름을 지정하고 앞서 생성한 id_rsa.pub 내용을 Key에 복사해서 붙여넣는다. $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxYxY9 email_address@mail.com 20.3 첫 커밋(commit) 인증작업을 완료한 후에 저장소에서 작업할 파일을 처음 커밋(commit)하는 경우 git add, git commit -m명령어를 이어서 전달시키게 되면 커밋을 때리는 사람이 누구인지를 등록하는 절차가 발생된다. git config를 통해 전자우편과 사용자명을 등록하게 되면 커밋을 정상적으로 진행시킬 수 있게 된다. $ git config --global user.email &quot;you@example.com&quot; $ git config --global user.name &quot;Your Name&quot; 20.4 비밀번호 입력없이 푸쉬(push) 2 다음 단계로 비밀번호 없이 커밋된 내용을 GitHub에 전달하는 방법은 자격인증(credential) 캐싱을 통한 간단한 방법이 있다. 물론 처음에는 사용자명과 비번을 입력하는 과정을 필수적으로 거치게 된다. $ git config credential.helper store $ git push https://github.com/repo.git Username for &#39;https://github.com&#39;: &lt;USERNAME&gt; Password for &#39;https://USERNAME@github.com&#39;: &lt;PASSWORD&gt; 캐쉬에 시간제한을 두어서 7200초 즉 2시간 보안을 강화시킨다. $ git config --global credential.helper &#39;cache --timeout 7200&#39; nickjoIT (2017), “GitHub SSH 키 생성 및 등록하여 사용하기”↩︎ Stackoverflow, “How do I avoid the specification of the username and password at every git push?”↩︎ "],["database-sql.html", "21 . 데이터베이스와 SQL 사용하기", " 21 . 데이터베이스와 SQL 사용하기 거의 모든 사람이 스프레드쉬트(spreadsheet) 사용했고, 거의 모든 사람이 종국에는 한계에 맞닥뜨렸다. 데이터셋이 더욱 복잡할수록, 데이터를 걸러내고, 다른 행과 열 사이에 관계를 표현하거나, 결측값을 다루기가 점점 어려워진다. 데이터베이스는 스프레드쉬트가 멈춘 곳에서 다시 시작한다. 만약 사용하고자 하는 것이 10여개의 숫자의 합이라면 데이터베이스는 사용하기가 간단하지는 않지만, 훨씬 큰 데이터셋에 훨씬 더 빨리 스프레드쉬트가 할 수 없는 많은 것을 수행할 수 있다. 그리고, 설사 데이터베이스를 스스로 생성할 필요는 없지만, 데이터베이스가 어떻게 동작하는지 파악하는 것은 우리가 사용하는 수 많은 시스템이 왜 그와 같은 방식으로 동작하는지 그리고 왜 특정한 방식으로 데이터를 구조화하려고 하는지도 이해를 준다. "],["database-sqlite.html", "22 . SQLite 설치 22.1 설치 22.2 SQLite 설치 3 22.3 실습 데이터베이스 다운로드 22.4 SQLite DB 연결/설치 테스트 22.5 SQLite DB 나오는 법", " 22 . SQLite 설치 이번 학습은 다음 장에서 사용되는 예제 데이터베이스를 어떻게 설치하는지 설명한다. 다음의 지도사항을 따르기 위해서는 명령-라인을 사용하여 어떻게 디렉토리를 여기저기 이동하는지와 명령-라인에서 명령문을 어떻게 실행하는지 숙지할 필요가 있다. 이런 주제와 친숙하지 않다면, 유닉스 쉘(Unix Shell) 학습을 참조하세요. 이후의 장에서 데이터베이스를 어떻게 생성하고 데이터를 채우는지 배울 것이지만, 먼저 SQLite 데이터베이스가 어떻게 동작하는지 설명을 할 필요가 있어서 데이터베이스를 선행하여 제공한다. 22.1 설치 인터랙티브하게 다음 학습을 수행하기 위해서는 설치 방법에 언급된 SQLite 를 참조하여 설치하세요. 그리고 , 여러분이 선택한 위치에 “software_carpentry_sql” 디렉토리를 생성하세요.예를 들어 명령 라인 터미널 윈도우를 여세요. 다음과 같이 타이핑한다. mkdir ~/swc/sql 생성한 디렉토리로 현재 작업 디렉토리를 변경한다. cd ~/swc/sql 22.2 SQLite 설치 3 SQLite Download Page에서 sqlite-tools-win32-x86-3200000.zip을 다운로드 받는다. 압축을 풀면 황당하게 몇개 .exe 파일이 존재하는 황당함을 느낀다. 설치가 완료되었다. $ ls gen-survey-database.sql sqlite3.exe survey.db sqldiff.exe sqlite3_analyzer.exe sqlite3.exe: sqlite 실행파일 gen-survey-database.sql: survey.db sqlite 데이터베이스를 생성시키는데 사용되는 스크립트 survey.db: sqlite3.exe 명령어를 실행해서 gen-survey-database.sql 스크립트를 통해 생성된 데이터베이스 22.3 실습 데이터베이스 다운로드 깃헙(GitHub)에서 gen-survey-database.sql 파일을 어떻게 다운로드 받을까요? ~/swc/sql 디렉토리로 이동한 후에 그 디렉토리에서 GitHub 사이트 https://github.com/swcarpentry/bc/blob/master/novice/sql/gen-survey-database.sqlSQL에 위치한 SQL 파일(“gen-survey-database.sql”)을 다운로드한다. 파일이 GitHub 저장소 내에 위치하고 있어서, 전체 Git 저장소(git repo)를 복제(cloning)하지 않고 단일 파일만 로컬로 가져온다. 이 목적을 달성하기 위해서, HTTP, HTTPS, FTP 프로토콜을 지원하는 명령-라인 웹크롤러(web-crawler) 소프트웨어 GNU Wget 혹은, 다양한 프로토콜을 사용하여 데이터를 전송하는데 사용되는 라이브러리이며 명령-라인 도구인 cURL을 사용한다. 두가지 도구 모두 크로스 플랫폼(cross platform)으로 다양한 운영체제를 지원한다. Wget 혹은 cURL을 로컬에 설치한 후에, 터미널에서 다음 명령어를 실행한다. Tip: 만약 cURL을 선호한다면, 다음 명령문에서 “wget”을 curl -O로 대체하세요. root@hangul:~/swc/sql$ wget https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql 상기 명령문으로 Wget은 HTTP 요청을 생성해서 github 저장소의 “gen-survey-database.sql” 원파일만 현재 작업 디렉토리로 가져온다. 성공적으로 완료되면 터미널은 다음 출력결과를 화면에 표시한다. --2014-09-02 18:31:43-- https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 103.245.222.133 Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|103.245.222.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 3297 (3.2K) [text/plain] Saving to: ‘gen-survey-database.sql’ 100%[=========================================================================================================================&amp;gt;] 3,297 --.-K/s in 0.01s 2014-09-02 18:31:45 (264 KB/s) - ‘gen-survey-database.sql’ saved [3297/3297] 이제 성공적으로 단일 SQL 파일을 가져와서, survey.db 데이터베이스를 생성하고 gen-survey-database.sql 에 저장된 지시방법에 따라서 데이터를 채워넣는다. 명령-라인 터미널에서 SQLite3 프로그램을 호출하기 위해서, 다음 명령문을 실행한다. root@hangul:~/swc/sql$ sqlite3 survey.db &lt; gen-survey-database.sql 22.4 SQLite DB 연결/설치 테스트 생성된 데이터베이스에 연결하기 위해서, 데이터베이스를 생성한 디렉토리 안에서 SQLite를 시작한다. 그래서 ~/swc/sql 디렉토리에서 다음과 같이 타이핑한다. root@hangul:~/swc/sql$ sqlite3 survey.db sqlite3 survey.db 명령문이 데이터베이스를 열고 데이터베이스 명령-라인 프롬프트로 안내한다. SQLite에서 데이터베이스는 플랫 파일(flat file)로 명시적으로 열 필요가 있다. 그리고 나서 SQLite 시작되고 sqlite로 명령-라인 프롬프트가 다음과 같이 변경되어 표시된다. SQLite version 3.20.0 2017-08-01 13:24:15 Enter &quot;.help&quot; for usage hints. Connected to a transient in-memory database. Use &quot;.open FILENAME&quot; to reopen on a persistent database. sqlite&gt; 다음 출력결과가 보여주듯이 .databases 명령문으로 소속된 데이터베이스 이름과 파일 목록을 확인한다. sqlite&gt; .databases seq name file --- --------------- ---------------------------------------------------------- 0 main ~/novice/sql/survey.db 다음과 같이 타이핑해서 필요한 “Person”, “Survey”, “Site” “Visited” 테이블이 존재하는 것을 확인한다. .table의 출력결과는 다음과 같다. sqlite&gt; .tables Person Site Survey Visited 22.5 SQLite DB 나오는 법 SQLite3 DB 명령-라인 인터페이스(CLI)를 어떻게 빠져나올까요? SQLite3를 빠져나오기 위해서, 다음과 같이 타이핑한다. sqlite&gt; .quit SQLite3 설치 및 간단한 사용법↩︎ "],["database-select.html", "23 . 변수/칼럼 선택하기 23.1 정의 몇가지 23.2 도전 과제 23.3 주요점", " 23 . 변수/칼럼 선택하기 1920년 후반, 1930년 초반 William Dyer, Frank Pabodie,Valentina Roerich는 남태평양 도달불가능한 극(Pole of Inaccessibility)과 이어서 남극 대륙을 탐험했다. 2년 전에 이들의 탐험 기록이 Miskatonic 대학 창고 사물함에서 발견됐다. 기록을 스캔해서 OCR로 저장했고, 이제는 검색가능하고 분석이 용히한 방식으로 정보를 저장하고자 한다. 기본적으로 3가지 선택 옵션(텍스트 파일, 스프레드쉬트, 데이터베이스)이 있다. 텍스트 파일은 생성하기 가장 쉽고 버젼 제어와 궁합이 맞지만, 검색과 분석 도구를 별도로 구축해야한다. 스프레드쉬트는 단순한 분석에는 적합하지만, 크고 복잡한 데이터셋을 매우 잘 다루지는 못한다. 그래서 데이터를 데이터베이스에 넣어서 어떻게 검색과 분석을 하는지 이번 학습에서 배울 것이다. 23.1 정의 몇가지 관계형 데이터베이스(relational database)는 테이블(tables)로 정렬된 정보를 저장하고 다루는 방식이다. 각 테이블은 데이터를 기술하는 필드(fields)로도 알려진 열(column)과 데이터를 담고 있는 레코드(records)로 알려진 행(row)으로 구성된다. 스프레드쉬트를 사용할 때, 이전 값에 기초하여 새로운 값을 계산할 때 공식을 셀(cell)에 넣어서 구한다. 데이터베이스를 사용할 때는 쿼리(queries, 질의)로 불리는 명령문을 데이터베이스 관리자(database manager)에게 보낸다. 데이터베이스 관리자는 사용자를 대신해서 데이터베이스를 다루는 프로그램이다. 데이터베이스 관리자는 쿼리가 명기하는 임의의 조회와 계산을 수행하고 다음 쿼리의 시작점으로 사용될 수 있는 테이블 형식으로 결과값을 반환한다. 모든 데이터베이스 관리자(IBM DB2, PostgreSQL, MySQL, Microsoft Access, SQLite)는 서로 다른 고유한 방식으로 데이터를 저장해서 한곳에서 생성된 데이터베이스는 다른 곳의 데이터베이스에서 직접적으로 사용될 수 없다. 하지만, 모든 데이터베이스 관리자는 데이터를 다양한 형식으로 가져오기(import)와 내보내기(export)를 지원한다. 그래서 한 곳에서 다른 곳으로 정보를 이동하는 것이 가능하다. 쿼리는 SQL로 불리는 언어로 작성된다. SQL 은 “Structured Query Language”(구조적 질의 언어)의 약자다. SQL은 데이터를 분석하고 다시 조합할 수 있는 수백개의 다른 방식을 제공한다. 학습에서 일부를 살펴볼 것이지만, 이 일부가 과학자가 수행하는 일의 대부분을 처리할 것이다. 다음 테이블은 예제로 사용할 데이터베이스를 보여준다. Person: 판독한 사람. ident personal family dyer William Dyer pb Frank Pabodie lake Anderson Lake roe Valentina Roerich danforth Frank Danforth Site: 판독한 장소. name lat long DR-1 -49.85 -128.57 DR-3 -47.15 -126.72 MSK-4 -48.87 -123.4 Visited: 특정 사이트에서 판독한 시점. ident site dated 619 DR-1 1927-02-08 622 DR-1 1927-02-10 734 DR-3 1939-01-07 735 DR-3 1930-01-12 751 DR-3 1930-02-26 752 DR-3   837 MSK-4 1932-01-14 844 DR-1 1932-03-22 Survey: 실제 판독. taken person quant reading 619 dyer rad 9.82 619 dyer sal 0.13 622 dyer rad 7.8 622 dyer sal 0.09 734 pb rad 8.41 734 lake sal 0.05 734 pb temp -21.5 735 pb rad 7.22 735   sal 0.06 735   temp -26.0 751 pb rad 4.35 751 pb temp -18.5 751 lake sal 0.1 752 lake rad 2.19 752 lake sal 0.09 752 lake temp -16.0 752 roe sal 41.6 837 lake rad 1.46 837 lake sal 0.21 837 roe sal 22.5 844 roe rad 11.25 3개 항목 (Visited 테이블에서 1개, Survey 테이블에서 2개) 은 붉은색으로 표기한 것을 주목하라. 왜냐하면 어떠한 값도 담고 있지 않아서 그렇다. 결측값(missing)은 추후 다룰 것이다. 지금으로서는 과학자의 이름을 화면에 표시하는 SQL을 작성하자. SQL select 문을 사용해서 원하는 칼럼이름과 원하는 테이블이름을 준다. 쿼리와 결과는 다음과 같다. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 23.1: 첫번째 SQL 쿼리 family personal Dyer William Pabodie Frank Lake Anderson Roerich Valentina Danforth Frank 쿼리 끝에 세미콜론(;)은 쿼리가 완료되어 실행준비 되었다고 데이터베이스 관리자에게 알려준다. 명령문과 칼럼 이름을 모두 소문자로 작성했고, 테이블 이름은 타이틀 케이스(Title Case, 단어의 첫 문자를 대문자로 표기)로 작성했다. 하지만 그렇게 반듯이 할 필요는 없다. 아래 예제가 보여주듯이, SQL은 대소문자 구분하지 않는다 표 23.2: SQL 쿼리문은 대소문자 구분하지 않음 family personal Dyer William Pabodie Frank Lake Anderson Roerich Valentina Danforth Frank 모두 소문자, 타이틀 케이스, 소문자 낙타 대문자(Lower Camel Case)를 선택하든지 관계없이 일관성을 가져라. 랜덤 대문자를 추가적으로 인지하지 않더라고 복잡한 쿼리는 충분히 그 자체로 이해하기 어렵다. 쿼리로 돌아가서, 데이터베이스 테이블의 행과 열이 특정한 순서로 저장되지 않는다는 것을 이해하는 것이 중요하다. 어떤 순서로 항상 표시되지만, 다양한 방식으로 제어할 수 있다. 예를 들어, 쿼리를 다음과 같이 작성해서 칼럼을 교환할 수 있다. 표 23.3: 칼럼 교환 personal family William Dyer Frank Pabodie Anderson Lake Valentina Roerich Frank Danforth 혹은 심지어 칼럼을 반복할 수도 있다. 표 23.4: 칼럼명 중복 선택 ident ident ident dyer dyer dyer pb pb pb lake lake lake roe roe roe danforth danforth danforth 손쉬운 방법으로, *을 사용해서 테이블의 모든 칼럼을 선택할 수도 있다. 표 23.5: 모든 칼럼 선택 ident personal family dyer William Dyer pb Frank Pabodie lake Anderson Lake roe Valentina Roerich danforth Frank Danforth 23.2 도전 과제 Site 테이블에서 사이트 이름만 선택하는 쿼리를 작성하세요. 많은 사람들이 쿼리를 다음과 같은 형식으로 작성한다. SELECT personal, family FROM person; 혹은 다음과 같이도 작성한다. select Personal, Family from PERSON; 읽기 쉽기 쉬운 스타일은 어느 것인가요? 이유는 무엇일까요? 23.3 주요점 관계형 데이터베이스는 정보를 테이블로 저장한다. 고정된 숫자의 칼럼과 변하기 쉬운 숫자의 레코드로 구성된다. 데이터베이스 관리자는 데이터베이스에 저장된 정보를 다루는 프로그램이다. 데이터베이스에서 정보를 추출하는데 SQL이라고 불리는 특화된 언어로 쿼리를 작성한다. SQL은 대소문자를 구별하지 않는다. "],["database-sort.html", "24 . 정렬, 중복 제거 24.1 도전 과제 24.2 도전 과제 24.3 주요점", " 24 . 정렬, 중복 제거 데이터는 종종 잉여가 있어서, 쿼리도 종종 과잉 정보를 반환한다. 예를 들어, survey 테이블에서 측정된 수량 정보를 선택하면, 다음을 얻게된다. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 24.1: SQL select 쿼리문 quant rad sal rad sal rad sal temp rad sal temp 결과를 좀더 읽을 수 있게 만들기 위해서 쿼리에 distinct 키워드를 추가해서 중복된 출력을 제거한다. 표 24.2: 중복 제거 쿼리문 quant rad sal temp 하나 이상의 칼럼(예를 들어 survey 사이트 ID와 측정된 수량)을 선택한다면, 별개로 구별된 값의 쌍이 반환된다. 표 24.3: 칼럼 두개 중복 제거 taken quant 619 rad 619 sal 622 rad 622 sal 734 rad 734 sal 734 temp 735 rad 735 sal 735 temp 양쪽 경우에 설사 데이터베이스 내에서 서로 인접하지 않더라도 모두 중복이 제거된 것을 주목하세요. 다시 한번, 행은 실제로 정렬되지는 않았다는 것을 기억하세요. 단지 정렬된 것으로 화면에 출력된다. 24.1 도전 과제 Site 테이블에서 별개로 구별되는 날짜를 선택하는 쿼리를 작성하세요. 앞서 언급했듯이, 데이터베이스 레코드는 특별한 순서로 저장되지 않는다. 이것이 의미하는 바는 쿼리 결과가 반드시 정렬되어 있지 않다는 것이다. 설사 정렬이 되어 있더라도, 종종 다른 방식으로 정렬하고 싶을 것이다. 예를 들어 과학자의 이름 대신에 프로젝트 이름으로 정렬할 수도 있다. SQL에서 쿼리에 order by 절을 추가해서 간단하게 구현할 수 있다. 표 24.4: ident 칼럼 기준 정렬 ident personal family danforth Frank Danforth dyer William Dyer lake Anderson Lake pb Frank Pabodie roe Valentina Roerich 디폴트로, 결과는 오름차순으로 정렬되어야 한다. (즉, 가장 적은 값에서 가장 큰 값 순으로 정렬된다.) desc (“descending”)를 사용해서 역순으로도 정렬할 수 있다. 표 24.5: ident 칼럼 기준 역정렬 ident personal family roe Valentina Roerich pb Frank Pabodie lake Anderson Lake dyer William Dyer danforth Frank Danforth (그리고, desc 대신에 asc를 사용해서 오름차순으로 정렬하고 있다는 것을 명시적으로 표현할 수도 있다.) 한번에 여러 필드를 정렬할 수도 있다. 예를 들어, 다음 쿼리는 taken 필드를 오름차순으로 그리고 동일 그룹의 taken 값 내에서는 person으로 내림차순으로 결과를 정렬한다. 표 24.6: 칼럼 기준 순정렬, 역정렬 taken person 619 dyer 619 dyer 622 dyer 622 dyer 734 pb 734 pb 734 lake 735 pb 735 NA 735 NA 만약 중복을 제거한다면 이해하기가 더 쉽다. 표 24.7: 중복제거 칼럼 기준 순정렬, 역정렬 taken person 619 dyer 622 dyer 734 pb 734 lake 735 pb 735 NA 751 pb 751 lake 752 roe 752 lake 24.2 도전 과제 Visited 테이블에서 별개로 구별되는 날짜를 반환하는 쿼리를 작성하세요. 성(family name)으로 정렬된 Person 테이블에 과학자의 성명 전부를 화면에 출력하는 쿼리를 작성하세요. 24.3 주요점 데이터베이스 테이블의 레코드는 본질적으로 정렬되지 않는다. 만약 특정 순서로 정렬하여 표시하려면, 명시적으로 정렬을 명기하여야 한다. 데이터베이스의 값이 유일(unique)함을 보장하지는 않는다. 만약 중복을 제거하고자 한다면, 명시적으로 유일함을 명기하여야 한다. "],["database-filter.html", "25 . 필터링 (Filtering) 25.1 도전 과제 25.2 주요점", " 25 . 필터링 (Filtering) 데이터베이스의 가장 강력한 기능중 하나는 데이터를 필터(filter)하는 능력이다. 즉, 특정 기준에 맞는 레코드만 선택한다. 예를 들어, 특정 사이트를 언제 방문했는지 확인한다고 가정하자. 쿼리에 where 절을 사용해서 Visited 테이블로부터 레코드를 뽑아낼 수 있다. 표 25.1: SQL 필터 쿼리문 ident site dated 619 DR-1 1927-02-08 622 DR-1 1927-02-10 844 DR-1 1932-03-22 데이터베이스 관리자는 두 단계로 나누어 쿼리를 실행한다. 첫번째로, where 절을 만족하는 것이 있는지 확인하기 위해서 Visited 테이블의 각 행을 점검한다. 그리고 나서 무슨 칼럼을 표시할지 결정하기 위해서 select 키워드 다음에 있는 칼럼 이름을 사용한다. 이러한 처리 순서가 의미하는 바는 화면에 표시되지 않는 칼럼 값에 기반해서도 where 절을 사용해서 레코드를 필터링할 수 있다는 것이다. 표 25.2: SQL 칼럼 선택과 결합된 필터 쿼리문 ident 619 622 844 SQL 필터 쿼리문 적용 과정 데이터를 필터링하는데 불 연산자(Boolean Operators)를 사용할 수 있다. 예를 들어, 1930년 이후로 DR-1 사이트에서 수집된 모든 정보를 요청할 수도 있다. 표 25.3: SQL 필터 부울연산 반영쿼리문 ident site dated 844 DR-1 1932-03-22 (각 테스트 주위의 괄호는 엄밀히 말해 필요하지는 않지만 쿼리를 좀더 읽기 쉽게 한다.) 대부분의 데이터베이스 관리자는 날짜에 대한 특별한 데이터 형식을 가진다. 사실 많이 있지만 두가지 형식으로 볼 수 있다. 날짜 데이터 형식의 하나는 “May 31, 1971”와 같은 것이고, 다른 하나는 “31 days” 같은 기간에 대한 것이다. SQLite는 구분하지는 않는다. 대신에 SQLite는 날짜를 텍스트 (ISO-8601 표준 형식 “YYYY-MM-DD HH:MM:SS.SSSS”), 혹은 실수 (November 24, 4714 BCE 이후 지나간 일수), 혹은 정수 (1970년 1월 1일 자정 이후 초)로만 저장한다. 만약 복잡하게 들린다면, 그럴수도 있다 하지만 스웨덴의 역사적인 날짜(historical dates in Sweden)를 이해하는 것만큼 복잡하는지는 않다. Lake 혹은 Roerich가 무슨 측정을 했는지 알아내고자 한다면, or를 사용하여 이름에 테스트를 조합할 수 있다. 표 25.4: SQL 필터 부울 선택(OR) 연산자 반영쿼리문 taken person quant reading 734 lake sal 0.05 751 lake sal 0.10 752 lake rad 2.19 752 lake sal 0.09 752 lake temp -16.00 752 roe sal 41.60 837 lake rad 1.46 837 lake sal 0.21 837 roe sal 22.50 844 roe rad 11.25 다른 방식으로, in을 사용하여 특정 집합에 값이 있는지 확인할 수 있다. 표 25.5: SQL 필터 가독성 높은 부울 선택(OR) 연산 쿼리문 taken person quant reading 734 lake sal 0.05 751 lake sal 0.10 752 lake rad 2.19 752 lake sal 0.09 752 lake temp -16.00 752 roe sal 41.60 837 lake rad 1.46 837 lake sal 0.21 837 roe sal 22.50 844 roe rad 11.25 and와 or를 조합할 수는 있지만, 어느 연산자가 먼저 수행되는지 주의할 필요가 있다. 만약 괄호를 사용하지 않는다면, 다음을 얻게 된다. 표 25.6: SQL 필터 부울 선택(OR) 연산 적용순서 taken person quant reading 734 lake sal 0.05 751 lake sal 0.10 752 lake sal 0.09 752 roe sal 41.60 837 lake sal 0.21 837 roe sal 22.50 844 roe rad 11.25 상기 결과는 Lake가 측정한 염분량과 Roerich가 측정한 임의 측정값이다. 대신에 아마도 다음과 같은 결과를 얻고자 했을 것이다. 표 25.7: SQL 필터 괄호적용 부울 선택(OR) 연산 적용순서 taken person quant reading 734 lake sal 0.05 751 lake sal 0.10 752 lake sal 0.09 752 roe sal 41.60 837 lake sal 0.21 837 roe sal 22.50 마지막으로 distinct와 where를 사용하여 두번째 수준의 필터링을 한다. 표 25.8: SQL 중복제거 선택문과 결합된 필터 부울 선택(OR) 연산 person quant lake sal lake rad lake temp roe sal roe rad 하지만, 기억하라. distinct는 처리될 때 선택된 칼럼에 표시되는 값에만 적용되고 전체 행에는 적용되지 않는다. 방금전까지 수행하는 것은 대부분의 사람들이 어떻게 SQL 쿼리를 증가시키는지 살펴봤다. 의도한 것의 일부를 수행하는 단순한 것에서부터 시작했다. 그리고 절을 하나씩 하나씩 추가하면서 효과를 테스트했다. 좋은 전략이다. 사실 복잡한 쿼리를 작성할 때, 종종 유일한 전략이다. 하지만 이 전략은 빠른 회전(turnaround)시간에 달려있고 사용자에게는 정답을 얻게되면 인지하는 것에 달려있다. 빠른 회전시간을 달성하는 최선의 방법은 임시 데이터베이스에 데이터의 일부를 저장하고 쿼리를 실행하거나 혹은 합성된 레코드로 작은 데이터베이스를 채워놓고 작업을 하는 것이다. 예를 들어, 2천만 호주사람의 실제 데이터베이스에 쿼리를 작업하지 말고, 1만명 샘플을 뽑아 쿼리를 돌리거나 작은 프로그램을 작성해서 랜덤으로 혹은 그럴듯한 1만명 레코드를 생성해서 사용한다. 25.1 도전 과제 극에서 30&amp;deg보다 고위도에 위치한 모든 사이트를 선택하고자 한다고 가정하자. 작성한 첫번째 쿼리는 다음과 같다. select * from Site where (lat &gt; -60) or (lat &lt; 60); 왜 이 쿼리가 잘못된 것인지 설명하세요. 그리고 쿼리를 다시 작성해서 올바르게 동작하게 만드세요. 정규화된 염분 수치는 0.0에서 1.0 사이에 있어야 한다. 상기 범위 밖에 있는 염분수치를 가진 모든 레코드를 Survey 테이블에서 선택하는 쿼리를 작성하세요. 만약 명명된 칼럼의 값이 주어진 패턴과 일치한다면 SQL 테스트 *column-name* like *pattern*은 참이다. “0 혹은 그 이상의 문자와 매칭”된다는 것을 의미하기 위해서 ’%’문자를 패턴에 임의 숫자 횟수에 사용한다. 표현식 값 ‘a’ like ‘a’ True ‘a’ like ‘%a’ True ‘b’ like ‘%a’ False ‘alpha’ like ‘a%’ True ‘alpha’ like ‘a%p%’ True 표현식 *column-name* not like *pattern*은 테스트를 거꾸로 한다. like를 사용하여 사이트에서 ’DR-something’으로 라벨이 붙지 않은 모든 레코드를 Visited에서 찾는 쿼리를 작성하세요. 25.2 주요점 where를 사용해서 불 조건(Boolean conditions)에 따라 레코드를 필터링한다. 필터링이 전체 레코드에 적용되어서, 조건을 실제로 표시되지 않는 필드에 사용할 수 있다. "],["database-calc.html", "26 . 새로운 값 계산하기 26.1 도전 과제 26.2 주요점", " 26 . 새로운 값 계산하기 주의깊이 탐험 기록을 다시 정독한 뒤에, 탐험대가 보고한 방사선 측정치가 5%만큼 상향되어 수정될 필요가 있다는 것을 깨달았다. 저장된 데이터를 변형하기 보다는 쿼리의 일부분으로서 즉석에서 계산을 수행할 수 있다. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 26.1: 신규 칼럼 생성 쿼리문 1.05 * reading 10.31 8.19 8.83 7.58 4.57 2.30 1.53 11.81 쿼리를 실행하면, 표현식 1.05 * reading이 각 행마다 평가된다. 표현식에는 임의의 필드, 통상 많이 사용되는 연산자, 그리고 다양한 함수를 사용한다. (정확하게는 어느 데이터베이스 관리자를 사용되느냐에 따라 의존성을 띄게된다.) 예를 들어, 온도 측정치를 화씨에서 섭씨로 소수점 아래 두자리에서 반올림하여 변환할 수 있다. 표 26.2: 신규 칼럼 반올림 적용 쿼리문 taken round(5*(reading-32)/9, 2) 734 -29.7 735 -32.2 751 -28.1 752 -26.7 다른 필드의 값을 조합할 수도 있다. 예를 들어, 문자열 접합 연산자 (string concatenation operator, ||)를 사용한다. 표 26.3: 접합연산자 적용 신규 칼럼 생성 쿼리문 personal || ’ ’ || family William Dyer Frank Pabodie Anderson Lake Valentina Roerich Frank Danforth first와 last 대신에 필드 이름으로 personal과 family를 사용하는 것이 이상해 보일지 모른다. 하지만, 문화적 차이를 다루기 위한 필요한 첫번째 단계다. 예를 들어, 다음 규칙을 고려해보자. 성명 전부(Full Name) 알파벳 순서 이유 Liu Xiaobo Liu 중국 성이 이름보다 먼저 온다. Leonardo da Vinci Leonardo “da Vinci” 는 “from Vinci”를 뜻한다. Catherine de Medici Medici 성(family name) Jean de La Fontaine La Fontaine 성(family name)이 “La Fontaine”이다. Juan Ponce de Leon Ponce de Leon 전체 성(full family name)이 “Ponce de Leon”이다. Gabriel Garcia Marquez Garcia Marquez 이중으로 된 스페인 성(surnames) Wernher von Braun von or Braun 독일 혹은 미국에 있는냐에 따라 달라짐 Elizabeth Alexandra May Windsor Elizabeth 군주가 통치하는 이름에 따라 알파벳순으로 정렬 Thomas a Beckett Thomas 시성된(canonized) 이름에 따라 성인이름 사용 분명하게, 심지어 두부분 “personal”과 “family”으로 나누는 것도 충분하지 않다. 26.1 도전 과제 좀더 조사한 뒤에, Valentina Roerich는 염도를 퍼센티지(%)로 작성한 것을 알게되었다. Survey 테이블에서 값을 100으로 나누어서 모든 염도 측정치를 반환하는 쿼리를 작성하세요. union 연산자는 두 쿼리의 결과를 조합한다. 표 26.4: union 연산자 적용 쿼리 두개 결합 결과 ident personal family dyer William Dyer roe Valentina Roerich union을 사용하여 앞선 도전과제에서 기술되어 수정된 Roerich가 측정한, Roerich만 측정한 염도 측정치의 통합 리스트를 생성하세요. 출력결과는 다음과 같아야 한다. 619 0.13 622 0.09 734 0.05 751 0.1 752 0.09 752 0.416 837 0.21 837 0.225 Visited 테이블에 사이트 식별자는 ’-’으로 구분되는 두 부분으로 구성되어 있다. DR-1 DR-3 MSK-4 몇몇 주요 사이트 식별자는 두 문자길이를 가지고 몇몇은 3문자길이를 가진다. “in string” 함수 instr(X, Y)은 X 문자열에 문자열 Y가 첫번째 출현의 1-기반 인덱스를 반환하거나 Y가 X에 존재하지 않으면 0 을 반환한다. 부분 문자열 함수 substr(X, I)은 인덱스 I에서 시작하는 문자열 X의 부분문자열을 반환한다. 상기 두 함수를 사용해서 유일한 주요 사이트 식별자를 생성하세요. (이 데이터에 대해서 작업된 리스트는 “DR”과 “MSK”만 포함해야 한다.) 26.2 주요점 SQL은 쿼리의 일부로서 레코드의 값을 사용한 계산을 수행한다. "],["database-null.html", "27 . 결측 데이터 (Missing Data) 27.1 도전 과제 27.2 주요점", " 27 . 결측 데이터 (Missing Data) 현실 세계 데이터는 결코 완전하지 않고 구멍은 항상 있다. null로 불리는 특별한 값을 사용하여 데이터베이스는 구멍을 표현한다. null는 0, False, 혹은 빈 문자열도 아니다.”아무것도 없음(nothing here)“을 의미하는 특별한 값이다. null을 다루는 것은 약간 특별한 기교와 신중한 생각을 요구한다. 시작으로 Visited 테이블을 살펴보자. 레코드가 8개 있지만 #752은 날짜가 없다. 혹은 더 정확히 말하면 날짜가 null이다. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 27.1: 결측값을 갖는 테이블 ident site dated 619 DR-1 1927-02-08 622 DR-1 1927-02-10 734 DR-3 1939-01-07 735 DR-3 1930-01-12 751 DR-3 1930-02-26 752 DR-3 NA 837 MSK-4 1932-01-14 844 DR-1 1932-03-22 Null 다른 값과는 다르게 동작한다. 만약 1930년 이전 레코드를 선택한다면, 표 27.2: 1930년 이전 레코드 선택 ident site dated 619 DR-1 1927-02-08 622 DR-1 1927-02-10 결과 2개를 얻게 되고, 만약 1930년 동안 혹은 이후 레코드를 선택한다면, 표 27.3: 1930년 이후 레코드 선택 ident site dated 734 DR-3 1939-01-07 735 DR-3 1930-01-12 751 DR-3 1930-02-26 837 MSK-4 1932-01-14 844 DR-1 1932-03-22 결과를 5개 얻게되지만, 레코드 #752은 결과값 어디에도 존재하지 않는다. 이유는 null&lt;'1930-00-00' 평가결과가 참도 거짓도 아니기 때문이다. null 이 의미하는 것은 “알수가 없다”는 것이다. 그리고 만약 비교 평가식의 왼쪽편 값을 알지 못한다면, 비교도 참인지 거짓인지 알수가 없다. 데이터베이스는 “알 수 없음”을 null로 표현하기 때문에, null&lt;'1930-00-00'의 값도 사실 null이다. null&gt;='1930-00-00'도 또한 null인데 왜냐하면 질문에 답을 할 수 없기 때문이다. 그리고, where절에 레코드는 테스트가 참인 것만 있기 때문에 레코드 #752은 어느 결과값에도 포함되지 않게 된다. 평가식만 null값을 이와 같은 방식으로 다루는 연산자는 아니다. 1+null도 null이고, 5*null도 null이고, log(null)도 null이 된다. 특히, 무언가를 = 과 != 으로 null과 비교하는 것도 null이 된다. 표 27.4: NULL 값 갖는 레코드 선택 ident site dated 표 27.5: NULL 값 갖지 않는 레코드 선택 ident site dated null 인지 아닌지를 점검하기 위해서, 특별한 테스트 is null을 사용해야 한다. 표 27.6: is NULL 사용 NULL 값 갖는 레코드 선택 ident site dated 752 DR-3 NA 혹은, 역으로는 is not null을 사용한다. 표 27.7: is not NULL 사용 NULL 값 갖지 않는 레코드 선택 ident site dated 619 DR-1 1927-02-08 622 DR-1 1927-02-10 734 DR-3 1939-01-07 735 DR-3 1930-01-12 751 DR-3 1930-02-26 837 MSK-4 1932-01-14 844 DR-1 1932-03-22 null 값은 나타나는 곳마다 두통을 일으킨다. 예를 들어, Dyer가 측정하지 않은 모든 염분 정보를 찾는다고 가정하자. 다음과 같이 쿼리를 작성하는 것은 당연하다. 표 27.8: NULL 값이 갖는 문제 taken person quant reading 619 dyer sal 0.13 622 dyer sal 0.09 752 roe sal 41.60 837 roe sal 22.50 하지만, 상기 쿼리 필터는 누가 측정을 했는지 모르는 레코드는 빠뜨린다. 다시 한번, 이유는 person이 null일 때, !=비교는 null값을 만들어서 레코드가 결과값에 있지 않게 된다. 만약 이런 레코드도 유지하려고 한다면, 명시적으로 검사를 추가할 필요가 있다. 표 27.9: NULL 값 갖는 문제 명시적 해결 taken person quant reading 619 dyer sal 0.13 622 dyer sal 0.09 735 NA sal 0.06 752 roe sal 41.60 837 roe sal 22.50 여전히 이러한 접근법이 맞는 것인지 아닌 것인지 판단할 필요가 있다. 만약 절대적으로 결과에 Lake가 측정한 어떠한 값도 포함하지 않는다고 확신한다면, 누가 작업을 한 것인지 모르는 모든 레코드를 제외할 필요가 있다. 27.1 도전 과제 날짜가 알려지지 않은 (즉 null) 항목은 빼고, 날짜 순으로 Visited 테이블에 있는 레코드를 정렬한 쿼리를 작성하세요. 다음 쿼리가 무슨 결과를 할까요? select * from Visited where dated in (&#39;1927-02-08&#39;, null); 상기 쿼리가 실질적으로 무엇을 생기게 할까요? 몇몇 데이터베이스 디자이너는 null 보다 결측 데이터를 표기하기 위해서 보초값(sentinel value)를 사용한다. 예를 들어, 결측 날짜를 표기하기 위해서 “0000-00-00” 날짜를 사용하거나 결측 염분치 혹은 결측 방사선 측정값을 표기하기 위해서 -1.0을 사용한다. (왜냐하면 실제 측정값이 음수가 될 수 없기 때문이다.) 이러한 접근법은 무엇을 단순화할까요? 이러한 접근법이 어떤 부담과 위험을 가져올까요? 27.2 주요점 데이터베이스는 결측 정보를 표현하기 위해서 null을 사용한다. null이 관계되는 산술 혹은 불 연산 결과도 null이다. null과 함께 안전하세 사용될 수 있는 유일한 연산자는 is null과 is not null이다. "],["database-agg.html", "28 . 집합(Aggregation) 28.1 도전 과제 28.2 주요점", " 28 . 집합(Aggregation) 이제 데이터의 평균과 범위를 계산하고자 한다. Visited 테이블에서 모든 날짜 정보를 어떻게 선택하는지 알고 있다. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 28.1: SQL select 쿼리문 dated 1927-02-08 1927-02-10 1939-01-07 1930-01-12 1930-02-26 NA 1932-01-14 1932-03-22 하지만 조합하기 위해서는 min 혹은 max 같은 집합 함수(aggregation function)를 사용해야만 한다. 각 함수는 입력으로 레코드 집합을 받고 출력으로 단일 레코드를 만든다. 표 28.2: 최소값 집합 함수 적용 쿼리문 min(dated) 1927-02-08 SQL 집합함수 최소값(min) 찾는 과정 표 28.3: 최대값 집합 함수 적용 쿼리문 max(dated) 1939-01-07 min과 max는 SQL에 내장된 단지 두개의 집합 함수다. 다른 세개는 avg, count, sum이 있다. 표 28.4: 평균값 집합 함수 적용 쿼리문 avg(reading) 7.2 표 28.5: 개수 집합 함수 적용 쿼리문 count(reading) 9 표 28.6: 합계 집합 함수 적용 쿼리문 sum(reading) 64.8 여기서 count(reading)을 사용했다. 하지만 quant를 단순히 쉽게 세거나 테이블의 다른 어떤 필드도 셀 수 있고 심지어 count(*)을 사용하기도 한다. 왜냐하면 count()함수가 값 자체보다는 얼마나 많은 값이 있는지에만 관심을 두기 때문이다. SQL이 여러개의 집합연산도 한번에 수행한다. 예를 들어, 염분측정치의 범위도 알 수 있다. 표 28.7: 최소, 최대값 집합 함수 적용 쿼리문 min(reading) max(reading) 0.05 0.21 출력결과가 놀라움을 줄 수도 있지만, 원 결과값과 집합 결과를 조합할 수도 있다. 표 28.8: 원 결과값과 집합 함수를 적용한 쿼리문 person count(*) dyer 7 왜 Roerich 혹은 Dyer가 아닌 Lake의 이름이 나타날까요? 답은 필드를 집합하지만 어떻게 집합하는지 말을 하지 않기 때문에 데이터베이스 관리자가 입력에서 실제 값을 고른다. 처음 처리된 것, 마지막에 처리된 것, 혹은 완전히 다른 무언가를 사용할 수도 있다. 또다른 중요한 사실은 집합할 어떠한 값도 없을 때, 집합 결과는 0 혹은 다른 임의의 값 보다 “알지 못한다(don’t know)”가 된다. 표 28.9: NULL 값이 포함된 원데이터에 집합 함수를 적용한 쿼리문 person count(*) dyer 7 집합 함수의 마지막 중요한 한가지 기능은 매우 유용한 방식으로 나머지 SQL과는 일관되지 않다는 것이다. 만약 두 값을 더하는데 그중 하나가 null이면 결과는 null이다. 확장해서, 만약 한 집합의 모든 값을 더하기 위해서 sum을 사용하고 이들 중 임의의 값이 null이면, 결과도 또한 null이어야 한다. 하지만 집합함수가 null 값을 무시하고 단지 non-null 값만을 조합한다면 훨씬 더 유용하다. 명시적으로 항상 필터해야하는 대신에 이것의 결과 쿼리를 다음과 같이 작성할 수 있게 한다. 표 28.10: NULL 값이 포함된 원데이터를 명시적으로 처리한 후 집합 함수를 적용한 쿼리문 min(dated) 1927-02-08 명시적으로 항상 다음과 같이 필터하는 쿼리를 작성할 필요가 없다. 표 28.11: NULL 값이 포함된 원데이터를 명시적으로 처리하지 않는 집합 함수를 적용한 쿼리문 min(dated) 1927-02-08 한번에 모든 레코드를 집합하는 것이 항상 타당하지는 않다. 예를 들어, Gina가 데이터에 체계적인 편의(bias)가 있어서 다른 과학자의 방사선 측정치가 다른 사람의 것과 비교하여 높다고 의심한다고 가정하자. 다음 쿼리가 의도를 반영하여 동작하지 않는다는 것은 알고 있다. 표 28.12: 주의깊이 살펴볼 쿼리문 person count(reading) round(avg(reading), 2) dyer 8 6.56 왜냐하면 데이터베이스 관리자가 각 과학자별로 구분된 집합하기 보다는 임의의 한명의 과학자 이름만 선택하기 때문이다. 단지 5명의 과학자만 있기 때문에, 다음과 같은 형식의 5개 쿼리를 작성할 수 있다. 표 28.13: 사람별로 작성한 쿼리문 문제 예제 person count(reading) round(avg(reading), 2) dyer 2 8.81 하지만, 이러한 접근법은 성가시고, 만약 50명 혹은 500명의 과학자를 가진 데이터셋을 분석한다면, 모든 쿼리를 올바르게 작성할 가능성은 작다. 필요한 것은 데이터베이스 관리자가 group by절을 사용해서 각 과학자별로 시간을 집합하도록 지시하는 것이다. 표 28.14: group by 문을 사용해서 사람별로 작성한 쿼리문 예제 person count(reading) round(avg(reading), 2) dyer 2 8.81 lake 2 1.83 pb 3 6.66 roe 1 11.25 group by는 이름이 의미하는 것과 동일한 것을 정확하게 수행한다. 지정된 필드에 동일한 값을 가진 모든 레코드를 그룹으로 묶어서 집합을 각 배치별로 처리한다. 각 배치에 모든 레코드는 person에 동일한 값을 가지고 있기 때문에, 데이터베이스 관리자가 임의의 값을 잡아서 집합된 reading 값과 함께 표시하는지는 더 이상 문제가 되지 않는다. 한번에 다중 기준으로 정렬하듯이 다중 기준으로 묶어 그룹화할 수 있다. 예를 들어 과학자와 측정 수량에 따라 평균 측정값을 얻기 위해서, group by 절에 또다른 필드만 추가한다. 표 28.15: group by 문을 확장하여 적용한 쿼리문 사례 person quant count(reading) round(avg(reading), 2) NA sal 1 0.06 NA temp 1 -26.00 dyer rad 2 8.81 dyer sal 2 0.11 lake rad 2 1.83 lake sal 4 0.11 lake temp 1 -16.00 pb rad 3 6.66 pb temp 2 -20.00 roe rad 1 11.25 그렇지 않으면 결과가 의미가 없기 때문에, person을 표시되는 필드 리스트에 추가한 것을 주목하라. 한단계 더나아가 누가 측정을 했는지 알지 못하는 모든 항목을 제거하자. 표 28.16: 사람별로 측정값을 정렬한 쿼리문 사례 person quant count(reading) round(avg(reading), 2) dyer rad 2 8.81 dyer sal 2 0.11 lake rad 2 1.83 lake sal 4 0.11 lake temp 1 -16.00 pb rad 3 6.66 pb temp 2 -20.00 roe rad 1 11.25 roe sal 2 32.05 좀더 면밀하게 살펴보면, 이 쿼리는, Survey테이블에서 person 필드가 null이 아닌 레코드를 선택한다. 상기 레코드를 부분집합으로 그룹지어서 각 부분집합의 person과 quant의 값은 같다. 먼저 person으로 부분집합을 정렬하고나서 quant로 각 하위 그룹내에서도 정렬한다. 각 부분집합의 레코드 숫자를 세고, 각각 reading 평균을 계산하고, 각각 person과 quant 값을 선택한다. (모두 동등하기 때문에 어느 것인지는 문제가 되지 않는다.) 28.1 도전 과제 Frank Pabodie는 얼마 많이 온도 측정치를 기록했고 평균 값은 얼마인가요? 집합 값의 평균은 값을 합한 것을 값의 갯수로 나눈 것이다. 값이 1.0, null, 5.0 으로 주어졌을 때, avg 함수는 2.0 혹은 3.0을 반환하는 것을 의미하나요? 각 개별 방사선 측정값과 평균값 사이의 차이를 계산하고자 한다. 쿼리를 다음과 같이 작성한다. select reading - avg(reading) from Survey where quant=&#39;rad&#39;; 상기 쿼리가 무엇을 만드나요? 그리고 왜 그런가요? group_concat(field, separator) 함수는 지정된 구분 문자(혹은 만약 구분자가 지정되지 않는다면 ‘,’)를 사용하여 필드의 모든 값을 결합한다. 이 함수르 사용해서 과학자의 이름을 한줄 리스트로 다음과 같이 만드세요. William Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank Danforth 성씨(surname)으로 리스트를 정렬하는 방법을 제시할 수 있나요? 28.2 주요점 집합 함수는 많은 값을 조합해서 하나의 새로운 값을 만든다. 집합 함수는 null 값을 무시한다. 필터링 다음에 집합이 일어난다. "],["database-table-join.html", "29 . 데이터 결합하기 29.1 데이터 위생 (Data Hygiene) 29.2 도전 과제 29.3 주요점", " 29 . 데이터 결합하기 과거 기상 자료를 집계하는 웹사이트에 데이터를 제출해야 되어서, Gina는 위도, 경도, 날짜, 수량, 측정값 형식으로 자료를 체계적으로 만들 필요가 있다. 하지만, 위도와 경도 정보는 Site 테이블에 있는 반면에 측정 날짜 정보는 Visited 테이블에 있고, 측정값 자체는 Survey 테이블에 있다. 어떤 방식이든지 상기 테이블을 조합할 필요가 있다. 이러한 작업을 하는 SQL 명령어가 join이다. 어떻게 동작하는지 확인하기 위해서, Site와 Visited 테이블을 조인하면서 출발해보자. $ sqlite3 survey.db SQLite version 3.35.4 2021-04-02 15:20:15 Enter &quot;.help&quot; for usage hints. sqlite&gt; 표 29.1: SQL join 쿼리문 name lat long ident site dated DR-1 -49.9 -129 619 DR-1 1927-02-08 DR-1 -49.9 -129 622 DR-1 1927-02-10 DR-1 -49.9 -129 734 DR-3 1939-01-07 DR-1 -49.9 -129 735 DR-3 1930-01-12 DR-1 -49.9 -129 751 DR-3 1930-02-26 DR-1 -49.9 -129 752 DR-3 NA DR-1 -49.9 -129 837 MSK-4 1932-01-14 DR-1 -49.9 -129 844 DR-1 1932-03-22 DR-3 -47.1 -127 619 DR-1 1927-02-08 DR-3 -47.1 -127 622 DR-1 1927-02-10 join은 두 테이블을 벡터곱(cross product)한다. 즉, 모든 가능한 조합을 표현하려고 한 테이블의 레코드 각각마다 다른 테이블의 각 레코드와 조인한다. Site 테이블에 3개 레코드가 있고, Visited 테이블에 8개 레코드가 있어서, 조인된 결과는 24개 레코드가 된다. 그리고, 각 테이블이 3개 필드가 있어서 출력은 6개의 필드가 된다. 조인이 수행하지 않은 것은 조인되는 레코드가 서로 관계가 있는지를 파악하는 것이다. 어떻게 조인할지 명시할 때까지 레코드가 서로 관계가 있는지 없는지 알 수 있는 방법은 없다. 이를 위해서 동일한 사이트 이름을 가진 조합에만 관심있다는 것을 명시하는 절(clause)을 추가한다. 표 29.2: 키값을 명시한 SQL join 쿼리문 name lat long ident site dated DR-1 -49.9 -129 619 DR-1 1927-02-08 DR-1 -49.9 -129 622 DR-1 1927-02-10 DR-1 -49.9 -129 844 DR-1 1932-03-22 DR-3 -47.1 -127 734 DR-3 1939-01-07 DR-3 -47.1 -127 735 DR-3 1930-01-12 DR-3 -47.1 -127 751 DR-3 1930-02-26 DR-3 -47.1 -127 752 DR-3 NA MSK-4 -48.9 -123 837 MSK-4 1932-01-14 on 은 where와 같은 역할을 한다. 특정 테스트를 통과한 레코드만 간직한다. (on과 where의 차이점은 on은 레코드가 생성될 때 레코드를 필터링하는 반면에, where는 조인작업이 완료될 때까지 기다리고 난 뒤에 필터링을 한다.) 쿼리에 레코드를 추가하자 마자 데이터베이스 관리자는 두 다른 사이트에 관한 조합된 정보는 사용한 뒤에 버려버리고, 원하는 레코드만 남겨둔다. 조인 결과에 필드이름을 명기하기 위해서 table.field를 사용한 것에 주목하세요. 이렇게 하는 이유는 테이블이 동일한 이름을 가질 수 있고 어느 필드를 언급하는지 좀더 구체성을 띌 필요가 있다. 예를 들어, person과 visited 테이블을 조인한다면, 결과는 각각의 원래 테이블에서 ident로 불리는 필드를 상속한다. 이제는 조인에서 원하는 3개의 칼럼을 선택하려고 점 표기법(dotted notation)을 사용할 수 있다. 표 29.3: 점표기법을 적용한 SQL join 쿼리문 lat long dated -49.9 -129 1927-02-08 -49.9 -129 1927-02-10 -49.9 -129 1932-03-22 -47.1 -127 NA -47.1 -127 1930-01-12 -47.1 -127 1930-02-26 -47.1 -127 1939-01-07 -48.9 -123 1932-01-14 만약 두개의 테이블을 조인하는 것이 좋은 경우에, 많은 데이블을 조인하는 것은 더 좋아야한다. 더 많은 join 절과 의미없는 레코드 조합을 필터링해서 제거하는 더 많은 on 테스트를 단순히 추가해서 사실 쿼리에 임의 갯수의 테이블을 조인할 수 있다. 표 29.4: 다수 테이블을 확장하여 결합한 SQL join 쿼리문 lat long dated quant reading -49.9 -129 1927-02-08 rad 9.82 -49.9 -129 1927-02-08 sal 0.13 -49.9 -129 1927-02-10 rad 7.80 -49.9 -129 1927-02-10 sal 0.09 -47.1 -127 1939-01-07 rad 8.41 -47.1 -127 1939-01-07 sal 0.05 -47.1 -127 1939-01-07 temp -21.50 -47.1 -127 1930-01-12 rad 7.22 -47.1 -127 1930-01-12 sal 0.06 -47.1 -127 1930-01-12 temp -26.00 Site, Visited, Survey 테이블의 어느 레코드가 서로 대응되지는 분간할 수 있는데 이유는 각 테이블이 기본키(primary keys)와 외래키(foreign keys)를 가지고 있기 때문이다.. 기본키는 하나의 값 혹은 여러 값의 조합으로 테이블의 각 레코드를 유일하게 식별한다. 외래키는 또 다른 테이블에 있는 유일하게 레코드를 식별하는 하나의 값(혹은 여러 값의 조합)이다. 다르게 표현하면, 외래캐는 다른 테이블에 존재하는 테이블의 기본키다. 예제 데이터베이스에서 Person.ident는 Person 테이블의 기본키인 반면에, Survey.person은 외래키로 Survey 테이블의 항목과 Person 테이블의 항목을 연결한다. 대부분의 데이터베이스 디자이너는 모든 테이블은 잘 정의된 기본키가 있어야된다고 믿는다. 또한 이 키는 데이터와 떨어져서 만약 데이터를 변경할 필요가 있다면, 한 곳의 변경이 한 곳에만 변경을 만들어야만 한다. 이를 위한 쉬운 방법은 데이터베이스에 레코드를 추가할 때 임의의 유일한 ID를 각 레코드마다 추가하는 것이다. 실제로 이방법은 매우 흔하게 사용된다. “student numbers”, “patient numbers” 같은 이름을 ID로 사용하고, 몇몇 데이터베이스 시스템 혹은 다른 곳에서 원래 고유 레코드 식별자로 거의 항상 판명된다. 다음 쿼리가 시범으로 보여주듯이, 테이블에 레코드가 추가됨에 따라 SQLite는 자동으로 레코드에 숫자를 붙이고, 쿼리에서 이렇게 붙여진 레코드 숫자를 사용한다. 표 29.5: 행ID(rowid) 쿼리문 rowid ident personal family 1 dyer William Dyer 2 pb Frank Pabodie 3 lake Anderson Lake 4 roe Valentina Roerich 5 danforth Frank Danforth 29.1 데이터 위생 (Data Hygiene) 지금까지 조인이 어떻게 동작하는지 살펴봤으니, 왜 관계형 모델이 그렇게 유용한지 그리고 어떻게 가장 잘 사용할 수 있는지 살펴보자. 첫번째 규칙은 모든 값은 독립 요소로 분해될 수 없는 원자(atomic)적 속성을 지녀야 한다. 즉, 구별해서 작업하고자 하는 부분을 포함해서는 안된다. 하나의 칼럼에 전체 이름을 넣는 대신에 별도로 구별되는 칼럼에 이름과 성을 저장해서 이름 컴포넌트를 뽑아내는 부분 문자열 연산(substring operation)을 사용할 필요가 없다. 좀더 중요하게는, 별도로 이름을 두 부분으로 저장한다. 왜냐하면, 공백으로 쪼개는 것은 신뢰성이 약하다. “Eloise St. Cyr” 혹은 “Jan Mikkel Steubart” 같은 이름을 생각하면 쉽게 알 수 있다. 두번째 규칙은 모든 레코드는 유일한 기본키를 가져야한다. 내재적인 의미가 전혀없는 일련번호가 될 수 있고, 레코드의 값중의 하나 (Person 테이블의 ident 필드), 혹은 Survey 테이블에서 심지어 모든 측정값을 유일하게 식별하는 (taken, person, quant) 삼중값의 조합도 될 수 있다. 세번째 규칙은 불필요한 정보가 없어야 한다. 예를 들어, Site테이블을 제거하고 다음과 같이 Visited 테이블을 다시 작성할 수 있다. 619 -49.85 -128.57 1927-02-08 622 -49.85 -128.57 1927-02-10 734 -47.15 -126.72 1939-01-07 735 -47.15 -126.72 1930-01-12 751 -47.15 -126.72 1930-02-26 752 -47.15 -126.72 null 837 -48.87 -123.40 1932-01-14 844 -49.85 -128.57 1932-03-22 사실, 스프레드쉬트와 마찬가지로 각 행에 각 측정값에 관한 모든 정보를 기록하는 하나의 테이블을 사용할 수도 있다. 문제는 이와 같은 방식으로 조직된 데이터를 일관성있게 관리하는 것은 매우 어렵다. 만약 특정한 사이트의 특정한 방문 날짜가 잘못된다면, 데이터베이스에 다수의 레코드를 변경해야한다. 더 안좋은 것은 다른 사이트도 그 날짜에 방문되었기 때문에 어느 레코드를 변경할지 추정해야하는 것이다. 네번째 규칙은 모든 값의 단위는 명시적으로 저장되어야한다. 예제 데이터베이스는 그렇지 못해서 문제다. Roerich의 염분치는 다른 사람의 측정치보다 수천배 크다. 하지만, 천단위 대신에 백만 단위를 사용하고 있는지 혹은 1932년 그 사이트에 염분에 이상 실제로 있었는지 알지못한다. 한걸음 물러나서 생각하자, 데이터와 저장하는데 사용되는 도구는 공생관계다. 테이블과 조인은 데이터가 특정 방식으로 잘 조직되었다면 매우 효과적이다. 하지만, 만약 특정 형태로 되어 있다면 효과적으로 다룰 수 있는 도구가 있기 때문에 데이터를 그와 같은 방식으로 조직하기도 한다. 인류학자가 말했듯이, 도구는 도구를 만드는 손을 만든다. (the tool shapes the hand that shapes the tool) 29.2 도전 과제 DR-1 사이트의 모든 방사선 측정치를 출력하는 쿼리를 작성하세요. “Frank” 가 방문한 모든 사이트를 출력하는 쿼리를 작성하세요. 다음 쿼리가 무슨 결과를 산출하는지 말로 기술하세요. select Site.name from Site join Visited on Site.lat&lt;-49.0 and Site.name=Visited.site and Visited.dated&gt;=&#39;1932-00-00&#39;; 29.3 주요점 모든 사실은 데이터베이스에서 정확하게 한번만 표현되어야 한다. 조인은 한 테이블의 레코드와 다른 테이블의 레코드를 모두 조합한 결과를 출력한다. 기본키는 테이블의 레코드를 유일하게 식별하는 필드값(혹은 필드의 집합)이다. 외래키는 또 다른 테이블의 기본키가되는 필드값(혹은 필드의 집합)이다. 테이블사이에 기본키와 외래키를 매칭해서 의미없는 레코드의 조합을 제거할 수 있다. 조인을 좀더 단순하고 효율적으로 만들기 위해서 키(key)는 원자값(atomic value)이 되어야 한다. "],["database-data-create.html", "30 . 데이터 생성과 변형 30.1 도전 과제 30.2 주요점", " 30 . 데이터 생성과 변형 지금까지 어떻게 데이터베이스에서 정보를 추출하는지만 살펴봤다. 왜냐하면, 정보를 추가하는 것보다 정보를 조회하는 것이 더 자주 있는 일이기도 하고, 다른 연산자는 쿼리가 이해되어야만 의미가 통하기 때문이다. 만약 데이터를 생성하고 변형하고자 한다면, 다른 두짝의 명령어를 공부할 필요가 있다. 첫번째 짝은 create table과 drop table이다. 두 단어로 작성되지만, 사실 하나의 단일 명령어다. 첫번째 명령어는 새로운 테이블을 생성한다. 인자는 테이블 칼럼의 이름과 형식이다. 예를 들어, 다음 문장은 survey 데이터베이스에 테이블 4개를 생성한다. create table Person(ident text, personal text, family text); create table Site(name text, lat real, long real); create table Visited(ident integer, site text, dated text); create table Survey(taken integer, person text, quant real, reading real); 다음 명령어를 사용하여 테이블 중의 하나를 제거할 수도 있다. drop table Survey; 데이블을 제거할 때 매우 주의하라. 대부분의 데이터베이이스는 변경사항을 되돌리는 기능을 제공하지만, 이러한 기능에 의존하지 않는 것이 더 낫다. 다른 데이터베이스 시스템은 테이블 칼럼의 다른 데이터 형식도 지원하지만, 대부분은 다음을 다음을 제공한다. integer 부호있는 정수형 real 부동 소수점 실수 text 문자열 blob 이미지 같은 “이진 대형 개체” 대부분의 데이터베이스는 불(boolean)과 날짜/시간 값도 지원한다. SQLite는 불값을 정수 0 과 1 을 사용하고 날짜/시간은 앞선(earlier) 학습방식으로 표현한다. 점점 더 많은 데이터베이스가 위도와 경도 같은 지리정보 데이터 형식도 지원한다. 특정 시스템이 무슨 기능을 제공하고 제공하지 않는지 그리고 어떤 이름을 다른 데이터 형식에 부여하는지를 계속 파악하는 것은 끝없는 시스템 이식성에 대한 골치거리다. 테이블을 생성할 때, 칼럼에 몇가지 제약사항을 지정할 수 있다. 예를 들어, Survey 테이블에 대한 좀더 좋은 정의는 다음과 같이 될 것이다. create table Survey( taken integer not null, -- where reading taken person text, -- may not know who took it quant real not null, -- the quantity measured reading real not null, -- the actual reading primary key(taken, quant), foreign key(taken) references Visited(ident), foreign key(person) references Person(ident) ); 다시 한번, 정확하게 무슨 제약사항이 이용가능하고 어떻게 호출되는지는 어떤 데이터베이스 관리자를 사용하는야에 달려있다. 테이블이 생성되자마자, 다른 명령어 짝 insert와 delete를 사용하여 레코드를 추가하고 제거할 수 있다. insert 문의 가장 간단한 형식은 순서대로 값을 목록으로 나열하는 것이다. insert into Site values(&#39;DR-1&#39;, -49.85, -128.57); insert into Site values(&#39;DR-3&#39;, -47.15, -126.72); insert into Site values(&#39;MSK-4&#39;, -48.87, -123.40); 또한, 다른 테이블에서 직접 값을 테이블에 삽입할 수도 있다. create table JustLatLong(lat text, long text); insert into JustLatLong select lat, long from site; 레코드를 삭제하는 것은 약간 난이도가 있다. 왜냐하면, 데이터베이스가 내부적으로 일관성을 보장할 필요가 있기 때문이다. 만약 하나의 단독 테이블만 관심을 둔다면, 삭제하고자 하는 레코드와 매칭되는 where절과 delete문을 함께 사용한다. 예를 들어, Frank Danforth가 어떤 측정도 하지 않았다는 것을 인지하자마자, 다음과 같이 Person 테이블에서 Frank Danforth를 제거할 수 있다. delete from Person where ident = &quot;danforth&quot;; 하지만 대신에 Anderson Lake를 실수로 제거했다면 어떨까요? Survey 테이블은 Anderson Lake이 수행한 7개의 측정 레코드를 담고 있지만, 이것은 결코 일어나지 말아야 된다. Survey.person은 Person 테이블에 외래키이고, 모든 쿼리는 전자의 모든 값을 매칭하는 후자의 행이 있을 거라고 가정한다. 이러한 문제를 참조 무결성(referential integrity)이라고 부른다. 테이블 사이의 모든 참조는 항상 제대로 해결될 수 있도록 확인할 필요가 있다. 참조 무결성을 보증하는 한 방법은 기본키로 사용하는 레코드를 삭제하기 전에 외래키로 'lake'를 사용하는 모든 레코드를 삭제하는 것이다. 만약 데이터베이스 관리자가 이 기능을 지원한다면, 연쇄적인 삭제(cascading delete)를 사용해서 자동화할 수 있다. 하지만, 이 기법은 여기서 다루는 학습 영역밖이다. 모든 것을 데이터베이스에 저장하는 대신 많은 응용프로그램은 하이브리드 저장 모델을 사용한다. 천체 이미지 같은 실제 데이터는 파일에 저장되는 반면에, 파일 이름, 변경된 날짜, 커버하는 하늘의 영역, 스펙트럼 특성, 등등 정보는 데이터베이스에 저장한다. 대부분의 음악 재생기(MP3 플레이어) 소프트웨어가 작성되는 방식이기도 하다. 응용프로그램 내부 데이터베이스는 MP3 파일을 기억하고 있지만, MP3 파일 자체는 디스크에 있다. 30.1 도전 과제 Survey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요. 동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의 CSV 파일을 보내왔다. Taken,Temp 619,-21.5 622,-15.5 survey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는 작은 파이썬 프로그램을 작성하세요. Person 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다. 반복적으로 프로그램을 테스트하려면, SQL insert or replace 문을 자세히 살펴볼 필요도 있다. SQLite는 SQL 표준이 아닌 몇개 관리 명령어가 있다. 그중의 하나가 .dump로 데이터베이스를 다시 생성하는데 필요한 SQL 명령문을 출력한다. 또다른 것은 .load로 .dump에서 생성된 파일을 읽어서 데이터베이스를 복원한다. 여러분의 동료중의 한명이 텍스트인 dump 파일을 버젼 제어 시스템에 저장하는 것이 데이터베이스 변경사항을 추적하고 관리하는 좋은 방법이라고 생각한다. 이러한 접근법의 장점과 단점은 무엇일까요? (힌트: 레코드는 어느 특정한 순서로 저장되지 않는다.) 30.2 주요점 데이터베이스 테이블은 테이블 이름과 필드의 이름과 특성을 명시하는 쿼리를 사용해서 생성된다. 쿼리를 사용해서 레코드는 삽입, 갱신, 삭제될 수 있다. 모든 레코드가 유일한 기본키를 가질 때 데이터를 변경하는 것이 더 간단하고 안전하다. "],["참고문헌.html", "참고문헌", " 참고문헌 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
