[{"path":"index.html","id":"swc-intro","chapter":"데이터 과학을 지탱하는 기본기","heading":"데이터 과학을 지탱하는 기본기","text":"데이터 사이언스는 단일 도구나 언어로 구성되어 있지 않습니다.\n데이터 사이언스는 유닉스 쉘, Git/GitHub, Make, SQL, R 프로그래밍 언어로 팀을\n꾸려 급격히 진행되는 디지털 전환(Digital Transformation) 시대 불평등 해소와\n디지털 경제 성장에 큰 기여를 하고 있습니다.도구나 언어적인 측면에서 보면 운영체제 리눅스를 근간으로 하는 유닉스 쉘이 자동화를\n담당하는 것을 시작으로 빅데이터를 가공하고 가치를 높일 수 있는 형태의 정형 데이터를\n책임지는 SQL, 시간여행을 책임지는 Git, 협업과 공유를 담당하는 GitHub,\n작업흐름을 담당하는 Make 그리고 기계와 대화를 담당하고 추상화 역할을 수행하는\n프로그래밍 언어 R이 각자 역할을 하면서 데이터 사이언스 생태계를 구성하게 됩니다.데이터 과학을 지탱하는 도구사단법인 한국 알(R) 사용자회는 디지털 불평등 해소와 통계 대중화를 위해\n2022년 설립되었습니다. 오픈 통계 패키지 개발을 비롯하여\n최근에 데이터 사이언스 관련 교재도 함께 제작하여 발간하는 작업을 수행하고 있습니다.\n그 첫번째 결과물로 John Fox 교수님이 개발한 설치형 오픈 통계 패키지 Rcmdr(Fox 2016) (Fox Bouchet-Valat 2021) (Fox 2005) 를 신종화 님께서 한글화 및 문서화에 10년 넘게 기여해주신 한국알사용자회 저작권을 흔쾌히\n허락해 주셔서 설치형 오픈 통계 패키지 - Rcmdr로 세상에 나왔습니다.두번째 활동을 여기저기 산재되어 있던 시각화 관련 자료를 묶어\n데이터 시각화(Data Visualization)를 전자책 형태로 공개하였고,\n데이터 분석 관련 저술을 이어 진행하게 되었습니다.데이터 분석 언어 R에 관한 지식을 신속히 습득하여 독자들이 갖고 있는 문제에\n접목시키고자 하시는 분은 한국 알(R) 사용자회에서 번역하여 공개한\nR 신병훈련소(Bootcamp) 과정을\n추천드립니다.“데이터 과학을 지탱하는 기본기” 저작을 위해 소프트웨어/데이터 카펜트리(Software/Data Carpentry)의\n원작내용을 번역(Wilson 2022)하고 필요한 경우 한국에서 고급 데이터 분석작업을 수행하기 위해\n저자들의 경험을 녹여 제작한 출판물임을 밝혀둡니다.“데이터 과학을 지탱하는 기본기” 저작물을 비롯한 한국 알(R) 사용자회 저작물은\n크리에이티브 커먼즈 저작자표시-비영리-동일조건 변경 허락 (-NC-SA)\n라이선스를 준용하고 있습니다.관련 문의와 연락이 필요한 경우 한국 알(R) 사용자회 admin@r2bit.com 대표전자우편으로 연락주세요.후원계좌디지털 불평등 해소를 위해 제작중인 오픈 통계패키지 개발과 고품질 콘텐츠 제작에 큰 힘이 됩니다.하나은행 448-910057-06204사단법인 한국알사용자회","code":""},{"path":"shell-intro.html","id":"shell-intro","chapter":"1 .  쉘(Shell) 소개","heading":"1 .  쉘(Shell) 소개","text":"유닉스 쉘(Unix Shell)은 대부분의 컴퓨터 사용자가 살아온 것보다 오래 동안 존재했다.\n오래동안 생존한 이유는 사용자로 하여금 단지 키보드 몇번 쳐서 복잡한 작업을 수행할 수 있게 하는 강력한 도구이기 때문이다.\n좀더 중요하게는 기존의 프로그램을 새로운 방식으로 조합해서 반복적인 작업을 자동화함으로써, 동일한 작업을 반복적으로 하지 않게 만든다. 쉘 사용은 폭넓게 다양하고 강력한 도구와 컴퓨팅 자원(슈퍼컴퓨터와 “고성능 컴퓨팅(High Performance Computing, HPC)”이 포함)을 사용하는 근본이 된다.","code":""},{"path":"shell-intro.html","id":"shell-background","chapter":"1 .  쉘(Shell) 소개","heading":"1.1 배경","text":"상위 수준에서 컴퓨터는 네가지 일을 수행한다:프로그램 실행데이터 저장컴퓨터간 상호 의사소통사람과 상호작용마지막 작업을 뇌-컴퓨터 연결, 음성 인터페이스를 포함한 다양한 많은 방식으로 수행하고 있지만\n아직은 초보적인 수준이어서, 대부분은 WIMP((Window) 윈도우, (Icon)아이콘, (Mouse)마우스, (Pointer)포인터)를 사용한다.\n1980년대까지 이러한 기술은 보편적이지 않았지만,\n기술의 뿌리는 1960년대 Doug Engelbart의 작업에 있고,\n“Mother Demos”로 불리는 것에서 볼 수 있다.조금 더 멀리 거슬러 올라가면, 초기 컴퓨터와 상호작용하는 유일한 방법은 와이어로 다시 연결하는 것이다.\n하지만, 중간에 1950년에서 1980년 사이 대부분의 사람들이 라인 프린터(line printer)를 사용했다.\n이런 장치는 표준 키보드에 있는 문자, 숫자, 특수부호의 입력과 출력만 허용해서,\n프로그래밍 언어와 인터페이스는 이러한 제약사항에서 설계됐다.여전히 전통적인 화면, 마우수, 터치패드, 키보드를 사용하지만 터치 인터페이스와 음성 인터페이스가 보편화되고 있다.이런 종류의 인터페이스를 지금 대부분의 사람들이 사용하는 그래픽 사용자 인터페이스(GUI, graphical user interface)과 구별하기 위해서 명령-라인 인터페이스(CLI, command-line interface)라고 한다.\nCLI의 핵심은 읽기-평가-출력(REPL,read-evaluate-print loop)이다: 사용자가 명령어를 타이핑하고 엔터(enter)/반환(return)키를 입력하면,\n컴퓨터가 읽고, 실행하고, 결과를 출력한다.\n그러고 나면, 사용자는 다른 명령를 타이핑하는 것을 로그 오프해서 시스템을 빠져 나갈때까지 계속한다.GUI는 WIMP((Window) 윈도우, (Icon)아이콘, (Mouse)마우스, (Pointer)포인터)로 구성되는데 배우기 쉽고, 단순 작업에 대해서는\n환상적이다. “클릭”하게 되면 명령이 “내가 원하는 작업을 수행해”라고 손쉽게 컴퓨터에 통역된다.\n하지만, 이런 마술은 단순한 작업을 수행하고, 정확하게 이러한 유형의 작업을 수행할 수 있는 프로그램에 불과하다.만약 복잡하고, 특정 목적에 부합되는 훨씬 묵직한 작업을 컴퓨터에 내리고자 한다고 해서,\n난해하거나 어렵거나할 필요는 없고, 단지 명령 어휘가 필요하고 이를 사용하는데 필요한 단순한 문법만 필요로 한다.쉘이 이런 기능을 제공한다 - 단순한 언어로 이를 사용하는데 명령-라인 인터페이스가 필요하다.\n명령라인 인터페이스의 심장은 읽기-평가-출력(REPL,read-evaluate-print loop)이다.\nREPL로 불리는 이유는 쉘에 명령어를 타이핑하고 Return를 치게되면 컴퓨터가 명령어를 읽어들이고 나서,\n평가(혹은 실행)하고 출력결과를 화면에 뿌린다. 또 다른 명령어를 입력할 때까지 대기하는 루푸를 반복하게 되서 그렇다.상기 묘사가 마치 사용자가 직접 명령어를 컴퓨터에 보내고,\n컴퓨터는 사용자에게 직접적으로 출력을 보내는 것처럼 들린다.\n사실 중간에 명령 쉘(command shell)로 불리는 프로그램이 있다.\n사용자가 타이핑하는 것은 쉘로 간다.\n쉘은 무슨 명령어를 수행할지 파악해서 컴퓨터에게 수행하도록 지시한다.\n쉘을 조개(shell)로 불리는데 이유는 운영체제를 감싸서,\n복잡성 일부를 숨겨서 운영체제와 더 단순하게 상호작용하게 만든다.","code":""},{"path":"shell-intro.html","id":"shell-shell","chapter":"1 .  쉘(Shell) 소개","heading":"1.2 쉘(Shell)","text":"쉘(Shell)은 다른 것과 마찬가지로 프로그램이다.\n조금 특별한 것은 자신이 연산을 수행하기 보다 다른 프로그램을 실행한다는 것이다.\n가장 보편적인 유닉스 쉘(Unix Shell)은 Bash(Bourne SHell)다.\nStephen Bourne이 작성한 쉘에서 나와서 그렇게 불리우고 — 프로그래머 사이에 재치로 통한다.\nBash는 대부분의 유닉스 컴퓨터에 기본으로 장착되는 쉘이고,\n윈도우용으로 유닉스스런 도구로 제공되는 패키지 대부분에도 적용된다.Bash나 다른 쉘을 사용하는 것이 마우스를 사용하는 것보다 프로그래밍 작성하는 느낌이 난다.\n명령어는 간략해서 (흔히 단지 2~3자리 문자다), 명령어는 자주 암호스럽고,\n출력은 그래프같이 시각적인 것보다 텍스트줄로 쭉 뿌려진다.\n다른 한편으로, 쉘을 사용하여 좀더 강력한 방식으로 현존하는 도구를 단지 키보드 입력값 몇개를 조합해서 대용량의 데이터를 자동적으로 처리할 수 있는 파이프라인을 구축할 수 있게 한다.\n추가로, 명령 라인은 종종 멀리 떨어진 컴퓨터 혹은 슈퍼컴퓨터와 상호작용하는 가장 쉬운 방법이다.\n고성능 컴퓨팅 시스템에 포함된 다양한 특화된 도구와 자원을 실행하는데 쉘과 친숙성이 거의 필연적이다.\n클러스트 컴퓨팅과 클라우드 컴퓨팅이 과학 데이터 클런칭(scientific data cruching)이 점점 대중화됨에 따라 원격 컴퓨터를 구동하는 것이 필수적인 기술이 되어가고 있다.\n여기서 다뤄지는 명령-라인 기술에 기반해서 광범위한 과학적 질문과 컴퓨터적 도전과제를 처리할 수 있다.","code":""},{"path":"shell-intro.html","id":"shell-looks-like","chapter":"1 .  쉘(Shell) 소개","heading":"1.3 어떻게 생겼을까?","text":"전형적인 쉘 윈도우는 다음과 같다:첫번째 줄은 프롬프트(prompt)만 보여주고 있고, 쉘이 입력준비가 되었다는 것을 나타낸다.\n프롬프트로 다른 텍스트를 지정할 수도 있다. 가장 중요한 것:\n명령어를 타이핑할 때, 프롬프트를 타이핑하지 말고, 인식되거나 수행할 수 있는 명령어만 타이핑한다.예제 두번째 줄에서 타이핑한 ls -F / 부분이 전형적인 구조를 보여주고 있다:\n명령어(command), 플래그(flags) (선택옵션(options) 혹은 스위치(switches)) 그리고 인자(argument).\n플래그는 대쉬(-) 혹은 더블 대쉬(--)로 시작하는데 명령어의 행동에 변화를 준다.인자는 명령어에 작업할 대상을 일러준다(예를 들어, 파일명과 디렉토리).\n종종 플래그를 매개변수(parameter)라고도 부른다.\n명령어를 플래그 한개 이상, 인자도 한개 이상 사용하기도 한다:\n하지만, 명령어가 항상 인자 혹은 플래그를 요구하지는 않는다.상기 예제의 두번째 줄에서, 명령어는 ls, 플래그는 -F,\n인자는 /이 된다. 각각은 공백으로 뚜렸하게 구분된다:\n만약 ls 와 -F 사이 공백을 빼먹게 되면 쉘은 ls-F 명령어를 찾게 되는데,\n존재하지 않는 명령어다. 또한, 대문자도 문제가 될 수 있다:\nLS 명령어와 ls 명령어는 다르다.다음으로 명령어가 생성한 출력결과를 살펴보자.\n이번 경우에 / 폴더에 위치한 파일 목록을 출력하고 있다.\n금일 해당 출력결과가 무엇을 의미하는지 다룰 예정이다.\n맥OS를 사용하시는 참석자분들은 이번 출력결과를 이미 인지하고 있을지도 모른다.마지막으로, 쉘은 프롬프트를 출력하고 다음 명령어가 타이핑되도록 대기모드로 바뀐다.이번 학습예제에서 프롬프트가 $이 된다. 명령어를 PS1='$ ' 타이핑하게 되면\n동일하게 프롬프트를 맞출 수 있다.\n하지만, 본인 취향에 맞추어 프롬프트를 둘 수도 있다 - 흔히 프롬프트에\n사용자명과 디렉토리 현재 위치정보를 포함하기도 하다.쉘 윈도우를 열고, ls -F / 명령어를 직접 타이핑한다.\n(공백과 대문자가 중요함으로 잊지 말자.)\n원하는 경우 프롬프트도 변경해도 좋다.","code":"bash-3.2$ \nbash-3.2$ ls -F / \nApplications/         System/\nLibrary/              Users/\nNetwork/              Volumes/\nbash-3.2$ "},{"path":"shell-intro.html","id":"shell-ls","chapter":"1 .  쉘(Shell) 소개","heading":"1.4 ls 와 플래그 의미 파악","text":"모든 쉘 명령어는 컴퓨터 어딘가에 저장된 프로그램으로,\n쉘은 명령어를 검색해서 찾을 장소를 목록으로 이미 가지고 있다.\n(명령목록은 PATH로 불리는 변수(variable)에 기록되어 있지만,\n이 개념을 나중에 다룰 것이라 현재로서는 그다지 중요하지는 않다.)\n명령어, 플래그, 인자가 공백으로 구분된다는 점을 다시 상기하자.REPL(읽기-평가-출력(read-evaluate-print) 루프)를 좀더 살펴보자.\n“평가(evaluate)” 단계는 두가지 부분으로 구성됨에 주목한다:타이핑한 것을 읽어들인다(이번 예제에서 ls -F /)\n쉘은 공백을 사용해서 명령어로 입력된 것을 명령어, 플래그, 인자로 쪼갠다.평가(Evaluate):\nls 라는 프로그램을 찾는다.\n찾은 프로그램을 실행하고 프로그램이 인식하고 해석한 플래그와 인자를 전달한다.\nls 라는 프로그램을 찾는다.찾은 프로그램을 실행하고 프로그램이 인식하고 해석한 플래그와 인자를 전달한다.프로그램 실행 결과를 출력한다.그리고 나서, 프롬프트를 출력하고 또다른 명령어를 입력받도록 대기한다.Command found 오류쉘이 타이핑한 명령어 이름을 갖는 프로그램을 찾을 수 없는 경우,\n다음과 같은 오류 메시지가 출력된다:일반적으로 명령어를 잘못 타이핑했다는 의미가 된다 - 이 경우,\nls 와 -F 사이 공백을 빼먹어서 그렇다. 즉, ls -F와 같이\n명령을 전달하면 의도한 바가 기계에 정확히 전달된다.","code":"$ ls-F\n-bash: ls-F: command not found"},{"path":"shell-intro.html","id":"shell-difficulty","chapter":"1 .  쉘(Shell) 소개","heading":"1.5 어려운가요?","text":"GUI와 비교하여 컴퓨터와 상호작용하는데 있어 어려운 모형이고 학습하는데\n노력과 시간이 다소 소요도니다.\nGUI는 선택지를 보여주고, 사용자가 선택지중에서 선택하는 하는 것이다.\n명령라인 인터페이스(CLI)로 선택지가 명령어와 패러미터의 조합으로 표현된다.\n사용자에게 제시되는 것이 아니라서 새로운 언어의 어휘를 학습하듯이 일부 학습이 필요하다.\n명령어의 일부만 배우게 되면 정말 도움이 많이 되고, 핵심적인 명령어를 다뤄보자.","code":""},{"path":"shell-intro.html","id":"shell-flexibility","chapter":"1 .  쉘(Shell) 소개","heading":"1.6 유연성과 자동화","text":"쉘문법(Grammar Shell)은 기존 도구를 조합해서 강력한 파이프라인을 구축하도록 해서\n방대한 데이터를 자동화하여 다룰 수 있다.\n명령 순서는 스크립트(script)로 작성하여 작업흐름의 재현가능성을 향상시켜서 쉽게\n반복이 가능하도록 한다.추가로, 명령 라인은 종종 멀리 떨어진 컴퓨터 혹은 슈퍼컴퓨터와 상호작용하는 가장 쉬운 방법이다.\n고성능 컴퓨팅 시스템에 포함된 다양한 특화된 도구와 자원을 실행하는데 쉘과 친숙성이 거의 필연적이다.\n클러스트 컴퓨팅과 클라우드 컴퓨팅이 과학 데이터 클런칭(scientific data cruching)이 점점 대중화됨에 따라 원격 컴퓨터를 구동하는 것이 필수적인 기술이 되어가고 있다.\n여기서 다뤄지는 명령-라인 기술에 기반해서 광범위한 과학적 질문과 컴퓨터적 도전과제를 처리할 수 있다.","code":""},{"path":"shell-intro.html","id":"shell-nelle","chapter":"1 .  쉘(Shell) 소개","heading":"1.7 Nelle 파이프라인 - 문제","text":"해양 생물학자 넬 니모(Nell Nemo) 박사가 방금전 6개월간 북태평양 소용돌이꼴 조사를 마치고 방금 귀환했다.\n태평양 거대 쓰레기 지대에서 젤리같은 해양생물을 표본주출했다.\n총 합쳐서 1,520개 시료가 있고 다음 작업이 필요하다:서로 다른 300개 단백질의 상대적인 함유량을 측정하는 분석기계로 시료를 시험한다.\n한 시료에 대한 컴퓨터 출력결과는 각 단백질에 대해 한 줄 파일형식으로 표현된다.goostat으로 명명된 그녀의 지도교수가 작성한 프로그램을 사용하여 각 단백질에 대한 통계량을 계산한다.다른 대학원 학생중 한명이 작성한 goodiff로 명명된 프로그램을 사용해서, 각 단백질에 대한 통계량과\n다른 단백질에 대해 상응하는 통계량을 비교한다.결과를 작성한다. 그녀의 지도교수는 이달 말까지 이 작업을 정말로 마무리해서,\n논문이 다음번 Aquatic Goo Letters 저널 특별판에 게재되기를 희망한다.각 시료를 분석장비가 처리하는데 약 반시간 정도 소요된다.\n좋은 소식은 각 시료를 준비하는데는 단지 2분만 소요된다.\n연구실에 병렬로 사용할 수 있는 분석장비 8대가 있어서, 이 단계는 약 2주정도만 소요될 것이다.나쁜 소식은 goostat, goodiff를 수작업으로 실행한다면,\n파일이름 입력하고 “OK” 버튼을 45,150번 눌려야 된다는 사실이다 (goostat 300회 더하기 goodiff 300×299/2). 매번 30초씩 가정하면 2주 이상 소요될 것이다.\n논문 마감일을 놓칠 수도 있지만, 이 모든 명령어를 올바르게 입력할 가능성은 거의 0 에 가깝다.다음 수업 몇개는 대신에 그녀가 무엇을 해야되는지 탐색한다.\n좀더 구체적으로, 처리하는 파이프라인 중간에 반복되는 작업을 자동화하는데 쉘 명령어(command shell)를 어떻게 사용하는지 설명해서, 논문을 쓰는 동안에 컴퓨터가 하루에 24시간 작업한다.\n덤으로 중간 처리작업 파이프라인을 완성하면, 더 많은 데이터를 얻을 때마다 다시 재사용할 수 있게 된다.","code":""},{"path":"shell-filedir.html","id":"shell-filedir","chapter":"2 .  파일과 폴더 넘나들기","heading":"2 .  파일과 폴더 넘나들기","text":"파일과 디렉토리 관리를 담당하고 있는 운영체제 부분을 파일 시스템(file system)이라고 한다.\n파일 시스템은 데이터를 정보를 담고 있는 파일과 파일 혹은 다른 디렉토리를 담고 있는 디렉토리(혹은 “폴더”“)로 조직화한다.파일과 디렉토리를 생성, 검사, 이름 바꾸기, 삭제하는데 명령어 몇개가 자주 사용된다.\n명령어를 살펴보기 위해, 쉘 윈도우를 연다:먼저, pwd 명령어를 사용해서 위치를 찾아낸다; pwd는 “print working directory”를 의미한다.\n디렉토리는 장소(place) 같다 - 쉘을 사용할 때마다 정확하게 한 장소에 위치하게 되는데,\n이를 현재 작업 디렉토리(current working directory)라고 부른다.\n명령어 대부분은 현재 작업 디렉토리에 파일을 읽고 쓰는 작업을 “이곳()”에 수행한다.\n그래서 명령어를 실행하기 전에 현재 위치가 어디인지 파악하는 것이 중요하다.\npwd 명령어를 숳애하게 되면 현재 위치를 다음과 같이 보여주게 된다:다음에서, 컴퓨터의 응답은 /Users/nelle으로 넬(Nelle)의 홈 디렉토리(home directory)다:홈 디렉토리(Home Directory) 변종홈 디렉토리 경로는 운영체제마다 다르게 보인다.\n리눅스에서 /home/nelle 처럼 보이고, 윈도우에서는\nC:\\Documents Settings\\nelle, C:\\Users\\nelle와 유사하게 보인다.\n(윈도우 버젼마다 다소 차이가 있을 수 있음에 주목한다.)\n다음 예제부터, 맥OS 출력결과를 기본설정으로 사용할 것이다;\n리눅스와 윈도우 출력결과에 다소 차이가 날 수 있지만, 전반적으로 유사하다.“홈 디렉토리(home directory)”를 이해하기 위해서,\n파일 시스템이 전체적으로 어떻게 구성되었는지 살펴보자.\n최상단에 다른 모든 것을 담고 있는 루트 디렉토리(root directory)가 있다.\n슬래쉬 / 문자로 나타내고, /users/nelle에서 맨 앞에 슬래쉬이기도 하다.Nelle 과학자 컴퓨터의 파일시스템을 사례로 살펴보자.\n시연을 통해서 유사한 방식으로 (하지만 정확하게 동일하지는 않지만) 본인 컴퓨터\n파일시스템을 탐색하는 명령어를 학습하게 된다.넬 과학자 컴퓨터의 파일 시스템은 다음과 같다:파일 시스템최상단에 다른 모든 것을 담고 있는 루트 디렉토리(root directory)가 있다.\n슬래쉬 / 문자로 나타내고, /users/nelle에서 맨 앞에 슬래쉬이기도 하다.홈 디렉토리 안쪽에 몇가지 다른 디렉토리가 있다:\nbin (몇몇 내장 프로그램이 저장된 디렉토리),\ndata (여러가지 데이터 파일이 저장된 디렉토리),\nUsers (사용자의 개인 디렉토리가 저장된 디렉토리),\ntmp (장기간 저장될 필요가 없는 임시 파일을 위한 디렉토리), 등등:현재 작업 디렉토리 /Users/nelle는 /Users 내부에 저장되어 있다는 것을 알고 있는데,\n이유는 /Users가 이름 처음 부분이기 때문에 알 수 있다.\n마찬가지로 /Users는 루트 디렉토리 내부에 저장되어 있다는 것을 알 수 있는데, 이름이 /으로 시작되기 때문이다.슬래쉬(Slashes)슬래쉬 / 문자는 두가지 의미가 있는 것에 주목한다.\n파일 혹은 디렉토리 이름 앞에 나타날 때, 루트 디렉토리를 지칭하게 되고,\n이름 가운데 나타날 때, 단순히 구분자 역할을 수행한다./Users 하단에서 Nelle 과학자 컴퓨터 계정과, 랩실 동료 미이라(Mummy)와 늑대인간(Wolfman) 디렉토리를 볼 수 있다.홈 디렉토리미이라(Mummy) 파일은 /Users/imhotep 디렉토리에 저장되어 있고,\n늑대인가(Wolfman)의 파일은 /Users/larry 디렉토리에 저장되어 있고\n/Users/nelle 디렉토리에 nelle의 정보가 저장되어 있는데,\n이것이 왜 nelle이 디렉토리 이름의 마지막 부분인 이유다.\n일반적으로 명령 프롬프트를 열게 되면, 처음 시작하는 곳이 본인 계정 홈 디렉토리가 된다.본인 파일시스템에 담긴 내용물을 파악하는데 사용하는 명령어를 학습해 보자.\n(Nelle의 홈 디렉토리에 무엇이 있는지 ls 명령어를 실행해서 살펴보자.)\nls는 “목록보기(listing)”를 나타낸다:(다시 한번, 본인 컴퓨터 운영체제와 파일시스템을 취향에 따라 바꿨는지에 따라\n출력결과는 다소 다를 수 있다.)ls는 알파벳 순서로 깔끔하게 열로 정렬하여 현재 디렉토리에 있는 파일과 디렉토리 이름을 출력한다.\n플래그(flag) -F(스위치(switch) 혹은 옵션(option)으로도 불린다)를 추가하여 출력을 좀더 이해하기 좋게 출력괄를 생성할 수도 있다.\nls으로 하여금 디렉토리 이름 뒤에 /을 추가하게 일러준다:\n끝에 붙은 /은 디렉토리라는 것을 지칭한다.\n설정에 따라 달라지도록 파일이냐 디렉토리냐에 따라 다른 색상을 입힐 수도 있다.\n앞선 학습에서 ls -F 명령어를 사용한 것을 상기한다.","code":"$ pwd\n/Users/nelle$ ls\nApplications Documents    Library      Music        Public\nDesktop      Downloads    Movies       Pictures$ ls -F\nApplications/ Documents/    Library/      Music/        Public/\nDesktop/      Downloads/    Movies/       Pictures/"},{"path":"shell-filedir.html","id":"shell-help","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.1 도움말 얻기","text":"ls 명령어에 딸린 플래그가 많다.\n일반적으로 명령어와 수반되는 플래그 사용법을 파악하는 방식이 두개 있다:--help 플래그를 명령어에 다음과 같이 전달하는 방법:man 명령어로 다음과 같이 매뉴얼을 읽는 방법:본인 컴퓨터 환경에 따라 상기 방법 중 하나만 동작(man 혹은 --help)할 수도 있다.\n아래에서 두가지 방법 모두 살펴보자.","code":"$ ls --help$ man ls "},{"path":"shell-filedir.html","id":"shell-help-flag","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.1.1 --help 플래그","text":"배쉬 내부에서 동작하도록 작성된 배쉬 명령어와 프로그램은 --help 플래그를 지원해서\n명령어 혹은 프로그램을 사용하는 방식에 대한 더 많은 정보를 볼 수 있게 해 준다.지원되지 않는 명령-라인 선택옵션지원되지 않는 선택옵션(플래그)를 사용하게 되면, ls를 비롯한 다른 프로그램은\n다음과 같은 오류 메시지를 일반적으로 출력하게 된다:","code":"$ ls --help\n\nUsage: ls [OPTION]... [FILE]...\nList information about the FILEs (the current directory by default).\nSort entries alphabetically if none of -cftuvSUX nor --sort is specified.\n\nMandatory arguments to long options are mandatory for short options too.\n  -a, --all                  do not ignore entries starting with .\n  -A, --almost-all           do not list implied . and ..\n      --author               with -l, print the author of each file\n  -b, --escape               print C-style escapes for nongraphic characters\n      --block-size=SIZE      scale sizes by SIZE before printing them; e.g.,\n                               '--block-size=M' prints sizes in units of\n                               1,048,576 bytes; see SIZE format below\n  -B, --ignore-backups       do not list implied entries ending with ~\n  -c                         with -lt: sort by, and show, ctime (time of last\n                               modification of file status information);\n                               with -l: show ctime and sort by name;\n                               otherwise: sort by ctime, newest first\n\n... 중략\n\n  -X                         sort alphabetically by entry extension\n  -Z, --context              print any security context of each file\n  -1                         list one file per line.  Avoid '\\n' with -q or -b\n      --help     display this help and exit\n      --version  output version information and exit\n\nThe SIZE argument is an integer and optional unit (example: 10K is 10*1024).\nUnits are K,M,G,T,P,E,Z,Y (powers of 1024) or KB,MB,... (powers of 1000).\n\nUsing color to distinguish file types is disabled both by default and\nwith --color=never.  With --color=auto, ls emits color codes only when\nstandard output is connected to a terminal.  The LS_COLORS environment\nvariable can change the settings.  Use the dircolors command to set it.\n\nExit status:\n 0  if OK,\n 1  if minor problems (e.g., cannot access subdirectory),\n 2  if serious trouble (e.g., cannot access command-line argument).\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\nFull documentation at: <http://www.gnu.org/software/coreutils/ls>\nor available locally via: info '(coreutils) ls invocation'$ ls -j\nls: invalid option -- 'j'\nTry 'ls --help' for more information."},{"path":"shell-filedir.html","id":"shell-help-man","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.1.2 man 명령어","text":"ls에 대해 배울 수 있는 다른 방식은 다음 명령어를 타이핑하는 것이다.상기 명령어를 실행하게 되면 ls 명령어와 선택 옵션에 대해 기술된 페이지로\n탈바꿈하게 된다. 만약 운이 좋은 경우 상용법에 대한 예제도 포함되어 있다.man 페이지를 살펴보는 방법은 행단위로 이동하는데 ↑, ↓을 사용하거나\n전체 페이지 단위로 건너뛰거나 아래 페이지로 이동할 경우 B, Spacebar을 사용한다.\nman 페이지에서 단어나 문자를 찾는 경우 / 다음에 검색할 문자 혹은 단어를 타이핑하면 된다.man 페이지에서 빠져 나오고자 종료(quit)하고자 한다면 Q을 누른다.웹상의 매뉴얼 페이지물론 명령어에 대한 도움말에 접근하는 세번째 방식이 있다:\n웹브라우저를 통해서 인터넷을 검색하는 것이다.\n인터넷 검색을 이용할 때, 검색쿼리에 unix man page 문구를\n포함할 경우 연관된 정보를 찾는데 도움이 될 수 있다.GNU도 GNU 핵심 유틸리티(core GNU utilities)이\n포함된 매뉴얼을 제공하고 있는데\n이번 학습에 소개된 많은 명령어를 망라하고 있다.더많은 ls 플래그 탐색-l, -h 플래그를 붙여 ls 명령어를 수행하게 되면 출력결과는 어떻게 나올까?출력결과의 일부는 이번 학습에서 다루지 않는 속성(property)에 대한 것으로 파일 권한과 파일 소유에 대한 것이다. 그럼에도 불구하고 나머지는 유용할 것이다.ls와 사용되는 -l 플래그는 long을 축약한 것으로\n파일/디렉토리 명칭 뿐만 아니라 파일 크기, 최종 변경 시간 같은 부가정보가 출력된다.\n-h 플래그는 “human readable” 사람이 읽기 편한 형태로 파일크기를 지정한다.\n예를 들어, 5369 대신에 5.3K이 화면에 출력된다.재귀적으로 시간순으로 목록 출력ls -R 명령어는 디렉토리에 담긴 내용을 재귀적으로 화면에 출력한다; 즉,\n각 단계별로 하위 디렉토리, 하위-하위 디렉토리 내용을 확면에 출력한다.\nls -t 명령어는 마지막 변경된 시점순으로 가장 최근에 변경된 파일 혹은 디렉토리를 화면에 정렬해서 출력한다.\nls -R -t 명령어는 어떤 순서로 화면엘 출력할까?힌트: ls -l 명령어를 사용해서 시간도장(timestamp)을 볼 수 있도록 전체 목록을 화면에 출력한다.각 디렉토리의 파일/디렉토리가 가장 마지막 시간 변경순으로 정렬되어 출력된다.여기서 홈 디렉토리가 하위 디렉토리(sub-directories)가 포함된것을 알 수 있다.\n슬래쉬(/)가 붙지 않는 명칭을 갖는 것은 것은 평범한 파일(file)이다.\nls 와 -F 사이에 공백이 있는 것에 주목한다:\n공백이 없다면 쉘은 존재하지 않는 ls-F 명령어를 실행시키려 한다고 간주한다.ls 명령어를 사용해서 다른 디렉토리에 들어 있는 파일과 디렉토리를 살펴볼 수 있다.\nls -F Desktop 명령어를 실행해서 바탕화면 Desktop 디렉토리에 담긴 것을 살펴보자.\n즉, ls 명령어는 -F 플래그, 그리고 인자(argument) Desktop으로 구성된다.\nDesktop 인자는 ls로 하여금 현재 작업 디렉토리가 아닌 바탕화면 디렉토리 내용을\n출력하도록 지정하는 역할을 수행한다:작업한 출력결과는 웹사이트에서 다운로드 받아 압축을 풀어 작업하여 생성한 data-shell 디렉토리와\n본인 바탕화면에 저장된 모든 파일과 하위디렉토리가 출력되어야 한다.","code":"$ man ls$ ls -F Desktop\ndata-shell/"},{"path":"shell-filedir.html","id":"shell-cd-change","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.2 cd 디렉토리 변경","text":"지금 확인했듯이, 배쉬 쉘은 파일을 계층적 파일 시스템으로 구성한다는 아이디어에\n강력히 의존하고 있다.\n이런 방식으로 계층적으로 파일과 디렉토리를 구조화하게 되면 본인 작업을 추적하는데 도움이 된다:\n책상위에 출력한 논문 수백개를 쌓아놓은 것는 것이 가능하듯이,\n홈 디렉토리에 파일 수백개를 저장하는 것도 가능하다.\n하지만, 이런 접근법은 자멸하는 전략이나 마찬가지다.data-shell 디렉토리가 바탕화면(Desktop)에 위치하는 것을 확인했으니,\n다음 두가지를 수행할 수 있다.먼저, data-shell 디렉토리에 담긴 것을 살펴보자; 디렉토리 이름에 ls를 전달해서\n앞서 확인된 동일한 전략을 사용하자:둘째로, 다른 디렉토리로 위치를 실제로 바꿀 수 있다.\n그렇게 하면 더이상 홈 디렉토리에 있지는 않게 된다.작업 디렉토리를 변경하기 위해서 cd 다음에 디렉토리 이름을 사용한다.\ncd는 “change directory”의 두문어다.\n하지만 약간 오해의 소지가 있다:\n명령어 자체가 디렉토리를 변경하지는 않고,\n단지 사용자가 어느 디렉토리에 있는지에 대한 쉘의 생각만 바꾼다.앞서 확인한 data 디렉토리로 이동해 보자.\n다음 명령어를 쭉 이어서 실행하게 되면 목적지에 도달할 수 있다:상기 명령어는 홈 디렉토리에 바탕화면(Desktop) 디렉토리로 이동하고 나서,\ndata-shell 디렉토리로 이동하고 나서, data 디렉토리에 이동하게 된다.\ncd 명령어는 아무것도 출력하지는 않지만, pwd 명령어를 실행하게 되면\n/Users/nelle/Desktop/data-shell/data 위치한 것을 확인하게 된다.\n인자 없이 ls 명령어를 실행하게 되면, /Users/nelle/Desktop/data-shell/data 디렉토리\n파일과 디렉토리를 출력하게 되는데 이유는 지금 있는 위치이기 때문이다:이제 디렉토리 나무를 타서 아래로 내려가는 방법을 익혔다.\n하지만 어떻게 하면 위로 올라갈 수 있을까?\n다음 명령어를 시도해보자:하지만, 오류 발생! 이유가 뭘까?지금까지 방법으로 cd 명령어는 현재 디렉토리 내부에 하위 디렉토리만 볼 수 있다.\n현재 디렉토리에서 상위 디렉토리를 볼 수 있는 다른 방법이 있다;\n가장 단순한 것부터 시작해보자.쉘에서 한단계 위 디렉토리로 이동할 수 있는 단축키가 존재하는데 다음과 같이 생겼다:..은 특별한 디렉토리명인데 “현재 디렉토리를 포함하는 디렉토리”, 좀더 간결하게 표현하면\n현재 디렉토리의 부모를 의미한다.\n물론, cd .. 명령어를 실행하고 나서 pwd을 실행하게 되면\n/Users/nelle/Desktop/data-shell로 되돌아 간다:단순히 ls 명령어를 실행하게 되면 특수 디렉토리 ..이 화면에 출력되지는 않는다.\n.. 디렉토리를 출력하려면 ls 명령어와 -플래그를 사용한다:-a은 “show ”의 축약으로 모두 보여주기를 의미한다;\nls로 하여금 ..와 같은 .로 시작하는 파일과 디렉토리명도 화면에 출력하게 강제한다.\n(/Users/nelle 디렉토리에 위치한다면, /Users 디렉토리를 지칭)\n.도 또다른 특별한 디렉토리로,\n“현재 작업 디렉토리(current working directory)”를 의미한다.\n중복되어 불필요해 보일 수 있지만, 곧 .에 대한 사용법을 학습할 것이다.대부분의 명령라인 도구에서 플래그 다수룰 조합해서 플래그 사이 공백없이 단일 -로 사용함에 주목한다:\nls -F -a은 ls -Fa와 동일하다.다른 숨은 파일들숨은 .., . 디렉토리에 더해서,\n.bash_profile 파일도 봤을 것이다.\n.bash_profile 파일에는 쉘 환경설정 정보가 담겨져 있다.\n.으로 시작하는 다른 파일과 디렉토리를 봤을 수도 있다.\n이런 파일은 본인 컴퓨터의 다른 프로그램에서 환경설정을 하기 위해서 사용되는\n파일과 디렉토리라고 보면 된다.\n. 접두어를 사용해서 ls 명령어를 사용할 때 이러한 환경설정 파일들이 터미널을\n난잡하게 만드는 것을 방지하는 기능을 수행한다.직교(Orthogonality)특수 이름 .과 ..는 ls에만 속하는 것이 아니고;\n모든 프로그램에서 같은 방식으로 해석된다.\n예를 들어, /Users/nelle/data 디렉토리에 있을 때,\nls .. 명령어는 /Users/nelle의 목록을 보여줄 것이다.\n어떻게 조합되든 상관없이 동일한 의미를 가지게 될 때,\n프로그래머는 이를 직교(orthogonal)한다고 부른다.\n직교 시스템은 사람들이 훨씬 배우기 쉬운데,\n이유는 기억하고 추적할 특수 사례와 예외가 더 적기 때문이다.","code":"$ ls -F Desktop/data-shell\ncreatures/          molecules/          notes.txt           solar.pdf\ndata/               north-pacific-gyre/ pizza.cfg           writing/$ cd Desktop\n$ cd data-shell\n$ cd data$ pwd\n/Users/nelle/Desktop/data-shell/data$ ls -F\namino-acids.txt   elements/     pdb/            salmon.txt\nanimals.txt       morse.txt     planets.txt     sunspot.txt$ cd data-shell\n-bash: cd: data-shell: No such file or directory$ cd ..$ pwd\n/Users/nelle/Desktop/data-shell$ ls -F -a\n./   .bash_profile  data/       north-pacific-gyre/  pizza.cfg  thesis/\n../  creatures/     molecules/  notes.txt            solar.pdf  writing/"},{"path":"shell-filedir.html","id":"shell-path-absolute","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.3 상대/절대 경로","text":"컴퓨터에 파일시스템을 돌아다니는데 기본 명령어는 pwd, ls, cd을 들 수 있다.\n지금까지 사용했던 했던 방식을 벗어난 사례를 살펴보자.\n프롬프트에서 cd 명령어를 디렉토리를 특정하지 않고 실행시키면 어떻게 될까?상기 명령어 실행 결과를 어떻게 확인할 수 있을까?\npwd 명령어가 정답을 제시한다!어떤 플래그도 없는 cd 명령어는 홈디렉토리로 이동시킨다.\n파일시스템에서 방향을 잃었을 경우 큰 도움이 된다.data 디렉토리로 되돌아가자. 앞서\n명령어 세개를 동원했지만 한방에 해당 디렉토리를 명세해서 바로 이동할 수 있다.pwd 와 ls -F 명령어를 실행해서 올바른 자리로 돌아왔는지 확인하자.\ndata 디렉토리에서 한단계 위로 올라가려고 하면 cd .. 명령어를 사용했다.\n현재 디렉토리 위치에 관계없이 특정 디렉토리로 이동할 수 있는 다른 방식도 있다.지금까지 디렉토리명을 명세할 때 상대경로(relative paths)를 사용했다.\nls 혹은 cd와 같은 명령어와 상대 경로를 사용할 때는 시스템이\n파일시스템의 루트 위치(/)에서 차근차근 찾기보다\n해당 위치를 현재 위치를 찾아 명령을 실행시킨다.하지만, / 슬래쉬로 표현되는 루트 디렉토리에서 전체 경로를\n추가한 절대경로(absolute path)로 명세하는 것도 가능하다.\n/ 슬래쉬는 컴퓨터가 루트 디렉토리에서 경로를 탐색하도록 지시한다.\n따라서, 명령어를 실행할 때 현재 디렉토리 위치에 관계없이\n정확한 특정 디렉토리를 항상 명세하게 된다.절대경로를 사용하면 파일 시스템에 어느 위치에서든 있던 관계없이\ndata-shell 디렉토리로 이동할 수 있다.\n절대경로를 찾기 쉬운 방법은 pwd 명령어를 사용해서 필요한 디렉토리 정보를\n추출하고 이를 활용해서 data-shell 디렉토리로 이동한다.pwd와 ls -F 명령어를 실행하게 되면 원하던 디렉토로리 제대로 이동되었는지\n확인이 가능하다.단축(Shortcuts) 두개 더쉘을 ~ (틸드) 문자를 경로의 시작으로 해석해서 “현재 사용자 홈 디렉토리”를 의미하게 된다.\n예를 들어, Nelle의 홈 디렉토리가 /Users/nelle이라면, ~/data은\n/Users/nelle/data와 동치가 된다. 경로명에 첫 문자로 있을 때만 이것이 동작한다:\n//~/elsewhere이 //Users/nelle/elsewhere이 되는 것은 아니다.\n따라서, cd ~을 홈 디렉토리로 변경하는데 사용한다.또 다룩 단축은 대쉬(-) 문자다. cd는 - 문자를 지금 있는 이전 디렉토리로 변역한다.\n이 방법이 전체 경로를 기억하고 있다가 타이핑하는 것보다 더 빠르다.\n이를 통해 디렉토리를 앞뒤로 매우 효율적으로 이동하게 된다.\ncd .. 와 cd - 명령어 사이 차이점은 전자(cd ..)는 위로,\n후자(cd -)는 아래로 이동하게 위치를 바꾸는 역할을 수행한다.\nTV 리모컨의 이전 채널 기능으로 생각하면 편하다.동일 작업을 수행하는 수많은 방법 - 절대 경로 vs. 상대 경로/home/amanda/data/ 디렉토리에서 시작할 때,\nAmanda가 홈디렉토리인 /home/amanda로 돌아가도록 사용할 수 있는 명령어를 아래에서 선택하시요.cd .cd /cd /home/amandacd ../..cd ~cd homecd ~/data/..cdcd ..해답 풀이\n1. : .은 현재 디렉토리를 나타냄.\n2. : /는 루트 디렉토리를 나타냄.\n3. : Amanda 홈 디렉토리른 /Users/amanda임.\n4. : ../..은 두 단계 거슬러 올라간다; 즉, /Users에 도달함.\n5. Yes: ~은 사용자 홈 디렉토리를 나타남; 이 경우 /Users/amanda이 됨.\n6. : 현재 디렉토리 내부에 home 디렉토리가 존재하는 경우 home 디렉토리로 이동하게 됨.\n7. Yes: 불필요하게 복잡하지만, 정답이 맞음.\n8. Yes: 사용자 홈 디렉토리로 이동할 수 있는 단축키를 사용함.\n9. Yes: 한 단계 위로 이동.상대경로 해결만약 pwd 명령어를 쳤을 때, 화면에 /Users/thing이 출력된다면, ls -F ../backup은 무엇을 출력할까요?../backup: file directory2012-12-01 2013-01-08 2013-01-272012-12-01/ 2013-01-08/ 2013-01-27/original/ pnas_final/ pnas_sub/도전과제 질문 파일 시스템해답 풀이No: backup /Users 디렉토리 내부에 backup 디렉토리가 있다. : Users/thing/backup 디렉토리에 담긴 것을 출력한다.\n하지만 ..으로 한 단계 상위 레벨 위를 찾도록 요청했다.: 이전 해답을 참조한다.Yes: ../backup/ 은 /Users/backup/을 지칭한다.ls 독해 능력상기 그림(도전과제 질문에 사용되는 파일 시스템)에 나온 디렉토리 구조를 상정한다.\n만약 pwd 명령어를 쳤을 때 화면에 /Users/backup이 출력되고,\n-r 인자는 ls 명령어가 역순으로 화면에 출력하게 한다면,\n어떤 명령어가 다음을 화면에 출력할까요?해답풀이\n1. : pwd 는 디렉토리 명칭이 아님.\n2. Yes: 디렉토리 인자가 없는 ls 명령어는 현재 디렉토리의 파일과 디렉토리를 화면에 출력함.\n3. Yes: 절대 경로를 명시적으로 사용.\n4. Correct: 상기 해설 참조.","code":"$ cd$ pwd\n/Users/nelle$ cd Desktop/data-shell/data$ pwd\n/Users/nelle/Desktop/data-shell/data$ cd /Users/nelle/Desktop/data-shellpnas_sub/ pnas_final/ original/\n1.  `ls pwd`\n2.  `ls -r -F`\n3.  `ls -r -F /Users/backup`\n4.  위 #2 혹은 #3, 하지만, #1은 아님."},{"path":"shell-filedir.html","id":"nelle-filedir","chapter":"2 .  파일과 폴더 넘나들기","heading":"2.4 Nelle 파이프라인: 파일 구성","text":"파일과 디렉토리에 대해서 알았으니, Nelle은 단백질 분석기가 생성하는 파일을 구성할 준비를 마쳤다.\n우선 north-pacific-gyre 디렉토리를 생성해서 데이터가 어디에서 왔는지를 상기하도록 한다.\n2012-07-03 디렉토리를 생성해서 시료 처리를 시작한 날짜를 명기했다.\nNelle은 conference-paper와 revised-results같은 이름을 사용하곤 했다.\n하지만, 몇년이 지난 후에 이해하기 어렵다는 것을 발견했다.\n(마지막 지푸라기는 revised-revised-results-3 디렉토리를 본인이 생성했다는 것을 발견했을 때였다.)출력결과 정렬Nelle은 월과 일에 0을 앞에 붙여 디렉토리를 “년-월-일(year-month-day)” 방식으로 이름지었다.\n왜냐하면 쉘이 알파벳 순으로 파일과 디렉토리 이름을 화면에 출력하기 때문이다.\n만약 월이름을 사용한다면, 12월(December)이 7월(July) 앞에 위치할 것이다:\n만약 앞에 0을 붙이지 않으면 11월이 7월 앞에 올 것이다.각각의 물리적 시료는 “NENE01729A”처럼 10자리 중복되지 않는 ID로 연구실 관례에 따라 표식을 붙였다.\n시료의 장소, 시간, 깊이, 그리고 다른 특징을 기록하기 위해서 수집 기록에 사용된 것과 동일하다.\n그래서 이를 각 파일 이름으로 사용하기로 결정했다.\n분석기 출력값이 텍스트 형식이기 때문에 NENE01729A.txt, NENE01812A.txt, … 같이 확장자를 붙였다.\n총 1,520개 파일 모두 동일한 디렉토리에 저장되었다.이제 data-shell 현재 작업 디렉토리에서\nNelle은 다음 명령어를 사용해서, 무슨 파일이 있는지 확인할 수 있다:엄청나게 많은 타이핑이지만 탭 자동완성(tab completion)을 통해 쉘에게 많은 일을 시킬 수도 있다.\n만약 다음과 같이 타이핑하고:그리고 나서 탭(키보드에 탭 키)을 누르면, 자동으로 쉘이 디렉토리 이름을 자동완성 시켜준다:탭을 다시 누르면, Bash가 명령문에 2012-07-03/을 추가하는데,\n왜냐하면 유일하게 가능한 자동완성조건이기 때문이다.\n한번더 탭을 누려면 아무것도 수행하지 않는다.\n왜냐하면 1520가지 경우의 수가 있기 때문이다;\n탭을 두번 누르면 모든 파일 목록을 가져온다.\n이것을 탭 자동완성(tab completion)이라고 부르고,\n앞으로도 다른 많은 툴에서도 많이 볼 것이다.","code":"$ ls north-pacific-gyre/2012-07-03/$ ls nor$ ls north-pacific-gyre/"},{"path":"shell-create.html","id":"shell-create","chapter":"3 .  파일과 디렉토리 작업","heading":"3 .  파일과 디렉토리 작업","text":"이제는 어떻게 파일과 디렉토리를 살펴보는지 알게 되었지만,\n우선, 어떻게 파일과 디렉토리를 생성할 수 있을까요?\n바탕화면(Desktop) data-shell 디렉토리로 돌아가서\nls -F 명령어를 사용하여 무엇을 담고 있는지 살펴봅시다:명령어 mkdir thesis을 사용하여 새 디렉토리 thesis를 생성합시다\n(출력되는 것은 아무것도 없습니다.):이름에서 유추를 할 수도, 하지 못할 수도 있지만,\nmkdir은 “make directory(디렉토리 생성하기)”를 의미한다.\nthesis는 상대 경로여서(즉, 앞에 슬래쉬가 없음),\n새로운 디렉토리는 현재 작업 디렉토리 아래 만들어진다:동일한 작업을 수행하는 두가지 방법쉘을 사용해서 디렉토리를 생성하는 것이나 파일 탐색기를 사용하는 것과 별반 차이가 없다.\n운영체제 그래픽 파일 탐색기를 사용해서 현재 디렉토리를 열게 되면,\nthesis 디렉토리가 마찬가지로 나타난다.\n파일과 상호작용하는 두가지 다른 방식이 존재하지만,\n파일과 디렉토리는 동일하다.명령라인으로 작업할 때, 복잡하고 어려운 파일과 디렉토리는 삶을 질을 현격히 저하시킨다.\n다음에 파일 명칭에 대한 유용한 팁이 몇개 있다.공백(whitespaces)을 사용하지 마라\n공백은 이름을 의미있게 할 수도 있지만,\n공백이 명령라인 인터페이스에서 인자를 구별하는데 사용되기에,\n파일과 디렉토리 명에서는 피하는 것이 상책이다.\n공백 대신에 - 혹은 _ 문자를 사용한다.공백(whitespaces)을 사용하지 마라\n공백은 이름을 의미있게 할 수도 있지만,\n공백이 명령라인 인터페이스에서 인자를 구별하는데 사용되기에,\n파일과 디렉토리 명에서는 피하는 것이 상책이다.\n공백 대신에 - 혹은 _ 문자를 사용한다.대쉬(-)로 명칭을 시작하지 않는다.\n명령어가 -으로 시작되는 명칭을 선택옵션으로 처리하기 때문이다.대쉬(-)로 명칭을 시작하지 않는다.\n명령어가 -으로 시작되는 명칭을 선택옵션으로 처리하기 때문이다.명칭에 문자, 숫자, . (마침표), - (대쉬) _ (밑줄)을 고수한다.\n명령라인 인터페이스에서 다른 많은 문자는 특별한 의미를 갖는다.\n학습을 진행하면서 이들 중 일부를 배울 것이다.\n일부 특수 문자는 명령어가 기대했던 대로 동작하지 못하게 하거나,\n심한 경우 데이터 유실을 야기할 수도 있다.명칭에 문자, 숫자, . (마침표), - (대쉬) _ (밑줄)을 고수한다.\n명령라인 인터페이스에서 다른 많은 문자는 특별한 의미를 갖는다.\n학습을 진행하면서 이들 중 일부를 배울 것이다.\n일부 특수 문자는 명령어가 기대했던 대로 동작하지 못하게 하거나,\n심한 경우 데이터 유실을 야기할 수도 있다.공백을 포함하거나 알파벳이 아닌 문자를 갖는 파일명이나 디렉토리명을 굳이 지정할 필요가 있다면,\n인용부호(\"\")로 파일명이나 디렉토리명을 감싸야 한다.thesis 디렉토리를 방금 생성했기에 내부에는 아무것도 없다:cd 명령어를 사용하여 thesis로 작업 디렉토리를 변경하자.\nNano 텍스트 편집기를 실행해서 draft.txt 파일을 생성하자:어떤 편집기가 좋을까요?“nano가 텍스트 편집기다”라고 말할 때, 정말 “텍스트”만 의미한다.\n즉, 일반 문자 데이터만 작업할 수 있고, 표, 이미지, 혹은 다른 형태의 인간 친화적 미디어는 작업할 수 없다.\nnano를 워크샵에서 사용하는데 이유는 거의 누구나 훈련없이 사용할 수 있기 때문이다.\n하지만, 실제 작업에는 좀더 강력한 편집기 사용을 추천한다.\n유닉스 시스템 계열(맥 OS X, 리눅스)에서 많은 프로그래머는\nEmacs 혹은 Vim을 사용하거나,\n(둘다 완전히 비직관적이만, 심지어 유닉스 표준이기도 하다)\n혹은 그래픽 편집기로 Gedit를 사용한다.\n윈도우에서는 Notepad++를 사용하는 것도 좋다.\n윈도우에는 메모장(notepad)이라고 불리는 자체 내장 편집기도 있는데\nnano 편집기와 마찬가지로 명령라인에서 바로 불러 실행될 수 있다.어떤 편집기를 사용하든, 파일을 검색하고 저장하는 것을 알 필요가 있다.\n쉘에서 편집기를 시작하면, (아마도) 현재 작업 디렉토리가 디폴트 시작 위치가 된다.\n컴퓨터 시작 메뉴에서 시작한다면, 대신에 바탕화면(Desktop) 혹은 문서 디렉토리에 파일을 저장하고 싶을지도 모른다.\n“다른 이름으로 저장하기(Save …)”로 다른 디렉토리로 이동하여 작업 디렉토리를 변경하여 파일을 저장할 수도 있다.텍스트 몇 줄을 타이핑하고,\n컨트롤+O (Control-O, Ctrl 혹은 콘트롤 키보드를 누르면서 O 를 누름)를 눌러서 데이터를 디스크에 쓰면 저장된다:\n(저장하고자 하는 파일명을 입력하도록 독촉받게 되면 draft.txt 기본디폴트로 설정된 것을 받아들이고 엔터키를 친다.)Nano Action파일이 저장되면, 컨트롤+X (Ctrl-X, Control-X)를 사용하여 편집기를 끝내고 쉘로 돌아간다.Control, Ctrl, ^ Key컨트롤 키를 줄여서 “Ctrl” 키라고도 부른다.\n컨트롤 키를 기술하는 몇가지 방식이 있다.\n예를 들어, “컨트롤 키를 누룬다”, “컨트롤 키를 누르면서 X 키를 친다”라는 표현은\n다음 중 하나로 기술된다:Control-XControl+XCtrl-XCtrl+X^XC-xnano 편집기에서 화면 하단에 ^G Get Help ^O WriteOut을 볼 수 있다.\nControl-G를 눌러 도움말을 얻고, Control-O를 눌러 파일을 저장한다는 의미를 갖는다.nano는 화면에 어떤 출력도 뿌려주지 않고 끝내지만,\nls 명령어를 사용하여 draft.txt 파일이 생성된 것을 확인할 수 있다:파일을 생성하는 다른 방법nano 편집기를 사용해서 텍스트 파일을 생성하는 방법을 살펴봤다.\n홈 디렉토리에서 다음 명령어를 실행해 보자:touch 명령어는 어떤 작업을 수행하는가?\nGUI 파일 탐색기를 사용해서 본인 홈 디렉토리를 살펴보게 되면,\n파일이 생성된 것이 보이는가?ls -l 명령어를 사용해서 파일을 살펴보자. my_file.txt 파일은 얼마나 큰가?이런 방식으로 파일을 언제 생성하면 좋을까?실행결과 및 해석touch 명령어가 홈 디렉토리에 ‘my_file.txt’ 파일을 새로 생성시킨다.\n터미널로 현재 홈 디렉토리에 있는 경우, ls 를 타이핑하게 되면\n새로 생성된 파일을 확인할 수 있다. GUI 파일 탐색기로도\n‘my_file.txt’ 파일을 볼 수 있다.touch 명령어가 홈 디렉토리에 ‘my_file.txt’ 파일을 새로 생성시킨다.\n터미널로 현재 홈 디렉토리에 있는 경우, ls 를 타이핑하게 되면\n새로 생성된 파일을 확인할 수 있다. GUI 파일 탐색기로도\n‘my_file.txt’ 파일을 볼 수 있다.‘ls -l’ 명령어로 파일을 조사하게 되면, ‘my_file.txt’ 파일크기가 0kb 임에 주목한다.\n다른 말로 표현하면, 데이터가 아무 것도 없다는 의미가 된다.\n텍스트 편집기로 ‘my_file.txt’ 파일을 열게 되면, 텅 비어 있다.‘ls -l’ 명령어로 파일을 조사하게 되면, ‘my_file.txt’ 파일크기가 0kb 임에 주목한다.\n다른 말로 표현하면, 데이터가 아무 것도 없다는 의미가 된다.\n텍스트 편집기로 ‘my_file.txt’ 파일을 열게 되면, 텅 비어 있다.일부 프로그램은 그 자체로 출력 파일을 생성하지 않지만,\n빈 파일이 이미 생성되어 있는 것을 요구조건으로 하는 경우가 있다.\n프로그램이 실행되면, 출력결과를 채울 수 있는 파일이 존재하는지 검색한다.\n이런 프로그램에게 touch 명령어는 빈 텍스트 파일을 효율적으로 생성할 수 있는\n메커니즘을 제공한다는 점에서 유용하다.일부 프로그램은 그 자체로 출력 파일을 생성하지 않지만,\n빈 파일이 이미 생성되어 있는 것을 요구조건으로 하는 경우가 있다.\n프로그램이 실행되면, 출력결과를 채울 수 있는 파일이 존재하는지 검색한다.\n이런 프로그램에게 touch 명령어는 빈 텍스트 파일을 효율적으로 생성할 수 있는\n메커니즘을 제공한다는 점에서 유용하다.data-shell 디렉토리로 돌아가서,\n생성한 초안을 제거해서 thesis 디렉토리를 깔끔하게 정리하자:상기 명령어는 파일을 제거한다(rm은 “remove”를 줄인 것이다.)\nls 명령어를 다시 실행하게 되면,\n출력결과는 아무 것도 없게 되는데 파일이 사라진 것을 확인시켜준다:삭제는 영원하다유닉스에는 삭제된 파일을 복구할 수 있는 휴지통이 없다.\n(하지만, 유닉스에 기반한 대부분의 그래픽 인터페이스는 휴지통 기능이 있다)\n파일을 삭제하면 파일시스템의 관리대상에서 빠져서 디스트 저장공간이 다시 재사용되게 한다.\n삭제된 파일을 찾아 되살리는 도구가 존재하지만,\n어느 상황에서나 동작한다는 보장은 없다.\n왜냐하면 파일이 저장되었던 공간을 컴퓨터가 바로 재사용할지 모르기 때문이다.파일을 다시 생성하고 나서, cd ..를 사용하여 /Users/nelle/Desktop/data-shell 상위 디렉토리로 이동해보자:rm thesis을 사용하여 전체 thesis 디렉토리를 제거하려고 하면 오류 메시지가 생긴다:rm 명령어는 파일에만 동작하고 디렉토리에는 동작하지 않기 때문에 오류가 발생한다.\nthesis 디렉토리를 제거하려면, draft.txt 파일도 삭제해야 한다.\nrm 명령어에 재귀(recursive) 선택옵션을 사용해서\n삭제 작업을 수행할 수 있다:rm 안전하게 사용하기rm -thesis/quotations.txt 타이핑하면 무슨 일이 일어날까?\nrm 명령어를 사용할 때 왜 이러한 보호장치가 필요할까?-선택옵션은 삭제하기 전에 삭제를 확인하게 해준다.\n유닉스 쉘에는 휴지통이 없어서, 삭제되는 모든 파일은 영원히 사라진다.\n-플래그를 사용하게 되면, 삭제를 원하는 파일만 삭제되는지 점검할 수 있는 기회를 갖게된다.큰 힘에는 큰 책임이 따른다(Great Power Comes Great Responsibility)디렉토리에 먼저 파일을 제거하고, 그리고 나서 디렉토리를 제거하는 방식은 지루하고 시간이 많이 걸린다.\n대신에 -r 옵션을 가진 rm 명령어를 사용할 수 있다.\n-r 플래그 옵션은 “recursive(재귀적)”을 나타낸다.디렉토리에 모든 것을 삭제하고 나서 디렉토리 자체도 삭제한다.\n만약 디렉토리가 하위 디렉토리를 가지고 있다면, rm -r은 하위 디렉토리에도 같은 작업을 반복한다.\n매우 편리하지만, 부주위하게 사용되면 피해가 엄청날 수 있다.디렉톨리 파일을 재귀적으로 제거하는 것은 매우 위험할 수 있다.\n삭제되는 것에 염려가 된다면, rm 명령어에 -인터랙티브 플래그를 추가해서\n삭제단계마다 확인을 하고 삭제하는 것도 가능하다.상기 명령어는 thesis 디렉토리 내부 모든 것을 삭제하고 나서 thesis 디렉토리도\n삭제하는데 삭제단계별로 확인 절차를 거친다.다시 한번 디렉토리와 파일을 생성하자.\n이번에는 thesis/draft.txt 파일경로로 바로 nano를 실행함을 주목하자.\n이전에는 thesis디렉토리로 가서 draft.txt이름으로 nano를 실행했다.","code":"$ pwd\n/Users/nelle/Desktop/data-shell$ ls -F\ncreatures/  data/  molecules/  north-pacific-gyre/  notes.txt  pizza.cfg  solar.pdf  writing/$ mkdir thesis$ ls -F\ncreatures/  data/  molecules/  north-pacific-gyre/  notes.txt  pizza.cfg  solar.pdf  thesis/  writing/$ ls -F thesis$ cd thesis\n$ nano draft.txt$ ls\ndraft.txt$ cd                  # 홈 디렉토리로 이동하기\n$ touch my_file.txt$ cd thesis\n$ rm draft.txt$ ls$ pwd\n/Users/nelle/Desktop/data-shell/thesis$ nano draft.txt\n$ ls\ndraft.txt$ cd ..$ rm thesis\nrm: cannot remove `thesis': Is a directory$ rm -r thesis$ rm: remove regular file 'thesis/quotations.txt'?$ rm -r thesis$ rm -r -i thesis\nrm: descend into directory ‘thesis’? y\nrm: remove regular file ‘thesis/draft.txt’? y\nrm: remove directory ‘thesis’? y$ pwd\n/Users/nelle/Desktop/data-shell$ mkdir thesis\n$ nano thesis/draft.txt\n$ ls thesis\ndraft.txt"},{"path":"shell-create.html","id":"파일과-디렉토리를-위한-좋은-명칭","chapter":"3 .  파일과 디렉토리 작업","heading":"3.1 파일과 디렉토리를 위한 좋은 명칭","text":"명령라인으로 작업할 때, 복잡하고 어려운 파일과 디렉토리는 삶을 질을 현격히 저하시킨다.\n다음에 파일 명칭에 대한 유용한 팁이 몇개 있다.공백(whitespaces)을 사용하지 마라\n공백은 이름을 의미있게 할 수도 있지만,\n공백이 명령라인 인터페이스에서 인자를 구별하는데 사용되기에,\n파일과 디렉토리 명에서는 피하는 것이 상책이다.\n공백 대신에 - 혹은 _ 문자를 사용한다.공백(whitespaces)을 사용하지 마라\n공백은 이름을 의미있게 할 수도 있지만,\n공백이 명령라인 인터페이스에서 인자를 구별하는데 사용되기에,\n파일과 디렉토리 명에서는 피하는 것이 상책이다.\n공백 대신에 - 혹은 _ 문자를 사용한다.대쉬(-)로 명칭을 시작하지 않는다.\n명령어가 -으로 시작되는 명칭을 선택옵션으로 처리하기 때문이다.대쉬(-)로 명칭을 시작하지 않는다.\n명령어가 -으로 시작되는 명칭을 선택옵션으로 처리하기 때문이다.명칭에 문자, 숫자, . (마침표), - (대쉬) _ (밑줄)을 고수한다.\n명령라인 인터페이스에서 다른 많은 문자는 특별한 의미를 갖는다.\n학습을 진행하면서 이들 중 일부를 배울 것이다.\n일부 특수 문자는 명령어가 기대했던 대로 동작하지 못하게 하거나,\n심한 경우 데이터 유실을 야기할 수도 있다.명칭에 문자, 숫자, . (마침표), - (대쉬) _ (밑줄)을 고수한다.\n명령라인 인터페이스에서 다른 많은 문자는 특별한 의미를 갖는다.\n학습을 진행하면서 이들 중 일부를 배울 것이다.\n일부 특수 문자는 명령어가 기대했던 대로 동작하지 못하게 하거나,\n심한 경우 데이터 유실을 야기할 수도 있다.공백을 포함하거나 알파벳이 아닌 문자를 갖는 파일명이나 디렉토리명을 굳이 지정할 필요가 있다면,\n인용부호(\"\")로 파일명이나 디렉토리명을 감싸야 한다.","code":""},{"path":"shell-create.html","id":"shell-move-file","chapter":"3 .  파일과 디렉토리 작업","heading":"3.2 파일과 폴더 이동","text":"draft.txt가 특별한 정보를 제공하는 이름이 아니어서 mv를 사용하여 파일 이름을 변경하자.\nmv는 “move”의 줄임말이다:첫번째 매개변수는 mv 명령어에게 이동하려는 대상을, 두번째 매개변수는 어디로 이동되는지를 나타낸다.\n이번 경우에는 thesis/draft.txt 파일을 thesis/quotes.txt으로 이동한다.\n이렇게 파일을 이동하는 것이 파일 이름을 바꾸는 것과 동일한 효과를 가진다.\n아니나 다를까, ls 명령어를 사용하여 확인하면 thesis 디렉토리에는 이제 quotes.txt 파일만 있음을 확인할 수 있다:목표 파일명을 명세할 때 주의를 기울일 필요가 있다.\n왜냐하면, mv 명령어는 동일 명칭을 갖는\n어떤 기존 파일도 아주 조용히 덮어 써버리는 재주가 있어 데이터 유실에 이르게 된다.\n부가적인 옵션 플래그, mv -(즉 mv --interactive)를 사용해서\n덮어쓰기 전에 사용자가 확인하도록 mv 명령어를 활용할 수도 있다.일관성을 갖고 있어서, mv는 디렉토리에도 동작한다 — 별도 mvdir 명령어는 없다.quotes.txt 파일을 현재 작업 디렉토리로 이동합시다.\nmv를 다시 사용한다.\n하지만 이번에는 두번째 매개변수로 디렉토리 이름을 사용해서 파일이름을 바꾸지 않고, 새로운 장소에 놓는다.\n(이것이 왜 명령어가 “move(이동)”으로 불리는 이유다.)\n이번 경우에 사용되는 디렉토리 이름은 앞에서 언급한 특수 디렉토리 이름 . 이다.과거에 있던 디렉토리에서 파일을 현재 작업 디렉토리로 옮긴 효과가 나타난다.\nls 명령어가 thesis 디렉토리가 비였음을 보여준다:더 나아가,\nls 명령어를 인자로 파일 이름 혹은 디렉토리 이름과 함께 사용하면,\n그 해당 파일 혹은 디렉토리만 화면에 보여준다.\n이렇게 사용하면, quotes.txt 파일이 현재 작업 디렉토리에 있음을 볼 수 있다:현재 폴더로 이동하기다음 명령어를 실행한 후에, 정훈이는 sucrose.dat, maltose.dat 파일을 잘못된 폴더에 넣은 것을 인지하게 되었다:해당 파일을 현재 디렉토리(즉, 현재 사용자가 위치한 폴더)로 이동시키도록 아래 빈칸을 채우시오:.. 디렉토리는 부모 디렉토리(즉, 현재 디렉토리에서 상위 디렉토리를 지칭)\n. 디렉토리는 현재 디렉토리를 지칭함을 상기한다.cp 명령어는 mv 명령어와 거의 동일하게 동작한다.\n차이점은 이동하는 대신에 복사한다는 점이다.\n인자로 경로를 두개 갖는 ls 명령어로 제대로 작업을 했는지 확인할 수 있다.\n대부분의 유닉스 명령어와 마찬가지로, ls 명령어로 한번 경로 다수를 전달할 수도 있다:복사를 제대로 수행했는지 증명하기 위해서,\n현재 작업 디렉토리에 있는 quotes.txt 파일을 삭제하고 나서, 다시 동일한 ls 명령어를 실행한다.이번에는 현재 디렉토리에서 quotes.txt 파일은 찾을 수 없지만,\n삭제하지 않은 thesis 폴더의 복사본은 찾아서 보여준다.파일명이 뭐가 중요해?Nelle의 파일 이름이 “무엇.무엇”으로 된 것을 알아챘을 것이다.\n이번 학습에서, 항상 .txt 확장자를 사용했다.\n이것은 단지 관례다: 파일 이름을 mythesis 혹은 원하는 무엇이든지 작명할 수 있다.\n하지만, 대부분의 사람들은 두 부분으로 구분된 이름을 사용하여\n사람이나 프로그램이 다른 유형의 파일임을 구분하도록 돕는다.\n이름에 나온 두번째 부분을 파일 확장자(filename extension)라고 부르고,\n파일에 어떤 유형의 데이터가 담고 있는지 나타낸다.\n.txt 확장자는 텍스트 파일임을, .pdf는 PDF 문서임을,\n.cfg 확장자는 어떤 프로그램에 대한 구성정보를 담고 있는 형상관리 파일임을 내고,\n.png 확장자는 PNG 이미지 등등을 나타낸다.단지 관습이기는 하지만 중요하다.\n파일은 바이트(byte) 정보를 담고 있다: PDF 문서, 이미지, 등에 대해서 규칙에 따라\n바이트를 해석하는 것은 사람과 작성된 프로그램에 맡겨졌다.whale.mp3처럼 고래 PNG 이미지 이름을 갖는 파일을 고래 노래의 음성파일로 변환하는 마술은 없다.\n설사 누군가 두번 클릭할 때, 운영체제가 음악 재생기로 열어 실행할 수는 있지만 동작은 되지 않을 것이다.파일 이름 바꾸기데이터를 분석하는데 필요한 통계 검정 목록을 담고 있는 .txt 파일을 현재 디렉토리에 생성했다고 가정하자;\n파일명은 statstics.txt.\n파일을 생성하고 저장한 후에 곰곰히 생각해 보니 파일명 철자가 틀린 것을 알게 되었다!\n틀린 철자를 바로잡고자 하는데, 다음 중 어떤 명령어를 사용해야 하는가?\n1. cp statstics.txt statistics.txt\n2. mv statstics.txt statistics.txt\n3. mv statstics.txt .\n4. cp statstics.txt .해답\n1. . 철자오류가 수정된 파일이 생성되지만, 철자가 틀린 파일도 디렉토리에 여전히 존재하기 때문에 삭제작업이 필요하다.\n2. Yes, 이 명령어를 통해서 파일명을 고칠 수 있다.\n3. , 마침표(.)는 파일을 이동할 디렉토리를 나타내지 새로운 파일명을 제시하고 있지는 않고 있다; 동일한 파일명은 생성될 수 없다.\n4. , 마침표(.)는 파일을 복사할 디렉토리를 나타내지 새로운 파일명을 제시하고 있지는 않고 있다; 동일한 파일명은 생성될 수 없다.이동과 복사\n아래 보여진 일련의 명령문에 뒤에 ls명령어의 출력값은 무엇일까요?proteins-saved.dat recombinerecombineproteins.dat recombineproteins-saved.dat해답\n/Users/jamie/data 디렉토리에서 출발해서, recombine 이름의 디렉토리를 새로 생성한다.\n두번째 행은 proteins.dat 파일을 새로 만든 폴더 recombine으로 이동(mv) 시킨다.\n세번째 행은 방금전에 이동한 파일에 대한 사본을 생성시킨다.\n여기서 조금 까다로운 점은 파일이 복사되는 디렉토리다.\n.. 이 의미하는 바가 “한단계 위로 이동”하라는 의미라서,\n복사되는 파일은 이제 /Users/jamie 디렉토리에 위치하게 됨을 상기한다.\n.. 이 의미하는 바는 복사되는 파일 위치에 대한 것이 아니라 현재 작업 디렉토리에 대한\n것으로 해석됨에 유의한다.\n그래서, 그래서, ls 명령어를 사용해서 보여지게 되는 것은 (/Users/jamie/data에 있기 때문에) recombine 폴더가 된다., 상기 해설을 참조한다. proteins-saved.dat 데이터는 /Users/jamie 폴더에 위치한다.YesNo, 상기 해설을 참조한다. proteins.dat 데이터는 /Users/jamie/data/recombine 폴더에 위치한다., 상기 해설을 참조한다. proteins-saved.dat 데이터는 /Users/jamie 폴더에 위치한다.","code":"$ mv thesis/draft.txt thesis/quotes.txt$ ls thesis\nquotes.txt$ mv thesis/quotes.txt .$ ls thesis$ ls quotes.txt\nquotes.txt$ ls -F\n analyzed/ raw/\n$ ls -F analyzed\nfructose.dat glucose.dat maltose.dat sucrose.dat\n$ cd raw/$ mv ___/sucrose.dat  ___/maltose.dat ___$ mv ../analyzed/sucrose.dat ../analyzed/maltose.dat .$ cp quotes.txt thesis/quotations.txt\n$ ls quotes.txt thesis/quotations.txt\nquotes.txt   thesis/quotations.txt$ rm quotes.txt\n$ ls quotes.txt thesis/quotations.txt\nls: cannot access quotes.txt: No such file or directory\nthesis/quotations.txt$ pwd\n/Users/jamie/data$ ls\nproteins.dat$ mkdir recombine\n$ mv proteins.dat recombine/\n$ cp recombine/proteins.dat ../proteins-saved.dat\n$ ls"},{"path":"shell-create.html","id":"shell-moving-multiple","chapter":"3 .  파일과 디렉토리 작업","heading":"3.3 다수 파일과 폴더 작업","text":"다수 파일을 복사하기\n이번 연습문제에서는 data-shell/data 디렉토리에서 명령어를 테스트한다.\n아래 예제에서, 파일명 다수와 디렉토리명이 주어졌을 떄 cp 명령어는 어떤 작업을 수행하는가?아래 예제에서, 3개 혹은 그 이상의 파일명이 주어졌을 때 cp 명령어는 어떤 작업을 수행하는가?해답\n하나이상 파일명 다음에 디렉토리명이 주어지게 되면(즉, 목적지 디렉토리는 마지막 인자에 위치해야 한다.),\ncp 명령어는 파일을 해당 디렉토리에 복사한다.연달아 파일명이 세게 주어지면, cp 명령어는 오류를 던지는데 이유는 마지막 인자로 디렉토리를 기대했기 때문이다.와일드 카드(Wildcards)*는 와일드카드(wildcard)다.\n와일드카드는 0 혹은 그 이상의 문자와 매칭되서,\n*.pdb은 ethane.pdb, propane.pdb 등등에 매칭한다.\n반면에, p*.pdb은 propane.pdb와 pentane.pdb만 매칭하는데,\n맨 앞에 ’p’로 시작되는 파일명만 일치하기만 하면 되기 때문이다.?도 또한 와일드카드지만 단지 단일 문자만 매칭한다.\n이것이 의미하는 바는 p?.pdb은 pi.pdb\n혹은 p5.pdb을 매칭하지만 (molecules 디렉토리에 두 파일이 있다면),\npropane.pdb은 매칭하지 않는다.\n한번에 원하는 수만큼 와일드카드를 사용할 수 있다.\n예를 들어, p*.p?*는 ‘p’로 시작하고’.’과 ‘p’,\n그리고 최소 한자의 이상의 문자로 끝나는 임의의 문자열을 매칭한다고 표현할 수 있는데\n‘?’이 한 문자를 매칭해야하고 마지막’*‘은 끝에 임의의 문자숫자와 매칭할 수 있기 때문이다.\n그래서 p*.p?*은 preferred.practice과 심지어 p.pi도 매칭한다(첫번째’*‘은 어떤 문자도 매칭할 수가 없음).\n하지만 quality.practice은 매칭할 수 없는데 이유는 ’p’로 시작하지 않고,\npreferred.p도 매칭할 수 없는데 ’p’ 다음에 최소 하나의 문자가 필요한데 없기 때문이다.쉘이 와일드카드를 봤을 때, 요청된 명령문을 시작하기 전에 와일드카드를 확장하여 매칭할 파일 이름 목록을 생성한다.\n예외로, 와일드카드 표현식이 어떤 파일과도 매칭되지 않게되면, 배수는 명령어에 인자로 표현식을 있는 그대로 전달한다.\n예를 들어, molecules 디렉토리(.pdb 확장자로 끝나는 파일만 모여있다.)에 ls *.pdf을 타이핑하게 되면, *.pdf으로 불리는 파일이 없다고\n오류 메시지를 출력한다.\n하지만, 일반적으로 wc과 ls 명령어는 와일드카드 표현식과 매칭되는 파일명 목록을 보게 되고 와일드카드\n자체가 아니다.\n다른 프로그램은 아니지만, 쉘은 와일드카드를 확장한 것을 다룬다는 점에서\n직교 설계(orthogonal design)의 또 다른 사례로 볼 수 있다.와일드카드 추가 문제정훈이는 미세조정(calibration), 원본 데이터(dataset), 데이터 설명 데이터를 디렉토리에 보관하고 있다:또 다른 견학여행을 떠나기 전에, 정훈이는 데이터를 백업하고\n일부 데이터를 랩실 동료 기민에게 보내고자 한다.\n정훈이는 백업과 전송 작업을 위해서 다음 명령어를 사용한다:정훈이가 빈칸을 채우도록 도움을 주세요.\n> 해답\n>\n> > $ cp *calibration.txt /backup/calibration > $ cp 2015-11-* ~/send_to_bob/all_november_files/ > $ cp *-23-dataset* ~send_to_bob/all_datasets_created_on_a_23rd/ >디렉토리와 파일 조직화정훈이가 프로젝트 작업을 하고 있는데, 작업 파일이 그다지 잘 조직적으로 정리되어 있지 않음을 알게 되었다:fructose.dat 와 sucrose.dat 파일은 자료분석 결과 산출된 출력결과를 담고 있다.\n이번 학습에서 배운 어떤 명령어를 실행해야,\n아래 명령어를 실행했을 때 다음에 보여지는 출력을 생성할까요?해답정훈이는 analyzed 디렉토리에 fructose.dat, sucrose.dat 파일을 이동시킬 필요가 있다.\n쉘에서 현재 디렉토리에서 *.dat 와일드카드가 .dat 확장자를 갖는 모든 파일을 매칭한다.\nmv 명령어가 .dat 확장자를 갖는 파일을 analyzed 디렉토리로 이동시킨다.폴더 구조를 복사하지만, 파일을 복사하지 말자.새로운 실험을 시작해 보자. 데이터 파일 없이 이전 실험에게 만들었던\n파일 구조만 복제하자. 그렇게 하면 새로운 데이터를 쉽게 추가할 수 있게 된다.\n‘2016-05-18-data’ 디렉토리에 data 폴더로 raw와 processed가 있는데,\n각자 데이터 파일이 담겨있다.목적은 2016-05-18-data 폴더를 2016-05-20-data 폴더로 복사하는 것인데\n복사된 폴더에는 모든 데이터 파일을 제거해야 된다.\n다음 명령어 집합 중 어떤 명령어 집합이 상기 목적을 달성할까요?\n다른 명령어 집합은 무슨 작업을 수행하는 것일가?해답첫번째 명령어들이 해당 목적을 달성한다.\n먼저 재귀적으로 데이터 폴더를 복사한다.\n그리고 나서 rm 명령어 두번 사용해서 복사한 디렉토리의 모든 파일을 제거한다.\n쉘은 * 와일드카드로 매칭되는 모든 파일과 하위디렉토리를 확장하도록 한다.두번째 명령어들은 순서가 잘못되었다:\n복사하지 않는 파일을 샂게하고 나서 재귀 복사 명령어로 디렉토리를 복사했다.세번째 명령어도 목적을 달성하는데, 시간이 다소 소요된다:\n첫번째 명령어가 디렉토리를 재귀적으로 복사하지만, 두번째 명령어는 인터랙티브하게\n각 파일과 디렉토리에 대한 확인하는 과정을 거쳐\n삭제를 하게 되어 시간이 추가로 소요된다.","code":"$ mkdir backup\n$ cp amino-acids.txt animals.txt backup/$ ls -F\namino-acids.txt  animals.txt  backup/  elements/  morse.txt  pdb/  planets.txt  salmon.txt  sunspot.txt$ cp amino-acids.txt animals.txt morse.txt cp: target ‘morse.txt’ is not a directory2015-10-23-calibration.txt\n2015-10-23-dataset1.txt\n2015-10-23-dataset2.txt\n2015-10-23-dataset_overview.txt\n2015-10-26-calibration.txt\n2015-10-26-dataset1.txt\n2015-10-26-dataset2.txt\n2015-10-26-dataset_overview.txt\n2015-11-23-calibration.txt\n2015-11-23-dataset1.txt\n2015-11-23-dataset2.txt\n2015-11-23-dataset_overview.txt$ cp *dataset* /backup/datasets\n$ cp ____calibration____ /backup/calibration\n$ cp 2015-____-____ ~/send_to_bob/all_november_files/\n$ cp ____ ~/send_to_bob/all_datasets_created_on_a_23rd/$ ls -F\nanalyzed/  fructose.dat    raw/   sucrose.dat$ ls -F\nanalyzed/   raw/$ ls analyzed\nfructose.dat    sucrose.datmv *.dat analyzed$ cp -r 2016-05-18-data/ 2016-05-20-data/\n$ rm 2016-05-20-data/raw/*\n$ rm 2016-05-20-data/processed/*$ rm 2016-05-20-data/raw/*\n$ rm 2016-05-20-data/processed/*\n$ cp -r 2016-05-18-data/ 2016-5-20-data/$ cp -r 2016-05-18-data/ 2016-05-20-data/\n$ rm -r -i 2016-05-20-data/"},{"path":"pipe-filter.html","id":"pipe-filter","chapter":"4 .  파이프와 필터","heading":"4 .  파이프와 필터","text":"몇가지 기초 유닉스 명령어를 배웠기 때문에,\n마침내 쉘의 가장 강령한 기능을 살펴볼 수 있게 되었다:\n새로운 방식으로 기존에 존재하던 프로그램을 쉽게 조합해 낼 수 있게 한다.\n간단한 유기분자 설명을 하는 6개 파일을 담고 있는 molecules(분자)라는 디렉토리에서 시작한다.\n.pdb 파일 확장자는 단백질 데이터 은행 (Protein Data Bank) 형식으로,\n분자의 각 원자 형식과 위치를 표시하는 간단한 텍스트 형식으로 되어 있다.명령어 cd로 해당 디렉토리로 가서 wc *.pdb 명령어를 실행한다.\nwc 명령어는 “word count”의 축약어로 파일의 라인 수, 단어수, 문자수를 개수한다. (왼쪽에서 오른쪽 순서로)*.pdb에서 *은 0 혹은 더 많이 일치하는 문자를 매칭한다.\n그래서 쉘은 *.pdb을 통해 .pdb 전체 리스트 목록을 반환한다:wc 대신에 wc -l을 실행하면, 출력결과는 파일마다 행수만을 보여준다:단어 숫자만을 얻기 위해서 -w, 문자 숫자만을 얻기 위해서 -c을 사용할 수 있다.파일 중에서 어느 파일이 가장 짧을까요?\n단지 6개의 파일이 있기 때문에 질문에 답하기는 쉬울 것이다.\n하지만 만약에 6000 파일이 있다면 어떨까요?\n해결에 이르는 첫번째 단계로 다음 명령을 실행한다:> 기호는 쉘로 하여금 화면에 처리 결과를 뿌리는 대신에 파일로 방향변경(redirect)하게 한다.\n만약 파일이 존재하지 않으면 파일을 생성하고 파일이 존재하면 파일에 내용을 덮어쓰기 한다.\n조용하게 덮어쓰기 하기 때문에 자료가 유실될 수 있어서 주의가 요구된다.\n(이것이 왜 화면에 출력결과가 없는 이유다. wc가 출력하는 모든 것은 lengths.txt 파일에 대신 들어간다.)\nls lengths.txt 을 통해 파일이 존재하는 것을 확인한다:cat lengths.txt을 사용해서 화면으로 lengths.txt의 내용을 보낼 수 있다.\ncat은 “concatenate”를 줄인 것이고 하나씩 하나씩 파일의 내용을 출력한다.\n이번 사례에는 단지 파일이 하나만 있어서, cat 명령어는 단지 한 파일이 담고 있는 내용만 보여준다:페이지 단위 출력결과 살펴보기이번 학습에서 편리성과 일관성을 위해서 cat 명령어를 계속 사용한다.\n하지만, 파일 전체를 화면에 쭉 뿌린다는 면에서 단점이 있다.\n실무적으로 less 명령어가 더 유용한데 $ less lengths.txt와 같이 사용한다.\n파일을 화면 단위로 출력한다.\n아래로 내려가려면 스페이스바를 누르고, 뒤로 돌아가려면 b를 누르면 되고,\n빠져 나가려면 q를 누른다.이제 sort 명령어를 사용해서 파일 내용을 정렬합니다.sort -n 명령어는 어떤 작업을 수행할까?다음 파일 행을 포함하고 있는 파일에 sort 명령어를 실행하면:출력결과는 다음과 같다:동일한 입력에 대해서 sort -n을 실행하면, 대신에 다음 결과를 얻게 된다:인수 -n이 왜 이런 효과를 가지는지 설명하세요.해답-n 플래그는 알파벳 정렬이 아닌, 숫자 정렬하도록 명세한다.-n 플래그를 사용해서 알파벳 대신에 숫자 방식으로 정렬할 것을 지정할 수 있다.\n이 명령어는 파일 자체를 변경하지 않고 대신에 정렬된 결과를 화면으로 보낸다:> lengths.txt을 사용해서 wc 실행결과를 lengths.txt에 넣었듯이,\n명령문 다음에 > sorted-lengths.txt을 넣음으로서,\n임시 파일이름인 sorted-lengths.txt에 정렬된 목록 정보를 담을 수 있다.\n이것을 실행한 다음에, 또 다른 head 명령어를 실행해서 sorted-lengths.txt에서 첫 몇 행을 뽑아낼 수 있다:head에 -n 1 매개변수를 사용해서 파일의 첫번째 행만이 필요하다고 지정한다.\n-n 20은 처음 20개 행만을 지정한다.\nsorted-lengths.txt이 가장 작은 것에서부터 큰 것으로 정렬된 파일 길이 정보를 담고 있어서,\nhead의 출력 결과는 가장 짧은 행을 가진 파일이 되어야만 된다.동일한 파일에 방향변경하기명령어 출력결과를 방향변경하는데 동일한 파일에 보내는 것은 매우\n나쁜 아이디어다. 예를 들어:위와 같이 작업하게 되면 틀린 결과를 얻을 수 있을 뿐만 아니라\n경우에 따라서는 lengths.txt 파일 내용을 잃어버릴 수도 있다.>>은 무엇을 의미하는가?> 사용법을 살펴봤지만, 유사한 연산자로 >>도 있는데 다소 다른 방식으로 동작한다.\n문자열을 출력하는 echo 명령어를 사용해서, 두 연산자 차이를 밝혀내는데 아래 명령어를 테스트 한다:힌트: 각 명령문을 연속해서 두번 실행하고 나서, 출력결과로 나온 파일을 면밀히 조사한다.\n> 해답\n>\n> > 연산자를 갖는 첫번째 예제에서 문자열 “hello”는 testfile01.txt 파일에 저장된다.\n> 하지만, 매번 명령어를 실행할 때마다 파일에 덮어쓰기를 한다.\n>\n> 두번째 예제에서 >> 연산자도 마찬가지로 “hello”를 파일에 저장(이 경우 testfile02.txt)하는 것을 알 수 있다.\n> see second example >> operator also writes “hello” file\n> 하지만, 파일이 이미 존재하는 경우(즉, 두번째 명령어를 실행하게 되면) 파일에 문자열을 덧붙인다.\n{: .solution}데이터 덧붙이기head 명령어는 이미 만나봤다. 파일 시작하는 몇줄을 화면에 출력하는 역할을 수행한다.\ntail 명령어도 유사하지만, 반대로 파일 마지막 몇줄을 화면에 출력하는 역할을 수행한다.\ndata-shell/data/animals.txt 파일을 생각해 보자.\n다음 명령어를 실행하게 되면 animalsUpd.txt 파일에\n저장될 내용이 어떤 것일지 아래에서 정답을 고르세요:animals.txt 파일 첫 3줄.animals.txt 파일 마지막 2줄.animals.txt 파일의 첫 3줄과 마지막 2줄.animals.txt 파일의 두번째 세번째 줄.해답\n정답은 3.\n1번이 정답이 되려면, head 명령어만 실행한다.\n2번이 정답이 되려면, tail 명령어만 실행한다.\n4번이 정답이 되려면, head -3 animals.txt | tail -2 >> animalsUpd.txt 명령어를 실행해서 head 출력결과를 파이프에 넣어 tail -2를 실행해야 한다.이것이 혼란스럽다면, 좋은 친구네요:\nwc, sort, head 명령어 각각이 무엇을 수행하는지 이해해도,\n중간에 산출되는 파일에 무슨 일이 진행되고 있는지 따라가기는 쉽지 않다.\nsort와 head을 함께 실행해서 이해하기 훨씬 쉽게 만들 수 있다:두 명령문 사이의 수직 막대를 파이프(pipe)라고 부른다.\n수직막대는 쉘에게 왼편 명령문의 출력결과를 오른쪽 명령문의 입력값으로 사용된다는 뜻을 전달한다.\n컴퓨터는 필요하면 임시 파일을 생성하거나,\n한 프로그램에서 주기억장치의 다른 프로그램으로 데이터를 복사하거나,\n혹은 완전히 다른 작업을 수행할 수도 있다;\n사용자는 알 필요도 없고 관심을 가질 이유도 없다.어떤 것도 파이프를 연속적으로 사슬로 엮어 사용하는 것을 막을 수는 없다.\n즉, 예를 들어 또 다른 파이프를 사용해서 wc의 출력결과를 sort에 바로 보내고 나서,\n다시 처리 결과를 head에 보낸다.\nwc 출력결과를 sort로 보내는데 파이프를 사용했다:또 다른 파이프를 사용해서 wc의 출력결과를 sort에 바로 보내고 나서,\n다시 처리 결과를 head로 보내게 되면 전체 파이프라인은 다음과 같이 된다:이것이 정확하게 수학자가 log(3x) 같은 중첩함수를 사용하는 것과 같다.\n“log(3x)은 x에 3을 곱하고 로그를 취하는 것과 같다.”\n이번 경우는,\n*.pdb의 행수를 세어서 정렬해서 첫부분만 계산하는 것이 된다.명령문을 파이프로 연결하기현재 작업 디렉토리에, 최소 행수를 갖는 파일을 세개 찾고자 한다.\n아래 열거된 어떤 명령어 중 어떤 것이 원하는 파일 3개를 찾아줄까?wc -l * > sort -n > head -n 3wc -l * | sort -n | head -n 1-3wc -l * | head -n 3 | sort -nwc -l * | sort -n | head -n 3해답\n해답은 4.\n파이프 문자 |을 사용해서 이 프로세스 표준출력을 다른 프로세스 표준입력으로 넣어준다.\n> 기호는 표준입력을 파일로 방향변경할 때 사용한다.\ndata-shell/molecules 디렉토리에서도 시도해 보라!파이프를 생성할 때 뒤에서 실질적으로 일어나는 일은 다음과 같다.\n컴퓨터가 한 프로그램(어떤 프로그램도 동일)을 실행할 때 프로그램에 대한 소프트웨어와 현재 상태 정보를 담기 위해서 주기억장치 메모리에 프로세스(process)를 생성한다.\n모든 프로세스는 표준 입력(standard input)이라는 입력 채널을 가지고 있다.\n(여기서 이름이 너무 기억하기 좋아서 놀랄지도 모른다. 하지만 걱정하지 마세요. 대부분의 유닉스 프로그래머는 “stdin”이라고 부른다).\n또한 모든 프로세스는 표준 출력(standard output)(혹은 “stdout”)이라고 불리는 기본디폴트 출력 채널도 있다.\n이 채널이 일반적으로 오류 혹은 진단 메시지 용도로 사용되어서\n터미널로 오류 메시지를 받으면서도 그 와중에 프로그램 출력값이 또다른 프로그램에 파이프되어\n들어가는 것이 가능하게 한다.쉘은 실질적으로 또다른 프로그램이다.\n정상적인 상황에서 사용자가 키보드로 무엇을 타이핑하는 모든 것은 표준 입력으로 쉘에 보내지고,\n표준 출력에서 만들어지는 무엇이든지 화면에 출력된다.\n쉘에게 프로그램을 실행하게 할때,\n새로운 프로게스를 생성하고, 임시로 키보드에 타이핑하는 무엇이든지 그 프로세스의 표준 입력으로 보내지고,\n프로세스는 표준 출력을 무엇이든 화면에 전송한다.wc -l *.pdb > lengths을 실행할 때 여기서 일어나는 것을 설명하면 다음과 같다.\nwc 프로그램을 실행할 새로운 프로세스를 생성하라고 쉘이 컴퓨터에 지시한다.\n파일이름을 인자로 제공했기 때문에 표준입력 대신 wc는 인자에서 입력값을 읽어온다.\n>을 사용해서 출력값을 파일로 방향변경 했기했기 때문에,\n쉘은 프로세스의 표준 출력결과를 파일에 연결한다.wc -l *.pdb | sort -n을 실행한다면, 쉘은 프로세스 두개를 생성한다.\n(파이프 프로세스 각각에 대해서 하나씩) 그래서 wc과 sort은 동시에 실행된다.\nwc의 표준출력은 직접적으로 sort의 표준 입력으로 들어간다;\n>같은 방향변경이 없기 때문에 sort의 출력은 화면으로 나가게 된다.\nwc -l *.pdb | sort -n | head -1을 실행하면,\n파일에서 wc에서 sort로, sort에서 head을 통해 화면으로 나가게 되는 데이터 흐름을 가진 프로세스 3개가 있게 된다.방향변경과 파이프이 간단한 아이디어가 왜 유닉스가 그토록 성공적이었는지를 보여준다.\n다른 많은 작업을 수행하는 거대한 프로그램을 생성하는 대신에,\n유닉스 프로그래머는 각자가 한가지 작업만을 잘 수행하는 간단한 도구를 많이 생성하는데 집중하고,\n서로간에 유기적으로 잘 작동하게 만든다.\n이러한 프로그래밍 모델을 파이프와 필터(pipes filters)라고 부른다;\n파이프는 이미 살펴봤고, 필터(filter)는 wc, sort같은 프로그램으로 입력 스트림을 출력 스트림으로 변환하는 것이다.\n거의 모든 표준 유닉스 도구는 이런 방식으로 동작한다:\n별도로 언급되지 않는다면,\n표준 입력에서 읽고, 읽은 것을 가지고 무언가를 수행하고 표준출력에 쓴다.중요한 점은 표준입력에서 텍스트 행을 읽고,\n표준 출력에 텍스트 행을 쓰는 임의 프로그램은 이런 방식으로 동작하는 모든 다른 프로그램과 조합될 수 있다는 것이다.\n여러분도 여러분이 작성한 프로그램을 이러한 방식으로 작성할 수 있어야 하고 작성해야 한다.\n그래서 여러분과 다른 사람들이 이러한 프로그램을 파이프에 넣어서 생태계 전체 힘을 배가할 수 있다.입력 방향변경프로그램의 출력 결과 방향변경을 위해서 >을 사용하는 것과 마찬가지로, <을 사용해서 입력을 되돌릴 수도 있다.\n즉, 표준입력 대신에 파일로부터 읽어 들일 수 있다.\n예를 들어, wc ammonia.pdb 와 같이 작성하는 대신에, wc < ammonia.pdb 작성할 수 있다.\n첫째 사례는, wc는 무슨 파일을 여는지를 명령 라인의 매개변수에서 얻는다.\n두번째 사례는, wc에 명령 라인 매개변수가 없다.\n그래서 표준 입력에서 읽지만, 쉘에게 ammonia.pdb의 내용을 wc에 표준 입력으로 보내라고 했다.< 기호이 의미하는 것은 무엇인가?(다운로드 예제 데이터를 갖고 있는 최상위) data-shell 디렉토리로 작업 디렉토리를 변경한다.\n다음 두 명령어 차이는 무엇인가?해답\n< 기호는 입력을 방향변경을 해서 명령어로 전달한다.상기 예제 모두에서, 쉘은 입력에서 wc 명령어를 통해 행수를 반환한다.\n첫번째 예제에서, 입력은 notes.txt 파일이고, 파일명이\nwc 명령어로부터 출력으로 주어지게 된다.\n두번째 예제로부터, notes.txt 파일 내용이 표준입력으로 방향변경을 통해 보내지게 된다.\n이것은 마치 프롬프트에서 파일 콘텐츠를 타이핑하는 것과 같다.\n따라서, 파일명이 출력에 주어지지 않는다 - 단지 행번호만 주어진다.\n다음과 같이 타이핑해보자:3\n```uniq가 왜 인접한 중복 행만을 단지 제거한다고 생각합니까?명령문 uniq는 입력으로부터 인접한 중복된 행을 제거한다.\n예를 들어, salmon.txt 파일에 다음이 포함되었다면,data-shell/data 디렉토리의 uniq salmon.txt 명령문 실행은 다음을 출력한다.uniq가 왜 인접한 중복 행만을 단지 제거한다고 생각합니까?\n(힌트: 매우 큰 파일을 생각해보세요.)\n모든 중복된 행을 제거하기 위해, 파이프로 다른 어떤 명령어를 조합할 수 있을까요?\n> 해답\n>\n> > $ sort salmon.txt | uniq >파이프 독해능력data-shell/data 폴더에 animals.txt로 불리는 파일은 다음 데이터를 포함한다다음 아래 파이프라인에 각 파이프를 통과하고, 마지막 방향변경을 마친 텍스트는 무엇이 될까요?힌트: 명령어를 한번에 하나씩 작성해서 파이프라인을 구축한 뒤에 이해한 것이 맞는지 시험한다.해답\nhead 명령어는 animals.txt 파일에서 첫 5 행을 추출한다.\n그리고 나서, tail 명령어로 이전 5 행에서 마지막 3 행을 추출된다.\nsort -r 명령어는 역순으로 정렬을 시키게 된다.\n마지막으로 출력결과는 final.txt 파일에 방향변경하여 화면이 아닌 파일로 보내진다.\n파일에 저장된 내용은 cat final.txt 명령어를 실행하면 확인이 가능하다.\n파일에는 다음 내용이 저장되어야 한다:파이프 구성하기이전 연습문제에 사용된 animals.txt 파일을 가지고 다음 명령어를 실행한다:콤마를 구분자로 각 행을 쪼개려고 하면 -d 플래그를 사용하고,\n-f 플래그는 각행의 두번째 필드를 지정하게 되서 출력결과는 다음과 같다:파일에 담겨 있는 동물이 무엇인지를 알아내려면,\n다른 어떤 명령어가 파이프라인에 추가되어야 하나요?\n(동물 이름에 어떠한 중복도 없어야 합니다.)해답{: .language-bash}파이프 선택?animals.txt 파일은 아래 형식으로 586줄로 구성되어 있다:data-shell/data/ 현재 디렉토리로 가정하고,\n다음 중 어떤 명령어가 동물 종류별로 전체 출현 빈도수를 나타내는 표를\n작성하는데 사용하면 좋을까요?grep {deer, rabbit, raccoon, deer, fox, bear} animals.txt | wc -lsort animals.txt | uniq -csort -t, -k2,2 animals.txt | uniq -ccut -d, -f 2 animals.txt | uniq -ccut -d, -f 2 animals.txt | sort | uniq -ccut -d, -f 2 animals.txt | sort | uniq -c | wc -l해답\n정답은 5.\n정답을 이해하는데 어려움이 있으면, (data-shell/data 디렉토리에 위치한 것을 확인한 후)\n명령어 전체를 실행하거나, 파이프라인 일부를 실행해 본다.","code":"$ ls molecules\ncubane.pdb    ethane.pdb    methane.pdb\noctane.pdb    pentane.pdb   propane.pdb$ cd molecules\n$ wc *.pdb\n\n  20  156  1158  cubane.pdb\n  12  84   622   ethane.pdb\n   9  57   422   methane.pdb\n  30  246  1828  octane.pdb\n  21  165  1226  pentane.pdb\n  15  111  825   propane.pdb\n 107  819  6081  total$ wc -l *.pdb\n\n  20  cubane.pdb\n  12  ethane.pdb\n   9  methane.pdb\n  30  octane.pdb\n  21  pentane.pdb\n  15  propane.pdb\n 107  total$ wc -l *.pdb > lengths.txt$ ls lengths.txt\n\nlengths.txt$ cat lengths.txt\n\n  20  cubane.pdb\n  12  ethane.pdb\n   9  methane.pdb\n  30  octane.pdb\n  21  pentane.pdb\n  15  propane.pdb\n 107  total10\n2\n19\n22\n610\n19\n2\n22\n62\n6\n10\n19\n22$ sort -n lengths.txt\n\n  9  methane.pdb\n 12  ethane.pdb\n 15  propane.pdb\n 20  cubane.pdb\n 21  pentane.pdb\n 30  octane.pdb\n107  total$ sort -n lengths.txt > sorted-lengths.txt\n$ head -n 1 sorted-lengths.txt\n\n  9  methane.pdb$ sort -n lengths.txt > lengths.txt$ echo hello > testfile01.txt$ echo hello >> testfile02.txt$ head -n 3 animals.txt > animalsUpd.txt\n$ tail -n 2 animals.txt >> animalsUpd.txt$ sort -n lengths.txt | head -n 1\n\n  9  methane.pdb$ wc -l *.pdb | sort -n\n\n   9 methane.pdb\n  12 ethane.pdb\n  15 propane.pdb\n  20 cubane.pdb\n  21 pentane.pdb\n  30 octane.pdb\n 107 total$ wc -l *.pdb | sort -n | head -n 1\n\n   9  methane.pdb$ wc -l notes.txt\n$ wc -l < notes.txt$ wc -l\nthis\nis\na test\nCtrl-D # Ctrl-D를 타이핑하게 되면 쉘이 입력을 마무리한 것을 알게 전달하는 역할을 한다.\n\ncoho\ncoho\nsteelhead\ncoho\nsteelhead\nsteelheadcoho\nsteelhead\ncoho\nsteelhead2012-11-05,deer\n2012-11-05,rabbit\n2012-11-05,raccoon\n2012-11-06,rabbit\n2012-11-06,deer\n2012-11-06,fox\n2012-11-07,rabbit\n2012-11-07,bear$ cat animals.txt | head -n 5 | tail -n 3 | sort -r > final.txt2012-11-06,rabbit\n2012-11-06,deer\n2012-11-05,raccoon$ cut -d , -f 2 animals.txtdeer\nrabbit\nraccoon\nrabbit\ndeer\nfox\nrabbit\nbear$ cut -d , -f 2 animals.txt | sort | uniq2012-11-05,deer\n2012-11-05,rabbit\n2012-11-05,raccoon\n2012-11-06,rabbit\n..."},{"path":"pipe-filter.html","id":"nelle-file","chapter":"4 .  파이프와 필터","heading":"4.1 Nelle 파이프라인: 파일 확인하기","text":"앞에서 설명한 것처럼 Nelle은 분석기를 통해 시료를 시험해서 17개 파일을 north-pacific-gyre/2012-07-03 디렉토리에 생성했다.\n빠르게 건전성 확인하기 위해, 홈디렉토리에서 시작해서, 다음과 같이 타이핑한다:결과는 다음과 같은 18 행이 출력된다:이번에는 다음과 같이 타이핑한다:이런, 파일중에 하나가 다른 것보다 60행이 짧다.\n다시 돌아가서 확인하면, 월요일 아침 8:00 시각에 분석을 수행한 것을 알고 있다 —\n아마도 누군가 주말에 기계를 사용했고, 다시 재설정하는 것을 깜빡 잊었을 것이다.\n시료를 다시 시험하기 전에 파일중에 너무 큰 데이터가 있는지를 확인한다:숫자는 예뻐 보인다 —\n하지만 끝에서 세번째 줄에 ‘Z’는 무엇일까?\n모든 시료는 ’’ 혹은 ’B’로 표시되어야 한다.\n시험실 관례로 ’Z’는 결측치가 있는 시료를 표식하기 위해 사용된다.\n더 많은 결측 시료를 찾기 위해, 다음과 같이 타이핑한다:노트북의 로그 이력을 확인할 때, 상기 샘플 각각에 대해 깊이(depth) 정보에 대해서 기록된 것이 없었다.\n다른 방법으로 정보를 더 수집하기에는 너무 늦어서,\n분석에서 두 파일을 제외하기로 했다.\nrm 명령어를 사용하여 삭제할 수 있지만,\n향후에 깊이(depth)정보가 관련없는 다른 분석을 실시할 수도 있다.\n그래서 와일드 카드 표현식 *[AB].txt을 사용하여 파일을 조심해서 선택하기로 한다.\n언제나 그렇듯이, ’*’는 임의 숫자의 문자를 매칭한다.\n[AB] 표현식은 ’’혹은 ’B’를 매칭해서 Nelle이 가지고 있는 유효한 데이터 파일 모두를 매칭한다.와일드카드 표현식(Wildcard Expressions)와일드카드 표현식은 매우 복잡할 수 있지만, 종종 다소 장황할 수 있는 비용을 지불하고\n간단한 구문만 사용해서 작성하기도 한다.\ndata-shell/north-pacific-gyre/2012-07-03 디렉토리를 생각해 보자:\n*[AB].txt 와일드카드 표현식은 .txt 혹은 B.txt으로 끝나는 모든 파일을 매칭시킨다.\n이 와일드카드 표현식을 잊었다고 상상해보자:[] 구문을 사용하지 않는 기본 와일드드카드 표현식으로 동일하게 파일을 매칭할 수 있을까?\n힌트: 표현식이 하나 이상 필요할 수도 있다.[] 구문을 사용하지 않고 작성한 표현식은 동일한 파일을 매칭한다.\n두 출력결과의 작은 차이점은 무엇인가?최초 와일드카드 표현식은 오류가 나지 않는데 어떤 상황에서 본인 표현식은 오류 메시지를 출력하는가?해답\n1.새로운 명령어에서 나온 출력결과는 명령어가 두개라 구분된다.\noutput new commands separated two commands..txt로 끝나는 파일이 없거나 B.txt로 끝나는 파일이 없는 경우 그렇다.불필요한 파일 제거하기저장공간을 절약하고자 중간 처리된 데이터 파일을 삭제하고\n원본 파일과 처리 스크립트만 보관했으면 한다고 가정하자.원본 파일은 .dat으로 끝나고, 처리된 파일은 .txt으로 끝난다.\n다음 중 어떤 명령어가 처리과정에서 생긴 중간 모든 파일을 삭제하게 하는가?\n1. rm ?.txt\n2. rm *.txt\n3. rm * .txt\n4. rm *.*해답\n1. 한문자 .txt 파일을 제거한다.\n2. 정답\n3. * 기호로 인해 현재 디렉토리 모든 파일과 디렉토리를 매칭시킨다.\n그래서 * 기호로 매칭되는 모든 것과 추가로 .txt 파일도 삭제한다.\n4. *.* 기호는 임의 확장자를 갖는 모든 파일을 매칭시킨다.\n따라서 *.* 기호는 모든 파일을 삭제한다.","code":"$ cd north-pacific-gyre/2012-07-03\n$ wc -l *.txt300 NENE01729A.txt\n300 NENE01729B.txt\n300 NENE01736A.txt\n300 NENE01751A.txt\n300 NENE01751B.txt\n300 NENE01812A.txt\n... ...$ wc -l *.txt | sort -n | head -n 5\n\n 240 NENE02018B.txt\n 300 NENE01729A.txt\n 300 NENE01729B.txt\n 300 NENE01736A.txt\n 300 NENE01751A.txt$ wc -l *.txt | sort -n | tail -n 5\n\n 300 NENE02040B.txt\n 300 NENE02040Z.txt\n 300 NENE02043A.txt\n 300 NENE02043B.txt\n5040 total$ ls *Z.txt\n\nNENE01971Z.txt    NENE02040Z.txt  $ ls *A.txt\n  $ ls *B.txt"},{"path":"shell-loop.html","id":"shell-loop","chapter":"5 .  루프(Loops)","heading":"5 .  루프(Loops)","text":"반복적으로 명령어를 실행하게 함으로써 자동화를 통해서 루프는 생산성 향상에 핵심이 된다.\n와일드카드와 탭 자동완성과 유사하게, 루프를 사용하면 타이핑 상당량(타이핑 실수)을 줄일 수 있다.\n와일드카드와 탭 자동완성은 타이핑을 (타이핑 실수를) 줄이는 두가지 방법이다.\n또다른 것은 쉘이 반복해서 특정 작업을 수행하게 하는 것이다.\nbasilisk.dat, unicorn.dat 등으로 이름 붙여진 게놈 데이터 파일이 수백개 있다고 가정하자.\n이번 예제에서,\n단지 두개 예제 파일만 있는 creatures 디렉토리를 사용할 것이지만 동일한 원칙은 훨씬 더 많은 파일에 즉시 적용될 수 있다.\n디렉토리에 있는 파일을 변경하고 싶지만,\n원본 파일을 original-basilisk.dat와 original-unicorn.dat으로 이름을 변경해서 저장한다.\n하지만 다음 명령어를 사용할 수 없다:왜냐하면 상기 두 파일 경우에 전개가 다음과 같이 될 것이기 때문이다:상기 명령어는 파일을 백업하지 않고 대신에 오류가 발생된다:cp 명령어는 입력값 두개 이상을 받을 때 이런 문제가 발생한다.\n이런 상황이 발생할 때, 마지막 입력값을 디렉토리로 예상해서 모든 파일을 해당 디렉토리로 넘긴다.\ncreatures 디렉토리에는 original-*.dat 라고 이름 붙은 하위 디렉토리가 없기 때문에, 오류가 생긴다.대신에, 리스트에서 한번에 연산작업을 하나씩 수행하는\n루프(loop)를 사용할 수 있다.\n교대로 각 파일에 대해 첫 3줄을 화면에 출력하는 단순한 예제가 다음에 나와 있다:루프 내부에 코드 들여쓰기for 루프 내부의 코드를 들여쓰는 것이 일반적인 관행이다.\n들여쓰는 유일한 목적은 코드를 더 읽기 쉽게 하는 것 밖에 없다 – 루프를 실행하는데는 꼭 필요하지는 않다.쉘이 키워드 for를 보게 되면,\n쉘은 리스트에 있는 각각에 대해 명령문 하나(혹은 명령문 집합)을 반복할 것이라는 것을 알게 된다.\n루프를 반복할 때마다(iteration 이라고도 한다),\n현재 작업하고 있는 파일 이름은 filename으로 불리는 변수(variable)에 할당된다.\n리스트의 다음 원소로 넘어가기 전에 루프 내부 명령어가 실행된다.\n루프 내부에서, 변수 이름 앞에 $ 기호를 붙여 변수 값을 얻는다:\n$ 기호는 쉘 해석기가 변수명을 텍스트나 외부 명령어가 아닌 변수로 처리해서 값을 해당 위치에 치환하도록 지시한다.이번 경우에 리스트는 파일이름이 두개다: basilisk.dat, unicorn.dat.\n매번 루프가 돌 때마다 파일명을 filename 변수에 할당하고 head 명령어를 실행시킨다.\n즉, 루프가 첫번째 돌 때 $filename 은 basilisk.dat이 된다.\n쉘 해석기는 basilisk.dat 파일에 head 명령어를 실행시켜서\nbasilisk.dat 파일의 첫 3줄을 화면에 출력시킨다.두번째 반복에서, $filename은 unicorn.dat이 된다.\n이번에는 쉘이 head 명령어를 unicorn.dat 파일에 적용시켜\nunicorn.dat 파일 첫 3줄을 화면에 출력시킨다.\n리스트에 원소가 두개라서, 쉘은 루프를 빠져나온다.변수명을 분명히 구분하는데, 중괄호 내부에 변수명을 넣어서 변수로 사용하는 것도 가능하다:\n$filename 은 ${filename}와 동치지만, ${file}name와는 다르다.\n이 표기법을 다른 사람 프로그램에서 찾아볼 수 있다.루프 내부의 변수이번 예제는 data-shell/molecules 디렉토리를 가정한다.\nls 명령어를 던지면 출력결과는 다음과 같다:다음 코드의 출력결과는 어떻게 나오는가?이제 다음 코드의 출력결과는 무엇인가?왜 상기 두 루프 실행결과는 다를까?해답\n첫번째 코드 블록은 루프를 돌릴 때마다 동일한 출력결과를 출력한다.\n배쉬는 루프 몸통 내부 와일드카드 *.pdb을 확장해서 .pdb로 끝나는\n모든 파일을 매칭시킨다.\n확장된 루프는 다음과 같이 생겼다:두번째 코드 블록은 루프를 돌 때마다 다른 파일을 출력한다.\ndatafile 파일 변수값이 $datafile을 통해 평가되고\nls 명령어를 사용해서 파일 목록을 출력하게 된다.프롬프트 따라가기루프안에서 타이핑을 할 때, 쉘 프롬프트가 $에서 >으로 바뀐다.\n두번째 프롬프트는, >, 온전한 명령문 타이핑이 끝마치지 않았음을 상기시키려고 다르게 표기된다.\n세미콜론 ; 을 사용해서 두 명령어로 구성된 문장을 단일 명령줄로 단순화한다.동일한 기호, 하지만 다른 의미쉘 프롬프트로 > 기호가 사용되는 것을 확인했지만,\n> 기호는 출력결과를 방향변경(redirect) 하는데도 사용된다.\n유사하게 $ 기호를 쉘 프롬프트로 사용했지만, 앞에서 살펴봤듯이,\n쉘로 하여금 변수값을 추출하는데도 사용된다.쉘이 > 혹은 $ 기호를 출력하게 되면, 사용자가 뭔가 타이핑하길 기대하고 있다는 것으로\n해당 기호는 프롬프트를 의미한다.사용자 본인이 > 혹은 $ 기호를 타이핑하게 되면,\n출력결과를 방향변경하거나 변수 값을 끄집어내는 지시를 쉘에 전달하게 된다.data-shell/creatures 디렉토리의 예제로 돌아가자.\n사람 코드를 읽는 독자에게 목적을 좀더 명확히 하기 위해서 루프의 변수명을 filename로 했다.\n쉘 자체는 변수명이 어떻게 작명되든지 문제삼지 않는다. 만약 루프를 다음과 같이 작성하거나:혹은:둘다 정확하게 동일하게 동작한다.\n이렇게는 절대 하지 마세요.\n사람이 프로그램을 이해할 수 있을 때만 프로그램이 유용하기 때문에,\n(x같은) 의미없는 이름이나, (temperature같은) 오해를 줄 수 있는 이름은\n오해를 불러일으켜서 독자가 생각하기에 당연히 프로그램이 수행해야 할 작업을 프로그램이 수행하지 못하게 할 가능성을 높인다.파일 집합 제한걸기data-shell/molecules 디렉토리에서 다음 루프를 실행하게 되면 출력결과는 어떻게 될까?어떤 파일도 출력되지 않는다.모든 파일이 출력된다.cubane.pdb, octane.pdb, pentane.pdb 파일만 출력된다.cubane.pdb 파일만 출력된다.해답\n정답은 4. 와일드카드 * 문자는 0 혹은 그 이상 문자를 매칭하게 된다.\n따라서, 문자 c로 시작하는 문자 다음에 0 혹은 그 이상 문자를 갖는 모든 파일이 매칭된다.대신에 다음 명령어를 사용하면 출력결과는 어떻게 달라지나?동일한 파일이 출력된다.이번에는 모든 파일이 출력된다.이번에는 어떤 파일도 출력되지 않는다.cubane.pdb 와 octane.pdb 파일이 출력된다.octane.pdb 파일만 출력된다.해답\n정답은 4. 와일드카드 * 문자는 0 혹은 그 이상 문자를 매칭하게 된다.\n따라서, c 앞에 0 혹은 그 이상 문자가 올 수 있고, c 문자 다음에 0 혹은 그 이상 문자가 모두 매칭된다.data-shell/creatures 디렉토리에서 예제를 계속해서 학습해보자.\n다음에 좀더 복잡한 루프가 있다:쉘이 *.dat을 전개해서 쉘이 처리할 파일 리스트를 생성한다.\n그리고 나서 루프 몸통(loop body) 부분이 파일 각각에 대해 명령어 두개를 실행한다.\n첫 명령어 echo는 명령 라인 매개변수를 표준 출력으로 화면에 뿌려준다.\n예를 들어:상기 명령은 다음과 같이 출력된다:이 사례에서, 쉘이 파일 이름으로 $filename을 전개했기 때문에,\necho $filename은 단지 파일 이름만 화면에 출력한다. 다음과 같이 작성할 수 없다는 것에 주의한다:왜냐하면, $filename이 basilisk.dat으로 전개될 때 루프 처음에 쉘이 프로그램으로 인식한 basilisk.dat를 실행하려고 하기 때문이다.\n마지막으로, head와 tail 조합은 어떤 파일이 처리되든 81-100줄만 선택해서 화면에 뿌려준다.\n(파일이 적어도 100줄로 되었음을 가정)::: {#shell-loop-space .rmdcaution}파일, 디렉토리, 변수 등 이름에 공백공백(whitespace)을 사용해서 루프를 돌릴 때 리스트의 각 원소를 구별했다.\n리스트 원소중 일부가 공백을 갖는 경우, 해당 원소를 인용부호로 감싸서 사용해야 된다.\n데이터 파일이 다음과 같은 이름으로 되었다고 가정하자:다음을 사용하여 파일을 처리하려고 한다면:파일명에 공백(혹은 다른 특수 문자)를 회피하는 것이 더 단순하다.\n상기 파일은 존재하지 않는다. 그래서 상기 코드를 실행하게 되면, head 명령어는\n파일을 찾을 수가 없어서 예상되는 파일명을 보여주는 오류 메시지가 반환된다:상기 루프 내부 $filename 파일명 주위 인용부호를 제거하고 공백 효과를 살펴보자.\ncreatures 디렉토리에서 코드를 실행시키게 되면 unicorn.dat 파일에 대한 결과를 루프 명령어 실행 결과를 얻게 됨에 주목한다:원래 파일 복사문제로 되돌아가서, 다음 루프를 사용해서 문제를 해결해 보자:상기 루프는 cp 명령문을 각 파일이름에 대해 실행한다.\n처음에 $filename이 basilisk.dat로 전개될 때, 쉘은 다음을 실행한다:두번째에는 명령문은 다음과 같다:cp 명령어는 아무런 출력결과도 만들어내지 않기 때문에,\n루프가 제대로 돌아가는지 확인하기 어렵다.\necho로 명령문 앞에 위치시킴으로써, 명령문 각각이 제대로\n동작되고 있는 확인하는 것이 가능하다.\n다음 도표를 통해서 스크립트가 동작할 때 어떤 작업이 수행하고 있는지 상술하고 있다.\n또한 echo 명령어를 사려깊이 사용하는 것이 어떻게 훌륭한 디버깅 기술이 되는지도 보여주고 있다.Loop Action","code":"$ cp *.dat original-*.dat$ cp basilisk.dat unicorn.dat original-*.datcp: target `original-*.dat' is not a directory$ for filename in basilisk.dat unicorn.dat\n> do\n>    head -n 3 $filename    # 루프 내부에 들여쓰기는 가독성에 도움을 준다.\n> done\n\nCOMMON NAME: basilisk\nCLASSIFICATION: basiliscus vulgaris\nUPDATED: 1745-05-02\nCOMMON NAME: unicorn\nCLASSIFICATION: equus monoceros\nUPDATED: 1738-11-24cubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb$ for datafile in *.pdb\n> do\n>    ls *.pdb\n> done$ for datafile in *.pdb\n> do\n>   ls $datafile\n> done$ for datafile in cubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\n> do\n> ls cubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\n> done\n\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdb\ncubane.pdb  ethane.pdb  methane.pdb  octane.pdb  pentane.pdb  propane.pdbcubane.pdb\nethane.pdb\nmethane.pdb\noctane.pdb\npentane.pdb\npropane.pdb$ for x in basilisk.dat unicorn.dat\n> do\n>    head -n 3 $x\n> done$ for temperature in basilisk.dat unicorn.dat\n> do\n>    head -n 3 $temperature\n> done$ for filename in c*\n> do\n>    ls $filename \n> done$ for filename in *c*\n> do\n>    ls $filename \n> done$ for filename in *.dat\n> do\n>     echo $filename\n>     head -n 100 $filename | tail -n 20\n> done$ echo hello therehello there$ for filename in *.dat\n> do\n>     $filename\n>     head -n 100 $filename | tail -n 20\n> donered dragon.dat\npurple unicorn.dat$ for filename in \"red dragon.dat\" \"purple unicorn.dat\"\n> do\n>     head -n 100 \"$filename\" | tail -n 3\n> donehead: cannot open ‘red dragon.dat’ for reading: No such file or directory\nhead: cannot open ‘purple unicorn.dat’ for reading: No such file or directoryhead: cannot open ‘red’ for reading: No such file or directory\nhead: cannot open ‘dragon.dat’ for reading: No such file or directory\nhead: cannot open ‘purple’ for reading: No such file or directory\nCGGTACCGAA\nAAGGGTCGCG\nCAAGTGTTCC$ for filename in *.dat\n> do\n>     cp $filename original-$filename\n> donecp basilisk.dat original-basilisk.datcp unicorn.dat original-unicorn.dat"},{"path":"shell-loop.html","id":"nelle-shell-loop","chapter":"5 .  루프(Loops)","heading":"5.1 Nelle의 파이프라인: 많은 파일 처리하기","text":"Nelle은 이제 goostats 프로그램(논문 지도교수가 작성한 쉘 스크립트)을 사용해서 데이터 파일을 처리할 준비가 되었다.\ngoostats 프로그램은 표본추출 단백질 파일에서 통계량을 산출하는데 인자를 두개 받는다:입력파일 (원본 데이터를 포함)출력파일 (산출된 통계량을 저장)아직 쉘을 어떻게 사용하는지 학습단계에 있기 때문에,\n단계별로 요구되는 명령어를 차근히 작성하기로 마음먹었다.\n첫번째 단계는 적합한 파일을 선택했는지를 확인하는 것이다\n— ‘Z’가 아닌 ’’ 혹은 ’B’로 파일이름이 끝나는 것이 적합한 파일이라는 것을 명심한다.\n홈 디렉토리에서 시작해서, 박사과정 Nelle이 다음과 같이 타이핑한다:다음 단계는 goostats 분석 프로그램이 생성할 파일이름을 무엇으로 할지 결정하는 것이다.\n“stats”을 각 입력 파일에 접두어로 붙이는 것이 간단해 보여서, 루프를 변경해서 작업을 수행하도록 한다:goostats을 아직 실행하지는 않았지만,\n이제 확신할 수 있는 것은 올바른 파일을 선택해서,\n올바른 출력 파일이름을 생성할 수 있다는 점이다.명령어를 반복적으로 타이핑하는 것은 귀찮은 일이지만,\n더 걱정이 되는 것은 Nelle이 타이핑 실수를 하는 것이다.\n그래서 루프를 다시 입력하는 대신에 위쪽 화살표를 누른다.\n위쪽 화살표에 반응해서 컴퓨터 쉘은 한줄에 전체 루프를 다시 보여준다.\n(스크립트 각 부분이 구분되는데 세미콜론이 사용됨):왼쪽 화살표 키를 사용해서,\nNelle은 echo명령어를 bash goostats으로 변경하고 백업한다:엔터키를 누를 때, 쉘은 수정된 명령어를 실행한다.\n하지만, 어떤 것도 일어나지 않는 것처럼 보인다 — 출력이 아무것도 없다.\n잠시뒤에 Nelle은 작성한 스크립트가 화면에 아무것도 출력하지 않아서,\n실행되고 있는지, 얼마나 빨리 실행되는지에 대한 정보가 없다는 것을 깨닫는다.\n컨트롤+C(Control-C)를 눌러서 작업을 종료하고,\n반복할 명령문을 위쪽 화살표로 선택하고,\n편집해서 다음과 같이 작성한다:시작과 끝쉘에 ^, 콘트롤+(Control-, Ctrl-)를 타이핑해서 해당 라인 처음으로 가고,\n^E (Ctrl-e, Control-E)를 쳐서 라인의 끝으로 이동한다.이번에 프로그램을 실행하면, 매 5초간격으로 한줄을 출력한다:1518 곱하기 5초를 60으로 나누면,\n작성한 스크립트를 실행하는데 약 2시간 정도 소요된다고 볼 수 있다.\n마지막 점검으로, 또다른 터미널 윈도우를 열어서,\nnorth-pacific-gyre/2012-07-03 디렉토리로 가서,\ncat stats-NENE01729B.txt을 사용해서 출력파일 중 하나를 면밀히 조사한다.\n출력결과가 좋아보인다.\n그래서 커피를 마시고 그동안 밀린 논문을 읽기로 한다.역사(history)를 아는 사람은 반복할 수 있다.앞선 작업을 반복하는 또다른 방법은 history 명령어를 사용하는 것이다.\n실행된 마지막 수백개 명령어 리스트를 얻고 나서,\n이들 명령어 중 하나를 반복실행하기 위해서 !123(“123”은 명령 숫자로 교체된다.)을 사용한다.\n예를 들어 Nelle이 다음과 같이 타이핑한다면:그리고 나서, 단순히 !458을 타이핑함으로써,\nNENE01729B.txt 파일에 goostats을 다시 실행할 수 있게 된다.다른 이력(history) 명령어이력(history)에 접근하는 단축 명령어가 다수 존재한다.Ctrl-R 탄축키는 “reverse--search” 이력 검색모드로\n입력한 텍스트와 매칭되는 가장 최슨 명령어를 이력에서 찾아서 제시한다.\nCtrl-R 단축키를 한번 혹은 그 이상 누르게 되면 그 이전 매칭을 검색해 준다.!! 명령어는 바로 직전 명령어를 불러온다.\n(키보드 윗화살표를 사용하는 것보다 더 편리할수도 편리하지 않을 수도 있다.)!$ 명령어는 마지막 명령문의 마지막 단어를 불러온다.\n기대했던 것보다 훨씬 유용할 수 있다:\nbash goostats NENE01729B.txt stats-NENE01729B.txt 명령문을 실행한 후에\nless !$을 타이핑하게 되면 stats-NENE01729B.txt 파일을 찾아준다.\n키보드 위화살표를 눌러 명령라인을 편집하는 것보다 훨씬 빠르다.루프 내부에서 파일에 저장하기 - 1부data-shell/molecules 디렉토리에 있다고 가정하자.\n다음 루프의 효과는 무엇인가?fructose.dat, glucose.dat, sucrose.dat을 출력하고, sucrose.dat에서 나온 텍스트를 xylose.dat에 저장된다.fructose.dat, glucose.dat, sucrose.dat을 출력하고, 모든 파일 3개에서 나온 텍스트를 합쳐 xylose.dat에 저장된다.fructose.dat, glucose.dat, sucrose.dat, xylose.dat을 출력하고, sucrose.dat에서 나온 텍스트를 xylose.dat에 저장된다.위 어느 것도 아니다.해답\n1. 순차적으로 각 파일의 텍스트가 alkanes.pdb 파일에 기록된다.\n하지만, 루프가 매번 반복될 때마다 파일에 덮어쓰기가 수행되어서 마지막 alkanes.pdb 파일 텍스트만\nalkanes.pdb 파일에 기록된다.루프 내부에서 파일에 저장하기 - 2부이번에도 data-shell/molecules 디렉토리에 있다고 가정하고, 다음 루프 실행 출력결과는 무엇일까?cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb 파일에 나온 모든 모든 텍스트가 하나로 붙여져서\n.pdb 파일에 저장된다.ethane.pdb 파일에 나온 텍스트만 .pdb 파일에 저장된다.cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb, propane.pdb 파일에서 나온 모든 텍스트가\n하나로 풑여져서 .pdb 파일에 저장된다.cubane.pdb, ethane.pdb, methane.pdb, octane.pdb, pentane.pdb, propane.pdb 파일에서 나온\n모든 텍스트가 화면에 출력되고 .pdb 파일에 저장된다.해답\n정답은 3. 명령어 실행 출력결과를 방향변경하여 덮었는 것이 아니라 >> 기호는 파일에 덧붙인다.\ncat 명령어에서 나온 출력결과가 파일로 방향변경되어 어떤 출력결과도 화면에 출력되지는 않는다.시운전(Dry Run)루프는 한번에 많은 작업을 수행하는 방식이다 — 만약 잘못된 것이 있다면,\n한번에 실수를 대단히 많이 범하게 된다.\n루프가 수행하는 작업을 점검하는 한 방법이 실제로 루프를 돌리는 대신에\necho 명령어를 사용하는 것이다.\n실제로 명령어를 실행하지 않고, 다음 루프가 실행할 명령어를 머릿속으로 미리보고자 한다고 가정한다:아래 두 루프 사이에 차이는 무엇이고, 어느 것을 시운전으로 실행하고 싶은가?해답\n두번째 버젼을 실행하면 좋을 것이다.\n달러 기호로 접두명을 주었기 때문에 루프 변수를 확장해서 인용부호로 감싼 모든 것을 화면에 출력한다.첫번째 버전은 echo analyze $file 명령을 수행해서 analyzed-$file 파일로\n출력결과를 방향변경하여 저장시킨다. 따라서 파일이 쭉 자동생성된다:analyzed-cubane.pdb,\nanalyzed-ethane.pdb …두가지 버젼을 직접 실행해보고 출력결과를 살펴보자!\nanalyzed-*.pdb 파일을 열어서 파일에 기록된 내용도 살펴본다.중첩루프(Nested Loops)\n다른 화합물과 다른 온도를 갖는 조합을 해서, 각 반응율 상수를 측정하는\n실험을 조직하도록 이에 상응하는 디렉토리 구조를 갖추고자 한다.\n다음 코드 실행결과는 어떻게 될까?해답\n중첩 루프(루프 내부에 루프가 포함됨)를 생성하게 된다.\n외부 루프에 각 화학물이, 내부 루프(중첩된 루프)에 온도 조건을 반복하게 되서,\n화학물과 온도를 조합한 새로운 디렉토리가 쭉 생성된다.직접 코드를 실행해서 어떤 디렉토리가 생성되는지 확인한다!","code":"$ cd north-pacific-gyre/2012-07-03\n$ for datafile in NENE*[AB].txt\n> do\n>     echo $datafile\n> done\n\nNENE01729A.txt\nNENE01729B.txt\nNENE01736A.txt\n...\nNENE02043A.txt\nNENE02043B.txt$ for datafile in NENE*[AB].txt\n> do\n>     echo $datafile stats-$datafile\n> done\n\nNENE01729A.txt stats-NENE01729A.txt\nNENE01729B.txt stats-NENE01729B.txt\nNENE01736A.txt stats-NENE01736A.txt\n...\nNENE02043A.txt stats-NENE02043A.txt\nNENE02043B.txt stats-NENE02043B.txt$ for datafile in NENE*[AB].txt; do echo $datafile stats-$datafile; done$ for datafile in NENE*[AB].txt; do bash goostats $datafile stats-$datafile; done$ for datafile in NENE*[AB].txt; do echo $datafile; bash goostats $datafile stats-$datafile; doneNENE01729A.txt\nNENE01729B.txt\nNENE01736A.txt\n...\n$ history | tail -n 5\n  456  ls -l NENE0*.txt\n  457  rm stats-NENE01729B.txt.txt\n  458  bash goostats NENE01729B.txt stats-NENE01729B.txt\n  459  ls -l NENE0*.txt\n  460  history$ for alkanes in *.pdb\n> do\n>     echo $alkanes\n>     cat $alkanes > alkanes.pdb\n> done$ for datafile in *.pdb\n> do\n>     cat $datafile >> all.pdb\n> done$ for file in *.pdb\n> do\n>   analyze $file > analyzed-$file\n> done# Version 1\n$ for file in *.pdb\n> do\n>   echo analyze $file > analyzed-$file\n> done# Version 2\n$ for file in *.pdb\n> do\n>   echo \"analyze $file > analyzed-$file\"\n> done$ for species in cubane ethane methane\n> do\n>     for temperature in 25 30 37 40\n>     do\n>         mkdir $species-$temperature\n>     done\n> done"},{"path":"shell-script.html","id":"shell-script","chapter":"6 .  쉘 스크립트","heading":"6 .  쉘 스크립트","text":"마침내 쉘을 그토록 강력한 프로그래밍 환경으로 탈바꾼할 준비가 되었다.\n자주 반복적으로 사용되는 명령어들을 파일에 저장시키고 나서,\n단 하나의 명령어를 타이핑함으써 나중에 이 모든 연산 작업작업을 다시 재실행할 수 있다.\n역사적 이유로 파일에 저장된 명령어 꾸러미를 통상 쉘 스크립트(shell script)라고 부르지만,\n실수로 그렇게 부르는 것은 아니다: 실제로 작은 프로그램이다.molecules/ 디렉토리로 돌아가서 middle.sh 파일에 다음 행을 추가하게 되면 쉘스크립트가 된다:nano middle.sh 명령어는 middle.sh 파일을 텍스트 편집기 “nano”로 열게 한다.\n(편집기 프로그램은 쉘 내부에서 실행된다.)\nmiddle.sh 파일이 존재하지 않는 경우, middle.sh 파일을 생성시킨다.\n텍스트 편집기를 사용해서 직접 파일을 편집한다 – 단순히 다음 행을 삽입시킨다:앞서 작성한 파이프에 변형이다: octane.pdb 파일에서 11-15 행을 선택한다.\n기억할 것은 명령어로서 실행하지 않고: 명령어를 파일에 적어 넣는다는 것이다.그리고 나서 나노 편집기에서 Ctrl-O를 눌러 파일을 저장하고,\n나노 편집기에서 Ctrl-X를 눌러 텍스트 편집기를 빠져나온다.\nmolecules 디렉토리에 middle.sh 파일이 포함되어 있는지 확인한다.saved file,\ncan ask shell execute commands contains.\nshell called bash, run following command:파일을 저장하면, 쉘로 하여금 파일에 담긴 명령어를 실행하도록 한다.\n지금 쉘은 bash라서, 다음과 같이 다음 명령어를 실행시킨다:아니나 다를까, 스크립트의 출력은 정확하게 파이프라인을 직접적으로 실행한 것과 동일하다.텍스트 vs. 텍스트가 아닌 것 아무거나종종 마이크로소프트 워드 혹은 리브르오피스 Writer 프로그램을 “텍스트 편집기”라고 부른다.\n하지만, 프로그래밍을 할때 조금더 주의를 기울일 필요가 있다.\n기본 디폴트로, 마이크로소프트 워드는 .docx 파일을 사용해서 텍스트를 저장할 뿐만 아니라,\n글꼴, 제목, 등등의 서식 정보도 함께 저장한다.\n이런 추가 정보는 문자로 저장되지 않아서, head 같은 도구에게는 무의미하다:\nhead 같은 도구는 입력 파일에 문자, 숫자, 표준 컴퓨터 키보드 특수문자만이 포함되어 있는 것을 예상한다.\n따라서, 프로그램을 편집할 때, 일반 텍스트 편집기를 사용하거나,\n혹은 일반 텍스트로 파일을 저장하도록 주의한다.만약 임의 파일의 행을 선택하고자 한다면 어떨까요?\n파일명을 바꾸기 위해서 매번 middle.sh을 편집할 수 있지만,\n단순히 명령어를 다시 타이핑하는 것보다 아마 시간이 더 걸릴 것이다.\n대신에 middle.sh을 편집해서 좀더 다양한 기능을 제공하도록 만들어보자:나노 편집기로 octane.pdb을 $1으로 불리는 특수 변수로 변경하자:쉘 스크립트 내부에서, $1은 “명령라인의 첫 파일 이름(혹은 다른 인자)”을 의미한다.\n이제 스크립트를 다음과 같이 바꿔 실행해 보자:혹은 다음과 같이 다른 파일에 대해 스크립트 프로그램을 실행해 보자:인자 주위를 이중 인용부호로 감싸기파일명에 공백이 포함된 경우 루프 변수 내부에 이중 인용부호로 감싼 것과 동일한 사유로,\n파일명에 공백이 포함된 경우 이중 인용부호로 $1을 감싼다.하지만, 매번 줄 범위를 조정할 때마다 여전히 middle.sh 파일을 편집할 필요가 있다.\n이 문제를 특수 변수 $2 와 $3 을 사용해서 고쳐보자: head, tail 명령어에\n해당 줄수를 출력하도록 인자로 넘긴다.이제 다음을 실행시킨다:명령문의 인자를 변경함으로써 스크립트 동작을 바꿀 수 있게 된다:제대로 동작하지만,\nmiddle.sh 쉘스크립트를 읽는 다른 사람은 잠시 시간을 들여,\n스크립트가 무엇을 수행하는지 알아내야 할지 모른다.\n스크립트를 상단에 주석(comments)을 추가해서 좀더 낫게 만들 수 있다:주석은 #문자로 시작하고 해당 행 끝까지 주석으로 처리된다.\n컴퓨터는 주석을 무시하지만,\n사람들이(미래의 본인 자신도 포함) 스크립트를 이해하고 사용하는데 정말 귀중한 존재다.\n유일한 단점은 스크립트를 변경할 때마다, 주석이 여전히 유효한지 확인해야 된다는 점이다:\n잘못된 방향으로 독자를 오도하게 만드는 설명은 아무것도 없는 것보다 더 나쁘다.만약 많은 파일을 단 하나 파이프라인으로 처리하고자 한다면 어떨까?\n예를 들어, .pdb 파일을 길이 순으로 정렬하려면, 다음과 같이 타이핑한다:wc -l은 파일에 행갯수를 출력하고(wc는 ’word count’로 -l 플래그를 추가하면 ’count lines’의미가 됨을 상기한다),\nsort -n은 숫자순으로 파일의 행갯수를 정렬한다.\n파일에 담을 수 있지만, 현재 디렉토리에 .pdb 파일만을 정렬한다.\n다른 유형의 파일에 대한 정렬된 목록을 얻으려고 한다면,\n스크립트에 이 모든 파일명을 얻는 방법이 필요하다.\n$1, $2 등등은 사용할 수 없는데,\n이유는 얼마나 많은 파일이 있는지를 예단할 수 없기 때문이다.\n대신에, 특수 변수 $@을 사용한다.\n$@은 “쉘 스크립트 모든 명령-라인 인자”를 의미한다.\n공백을 포함한 매개변수를 처리하려면 이중 인용부호로 $@을 감싸두어야 된다.\n(\"$@\"은 \"$1\" \"$2\" … 와 동치다).\n예제가 다음에 있다:실행방법과 실행결과는 다음과 같다.유일무이한 개체 목록으로 나열\n정훈이는 데이터 파일 수백개를 갖고 있는데, 각각은 다음과 같은 형식을 가지고 있다:data-shell/data/animal-counts/animals.txt 파일을 대상으로 예제를 작성한다.\n임의 파일이름을 명령-라인 인자로 갖는 species.sh 이름의 쉘 스크립트를 작성하라.\ncut, sort, uniq를 사용해서 각각의 파일별로 나오는 유일무이한 개체에 대한 목록을 화면에 출력하세요.해답for file $@\n\necho “Unique species $file:”\n# 개체명을 추출한다.\ncut -d , -f 2 $file | sort | uniq\ndone\n```왜 쉘 스크립트가 어떤 작업도 수행하지 않을까?스크립트가 아주 많은 파일을 처리하고 했지만, 어떠한 파일 이름도 부여하지 않는다면 무슨 일이 발생할까?\n예를 들어, 만약 다음과 같이 타이핑한다면 어떻게 될까요?:하지만 *.dat (혹은 다른 어떤 것)를 타이핑하지 않는다면 어떨까요?\n이 경우 $@은 아무 것도 전개하지 않아서, 스크립트 내부의 파이프라인은 사실상 다음과 같다:어떠한 파일이름도 주지 않아서, wc은 표준 입력을 처리하려 한다고 가정한다.\n그래서, 단지 앉아서 사용자가 인터랙티브하게 어떤 데이터를 전달해주길 대기하고만 있게 된다.\n하지만, 밖에서 보면 사용자에게 보이는 것은 스크립트가 거기 앉아서 정지한 것처럼 보인다:\n스크립트가 아무 일도 수행하지 않는 것처럼 보인다.유용한 무언가를 수행하는 일련의 명령어를 방금 실행했다고 가정하자 —\n예를 들어, 논문에 사용될 그래프를 스크립트가 생성.\n필요하면 나중에 그래프를 다시 생성할 필요가 있어서,\n파일에 명령어를 저장하고자 한다.\n명령문을 다시 타이핑(그리고 잠재적으로 잘못 타이핑할 수도 있다)하는 대신에, 다음과 같이 할 수도 있다:redo-figure-3.sh 파일은 이제 다음을 담고 있다:명령어의 일련 번호를 제거하고, history 명령어를 포함한 마지막 행을 지우는 작업을\n편집기에서 한동안 작업한 후에,\n그림을 어떻게 생성시켰는지에 관한 정말 정확한 기록을 갖게 되었다.왜 명령어를 실행하기 전에 history에 명령어를 기록할까?다음 명령어를 실행시키게 되면:파일에 마지막 명령어는 history 명령 그자체다; 즉\n쉘이 실제로 명령어를 실행하기 전에 명령 로그에 먼저 history를 추가했다.\n실제로 항상 쉘은 명령어를 실행시키기 전에 로그에 명령어를 기록한다.\n왜 이런 동작을 쉘이 한다고 생각하는가?해답\n만약 명령어가 죽던가 멈추게 되면, 어떤 명령어에서\n문제가 발생했는지 파악하는 것이 유용할 수 있다.\n명령어가 실행된 후에 기록하게 되면,\n크래쉬(crash)가 발생된 마지막 명령어에 대한 기록이 없게 된다.실무에서, 대부분의 사람들은 쉘 프롬프트에서 몇번 명령어를 실행해서 올바르게 수행되는지를 확인한 다음,\n재사용을 위해 파일에 저장한다.\n이런 유형의 작업은 데이터와 작업흐름(workflow)에서 발견한 것을\nhistory를 호출해서 재사용할 수 있게 하고,\n출력을 깔끔하게 하기 위해 약간의 편집을 하고 나서,\n쉘 스크립트로 저장하는 흐름을 탄다.","code":"$ cd molecules\n$ nano middle.shhead -n 15 octane.pdb | tail -n 5$ bash middle.sh\n\nATOM      9  H           1      -4.502   0.681   0.785  1.00  0.00\nATOM     10  H           1      -5.254  -0.243  -0.537  1.00  0.00\nATOM     11  H           1      -4.357   1.252  -0.895  1.00  0.00\nATOM     12  H           1      -3.009  -0.741  -1.467  1.00  0.00\nATOM     13  H           1      -3.172  -1.337   0.206  1.00  0.00$ nano middle.shhead -n 15 \"$1\" | tail -n 5$ bash middle.sh octane.pdb\n\nATOM      9  H           1      -4.502   0.681   0.785  1.00  0.00\nATOM     10  H           1      -5.254  -0.243  -0.537  1.00  0.00\nATOM     11  H           1      -4.357   1.252  -0.895  1.00  0.00\nATOM     12  H           1      -3.009  -0.741  -1.467  1.00  0.00\nATOM     13  H           1      -3.172  -1.337   0.206  1.00  0.00$ bash middle.sh pentane.pdb\n\nATOM      9  H           1       1.324   0.350  -1.332  1.00  0.00\nATOM     10  H           1       1.271   1.378   0.122  1.00  0.00\nATOM     11  H           1      -0.074  -0.384   1.288  1.00  0.00\nATOM     12  H           1      -0.048  -1.362  -0.205  1.00  0.00\nATOM     13  H           1      -1.183   0.500  -1.412  1.00  0.00$ nano middle.shhead -n \"$2\" \"$1\" | tail -n \"$3\"$ bash middle.sh pentane.pdb 15 5\n\nATOM      9  H           1       1.324   0.350  -1.332  1.00  0.00\nATOM     10  H           1       1.271   1.378   0.122  1.00  0.00\nATOM     11  H           1      -0.074  -0.384   1.288  1.00  0.00\nATOM     12  H           1      -0.048  -1.362  -0.205  1.00  0.00\nATOM     13  H           1      -1.183   0.500  -1.412  1.00  0.00$ bash middle.sh pentane.pdb 20 5\n\nATOM     14  H           1      -1.259   1.420   0.112  1.00  0.00\nATOM     15  H           1      -2.608  -0.407   1.130  1.00  0.00\nATOM     16  H           1      -2.540  -1.303  -0.404  1.00  0.00\nATOM     17  H           1      -3.393   0.254  -0.321  1.00  0.00\nTER      18              1$ nano middle.sh# Select lines from the middle of a file.\n# Usage: bash middle.sh filename end_line num_lines\nhead -n \"$2\" \"$1\" | tail -n \"$3\"$ wc -l *.pdb | sort -n$ nano sorted.sh# Sort filenames by their length.\n# Usage: bash sorted.sh one_or_more_filenames\nwc -l \"$@\" | sort -n$ bash sorted.sh *.pdb ../creatures/*.dat\n\n9 methane.pdb\n12 ethane.pdb\n15 propane.pdb\n20 cubane.pdb\n21 pentane.pdb\n30 octane.pdb\n163 ../creatures/basilisk.dat\n163 ../creatures/unicorn.dat2013-11-05,deer,5\n2013-11-05,rabbit,22\n2013-11-05,raccoon,7\n2013-11-06,rabbit,19\n2013-11-06,deer,2\n2013-11-06,fox,1\n2013-11-07,rabbit,18\n2013-11-07,bear,1# csv 파일에 유일무이한 개체를 찾는 스크립트로 개체는 두번째 데이터 필드가 된다.\n# 스크립트는 명령라인 인자로 모든 파일명을 인자로 받는다.\n\n# 모든 파일에 대해 루프를 돌려 반복한다.$ bash sorted.sh$ wc -l | sort -n$ history | tail -n 5 > redo-figure-3.sh297 bash goostats NENE01729B.txt stats-NENE01729B.txt\n298 bash goodiff stats-NENE01729B.txt /data/validated/01729.txt > 01729-differences.txt\n299 cut -d ',' -f 2-3 01729-differences.txt > 01729-time-series.txt\n300 ygraph --format scatter --color bw --borders none 01729-time-series.txt figure-3.png\n301 history | tail -n 5 > redo-figure-3.sh$ history | tail -n 5 > recent.sh"},{"path":"shell-script.html","id":"nelle-script","chapter":"6 .  쉘 스크립트","heading":"6.1 Nelle 파이프라인: 스크립트 생성하기","text":"Nelle의 지도교수는 모든 분석결과가 재현가능해야 된다는 고집을 갖고 있다.\n모든 분석 단계를 담아내는 가장 쉬운 방법은 스크립트에 있다.\n편집기를 열어서 다음과 같이 작성한다:-stats.sh 이름으로된 파일에 저장해서,\n다음과 같이 타이핑해서 첫번째 단계 분석을 다시 실행할 수 있게 되었다:또한 다음과 같이도 할 수 있다:그렇게 해서 출력은 처리된 파일 이름이 아니라 처리된 파일의 숫자만 출력된다.Nelle의 스크립트에서 주목할 한가지는 스크립트를 실행하는 사람이 무슨 파일을 처리할지를 결정하게 하는 것이다.\n스크립트를 다음과 같이 작성할 수 있다:장점은 이 스크립트는 항상 올바른 파일만을 선택한다: ‘Z’파일을 제거했는지 기억할 필요가 없다.\n단점은 항상 이 파일만을 선택한다는 것이다 —\n모든 파일(’Z’를 포함하는 파일), 혹은 남극 동료가 생성한 ’G’, ‘H’ 파일에 대해서 스크립트를 편집하지 않고는 실행할 수 없다.\n좀더 모험적이라면, 스크립트를 변경해서 명령-라인 매개변수를 검증해서 만약 어떠한 매개변수도 제공되지 않았다면 NENE*[AB].txt을 사용하도록\n바꿀수도 있다.\n물론, 이런 접근법은 유연성과 복잡성 사이에 서로 대립되는 요소 사이의 균형, 즉 트레이드오프(trade-)를 야기한다.쉘 스크립트의 변수molecules 디렉토리에서, 다음 명령어를 포함하는 script.sh라는 쉘스크립트가 있다고 가정한다:molecules 디렉토리에서 다음 명령어를 타이핑한다:다음 출력물 결과 중 어떤 결과가 나올 것으로 예상하나요?\n1. molecules 디렉토리에 있는 *.pdb 확장자를 갖는 각 파일의 첫번줄과 마지막줄 사이 모든 줄을 출력.\n2. molecules 디렉토리에 있는 *.pdb 확장자를 갖는 각 파일의 첫번줄과 마지막 줄을 출력.\n3. molecules 디렉토리에 있는 각 파일의 첫번째와 마지막 줄을 출력.\n4. *.pdb 를 감싸는 인용부호로 오류가 발생.해답\n정답은 2.특수 변수 $1, $2, $3은 스크립트에 명령라인 인수를 나타낸다. 따라서\n실행되는 명령어는 다음과 같다:인용부호로 감싸져서 쉘이 '*.pdb'을 명령라인에서 확장하지 않는다.\n이를 테면, 스크립트의 첫번째 인자는 '*.pdb'으로 전달되어 스크립트 내부에서 확장되어\nhead와 tail 명령어를 실행시키게 된다.주어진 확장자 내에서 가장 긴 파일을 찾아낸다\n인자로 디렉토리 이름과 파일이름 확장자를 갖는 longest.sh이름의 쉘 스크립트를 작성해서,\n그 디렉토리에서 해당 확장자를 가지는 파일 중에 가장 긴 줄을 가진 파일이름을 화면에 출력하세요.\n예를 들어, 다음은/tmp/data 디렉토리에 .pdb 확장자를 가진 파일 중에 가장 긴 줄을 가진 파일이름을 화면에 출력한다.해답스크립트 독해 능력이번 문제에 대해, 다시 한번 data-shell/molecules 디렉토리에 있다고 가정한다.\n지금까지 생성한 파일에 추가해서 디렉토리에는 .pdb 파일이 많다.\n만약 다음 행을 담고 있는 스크립트로 bash example.sh *.dat을 실행할 때,\nexample.sh 이름의 스크립트가 무엇을 수행하는지 설명하세요:해답\n스크립트 1은 파일명에 구두점(.)이 포함된 모든 파일을 출력한다.스크립트 2는 파일 확장자가 매칭되는 첫 3 파일의 내용을 화면에 출력시킨다.\n쉘이 인자를 example.sh 스크립트에 전달하기 전에 와일드카드를 확장시킨다.스크립트 3은 .pdb로 끝나는 스크립트의 모든 인자(즉, 모든 .pdb 파일)를 화면에 출력시킨다.스크립트 디버깅Nelle 컴퓨터 north-pacific-gyre/2012-07-03 디렉토리의\n-errors.sh 파일에 다음과 같은 스크립트가 저장되었다고 가정하자.다음을 실행하게 되면:출력결과는 아무 것도 없다.\n원인을 파악하고자 -x 선택옵션을 사용해서 스크립트를 재실행시킨다:보여지는 출력결과는 무엇인가?\n몇번째 행에서 오류가 발생했는가?\n> 해답\n> -x 플래그를 사용하면 디버그 모드에서 bash를 실행시키게 된다.\n> 각 명령어를 행단위로 실행시키고 출력결과를 보여주는데, 오류를 특정하는데 도움이 된다.\n> 이번 예제에서 echo 명령어는 아무 것도 출력하지 않는 것을 볼 수 있다.\n> 루프 변수명의 철자가 잘못 타이핑 되어 있다.\n> datfile 변수가 존재하지 않아서 빈 문자열이 반환되었다.","code":"# 데이터 파일별로 통계량 계산.\nfor datafile in \"$@\"\ndo\n    echo $datafile\n    bash goostats $datafile stats-$datafile\ndone$ bash do-stats.sh NENE*[AB].txt$ bash do-stats.sh NENE*[AB].txt | wc -l# Site A, Site B 데이터 파일에 대한 통계량 계산\nfor datafile in NENE*[AB].txt\ndo\n    echo $datafile\n    bash goostats $datafile stats-$datafile\ndonehead -n $2 $1\ntail -n $3 $1bash script.sh '*.pdb' 1 1$ head -n 1 cubane.pdb ethane.pdb octane.pdb pentane.pdb propane.pdb\n$ tail -n 1 cubane.pdb ethane.pdb octane.pdb pentane.pdb propane.pdb$ bash longest.sh /tmp/data pdb# 쉘 스크립트는 다음 두 인자를 갖는다: \n#    1. 디렉토리명\n#    2. 파일 확장자\n# 해당 디렉토리에서 파일 확장자와 매칭되는 가장 길이가 긴 파일명을 출력한다.\n\nwc -l $1/*.$2 | sort -n | tail -n 2 | head -n 1# 스크립트 1\necho *.*# 스크립트 2\nfor filename in $1 $2 $3\ndo\n    cat $filename\ndone# 스크립트 3\necho $@.pdbcubane.pdb ethane.pdb methane.pdb octane.pdb pentane.pdb propane.pdb.pdb# Calculate stats for data files.\nfor datafile in \"$@\"\ndo\n    echo $datfile\n    bash goostats $datafile stats-$datafile\ndone$ bash do-errors.sh NENE*[AB].txtbash -x do-errors.sh NENE*[AB].txt"},{"path":"shell-find.html","id":"shell-find","chapter":"7 .  파일, 문자, 디렉토리 등 찾기","heading":"7 .  파일, 문자, 디렉토리 등 찾기","text":"“구글(Google)”을 “검색”을 의미하는 동사로 많은 분들이 사용하는 것처럼\n유닉스 프로그래머는 “grep”을 동일하게 사용한다.\ngrep은 “global/regular expression/print(전역/정규표현식/출력)”의 축약어로\n초기 유닉스 편집기에서 일반적인 일련의 연산작업을 뜻한다.\n매우 유용한 명령-라인 프로그램 이름이기도 하다.grep은 패턴과 매칭되는 파일의 행을 찾아 화면에 뿌려준다.\n예제 파일로, Salon 잡지 1988년 경쟁부문에서 하이쿠(haiku, 일본의 전통 단시) 3개를 담고 있는 파일을 사용례로 활용할 것이다.\n이 예제 파일을 갖는 “writing” 하위 디렉토리에서 작업을 할 것이다:영원히 혹은 5년원본 하이쿠에 링크를 걸지 않았는데 이유는 Salon 사이트에 더 이상 보이는 것 같지 않아서다.\nJeff Rothenberg가 말했듯이,\n“디지털 정보는 어느 것이 먼저 오든 영원한 영속성을 가지거나 혹은 5년이다.”\n운이 좋은 경우 인기 콘텐트는 종종 백업된다.단어 “”을 포함하는 행을 찾아 봅시다:여기서 not이 찾고자 하는 패턴이다.\ngrep 명령어는 파일을 뒤져 지정된 패턴과 매칭되는 것을 찾아낸다.\n명령어를 사용하려면 grep을 타이핑하고 나서,\n찾고자 하는 패턴을 지정하고 나서 검색하고자 하는 파일명(혹은 파일 다수)를 지정하면 된다.출력값으로 “”을 포함하는 파일에 행이 3개 있다.다른 패턴을 시도해 보자. 이번에는 “”이다.이번에는 문자 “”를 포함한 행이 두줄 출력되었다.\n하지만, 더 큰 단어 안에 포함된 단어(“Thesis”)도 함께 출력된다.grep명령어에 -w 옵션을 주면, 단어 경계로 매칭을 제한해서,\n“day” 단어만을 가진 행만이 화면에 출력된다.매칭을 “” 단어 자체만 포함하는 행만 매칭시키려면,\ngrep명령어에 -w 옵션을 주게 되면, 단어 경계로 매칭을 제한시킨다.“단어 경계”는 행의 시작과 끝이 포함됨에 주의한다. 그래서 공백으로 감싼 단어는 해당사항이 없게 된다.\n때때로, 단어 하나가 아닌, 문구를 찾고자 하는 경우도 있다.\n인용부호 내부에 문구를 넣어 grep으로 작업하는 것이 편하다.지금까지 단일 단어 주위를 인용부호로 감쌀 필요가 없다는 것을 알고 있다.\n하지만, 단어 다수를 검색할 때 인용부호를 사용하는 것이 유용하다.\n이렇게 하면, 검색어(term) 혹은 검색 문구(phrase)와 검색 대상이 되는 파일 사이를 더 쉽게 구별하는데 도움을 준다.\n나머지 예제에서는 인용부호를 사용한다.또다른 유용한 옵션은 -n으로, 매칭되는 행에 번호를 붙여 출력한다:상기에서 5, 9, 10번째 행이 문자 “”를 포함함을 확인할 수 있다.다른 유닉스 명령어와 마찬자기로 옵션(즉, 플래그)을 조합할 수 있다.\n단어 “”를 포함하는 행을 찾아보자.\n“”를 포함하는 행을 찾는 -w 옵션과 매칭되는 행에 번호를 붙이는 -n을 조합할 수 있다:이제 -옵션을 사용해서 대소분자 구분없이 매칭한다:이제, -v 옵션을 사용해서 뒤집어서 역으로 매칭을 한다.\n즉, 단어 “”를 포함하지 않는 행을 출력결과로 한다.grep 명령어는 옵션이 많다.\ngrep 명령어에 대한 도움을 찾으려면, 다음 명령어를 타이핑한다:grep 사용다음중 어떤 명령어가 다음 결과를 만들어낼까요?grep \"\" haiku.txtgrep -E \"\" haiku.txtgrep -w \"\" haiku.txtgrep -\"\" haiku.txt해답\n정답은 3번. -w 플래그는 온전한 단어만 매칭되는 것을 찾기 때문이다.와일드카드(Wildcards) grep의 진정한 힘은 옵션에서 나오지 않고;\n패턴에 와일드카드를 포함할 수 있다는 사실에서 나온다.\n(기술적 명칭은 정규 표현식(regular expressions)이고, “grep” 명령어의 “re”가 정규표현식을 나타낸다.)\n정규 표현식은 복잡하기도 하지만 강력하기도 하다.\n복잡한 검색을 하고자 한다면, 소프트웨어 카펜트리 웹사이트에서 수업내용을 볼 수 있다.\n맛보기로, 다음과 같이 두번째 위치에 ’o’를 포함한 행을 찾을 수 있다:-E 플래그를 사용해서 인용부호 안에 패턴을 넣어서 쉘이 해석하는 것을 방지한다.\n(예를 들어, 패턴에 ‘*’이 포함된다면, grep을 실행되기 전에 쉘이 먼저 전개하려 할 것이다.)\n패턴에서’^‘은 행의 시작에 매칭을 고정시키는 역할을 한다.’.’은 한 문자만 매칭하고(쉘의 ’?’과 마찬가지로), ’o’는 실제 영문 ’o’와 매칭된다.개체(species) 추적하기정훈이는 한 디렉토리에 수백개 데이터 파일이 있는데, 형태는 다음과 같다:명령라인에서 첫번째 인자로 개체(species), 두번째 인자로 디렉토리를 인자로 받는 쉘스크립트를 작성하고자 한다.\n스크립트는 일자별로 관측된 개체수를 담아 species.txt 라는 파일로 저장하면 된다.스크립트를 작성하는데 다음에 나온 명령어를 적절한 순서로 파이프에 연결시키면 된다:힌트: man grep 명령어를 사용해서 디렉토리에서 재귀적으로 텍스트를 grep하는지 찾아본다.\nman cut 명령어를 사용해서 한줄에 필드 하나 이상을 선택하는 방법을 살펴본다.\ndata-shell/data/animal-counts/animals.txt 파일이 예제 파일로 제공되고 있다:\n> 해답\n>\n> > grep -w $1 -r $2 | cut -d : -f 2 | cut -d , -f 1,3  > $1.txt >\n>\n> 상기 쉘 스크립트를 다음과 같이 호출하면 된다:\n>\n> > $ bash count-species.sh bear . >작은 아낙네(Little Women)Louisa May Alcott가 지은 작은 아낙네(Little Women)를 친구과 함께 읽고 논쟁중이다.\n책에는 Jo, Meg, Beth, Amy 네자매가 나온다. 친구가 Jo가 가장 많이 언급되었다고 생각한다.\n하지만, 나는 Amy라고 확신한다. 운좋게도, 소설의 전체 텍스트를 담고 있는 LittleWomen.txt\n파일이 있다(data-shell/writing/data/LittleWomen.txt).\n루프를 사용해서, 네자매 각각이 얼마나 언급되었는지 횟수를 개수할 수 있을까?힌트: 한가지 해결책은 grep, wc, | 명령어를 동원하는 것이지만,\n다른 해결책으로 grep 옵션을 활용하는 것도 있다.\noften one way solve programming task, \nparticular solution usually chosen based combination \nyielding correct result, elegance, readability, speed.\n프로그래밍 문제를 푸는 방식은 한가지 이상 존재한다.\n따라서, 올바른 결과를 도출해야 하고, 우아하고(elegance), 가독성이 좋고(readability), 속도를\n다 함께 고려하여 선택한다.해답또다른 해법으로, 다소 떨어지는 해답은 다음과 같다:이 해답이 다소 뒤떨어지는 이유는 grep -c는 매칭되는 행 숫자만 출력하기 때문이다.\n행마다 매칭되는 것이 하나 이상 되는 경우, 이 방법으로 매칭되는 전체 갯수는 낮아질 수 있기 때문이다.grep이 파일의 행을 찾는 반면에, find 명령어는 파일 자체를 검색한다.\n다시, find 명령어는 정말 옵션이 많다;\n가장 간단한 것이 어떻게 동작하는지 시연하기 위해,\n다음과 같은 디렉토리 구조를 사용할 것이다.Find 찾기 예제 파일 구조Nelle의 writing 디렉토리는 haiku.txt로 불리는 파일 하나와, 하위 디렉토리 4개를 포함한다.\nthesis 디렉토리는 슬프게고 아무것도 담겨있지 않는 빈 파일 empty-draft.md만 있고,\ndata 디렉토리는 LittleWomen.txt, one.txt과 two.txt 총 파일 3개를 포함하고,\ntools 디렉토리는 format과 stats 프로그램을 포함하고,\noldtool 파일을 담고 있는 old 하위 디렉토리로 구성되어 있다.첫 명령어로, find .을 실행하자.항상 그렇듯이, . 자체가 의미하는 바는 현재 작업 디렉토리로, 검색을 시작하는 디렉토리가 된다.\nfind 출력결과로 현재 작업 디렉토리 아래 있는 모든 파일, 그리고 디렉토리명이 나온다.\n출력결과가 쓸모없어 보이지만, find 명령어에 선택옵션이 많아서\n출력결과를 필터할 수 있다. 이번 학습에서는 그중 일부만 다뤄볼 것이다.첫번째 선택옵션은 -type d로 “디렉토리인 것들”을 의미한다.\n아니나 다를까, find의 출력에는 (.을 포함해서) 디렉토리 5개가 나온다.find 명령어가 찾는 객체가 특별한 순서를 갖고 출력되는 것이 아님에 주목한다.\n-type d에서 -type f로 옵션을 변경하면,\n대신에 모든 파일 목록이 나온다:이제 이름으로 매칭을 하자:모든 텍스트 파일을 찾기를 기대하지만,\n단지 ./haiku.txt만을 화면에 출력한다.\n문제는 명령문을 실행하기 전에,\n*같은 와일드카드 문자를 쉘이 전개하는 것이다.\n현재 디렉토리에서 *.txt을 전개하면 haiku.txt이 되기 때문에,\n실제 실행하는 명령어는 다음과 같다:find 명령어는 사용자가 요청한 것만 수행한다;\n사용자는 방금전에 잘못된 것을 요청했다.사용자가 원하는 것을 얻기 위해서, grep을 가지고 작업했던 것을 수행하자.\n단일 인용부호에 *.txt을 넣어서 쉘이 와일드카드 *을 전개하지 못하게 한다.\n이런 방식으로,\nfind 명령어는 확장된 파일명 haiku.txt이 아닌,\n실제로 *.txt 패턴을 얻는다:목록(Listing) vs. 찾기(Finding)올바른 옵션이 주어진 상태에서, ls와 find 명령어를 사용해서 비슷한 작업을 수행하도록 만들 수 있다.\n하지만, 정상 상태에서 ls는 가능한 모든 것을 목록으로 출력하는 반면에,\nfind는 어떤 특성을 가진 것을 검색하고 보여준다는 점에서 차이가 난다.앞에서 언급했듯이, 명령-라인(command-line)의 힘은 도구를 조합하는데 있다.\n파이프로 어떻게 조합하는지를 살펴봤고;\n또 다른 기술을 살펴보자.\n방금 보았듯이, find . -name '*.txt' 명령어는 현재 디렉토리 및 하위 디렉토리에 있는 모든 텍스트 파일 목록을 보여준다.\n어떻게 하면 wc -l 명령어와 조합해서 모든 파일의 행을 개수할 수 있을까?가장 간단한 방법은 $() 내부에 find 명령어를 위치시키는 것이다:쉘이 상기 명령어를 실행할 때,\n처음 수행하는 것은 $() 내부를 무엇이든 실행시키는 것이다.\n그리고 나서 $() 표현식을 명령어의 출력 결과로 대체한다.\nfind의 출력 결과가 파일 이름 4개, 즉, ./data/one.txt, ./data/LittleWomen.txt, ./data/two.txt, ./haiku.txt라서,\n쉘은 다음과 같이 명령문을 구성하게 된다:상기 명령문이 사용자가 원하는 것이다.\n이러한 확장이 *과 ? 같은 와일드카드로 확장할 때, 정확하게 쉘이 수행하는 것이다.\n하지만 자신의 “와일드카드”로 사용자가 원하는 임의 명령어를 사용해보자.find와 grep을 함께 사용하는 것이 일반적이다.\n먼저 find가 패턴을 매칭하는 파일을 찾고; 둘째로 grep이 또 다른 패턴과 매칭되는 파일 내부 행을 찾는다.\n예제로 다음에 현재 부모 디렉토리에서 모든 .pdb 파일에 “FE” 문자열을 검색해서,\n철(FE) 원자를 포함하는 PDB파일을 찾을 찾을 수 있다:매칭후 빼내기grep 명령어의 -v 옵션은 패턴 매칭을 반전시킨다. 패턴과 매칭하지 않는 행만 출력시킨다.\n다음 명령어 중에서 어느 것이 /data 폴더에 s.txt로 끝나는 (예로, animals.txt 혹은 planets.txt),\n하지만 net 단어는 포함하지 않게 모든 파일을 찾아낼까요?\n정답을 생각해냈다면, data-shell 디렉토리에서 다음 명령어를 시도해본다.find data -name '*s.txt' | grep -v netfind data -name *s.txt | grep -v netgrep -v \"temp\" $(find data -name '*s.txt')None .해답\n정답은 1. 매칭 표현식을 인용부호로 감싸서 쉘이 전개하는 것을 방지시킨\n상태로 find 명령어에 전개시킨다.2번은 틀렸는데, 이유는 쉘이 find 명령어에 와일드카드를 전달하는 대신에 *s.txt 을 전개하기 때문이다.3번은 틀렸는데, 이유는 파일명을 찾는 대신에 “temp”와 매칭되지 않는 행을 갖는 파일을 검색하기 때문이다.바이너리 파일(Binary File)텍스트 파일에 존재하는 것을 찾는 것에만 배타적으로 집중했다.\n데이터가 만약 이미지로, 데이터베이스로, 혹은 다른 형식으로 저장되어 있다면 어떨까?\n한가지 선택사항은 grep 같은 툴을 확장해서 텍스트가 아닌 형식도 다루게 한다.\n이 접근법은 발생하지도 않았고, 아마도 그러지 않을 것이다.\n왜냐하면 지원할 형식이 너무나도 많은 존재하기 때문이다.두번째 선택지는 데이터를 텍스트로 변환하거나, 데이터에서 텍스트같은 비트를 추출하는 것이다.\n아마도 가장 흔한 접근법이 (정보를 추출하기 위해서) 각 데이터 형식마다 도구 하나만 개발하면 되기 때문이다.\n한편으로, 이 접근법은 간단한 것을 쉽게 할 수 있게 한다.\n부정적인 면으로 보면, 복잡한 것은 일반적으로 불가능하다.예를 들어, grep을 이리 저리 사용해서 이미지 파일에서 X와 Y 크기를 추출하는 프로그램을 작성하기는 쉽다.\n하지만, 공식을 담고 있는 엑셀 같은 스프레드쉬트 셀에서 값을 찾아내는 것을 어떻게 작성할까?\n세번째 선택지는 쉘과 텍스트 처리가 모두 한계를 가지고 있다는 것을 인지하고,\n대신에 (R 혹은 파이썬 같은) 프로그램 언어를 사용하는 것이다.\n이러한 시점이 왔을 때 쉘에서 너무 고생하지 마세요:\nR 혹은 파이썬을 포함한 많은 프로그래밍 언어가 많은 아이디어를 여기에서 가져왔다.\n모방은 또한 칭찬의 가장 충심어린 형태이기도 하다.유닉스 쉘은 지금 사용하는 대부분의 사람보다 나이가 많다.\n그토록 오랫동안 생존한 이유는 지금까지 만들어진 가장 생산성이 높은 프로그래밍 환경 중 하나 혹은 아마도 가장 생산성 높은 프로그래밍 환경이기 때문이다.\n구문이 암호스러울 수도 있지만, 숙달한 사람은 다양한 명령어를 대화하듯이 실험하고 나서,\n본인 작업을 자동화하는데 학습한 것을 사용한다.\n그래픽 사용자 인터페이스(GUI)가 처음에는 더 좋을 수 있지만, 여전히 쉘이 최강이다.\n화이트헤드(Alfred North Whitehead) 박사가 1911년 썼듯이\n“문명은 생각없이 수행할 수 있는 중요한 작업의 수를 확장함으써 발전한다.\n(Civilization advances extending number important operations can perform without thinking .)”find 파이프라인 독해 능력다음 쉘 스크립트에 대해서 무슨 것을 수행하는지 짧은 설명문을 작성하세요.해답현재 디렉토리에서 .dat 확장자를 갖는 모든 파일을 찾아내시오.파일 각각이 담고 있는 행을 개수한다.앞선 단계에서 나온 출력결과를 숫자로 인식해서 정렬시킨다.다른 특성을 갖는 파일 찾아내기find 명령어에 “test”로 알려진 다른 기준을 제시해서 특정 속성을 갖는 파일을 지정할 수 있다. 예를 들어,\n파일 생성시간, 파일 크기, 파일권한, 파일소유.\nman find 명령어를 사용해서 이를 살펴보고 나서,\n지난 24시간 이내 ahmed 사용자가 변경시킨 모든 파일을 찾는 명령어를 적성한다.힌트 1: -type, -mtime, -user 플래그 세개를 모두 사용해야 한다.\n힌트 2: -mtime 값을 음수를 지정해야 된다 — 왜일까?해답Nelle의 홈이 작업 디렉토리라고 가정하고, 다음 명령어를 타이핑한다:","code":"$ cd\n$ cd Desktop/data-shell/writing\n$ cat haiku.txt\n\nThe Tao that is seen\nIs not the true Tao, until\nYou bring fresh toner.\n\nWith searching comes loss\nand the presence of absence:\n\"My Thesis\" not found.\n\nYesterday it worked\nToday it is not working\nSoftware is like that.$ grep not haiku.txt\n\nIs not the true Tao, until\n\"My Thesis\" not found\nToday it is not working$ grep The haiku.txt\n\nThe Tao that is seen\n\"My Thesis\" not found.$ grep -w The haiku.txt\n\nThe Tao that is seen$ grep -w \"is not\" haiku.txt\n\nToday it is not working$ grep -n \"it\" haiku.txt\n\n5:With searching comes loss\n9:Yesterday it worked\n10:Today it is not working$ grep -n -w \"the\" haiku.txt\n\n2:Is not the true Tao, until\n6:and the presence of absence:$ grep -n -w -i \"the\" haiku.txt\n\n1:The Tao that is seen\n2:Is not the true Tao, until\n6:and the presence of absence:$ grep -n -w -v \"the\" haiku.txt\n\n1:The Tao that is seen\n3:You bring fresh toner.\n4:\n5:With searching comes loss\n7:\"My Thesis\" not found.\n8:\n9:Yesterday it worked\n10:Today it is not working\n11:Software is like that.$ grep --help\n\nUsage: grep [OPTION]... PATTERN [FILE]...\nSearch for PATTERN in each FILE or standard input.\nPATTERN is, by default, a basic regular expression (BRE).\nExample: grep -i 'hello world' menu.h main.c\n\nRegexp selection and interpretation:\n  -E, --extended-regexp     PATTERN is an extended regular expression (ERE)\n  -F, --fixed-strings       PATTERN is a set of newline-separated fixed strings\n  -G, --basic-regexp        PATTERN is a basic regular expression (BRE)\n  -P, --perl-regexp         PATTERN is a Perl regular expression\n  -e, --regexp=PATTERN      use PATTERN for matching\n  -f, --file=FILE           obtain PATTERN from FILE\n  -i, --ignore-case         ignore case distinctions\n  -w, --word-regexp         force PATTERN to match only whole words\n  -x, --line-regexp         force PATTERN to match only whole lines\n  -z, --null-data           a data line ends in 0 byte, not newline\n\nMiscellaneous:\n...        ...        ...and the presence of absence:$ grep -E '^.o' haiku.txt\n\nYou bring fresh toner.\nToday it is not working\nSoftware is like that.2013-11-05,deer,5\n2013-11-05,rabbit,22\n2013-11-05,raccoon,7\n2013-11-06,rabbit,19\n2013-11-06,deer,22013-11-05,22\n2013-11-06,19cut -d : -f 2  \n>  \n|  \ngrep -w $1 -r $2  \n|  \n$1.txt  \ncut -d , -f 1,3  for sis in Jo Meg Beth Amy\ndo\n  echo $sis:\n  grep -ow $sis LittleWomen.txt | wc -l\ndonefor sis in Jo Meg Beth Amy\ndo\n  echo $sis:\n  grep -ocw $sis LittleWomen.txt\ndone$ find .\n\n.\n./data\n./data/one.txt\n./data/LittleWomen.txt\n./data/two.txt\n./tools\n./tools/format\n./tools/old\n./tools/old/oldtool\n./tools/stats\n./haiku.txt\n./thesis\n./thesis/empty-draft.md$ find . -type d\n\n./\n./data\n./thesis\n./tools\n./tools/old$ find . -type f\n\n./haiku.txt\n./tools/stats\n./tools/old/oldtool\n./tools/format\n./thesis/empty-draft.md\n./data/one.txt\n./data/LittleWomen.txt\n./data/two.txt$ find . -name *.txt\n\n./haiku.txt$ find . -name haiku.txt$ find . -name '*.txt'\n\n./data/one.txt\n./data/LittleWomen.txt\n./data/two.txt\n./haiku.txt$ wc -l $(find . -name '*.txt')\n\n11 ./haiku.txt\n300 ./data/two.txt\n21022 ./data/LittleWomen.txt\n70 ./data/one.txt\n21403 total$ wc -l ./data/one.txt ./data/LittleWomen.txt ./data/two.txt ./haiku.txt$ grep \"FE\" $(find .. -name '*.pdb')\n\n../data/pdb/heme.pdb:ATOM     25 FE           1      -0.924   0.535  -0.518wc -l $(find . -name '*.dat') | sort -n$ find ./ -type f -mtime -1 -user ahmed"},{"path":"git.html","id":"git","chapter":"8 .  자동화된 버젼제어","heading":"8 .  자동화된 버젼제어","text":"누군가 무엇을 했는지, 언제 했는지를 추적하기 위해서, 버젼제어를 어떻게 사용할 수 있는지 탐색해보자.\n다른 사람과 협업을 하지 않더라도, 자동화된 버젼제어가 다음 상황보다 훨씬 더 낫다:이전에 상기와 같은 상황에 처했었다: 같은 문서에 대해서 거의 동일한 다수 버젼을 관리하는 것은 우스워 보인다.\n일부 워드프로세서가 이런 상황을 좀더 잘 처리하도록 하는 기능이 있다. 예를 들어, 마이크로소프트 워드 “변경사항 추적(Track Changes)” 혹은\n구글 닥스(Google Docs)의 버젼 이력이 그것이다.버젼제어 시슽메은 문서의 기본 버젼으로 시작하고 나서, 각 단계마다 변경한 이력을 저장한다.\n테이프로 생각하면 쉽다: 테이프를 되감으면, 문서 시작한 지점으로 가고, 각 변경사항을 다시 돌리면 가장 최근 버젼이 된다.변경사항이 순차적으로 저장된다.변경사항을 문서 그자체로부터 떨어진 것으로 생각하면,\n동일 기반 문서에 다른 변경사항을 “재생(playback)”하고, 다른 문서 버젼을 관리하는 것으로 간주할 수 있다.\n예를 들어, 사용자 두명이 같은 문서에 독립적인 변경 작업을 수행할 수 있다.다른 버전이 저장될 수도 있다.만약 충돌나지 않으면, 심지어 동일 문서에서 두가지 변경사항을 작업할 수도 있다.버전 다수가 병합될 수도 있다.버젼제어 시스템은 사용자를 대신해서 변경사항을 기록하고,\n파일 버젼을 생성하고 파일병합하는데 유용한 도구다.\n버젼제어 시스템은 어떤 변경사항을 다음 버젼에 반영(커밋(commit))으로 불림)할지 결정하는 할 수 있게 하고,\n커밋에 관한 유용한 메타정보를 보관한다.\n특정 프로젝트와 프로젝트 메타정보에 대한 완전한 커밋이력은\n저장소(repository)에 보관된다.\n저장소는 협업하는 여러 동료 컴퓨터에 걸쳐 동기화될 수 있다.버젼제어 시스템의 오랜 역사자동화된 버젼제어 시스템이 새로운 것은 전혀 아니다.\n1980년부터 RCS, CVS, Subversion 같은 도구가 존재했고, 많은 대기업에서 사용되고 있다.\n하지만, 다양한 기능의 한계로 인해서 이들 중 다수는 이제 레거시 시스템(legacy system)으로 간주된다.\n최근에 등장한 도구 Git과 Mercurial은 분산(distributed) 기능을 제공한다.\n저장소를 굳이 중앙 서버에 둘 필요가 없다는 의미다.\n이러한 최신 시스템에는 동시간에 동일한 파일에 다수 저작자가 작업하는 것을 가능하게 하는 강력한 병합(merge) 도구도 내장하고 있다.논문 작성논문을 작성하면서 정말 멋진 문단을 초안을 작성했지만, 나중에 망치게 되었다고 상상해 보자.\n어떻게 정말 멋진 맺음말 버전이 포함된 문서를 되살릴 수 있을까? 가능하기도 할까?논문을 작성하면서 정말 멋진 문단을 초안을 작성했지만, 나중에 망치게 되었다고 상상해 보자.\n어떻게 정말 멋진 맺음말 버전이 포함된 문서를 되살릴 수 있을까? 가능하기도 할까?공저자가 5명이라고 상상해보자. 공저자가 논문에 반영한 변경사항과 코멘트를 어떻게 관리할 수 있을까?\n마이크로소프트 워드나 리브레오피스 Writer를 사용하는 경우, Track Changes 옵션을 사용해서 변경한 것을 반영하게 되면 어떻게 될까?\n이러한 변경사항에 대한 이력은 갖고 있는가?공저자가 5명이라고 상상해보자. 공저자가 논문에 반영한 변경사항과 코멘트를 어떻게 관리할 수 있을까?\n마이크로소프트 워드나 리브레오피스 Writer를 사용하는 경우, Track Changes 옵션을 사용해서 변경한 것을 반영하게 되면 어떻게 될까?\n이러한 변경사항에 대한 이력은 갖고 있는가?","code":""},{"path":"git-setup.html","id":"git-setup","chapter":"9 .  Git 구축 및 설정","heading":"9 .  Git 구축 및 설정","text":"처음 Git를 새로운 컴퓨터에 사용할 때, 몇가지 설정이 필요하다.\n다음에 Git을 시작할 때, 설정해야 되는 몇가지 사례가 나와있다:이름과 전자우편 주소선호하는 텍스트 편집기 선정전역(즉, 모든 프로젝트)으로 이런 설정을 할지 여부명령라인에서 Git 명령어는 다음과 같이 작성된다; git verb options, 즉, git 동사 선택옵션.\nverb 가 실제로 수행하고자 하는 명령어가 되고, options는 verb에 필요할지도 모르는 추가 선택옵션 정보가 된다.\n다음에 Dracula가 새로 구입한 노트북에 환경설정하는 방법이 나와있다:Dracula 대신에 본인 이름과 본인 전자우편 주소를 사용합니다. 사용자명과 전자우편 주소는 후속 Git 활동과 연관된다.\n이것이 의미하는 바는\nGitHub,\nBitBucket,\nGitLab, 혹은 Git 호스트 서버에 푸쉬하는 어떤 변경사항도 사용자명과 전자우편 주소를 담게되는 것을 의미한다.줄마침(Line Endings)다른 키보트 타이핑과 마찬가지로, 키보드로 Return를 치게 되면,\n컴퓨터는 엔터값을 문자로 인코딩한다.\n줄마침을 표현하기 위해서 운영체제마다 별도 문자를 사용한다.\n(개행 혹은 줄중단, 영어로 newline 혹은 line breaks를 들어봤을 수도 있다.)\nGit이 파일을 비교하는데 이러한 문자를 사용하기 때문에,\n운영체제가 다른 컴퓨텅에서 파일을 편집할 때 예기치 않은 이슈가 발생될 수 있다.\n이 문제는 금번 학습 범위를 넘어서는 것이지만, GitHub page\n웹페이지에서 좀더 자세한 정보를 얻을 수 있다.Git에서 줄마침을 인식하고 인코딩하는 방식을 변경하려면,\ngit config에 core.autocrlf 명령을 사용한다.\n권장되는 설정은 다음과 같다:맥OS와 리눅스:윈도우:이번 학습에서, GitHub을 사용하게 되는데, 사용되는 전자우편주소는 GitHub 계정을 설정할 때 사용하는 것과 같은 것이 되어야 한다.\n만약, 개인정보에 대해 걱정이 된다면, GitHub’s instructions keeping email address private을 참조한다.\nGitHub에서 사적인 개인 전자우편주소를 선택하기로 했다면,\nuser.email에 동일한 전자우편주소를 사용한다. 즉, username을 GitHub의 설정된 것으로 바꿔놓아 username@users.noreply.github.com게 된다.\n나중에 git config 명령어를 사용해서 전자우편 주소를 변경할 수 있다.Dracula도 자신이 선호하는 텍스트 편집기를 설정해야 하는데, 다음 표를 참조한다:원할 때마다 Git에 사용할 텍스트 편집기 환경설정을 다시 할 수 있다.Vim 나가기다수 프로그램에서 Vim이 기본설정된 편집기다.\nVim을 예전에 사용한 적이 없고, 변경사항을 저장하지 않고 세션을 빠져나가고자 한다면,\nEsc 다음에, :q!를 타이핑하고 나서 Return를 친다.\n변경사항을 저장하고 나가려면, Esc 다음에, :wq를 타이핑하고 Return을 친다.앞서 실행한 상기 명령어는 한번만 실행하면 된다: --global 플래그는 Git으로 하여금 해당 컴퓨터에 본인 계정의\n모든 프로젝트에 환경설정한 것을 사용하도록 한다.본인이 설정한 환경설정 내용은 언제라도 다음 명령어를 입력하여 확인할 수 있다:원하는 만큼 환경설정을 바꿀 수도 있다: 편집기를 바꾸거나 전자우편주소를 갱신할 때\n동일한 명령어를 사용하면 된다.프록시(Proxy)일부 네트워크에서 proxy를 사용할 필요가 있다.\n이런 경우, Git에게 프록시에 대해 일러줘야 한다:프록시를 비활성화 하는 경우, 다음 명령어를 사용한다.Git 도움말과 매뉴얼항상 기억할 것은 git 명령어를 잊은 경우, -h 선택옵션을 주어 명령어 목록을 볼 수 있고, --help를 사용해서 Git 매뉴얼도 이용할 수 있다:","code":"$ git config --global user.name \"Vlad Dracula\"\n$ git config --global user.email \"vlad@tran.sylvan.ia\"$ git config --global core.autocrlf input$ git config --global core.autocrlf true$ git config --list$ git config --global http.proxy proxy-url\n$ git config --global https.proxy proxy-url$ git config --global --unset http.proxy\n$ git config --global --unset https.proxy$ git config -h\n$ git config --help"},{"path":"git-create.html","id":"git-create","chapter":"10 .  저장소 생성","heading":"10 .  저장소 생성","text":"Git 환경설정이 완료되면, Git를 사용할 수 있다.\n행성 착륙선을 화성에 보낼 수 있는지 조사를 하고 있는 늑대인간과 드라큘라 이야기를 계속해서 진행해 보자.motivatingexample먼저 바탕화면(Desktop)에 작업할 디렉토리를 생성하고, 생성한 디렉토리로 이동하자:그리고 나서, planets을 저장소(repository)로 만든다 —\n저장소는 Git이 파일에 대한 버젼정보를 저장하는 장소다:git init 명령어가 서브디렉토리(subdirectory)와 파일을 담고 있는 저장소를 생성하는데 주목한다 —\nplanets 저장소 내부에 중첩된 별도 저장소를 생성할 필요는 없다.\n또한, planets 디렉토리를 생성하고 저장소로 초기화하는 것은 완전히 서로 다른 과정이다.ls를 사용해서 디렉토리 내용을 살펴보면, 변한 것이 아무것도 없는 것처럼 보인다:하지만, 모든 것을 보여주는 -플래그를 추가하면,\nGit은 planets 디렉토리 내부에 .git 로 불리는 숨겨진 디렉토리를 생성한 것을 볼 수 있다:Git은 .git이라는 특별한 하위 디렉토리에 프로젝트에 대한 정보를 저장한다.\n여기에는 프로젝트 디렉토리 내부에 위치한 모든 파일과 서브 디렉토리가 포함된다.\n만약 .git를 삭제하면, 프로젝트 이력을 모두 잃어버리게 된다.모든 것이 제대로 설정되었는지를 확인을 하려면,\nGit에게 다음과 같이 프로젝트 상태를 확인 명령어를 던진다:다른 git 버전을 사용할 경우, 출력 결과물이 다소 다를 수도 있다.Git 저장소를 생성할 장소(이미 생성한 프로젝트) 행성에 대한 정보를 추적하면서,\n드라큘라는 달에 관한 정보도 추적하고자 한다.\nplantes 프로젝트와 관련된, 새로운 프로젝트 moons 를 시작한다.\n늑대인간의 걱정에 불구하고, Git 저장소 내부에 또다른 Git 저장소를 생성하려고\n다음 순서로 명령어를 입력해 나간다:moons 서브 디렉토리에 저장된 파일을 추적하기 위해\nmoons 디렉토리 안에서 git init 명령을 실행해야 할까?해답아니다. moons 서브 디렉토리에 Git 저장소를 만들 필요는 없다.\n왜냐하면, planets 저장소가 이미 모든 파일, 서브 디렉토리, planets 디렉토리\n아래 서브 디렉토리 파일 모두를 추적하기 때문이다.\n따라서, 달에 관한 모든 정보를 추정하는데, 드랴큘라는 planets 디렉토리 아래\nmoons 서브 디렉토리를 추가하는 것으로 충분하다.추가적으로, 만약 Git 저장소가 중첩(nested)되면, Git 저장소는 서로 방해할 수 있다:\n바깥 저장소가 내부 저장소 버전관리를 하게 된다.\n따라서, 별도 디렉토리에 서로 다른 신규 Git 저장소를 생성하는게 최선이다.디렉토리에 저장소가 서로 충돌하지 않도록 하려면, git status 출력물을 점검하면 된다.\n만약, 다음과 같은 출력물이 생성되게 되면 신규 저장소를 생성하는 것이 권장된다:git init 실수 올바르게 고치기늑대인간은 드라큘라에게 중첩된 저장소가 중복되어 불필요한 이유와 함께 향후 혼란을 야기할 수 있는\n이유를 설명했다. 드라큘라는 중첩된 저장소를 제거하고자 한다.\nmoons 서브 디렉토리에 마지막으로 날린 git init 명령어 실행취소를 어떻게 할 수 있을까?해답 – 주의해서 사용바람!이러한 사소한 실수를 원복하고자, 드라큘라는 planets 디렉토리에서 다음 명령어를 실행하여\n.git 디렉토리를 제거하기만 하면 된다:하지만, 주의한다! 디렉토리를 잘못 타이핑하게 되면, 보관해야하는 프로젝트 정보를 담고 있는\nGit 이력 전체가 날아가게 된다. 따라서, pwd 명령어를 사용해서 현재 작업 디렉토리를 항상 확인한다.","code":"$ cd ~/Desktop\n$ mkdir planets\n$ cd planets$ git init$ ls$ ls -a\n\n.   ..  .git$ git status\n\n# On branch master\n#\n# Initial commit\n#\nnothing to commit (create/copy files and use \"git add\" to track)$ cd ~/Desktop   # 바탕화면 디렉토리로 되돌아 간다.\n$ cd planets     # planets 디렉토리로 들어간다.\n$ ls -a          # planets 디렉토리에 .git 서브 디렉토리가 있는지 확인한다.\n$ mkdir moons    # planets/moons 서브 디렉토릴르 생성한다.\n$ cd moons       # moons 서브 디렉토리로 이동한다.\n$ git init       # Git 저장소를 moons 하위디렉토리에 생성한다.\n$ ls -a          # 새로운 Git 저장소가 .git 하위 디렉토리에 있는지 확인한다.$ git status\n\nfatal: Not a git repository (or any of the parent directories): .git$ rm -rf moons/.git"},{"path":"git-change.html","id":"git-change","chapter":"11 .  변경사항 추적","heading":"11 .  변경사항 추적","text":"먼저 디렉토리 위치가 맞는 확인하자.\nplanets 디렉토리에 위치해야 한다.moons 디렉토리에 여전히 있다면, planets 디렉토로리 되돌아간다.전진기지로서 화성의 적합성에 관한 기록을 담고 있는 mars.txt 파일을 생성한다.\n(파일 편집을 위해서 nano 편집기를 사용한다; 원하는 어떤 편집기를 사용해도 된다.\n특히, 앞에서 전역으로 설정한 core.editor일 필요는 없다.\n하지만, 파일을 새로 생성하거나 편집할 때 배쉬 명령어는 사용자가 선택한 편집기에 의존하게 된다.(nano일 필요는 없다.)\n텍스트 편집기에 대한 환기로, Unix Shell의 “Editor?” 부분을 참고한다.mars.txt 파일에 다음 텍스트를 타이핑한다:mars.txt 파일은 이제 한 줄을 포함하게 되어서, 다음 명령어로 내용을 확인할 수 있다:다시 한번 프로젝트의 상태를 확인하고자 하면,\n새로운 파일이 인지되었다고 Git이 일러준다:“untracked files” 메시지가 의미하는 것은 Git가 추적하고 있지 않는 파일 하나가 디렉토리에 있다는 것이다.\ngit add를 사용해서 Git에게 추적관리하라고 일러준다:그리고 나서, 올바르게 처리되었는지 확인한다:이제 Git은 mars.txt 파일을 추적할 것이라는 것을 알고 있지만,\n커밋으로 아직 저장소에는 어떤 변경사항도 기록되지 않았다.\n이를 위해서 명령어 하나 더 실행할 필요가 있다:git commit을 실행할 때,\nGit은 git add를 사용해서 저장하려고 하는 모든 대상을 받아서\n.git 디렉토리 내부에 영구적으로 사본을 저장한다.\n이 영구 사본을 커밋(commit)\n(혹은 수정(revision))이라고 하고,\n짧은 식별자는 f22b25e이다. (여러분의 커밋번호의 짧은 식별자는 다를 수 있다.)-m (“message”를 위미) 플래그를 사용해서 나중에 무엇을 왜 했는지 기억에 도움이 될 수 있는 주석을 기록한다.\n-m옵션 없이 git commit을 실행하면,\nGit는 nano(혹은 처음에 core.editor에서 설정한 다른 편집기)를 실행해서 좀더 긴 메시지를 작성할 수 있다.좋은 커밋 메시지(Good commit messages) 작성은\n커밋으로 만들어진 간략한 (영문자 기준 50문자 이하) 변경사항 요약으로 시작된다.\n일반적으로 메시지는 완전한 문장이 되어야 한다. 예를 들어, “applied, commit ” .\n만약 좀더 상세한 사항을 남기려면,\n요약줄 사이에 빈줄을 추가하고 추가적인 내역을 적는다.\n추가되는 공간에 왜 변경을 하는지 사유를 남기고, 어떤 영향을 미치는지도 기록한다.이제 git status를 시작하면:모든 것이 최신 상태라고 보여준다.\n최근에 작업한 것을 알고자 한다면,\ngit log를 사용해서 프로젝트 이력을 보여주도록 Git에게 명령어를 보낸다:git log는 시간 역순으로 저장소의 모든 변경사항을 나열한다.\n각 수정사항 목록은 전체 커밋 식별자(앞서 git commit 명령어로 출력한 짧은 문자와 동일하게 시작),\n수정한 사람,\n언제 생성되었는지,\n커밋을 생성할 때 Git에 남긴 로그 메시지가 포함된다.내가 작성한 변경사항은 어디있나?이 시점에서 ls 명령어를 다시 실행하면,\nmars.txt 파일만 덩그러니 보게 된다.\n왜냐하면, Git이 앞에서 언급한 .git 특수 디렉토리에 파일 변경 이력 정보를 저장했기 때문이다.\n그래서 파일 시스템이 뒤죽박죽되지 않게 된다.\n(따라서, 옛 버젼을 실수로 편집하거나 삭제할 수 없다.)이제 드라큘라가 이 파일에 정보를 더 추가했다고 가정하자.\n(다시 한번 nano편집기로 편집하고 나서 cat으로 파일 내용을 살펴본다.\n다른 편집기를 사용할 수도 있고, cat으로 파일 내용을 꼭 볼 필요도 없다.)git status를 실행하면,\nGit이 이미 알고 있는 파일이 변경되었다고 일러준다:마지막 줄이 중요한 문구다:\n“changes added commit”.\nmars.txt 파일을 변경했지만, 아직 Git에게는 변경을 사항을 저장하려고 하거나 (git add로 수행),\n저장소에 저장하라고 (git commit로 수행) 일러주지도 않았다.\n이제 행동에 나서보자.\n저장하기 전에 변경사항을 항상 검토하는 것은 좋은 습관이다.\ngit diff를 사용해서 작업 내용을 두번 검증한다.\ngit diff는 현재 파일의 상태와 가장 최근에 저장된 버젼의 차이를 보여준다:출력 결과가 암호같은데 이유는 한 파일이 주어졌을 때 다른 파일 하나를 어떻게 재구성하는지를 일러주는\npatch와 편집기 같은 도구를 위한 일련의 명령어라서 그렇다.\n만약 해당 내역을 조각내서 쪼개다면:첫번째 행은 Git이 신규 파일과 옛 버젼 파일을 비교하는 유닉스 diff 명령어와 유사한 출력결과를 생성하고 있다.두번째 행은 정확하게 Git이 파일 어느 버젼을 비교하는지 일러준다;\ndf0654a와 315bf3a은 해당 버젼에 대해서 중복되지 않게 컴퓨터가 생성한 표식이다.세번째와 네번째 행은 변경되는 파일 명칭을 다시한번 보여주고 있다.나머지 행이 가장 흥미롭다. 실제 차이가 나는 것과 어느 행에서 발생했는지 보여준다.\n특히 첫번째 열의 + 기호는 어디서 행이 추가 되었는지 보여준다.변경사항 검토후에, 변경사항을 커밋(commit)하자.이럴 수가, git add을 먼저 하지 않아서 Git이 커밋을 할 수 없다.\n고쳐봅시다:실제로 무엇을 커밋하기 전에 커밋하고자하는 파일을 먼저 추가하라고 Git이 주문하는데,\n이유는 한번에 모든것을 커밋하지 싶지 않을 수도 있기 때문이다.\n예를 들어, 작성하고 있는 논문에 지도교수 논문을 일부 인용하여 추가한다고 가정하자.\n논문 중간에 인용되는 추가부분과 상응되는 참고문헌을 커밋하고는 싶지만,\n결론 부분을 커밋하고는 싶지 않다. (아직 결론이 완성되지 않았다.)이런 점을 고려해서,\nGit은 특별한 준비 영역(staging)이 있어서 현재 변경부분(change set)을 추가는 했으나 아직 커밋하지 않는 것을 준비 영역에서 추적하고 있다.준비 영역(Staging area)프로젝트 기간 동안에 걸쳐 발생된 변경사항에 대해 스냅사진을 찍는 것으로 Git을 바라보면,\ngit add 명령어는 무엇이 스냅사진(준비영역에 놓는 것)에 들어갈지 명세하고,\ngit commit 명령어는 실제로 스탭사진을 찍는 것이다.\n만약 git commit을 타이핑할 때 준비된 어떤 것도 없다면,\nGit이 git commit -혹은 git commit --명령어 사용을 재촉한다.\n사진을 찍으려고 모두 모이세요 하는 것과 같다.\n하지만, 준비영역에 추가할 것을 명시적으로 하는 것이 항상 좋다.\n왜냐하면 커밋을 했는데 잊은 것이 있을 수도 있기 때문이다.\n(스냅사진으로 돌아가서, -옵션을 사용했기 때문에 스냅사진에 들어갈 항목을 불완전하게\n작성했을 수도 있다!)\n수작업으로 준비영역에 올리거나,\n원하는 것보다 많은 것을 올렸다면 “git undo commit”을 찾아보라.Git 준비(Staging) 영역파일 변경사항을 편집기에서 준비 영역으로, 그리고 장기 저장소로 옮기는 것을 살펴보자.\n먼저, 파일에 행 하나를 더 추가한다:지금까지 좋다.\n파일의 끝에 행을 하나 추가했다(첫 열에 +이 보인다).\n이제, 준비영역에 변경 사항을 놓고, git diff 명령어가 보고하는 것을 살펴보자:출력결과가 없다.\nGit이 일러줄 수 있는 것은 영구히 저장되는 것과 현재 디렉토리에 작업하고 있는 것에 차이가 없다는 것이다.\n하지만, 다음과 같이 명령어를 친다면:마지막으로 커밋된 변경사항과 준비 영역(Staging)에 있는 것과 차이를 보여준다.\n변경사항을 저장하자:현재 상태를 확인하자:그리고 지금까지 작업한 이력을 살펴보자:단어 단위 차이분석(Word-based diffing)경우에 따라서는 줄단위로 텍스트 차이 분석이 너무 자세하지 않을 수도 있다.\ngit diff 명령어에 --color-words 선택옵션이 유용할 수 있는데\n이유는 색상을 사용해서 변경된 단어를 강조해서 표시해 주기 때문이다.로그 페이지별 보기화면에 git log 출력결과가 너무 긴 경우,\ngit에 화면 크기에 맞춰 페이지 단위로 쪼개주는 프로그램이 제공된다.\n페이지별 쪼개보기(“pager”)가 호출되면, 화면 마지막 줄에 프롬프트 대신에 :이 나타난다.페이저(pager)에서 나오려면, Q를 타이핑한다.다음 페이지로 이동하려면, Spacebar를 타이핑한다.전체 페이지에서 특정 단어를 검색하려면,\n/ 타이핑하고,\n특정단어를 검색하는 검색어를 타이핑한다.\n검색에 매칭되는 단어를 따라가려면 N을 타이핑한다.로그 크기 제한걸기git log가 전체 터미널 화면을 접수하는 것을 피하려면,\n-N 선택옵션을 적용해서 Git이 화면에 출력하는 커밋 숫자에 제한을 건다.\n여기서 -N은 보고자 하는 커밋 갯수가 된다.\n예를 들어 가장 마지막 커밋만 보려고 한다면 다음과 같이 타이핑한다:--oneline 선택옵션을 사용해서 출력되는 로그 메시지 크기를 줄일 수도 있다:--oneline 선택옵션과 다른 선택옵션을 조합할 수도 있다.\n유용한 조합 사례로 다음이 있다:디렉토리Git에서 디렉토리에 관해서 알아두면 좋을 두가지 사실.Git은 그 자체로 디렉토리를 추적하지 않고, 디렉토리에 담긴 파일만 추적한다.\n믿지 못하겠다면, 직접 다음과 같이 시도해 본다:새로 생성된 directory 이름을 갖는 디렉토리가 git add 명령어로 명시적으로\n추가했음에도 불구하고 untracked files 목록에 나오지 않고 있다.\n이런 이유로 인해서 가끔 .gitkeep 파일을 보게 된다.\n.gitignore와 달리, 특별하지는 않고 유일한 목적은 디렉토리를 만들어 내어\nGit이 저장소에 추가하도록 하는 역할만 수행한다.\n사실 원하는 이름으로 파일명을 붙일 수 있다.Git 저장소에 디렉토리를 생성하고 파일로 채워넣으면,\n다음과 같이 디렉토리의 모든 파일을 추가할 수 있다:요약하면,\n변경사항을 저장소에 추가하고자 할 때,\n먼저 변경된 파일을 준비 영역(Staging)에 git add 명령어로 추가하고 나서,\n준비 영역의 변경사항을 저장소에 git commit 명령어로 최종 커밋한다:Git 커밋(Commit) 작업흐름커밋 메시지 고르기다음 중 어떤 커밋 메시지가 mars.txt 파일의 마지막 커밋으로 가장 적절할까요?\n1. “Changes”\n2. “Added line ‘Mummy appreciate lack humidity’ mars.txt”\n3. “Discuss effects Mars’ climate Mummy”해답\n1번은 충분히 기술되어 있지 못하고 커밋 목적이 불확실하다;\n2번은 “git diff” 명령어를 사용한 것과 불필요하게 중복된다;\n3번이 좋다: 짧고, 기술이 잘되어 있고, 피할 수 없게 명백하다(imperative).Git에 변경사항 커밋하기다음 중 어떤 명령어가 로컬 Git 저장소에\nmyfile.txt 파일 변경사항을 저장시키는걸까?   $ git commit -m \"recent changes\"   $ git init myfile.txt\n   $ git commit -m \"recent changes\"   $ git add myfile.txt\n   $ git commit -m \"recent changes\"   $ git commit -m myfile.txt \"recent changes\"해답파일이 이미 준비영역(staging)에 올라온 경우만 커밋이 생성된다.신규 저장소를 생성하게 된다.정답: 파일을 준비영역에 추가하고 나서, 커밋하게 된다.myfile.txt 파일에 “recent changes” 메시지를 갖는 커밋을 생성한다.파일 다수를 커밋준비영역(staging area)은 스냅샷 한번에 원하는 만큼 파일을 변경사항을 담아 낼 수 있다.\n1. mars.txt 파일에 전진기지로 생각하는 금성(Venus)를 고려하고 있다는 결정을 담은 텍스트를 추가한다.\n2. venus.txt 파일을 새로 생성해서 본인과 친구들에게 금성에 관한 첫생각을 담아낸다.\n3. 파일 두개에 변경사항을 준비영역에 추가하고 커밋한다.해답먼저, mars.txt, venus.txt 파일에 변경사항을 기록한다:준비영역에 파일 두개를 추가한다.\n한줄로 추가작업을 수행할 수 있다:혹은 명령어를 다수 타이핑하면 된다:이제 파일을 커밋할 준비가 되었다.\ngit status를 사용해서 확인하면, 커밋을 할 준비가 되었다:bio 저장소bio라는 새로운 Git 저장소를 본인 로컬 컴퓨터에 생성한다..txt라는 파일로 본인에 대한 3줄 이력서를 작성한다.\n변경사항을 커밋한다.그리고 나서 한줄을 바꾸고, 네번째 줄을 추가하고 나서,원래 상태와 갱신된 상태의 차이를 화면에 출력한다.해답필요하다면, planets 폴더에서 빠져나온다:bio 폴더를 새로 생성하고 bio 폴더로 이동한다:git 명령어로 초기화한다:nano 혹은 선호하는 편집기를 사용해서 .txt 파일에 본인 일대기를 작성한다.\n파일을 추가하고 나서, 저장소에 커밋한다:기술된 것(한줄 변경하고, 4번째 줄을 추가한다)처럼 파일을 변경한다.\n원본 상태와 수정된 상태를 git diff 명령어를 사용해서 화면에 출력한다:저자(Author)와 커미터(Committer)매번 커밋을 할 때마다, Git은 이름을 두번 저장한다.\n본인 이름이 저자(Author)와 커미터(Committer)로 기록된다.\n마지막 커밋에 추가 정보를 Git에게 요구하면 확인이 가능하다:커밋할 때, 저자를 다른 누군가로 바꿀 수 있다:커밋을 두개 생성한다: 하나는 --author 옵션을 갖는 것으로\n저자로 동료이름을 반영한다.\ngit log와 git log --format=full 명령어를 실행한다.\n이런 방식이 동료와 협업하는 방식이 될 수도 있겠다고는 생각이 될 수 있다.해법","code":"$ pwd\n\n/home/vlad/Desktop/planets$ pwd\n\n/home/vlad/Desktop/planets/moons$ cd ..$ nano mars.txtCold and dry, but everything is my favorite color$ ls\n\nmars.txt$ cat mars.txt\n\nCold and dry, but everything is my favorite color$ git status\n\nOn branch master\n\nInitial commit\n\nUntracked files:\n   (use \"git add <file>...\" to include in what will be committed)\n\n    mars.txt\nnothing added to commit but untracked files present (use \"git add\" to track)$ git add mars.txt$ git status\n\nOn branch master\n\nInitial commit\n\nChanges to be committed:\n  (use \"git rm --cached <file>...\" to unstage)\n\n    new file:   mars.txt\n$ git commit -m \"Start notes on Mars as a base\"\n\n[master (root-commit) f22b25e] Start notes on Mars as a base\n 1 file changed, 1 insertion(+)\n create mode 100644 mars.txt$ git status\n\nOn branch master\nnothing to commit, working directory clean$ git log\n\ncommit f22b25e3233b4645dabd0d81e651fe074bd8e73b\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 09:51:46 2013 -0400\n\n    Start notes on Mars as a base$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git diff\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..315bf3a 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,2 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman$ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\n$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git add mars.txt\n$ git commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\n\n[master 34961b1] Add concerns about effects of Mars' moons on Wolfman\n 1 file changed, 1 insertion(+)$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity$ git diff\n\ndiff --git a/mars.txt b/mars.txt\nindex 315bf3a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity$ git add mars.txt\n$ git diff$ git diff --staged\n\ndiff --git a/mars.txt b/mars.txt\nindex 315bf3a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity$ git commit -m \"Discuss concerns about Mars' climate for Mummy\"\n\n[master 005937f] Discuss concerns about Mars' climate for Mummy\n 1 file changed, 1 insertion(+)$ git status\n\nOn branch master\nnothing to commit, working directory clean$ git log\n\ncommit 005937fbe2a98fb83f0ade869025dc2636b4dad5\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 10:14:07 2013 -0400\n\n    Discuss concerns about Mars' climate for Mummy\n\ncommit 34961b159c27df3b475cfe4415d94a6d1fcd064d\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 10:07:21 2013 -0400\n\n    Add concerns about effects of Mars' moons on Wolfman\n\ncommit f22b25e3233b4645dabd0d81e651fe074bd8e73b\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 09:51:46 2013 -0400\n\n    Start notes on Mars as a base$ git log -1\n\ncommit 005937fbe2a98fb83f0ade869025dc2636b4dad5\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 10:14:07 2013 -0400\n   Discuss concerns about Mars' climate for Mummy$ git log --oneline\n\n* 005937f Discuss concerns about Mars' climate for Mummy\n* 34961b1 Add concerns about effects of Mars' moons on Wolfman\n* f22b25e Start notes on Mars as a base$ git log --oneline --graph --all --decorate\n\n* 005937f Discuss concerns about Mars' climate for Mummy (HEAD, master)\n* 34961b1 Add concerns about effects of Mars' moons on Wolfman\n* f22b25e Start notes on Mars as a base$ mkdir directory\n$ git status\n$ git add directory\n$ git statusgit add <directory-with-files>   $ git commit -m \"my recent changes\"   $ git init myfile.txt\n   $ git commit -m \"my recent changes\"   $ git add myfile.txt\n   $ git commit -m \"my recent changes\"   $ git commit -m myfile.txt \"my recent changes\"$ nano mars.txt\n$ cat mars.txt\n\nMaybe I should start with a base on Venus.$ nano venus.txt\n$ cat venus.txt\n\nVenus is a nice planet and I definitely should consider it as a base.$ git add mars.txt venus.txt$ git add mars.txt\n$ git add venus.txt$ git commit -m \"Write plans to start a base on Venus\"\n\n[master cc127c2]\n Write plans to start a base on Venus\n 2 files changed, 2 insertions(+)\n create mode 100644 venus.txt$ cd ..$ mkdir bio\n$ cd bio$ git init$ git add me.txt\n$ git commit -m'Adding biography file'$ git diff me.txt$ git log --format=full$ git commit --author=\"Vlad Dracula <vlad@tran.sylvan.ia>\"$ git add me.txt\n$ git commit -m \"Update Vlad's bio.\" --author=\"Frank N. Stein <franky@monster.com>\"\n\n[master 4162a51] Update Vlad's bio.\nAuthor: Frank N. Stein <franky@monster.com>\n1 file changed, 2 insertions(+), 2 deletions(-)\n\n$ git log --format=full\ncommit 4162a51b273ba799a9d395dd70c45d96dba4e2ff\nAuthor: Frank N. Stein <franky@monster.com>\nCommit: Vlad Dracula <vlad@tran.sylvan.ia>\n\nUpdate Vlad's bio.\n\ncommit aaa3271e5e26f75f11892718e83a3e2743fab8ea\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nCommit: Vlad Dracula <vlad@tran.sylvan.ia>\n\nVlad's initial bio."},{"path":"git-history.html","id":"git-history","chapter":"12 .  이력 탐색","heading":"12 .  이력 탐색","text":"앞선 학습에서 살펴봤듯이, 식별자로 커밋을 조회할 수 있다.\nHEAD 식별자를 사용해서 작업 디렉토리의 가장 최근 커밋을 조회할 수 있다.mars.txt 파일에 한번에 한줄씩 추가했다. 따라서, 눈으로 봐도 진행사항을 쉽게 추적할 수 있다.\nHEAD를 사용해서 추적작업을 수행해보자. 시작전에 mars.txt 파일에 변경을 가해보자.이제, 변경된 사항을 살펴보자.HEAD만 빼면, 앞서 살펴본 것과 동일하다.\n이러한 접근법의 정말 좋은 점은 이전 커밋을 조회살 수 있다는 점이다.\n~1(“~”은 “틸드(tilde)”, 발음기호 [til-duh])을 추가해서 HEAD 이전 첫번째 커밋을 조회할 수 있다.git diff 명령어를 사용해서 이전 커밋과 차이난 점을 보고자 한다면,\nHEAD~1, HEAD~2 표기법을 사용해서 조회를 쉽게 할 수 있다:git show를 사용해서도 커밋 메시지 분만 아니라 이전 커밋과 변경사항을 보여준다.\ngit diff는 작업 디렉토리와 커밋 사이 차이나는 부분을 보여준다.이런 방식으로,\n연쇄 커밋 사슬을 구성할 수 있다.\n가장 최근 사슬의 끝값은 HEAD로 조회된다;\n~ 표기법을 사용하여 이전 커밋을 조회할 수 있다.\n그래서 HEAD~1(“head 마이너스 1”으로 읽는다.)은 “바로 앞선 커밋”을 의미하고,\nHEAD~123은 지금 있는 위치에서 123번째 이전 수정으로 간다는 의미가 된다.커밋된 것을 git log 명령어로 화면에 뿌려주는 숫자와 문자로 구성된 긴 문자열을 사용하여 조회할 수도 있다.\n변경사항에 대해서 중복되지 않는 ID로 “중복되지 않는(unique)”의 의미는 정말 유일하다는 의미다:\n특정 컴퓨터에 있는 임의 파일 집합에 대한 모든 변경사항은 중복되지 않는 40-문자 식별자가 붙어있다.\n첫번째 커밋은 ID로 f22b25e3233b4645dabd0d81e651fe074bd8e73b 이 주어졌다.\n그래서 다음과 같이 시도하자:올바든 정답이지만,\n난수 40-문자로 된 문자열을 타이핑하는 것은 매우 귀찮은 일이다.\n그래서 Git 앞의 몇개 문자만으로도 사용할 수 있게 했다:좋았어요!\n파일에 변경사항을 저장할 수 있고 변경된 것을 확인할 수 있다.\n어떻게 옛 버젼 파일을 되살릴 수 있을까?\n우연히 파일을 덮어썼다고 가정하자:이제 git status를 통해서 파일이 변경되었다고 하지만,\n변경사항은 아직 준비영역(Staging area)에 옮겨지지 않은 것으로 확인된다:git checkout 명령어를 사용해서 과거에 있던 상태로 파일을 돌려 놓을 수 있다:이름에서 유추할 수 있듯이, git checkout 명령어는 파일 옛 버젼을 확인하고 갖고 나간다. 즉, 되살린다.\n이 경우 HEAD에 기록된 가장 최근에 저장된 파일 버젼을 되살린다.\n좀더 오래된 버젼을 되살리고자 한다면, 대신에 커밋 식별자를 사용한다:변경사항은 준비영역에 머물러 있는 것에 주목한다.\n다시, git checkout 명령어를 사용해서 이전버젼으로 되돌아 간다:헤드(HEAD)를 잃지 말자f22b25e 커밋 상태로 mars.txt 파일을 되돌리는데 앞서 다음 명령어를 사용했다.하지만 주의하자! checkout 명령어는 다른 중요한 기능을 갖고 있고\n만약 타이핑에 오류가 있다면 의도를 Git이 오해할 수 있다.\n예를들어, 앞선 명령에서 mars.txt를 빼먹게 되면…“detached HEAD”는 “보기는 하지만 건드리지는 마시오”와 같다.\n따나서 현재 상태에서 어떤 변경도 만들지 말아야한다.\n저장소 지난 상태를 살펴본 후에 git checkout master 명령어로 HEAD를 다시 붙힌다.실행 취소를 하는 변경을 하기 *전에** 저장소 상태를 확인하는 커밋 번호를 사용해야 한다는 것을 기억하는 것이 중요하다.\n흔한 실수는 커밋 번호를 사용하는 것이다.\n아래 예제에서는 커밋 번호가 f22b25e인 가장 최신 커밋(HEAD~1) 앞의 상태로 다시 되돌리고자 한다:Git Checkout그래서, 모두 한군데 놓아보자:https://figshare.com/articles/How_Git_works_a_cartoon/1328266흔한 사례 단순화git status 출력결과를 주의깊이 읽게 되면,\n힌트가 포함된 것을 볼 수 있다.출력결과가 언급하는 바는, 버전 식별자 없이 git checkout 명령어를 실행하게 되면\nHEAD에 저장된 상태로 파일을 원복시킨다.\n더블 대쉬 --가 필요한 경우는 명령어 자체로부터 복구회야 되는 파일명을 구별할 때다:\n없는 경우, 커밋 식별자에 Git은 파일명을 사용한다.파일이 하나씩 하나씩 옛 상태로 되돌린다는 사실이 사람들이 작업을 조직하는 방식에 변화를 주는 경향이 있다.\n모든 것이 하나의 큰 문서로 되어있다면,\n나중에 결론부분에 변경사항을 실행취소하지 않고, 소개부분에 변경을 다시 되돌리기가 쉽지 않다(하지만 불가능하지는 않다).\n다른 한편으로 만약 소개부분과 결론부분이 다른 파일에 저장되어 있다면,\n시간 앞뒤로 이동하기가 훨씬 쉽다.파일 이전 버젼 복구하기정훈이가 몇주동안 작업한 파이썬 스크립트에 변경을 했고,\n오늘 아침 정훈이가 작업한 변경사항이 스크립트를 “망가 먹어서” 더이상 실행이 되지 않는다.\n복도 없이, 버그를 고치는데 1시간 이상 소모했다…다행스럽게도, Git을 사용한 프로젝트 버젼을 추적하고 있었다!\n다음 아래 명령어 중 어떤 것이 data_cruncher.py로 불리는 파이썬 스크립트 가장 최근 버젼을\n복구하게 할까요?$ git checkout HEAD$ git checkout HEAD data_cruncher.py$ git checkout HEAD~1 data_cruncher.py$ git checkout <unique ID last commit> data_cruncher.pyBoth 2 4커밋 되돌리기(Reverting Commit)정훈이는 동료와 함께 파이썬 코드를 협업해서 작성하고 있다.\n그룹 저장소에 마지막으로 커밋한 것이 잘못된 것을 알게 되서,\n실행취소하여 원복하고자 한다.정훈이는 실행취소를 올바르게 해서 그룹저장소를 사용하는\n모든 구성원이 제대로된 변경사항을 가지고 작업을 계속하길 원한다.\ngit revert [잘못된 커밋 ID] 명령어는 정훈이가 이전에 잘못 커밋했던\n작업에 대해 실행취소하는 커밋을 새로 생성시킨다.따라서, git revert는 git checkout [커밋 ID]와 다른데\n이유는 checkout이 그룹 저장소에 커밋되지 않는 로컬 변경사항에\n대해서 적용된다는 점에서 차이가 난다.\n정훈이가 git revert를 사용할 올바른 절차와 설명이 아래에 나와있다.\n빠진 명령어가 무엇일까?`________ # 커밋 ID를 찾을 수 있도록 Git 프로젝트 이력을 살펴본다.ID를 복사한다. (ID의 첫 문자 몇개만 사용한다. 예를 들어, 0b1d055).git revert [커밋 ID]새로운 커밋 메시지를 타이핑한다.저장하고 종료한다.작업흐름과 이력 이해하기다음 마지막 명령의 출력결과는 무엇일까?   Venus hot suitable base   Venus beautiful full love   Venus beautiful full love\n   Venus hot suitable base   Error changed venus.txt without committing changes해법정답은 2. 왜냐하면, git add venus.txt가 Venus hot suitable base 행을\n추가하기 전에만 적용된다. git checkout이 실행될 때 반영이 되지 않아서 그렇다.\ngit commit 명령어에 -플래그를 사용하게 되면 이런 손실을 막을 수 있다.git diff 이해 확인하기git diff HEAD~3 mars.txt 명령어를 고려해 보자.\n이 명령어를 실행하게 되면 실행결과로 예상하는 바를 말해보세요.\n명령어를 실행하게 되면 어떤 일이 발생하는가? 그리고 이유는 무엇인가?또 다른 명령어 git diff [ID] mars.txt를 시도해 보자.\n여기서, [ID]를 가장 최근 커밋 식별자로 치환한다.\n무슨 일이 생길까? 그리고 실제로 생긴 일은 무엇인가?준비 단계 변경사항(Staged Changes) 제거하기git checkout 명령어를 통해서 준비영역으로 올라오지 않은 변경사항이 있을 대, 이전 커밋을 복구할 수 있었다.\n하지만, git checkout은 준비영역에 올라왔지만, 커밋되지 않는 변경사항에 대해서도 동작한다.\nmars.txt 파일에 변경사항을 만들고, 변경사항을 추가하고 나서,\ngit checkout 명령어를 사용하게 되면 변경사항이 사라졌는지 살펴보자.변경 이력 탐색과 요약변경 이력 탐색은 Git에 있어 중요한 부분 중의 하나로,\n특히 커밋이 수개월 전에 이뤄졌다면, 올바른 커밋 ID를 찾는 것이 종종 크나큰 도전과제가 된다.\nplanets 프로젝트가 50 파일 이상으로 구성되었다고 상상해 보자.mars.txt 파일에 특정 텍스트가 변경된 커밋을 찾고자 한다.\ngit log를 타이핑하게 되면 매우 긴 목록이 출력된다.\n어떻게 하면 검색범위를 좁힐 수 있을까?\ngit diff 명령어가 특정 파일만 탐색할 수 있단느 점을 상기하자.예를 들어, git diff mars.txt. 이 문제에 유사한 아이디어를 적용해 보자.불행하게도 커밋 메시지 일부는 매우 애매모호하다. 예를 들어, update files.\n어떻게 하면 파일을 잘 검색할 수 있을까?\ngit diff, git log 명령어 모두 매우 유용하다. 두 명령어 모두 변경이력의 다른 부분을 요약해준다.\n둘을 조합하는 것은 가능할까? 다음 명령어를 실행해 보자:엄청 긴 출력 목록이 나타난다. 각 커밋마다 커밋 메시지와 차이가 쭉 출력된다.\n질문: 다음 명령어는 무슨 작업을 수행할까요?","code":"$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nAn ill-considered change$ git diff HEAD mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex b36abfd..0848c8d 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,3 +1,4 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n But the Mummy will appreciate the lack of humidity\n+An ill-considered change.$ git diff HEAD~1 mars.txt$ git diff HEAD~2 mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change$ git show HEAD~2 mars.txt\n\ncommit 34961b159c27df3b475cfe4415d94a6d1fcd064d\nAuthor: Vlad Dracula <vlad@tran.sylvan.ia>\nDate:   Thu Aug 22 10:07:21 2013 -0400\n\n    Start notes on Mars as a base\n\ndiff --git a/mars.txt b/mars.txt\nnew file mode 100644\nindex 0000000..df0654a\n--- /dev/null\n+++ b/mars.txt\n@@ -0,0 +1 @@\n+Cold and dry, but everything is my favorite color$ git diff f22b25e3233b4645dabd0d81e651fe074bd8e73b mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..93a3e13 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change$ git diff f22b25e mars.txt\n\ndiff --git a/mars.txt b/mars.txt\nindex df0654a..93a3e13 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,4 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\n+An ill-considered change$ nano mars.txt\n$ cat mars.txt\n\nWe will need to manufacture our own oxygen$ git status\n\nOn branch master\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git checkout HEAD mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity$ git checkout f22b25e mars.txt$ cat mars.txt\n\nCold and dry, but everything is my favorite color$ git status\n\n# On branch master\nChanges to be committed:\n  (use \"git reset HEAD <file>...\" to unstage)\n# Changes not staged for commit:\n#   (use \"git add <file>...\" to update what will be committed)\n#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n#\n#   modified:   mars.txt\n#\nno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git checkout HEAD mars.txt$ git checkout f22b25e mars.txt$ git checkout f22b25e\n\nNote: checking out 'f22b25e'.\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by performing another checkout.\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -b with the checkout command again. Example:\n git checkout -b <new-branch-name>\nHEAD is now at f22b25e Start notes on Mars as a base(use \"git checkout -- <file>...\" to discard changes in working directory)$ cd planets\n$ echo \"Venus is beautiful and full of love\" > venus.txt\n$ git add venus.txt\n$ echo \"Venus is too hot to be suitable as a base\" >> venus.txt\n$ git commit -m \"Comment on Venus as an unsuitable base\"\n$ git checkout HEAD venus.txt\n$ cat venus.txt #this will print the contents of venus.txt to the screen   Venus is too hot to be suitable as a base   Venus is beautiful and full of love   Venus is beautiful and full of love\n   Venus is too hot to be suitable as a base   Error because you have changed venus.txt without committing the changes$ git log mars.txt$ git log --patch mars.txt$ git log --patch HEAD~3 *.txt"},{"path":"git-ignore.html","id":"git-ignore","chapter":"13 .  추적대상에서 제외","heading":"13 .  추적대상에서 제외","text":"만약 Git가 추적하기 않았으면 하는 파일이 있다면 어떨까요?\n편집기에서 자동 생성되는 백업파일 혹은 자료 분석 중에 생성되는 중간 임시 파일이 좋은 예가 된다. 몇개 마루타 더미(dummy) 파일을 생성하자:그려면 Git은 다음을 보여준다:벼젼 제어 아래 이런 파일을 놓는 것은 디스크 공간 낭비다.\n더 좋은 않는 것은, 이런 파일을 모두 관리목록에 넣는 것이 실제적으로 중요한 변경사항을 관리하는데 집중하지 못하게 한다는 것이다.\n그래서 Git에게 중요하지 않는 이런 파일을 무시하게 일러준다..gitignore라는 프로젝트 루트 디렉토리에 파일을 생성해서 무시할 것을 명기함으로써 해당작업을 수행한다:상기 패턴은 .dat 확장자를 갖는 임의 파일과 results 디렉토리에 있는 모든 것을 무시한다.\n(하지만, 이들 파일 중 일부가 이미 추적되고 있다면, Git은 계속 추적한다.).gitignore 파일을 생성하자마자, git status 출력결과는 훨씬 깨끗해졌다:이제 Git가 알아차리는 유일한 것은 새로 생성된 .gitignore 파일이 된다.\n우리는 이들 파일을 추적하여 관리하지 않는다고 생각할 수도 있지만,\n우리와 저장소를 공유하고 있는 다른 모든 사람도 우리가 추적관리하지 않는 동일한 것을 무시하고 싶을 것이다.\n.gitignore 를 추가하고 커밋하자:보너스로, .gitignore는 실수로 추적하고 싶지 않는 파일이 저장소에 추가되는 것을 피할 수 있게 돕는다:만약 .gitignore 설정에 우선해서 파일을 추가하려면,\ngit add -f를 사용해서 강제로 Git에 파일을 추가할 수 있다.\n예를 들어, git add -f .dat.\n추적관리되지 않는 파일의 상태를 항상 보려면 다음을 사용한다:중첩된 파일 추적하지 않기디렉토리 구조가 다음과 같다:어떻게 하면 results/plots 만 추적하지 않을 수 있을까? results/data 디렉토리는 추적한다.해답대부분의 프로그래밍 이슈와 마찬가지로,\n이 문제를 해결하는 몇가지 방식이 있다.\nresults/plots 디렉토리 콘텐츠만 추적하지 않기로 한다면,\n.gitignore 파일에 /plots/ 폴더만 추적하지 않도록 다음과 같이\n.gitignore 파일을 변경하면 된다:results/plots/대신에 /results/ 디렉토리에 모든 것을 추적하지 않지만, results/data만 추적하고자 한다면,\nresults/ 폴더를 .gitignore 파일에 추가하고 results/data/ 폴더에 대해서 예외를 생성한다.\n다음 도전과제가 이런 유형의 해법을 다루게 된다.종종 ** 패턴이 사용하기 수월한데, 다수 디렉토리와 매칭을 지원한다.\n예를 들어, **/results/plots/*은 루트 디렉토리에 results/plots 디렉토리를 추정하기 않게 도니다.특정 파일만 포함시키기final.data 파일만 제외하고 모든 .data 파일은 추적하지 않고자 하면 어떻게 하면 될까?\n힌트: ! (느낌표 연산자) 부호가 수행하는 작업을 알아본다.해법.gitignore 파일에 다음 두 줄을 추가한다:느낌표 연산자가 앞서 제외된 항목을 포함시키게 한다.디렉토리에 모든 파일 추적하지 않기디렉토리 구조가 다음과 같다:result/data/position/gps 디렉토리에 모든 .data 파일을 추적하지 않도록\n.gitignore 파일에 규칙을 작성하는데 가장 짧은 규칙은 무엇일까?\ninfo.txt 파일은 추적하자.해답results/data/position/gps 디렉토리에 .data로 끝나는 모든 파일은 results/data/position/gps/*.data 규칙으로 매칭된다.\nresults/data/position/gps/info.txt 파일은 확장자가 달라서 계속 추적된다.적용 규칙 순서.gitignore 파일에 다음 내용이 담겨있다:적용 결과는 어떻게 될까?해답! 연산자는 이전에 정의된 추적제외 패턴을 부정한다.\n.gitignore파일에서 !*.data 규칙은 앞서 추적에서 제외한 .data 모든 파일 추적제외를 부정한다.\n따라서, 어떤 것도 추적제외되지 않고, .data 파일 모두가 추적된다.로그 파일스크립트를 작성해서 log_01, log_02, log_03 형태의 중간 로그 파일이 많이 생성되었다.\n로그 파일을 보관하고자 하지만, git으로 추적하고 싶지는 않다.log_01, log_02 … 형태 모든 파일을 추적 제외하는 .gitignore 규칙을 하나 작성한다.log_01 형태 마루타 파일을 생성해서 “추적제외 패턴”을 테스트한다.종국에 log_01 파일이 매우 중요하는 것을 알게 되어서 .gitignore 파일을 변경하지 않고 추적되게 추가한다.추적하기를 원하지 않지만, .gitignore를 통해서 추적제외할 수 있는 파일이 어떤 유형이 있는지 주변 동료와 상의하자.해답log_* 혹은 log* 규칙을 .gitignore 파일에 추가한다.git add -f log_01 명령어를 사용해서 log_01 파일에 대한 추적을 수행한다.","code":"$ mkdir results\n$ touch a.dat b.dat c.dat results/a.out results/b.out$ git status\n\nOn branch master\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n    a.dat\n    b.dat\n    c.dat\n    results/\nnothing added to commit but untracked files present (use \"git add\" to track)$ nano .gitignore\n$ cat .gitignore\n\n*.dat\nresults/$ git status\n\nOn branch master\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n    .gitignore\nnothing added to commit but untracked files present (use \"git add\" to track)$ git add .gitignore\n$ git commit -m \"Ignore data files and the results folder.\"\n$ git status\n\n# On branch master\nnothing to commit, working directory clean$ git add a.dat\n\nThe following paths are ignored by one of your .gitignore files:\na.dat\nUse -f if you really want to add them.$ git status --ignored\n\nOn branch master\nIgnored files:\n (use \"git add -f <file>...\" to include in what will be committed)\n\n        a.dat\n        b.dat\n        c.dat\n        results/\n\nnothing to commit, working directory cleanresults/data\nresults/plots*.data           # 모든 data 파일을 추적하지 않는다.\n!final.data      # final.data 파일만 예외로 한다.results/data/position/gps/a.data\nresults/data/position/gps/b.data\nresults/data/position/gps/c.data\nresults/data/position/gps/info.txt\nresults/plots*.data\n!*.data"},{"path":"git-github.html","id":"git-github","chapter":"14 .  GitHub 원격작업","heading":"14 .  GitHub 원격작업","text":"버젼 제어(version control)는 다른 사람과 협업할 때 진정으로 다가온다.\n우리는 이미 버젼 제어를 위해 필요한 작업 대부분을 수행했다;\n한가지 빠진 것은 한 저장소에서 다른 저장소로 변경사항을 복사하는 것이다.Git 같은 시스템은 임의 두 저장소 사이에 작업을 옮길 수 있는 기능을 제공한다.\n하지만, 실무에서 다른 사람의 노트북이나 PC보다는 중앙 허브에 웹 방식으로 하나의 원본을 두고 사용하는 것이 가장 쉽다.\n대부분의 프로그래머는 프로그램 마스터 원본을\nGitHub,\nBitBucket,\nGitLab 호스팅 서비스에 두고 사용한다;\n이번 학습 마지막 부분에서 이러한 접근법의 장점과 단점을 살펴본다.세상 사람들과 현재 프로젝트에서 변경한 사항을 공유하는 것에서부터 시작해보자.\nGitHub에 로그인하고 나서, 우측 상단 아이콘을 클릭해서 planets 이름으로 신규 저장소를 생성한다:(1단계) GitHub 저장소 생성저장소 이름을 “planets”으로 만들고 “Create Repostiory”를 클릭한다:(2단계) GitHub 저장소 생성저장소가 생성되자 마자, GitHub는 URL을 가진 페이지와 로컬 저장소 환경설정 방법에 대한 정보를 화면에 출력한다:(3단계) GitHub 저장소 생성다음 명령어가 실제로 GitHub 서버에서 자동으로 수행된 것이다:mars.txt 파일을 추가하고 커밋한 이전 학습을 상기한다면,\n로컬 저장소는 다음과 같이 도식적으로 표현할 수 있다:Git 준비영역(Staging) 로컬 저장소이제 저장소가 두개로 늘어서, 도식적으로 표현하면 다음과 같다:신선한 신규 GitHub 저장소현재 로컬 저장소는 여전히 mars.txt 파일에 대한 이전 작업정보를 담고 있다.\n하지만, GitHub의 원격 저장소에는 아직 어떠한 파일도 담고 있지는 않다:다음 단계는 두 저장소를 연결하는 것이다.\n로컬 저장소를 위해서 GitHub 저장소를 원격(remote)으로 만들어 두 저장소를 연결한다.\nGitHub의 저장소 홈페이지에 식별하는데 필요한 문자열이 포함되어 있다:GitHub 저장소 URL 발견장소SSH에서 HTTPS로 프로토콜(protocol)을 변경하려면 ‘HTTPS’ 링크를 클릭한다.HTTPS vs. SSH부가적인 설정이 필요하지 않아서 여기서는 HTTPS를 사용한다.\n워크샵 후에 SSH 접근 설정을 원할지도 모른다.\nSSH 접근이 좀더 안전하다.\nGitHub,\nAtlassian/BitBucket,\nGitLab의 훌륭한 지도서 중 하나를 따라하는 것도 좋다.\nGitLab은 온라인 동영상도 제공한다.GitHub 저장소 URL 변경웹 브라우져에서 URL을 복사하고 나서, 로컬 컴퓨터 planets 저장소로 가서 다음 명령어를 실행한다:Make sure use URL repository rather Vlad’s: \ndifference username instead vlad.Vlad가 아니고 여러분 저장소의 URL을 사용했는지 확인한다:\n유일한 차이점은 vlad 대신에 여러분의 사용자이름(username)이다.git remote -v 실행해서 명령어가 제대로 작동했는지 확인한다:origin 이름이 원격 저장소에 대한 로컬 별명이다.\n원한다면 다른 명칭을 사용할 수도 있지만, origin 이름이 가장 일반적인 선택이다.별명이 origin으로 설정되면,\n다음 명령어가 변경사항을 로컬 저장소에서 GitHub 원격 저장소로 밀어 넣어 푸쉬(push)한다:프록시(Proxy)만약 연결된 네트워크가 프록시를 사용한다면,\n“resolve hostname” 오류 메시지로 인해서 마지막 명령어가 실패할 가능성이 있다.\n이 문제를 해결하기 위해서, 프록시에 대한 정보를 Git에 전달할 필요가 있다:프록시를 사용하지 않는 또다른 네트워크에 연결될 때,\nGit에게 프록시 기능을 사용하지 않도록 다음 명령어를 사용하여 일러준다:비밀번호 관리자(password manager)운영체제 위에 비밀번호 관리자(password manager)가 설정되어 있다면,\n사용자이름(username)과 비밀번호(passord)가 필요로 할 때,\ngit push 명령어가 이를 사용하려 한다.\n“Git Bash Windows”를 사용하면 기본 디폴트 행동이다.\n관리자 비밀번호를 사용하는 대신에,\n터미널에서 사용자이름과 비밀번호를 입력하려면,\ngit push를 실행하기 전에 터미널에서 다음과 같이 타이핑한다:git uses SSH_ASKPASS credential entry에도 불구하고,\nSSH나 HTTPS를 경유하여 Git을 사용하든 SSH_ASKPASS을 설정하고 싶지 않을 수도 있다.~/.bashrc 파일 하단에 unset SSH_ASKPASS을 추가해서\nGit으로 하여금 사용자명과 비밀번호를 사용하도록 기본설정으로 둘 수도 있다.이제 로컬 저장소와 원격 저장소는 다음과 같은 상태가 된다:첫번째 푸쉬(Push) 다음 GitHub 저장소‘-u’ 플래그(flag)Git 문서에서 git push과 함께 사용되는 -u 옵션을 볼 수 있다.\ngit branch 명령어에 대한 --set-upstream-옵션과 동의어에 해당되는 옵션이다.\n원격 브랜치를 현재 브랜치와 연결시키는데 사용된다. 그래서 git pull 명령어가\n아무런 인자없이 사용될 수 있다.\n원격 저장소가 설정되면, git push -u origin master 명령어만 실행시키면 연결작업이 완료된다.또한, 원격 저장소에서 로컬 저장소로 변경사항을 풀(pull)해서 가져올 수도 있다:이 경우 가져오기 하는 풀(pull)은 아무런 결과가 없는데, 이유는 두 저장소가 이미 동기화가 되어서다.\n하지만, 만약 누군가 GitHub 저장소에 변경사항을 푸쉬했다면, 상기 명령어는 변경된 사항을 로컬 저장소로 다운로드한다.GitHub GUIGitHub 웹사이트에서 planets 저장소를 찾아간다.\nCode 탭아래 “XX commits”(“XX”는 숫자) 텍스트를 클릭한다.\n각 커밋 우측의 버튼 세개 여기 저기 둘러보고, 클릭해 본다.\n버튼을 눌러서 어떤 정보를 모을 수 있거나 탐색할 수 있는가?\n쉘에서 동일한 정보를 어떻게 얻을 수 있을까?해답\n(클립보드 그림을 갖는) 가장 좌측 버튼은 클립보드에 커밋 식별자 전체를 복사한다.\n쉘에서 git log 명령어가 각 커밋에 대한 전체 커밋 식별자를 보여준다.중간 버튼을 클릭하게 되면, 특정 커밋으로 변경한 내용 전체를 확인할 수 있다.\n녹색 음영선은 추가를 붉은색 음영선은 삭제를 의미한다.\n쉘에서 동일한 작업을 git diff로 할 수 있다.\n특히, git diff ID1..ID2(ID1와 ID2은 커밋 식별자다) 명령어(즉, git diff a3bf1e5..041e637)는 두 커밋 사이 차이를 보여준다.가장 우측 버튼은 커밋 당시에 저장소 모든 파일을 보여준다.\n쉘로 이런 작업을 수행하려면, 해당 시점의 저장소를 checkout 해야 한다.\n쉘에서 git checkout ID(여기서 ID는 살펴보려고 하는 커밋 식별자) 명령어를 실행하면 된다.\ncheckout 하게 되면, 나중에 저장소를 올바른 상태로 되돌려 놓아야 된다는 것을 기억해야 됩니다.GitHub 시간도장(Timestamp)GitHub에 원격저장소를 생성하라.\n로컬 저장소의 콘텐츠를 원격 저장소로 푸쉬하라.\n로컬 저장소에 변경사항을 만들고, 변경사항을 푸쉬하라.방금 생성한 GitHub 저장소로 가서\nGitHub 변경사항에 대한 시간도장(timestamps)을 살펴본다.\nGitHub이 시간정보를 어떻게 기록하는가? 왜 그런가?해답\nGitHub은 시간도장을 사람이 읽기 쉬운 형태로 표시한다(즉, “22 hours ago” 혹은 “three weeks ago”).\n하지만, 시간도장을 이리저리 살펴보면, 파일의 마지막 변경이 발생된 정확한 시간을 볼 수 있다.푸쉬(Push) vs. 커밋(Commit)이번 학습에서, “git push” 명령어를 소개했다.\n“git push” 명령어가 “git commit” 명령어와 어떻게 다른가?해답변경 사항을 푸쉬하면, 로컬에서 변경한 사항을 원격 저장소와 상호협의하여 최신 상태로 갱신한다.\n(흔히 다른 사람 변경시킨 것을 공유하는 것도 이에 해당된다.)\n커밋은 로컬 저장소만 갱신한다는 점에서 차이가 난다.원격 설정 고치기원격 URL에 오탈자가 발생되는 일이 실무에서 흔히 발생된다.\n이번 연습문제는 이런 유형의 이슈를 어떻게 고칠 수 있느냐에 대한 것이다.\n먼저 잘못된 URL을 원격(remote)에 추가하면서 시작해 보자.git remote로 추가할 때 오류를 받았나요?\n원격 URL을 적법한지 확인해 주는 명령어를 생각해 낼 수 있나요?\nURL을 어떻게 수정할 수 있을까요? (팁: git remote -h를 사용한다.)\n이번 연습문제를 수행한 다음에 원격(remote)를 지워버리는 것을 잊지말자.해답\n원격(remote)를 추가할 때 어떤 오류 메시지도 볼 수 없다. (원격 remote 를 추가하는 것은 Git에게 알려주기만 할 뿐 아직 사용하지는 않았기 때문이다.)\ngit push 명령어를 사용하자마자, 오류 메시지를 보게 된다.\ngit remote set-url 명령어를 통해서 잘못된 원격 URL을 바꿔 문제를 해결하게 된다.GitHub 라이선스와 README 파일이번 학습에서 GitHub에 원격 저장소를 생성하는 방법을 학습했다.\n하지만, GitHub 저장소를 초기화할 때 README.md 혹은 라이선스 파일을 추가하지 않았다.\n로컬 저장소와 원격 저장소를 연결시킬 때 두 파일을 갖게 되면 무슨 일이 발생될 것으로 생각하십니까?해답\n이런 경우, 관련없는 이력때문에 병합 충돌(merge conflict)이 발생된다.\nGitHub에서 README.md 파일을 생성시키고 원격 저장소에서 커밋작업을 수행한다.\n로컬 저장소로 원격 저장소를 풀(pull)로 땡겨오면, Git이 origin과 공유되지 않는 이력을 탐지하고 병합(merge)를 거부해 버린다.--allow-unrelated-histories 옵션으로 두 저장소를 강제로 병합(merge)시킬 수 있다.\n이런 옵션을 사용할 때 주의한다. 병합하기 전에 로컬저장소와 원격저장소의 콘텐츠를 면밀히 조사한다.","code":"$ mkdir planets\n$ cd planets\n$ git init$ git remote add origin https://github.com/vlad/planets.git$ git remote -v\n\norigin   https://github.com/vlad/planets.git (push)\norigin   https://github.com/vlad/planets.git (fetch)$ git push origin master\n\nCounting objects: 9, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (9/9), 821 bytes, done.\nTotal 9 (delta 2), reused 0 (delta 0)\nTo https://github.com/vlad/planets\n * [new branch]      master -> master\nBranch master set up to track remote branch master from origin.$ git config --global http.proxy http://user:password@proxy.url\n$ git config --global https.proxy http://user:password@proxy.url$ git config --global --unset http.proxy\n$ git config --global --unset https.proxy$ unset SSH_ASKPASS$ git pull origin master\n\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\nAlready up-to-date.git remote add broken https://github.com/this/url/is/invalid$ git pull origin master\n\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\n * [new branch]      master     -> origin/master\nfatal: refusing to merge unrelated histories$ git pull --allow-unrelated-histories origin master\n\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\nMerge made by the 'recursive' strategy.\n README.md | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 README.md"},{"path":"git-collab.html","id":"git-collab","chapter":"15 .  협업 (Collaborating)","heading":"15 .  협업 (Collaborating)","text":"다음 단계로, 짝을 이룬다.\n한 사람이 “소유자”(연습을 시작하는데 사용될 GitHub 저장소 주인)가 되고,\n다른 사람이 “협력자”(소유자 저장소를 복제해서 변경을 하는 사람)가 된다.\n목표는 협력자가 변경사항을 소유자 저장소에 추가하는 것이다.\n말미에는 역할을 바꿔서 두 사람 모두 소유자와 협력자의 역할을 수행한다.혼자 훈련하기혼자 힘으로 이번 학습을 쭉 진행해 왔다면, 두번째 터미널을 열어서 계속 진행할 수 있다.>\n두번째 윈도우가 여러분의 협력자를 나타내고, 다른 컴퓨터에서 작업하고 있는 것으로 볼 수 있다.\nGitHub 접근권한을 다른 사람에게 줄 필요가 없어졌다.\n왜냐하면 두 ‘파트너’ 모두 여러분이기 때문이다.소유자가 협력자에게 접근권한을 부여할 필요가 있다.\nGitHub에서 오른쪽에 ‘setting’ 버튼을 클릭해서 협력자(Collaborators)를 선택하고,\n파트너 이름을 입력한다.GitHub에 협업자(Collaborators) 추가소유자 저장소에 접근 권한이 부여되면,\n협력자(Collaborator)는 https://github.com/notifications으로 이동한다.\n그곳에서 소유자 저장소의 접근을 받아들이면 된다.다음으로 협력자(Collaborator)는 소유자 저장소 사본을 본인 컴퓨터로 내려받는다.\n이런 작업을 “저장소 복제(cloning repo)”라고 부른다.\n소유자의 저장소를 본인 바탕화면(Desktop) 폴더에 클론하려면, 협력자는 다음 명령어를 입력한다:’vlad’를 소유자 사용자이름(저장소를 소유하고 있는 사람)으로 바꾼다.저장소 클론한 후 모습앞서 작업했던 것과 정확하게 동일한 방식으로,\n협력자는 이제 소유자의 저장소 클론에서 변경을 마음대로 할 수 있다:그리고 나서, 변경사항을 GitHub의 소유자 저장소로 푸쉬한다:주목할 점은 origin 이라는 원격 저장소를 생성할 필요는 없다:\n저장소를 복제(clone)할때 Git이 자동으로 origin 이름을 붙여준다.\n(수작업으로 원격 설정을 할 때, 앞에서 왜 origin 이름을 사용한 것이 현명한 선택인 이유다.)이제 GitHub 웹사이트에서 소유자 저장소를 살펴본다(아마도 웹브라우져 다시 고치기를 수행할 필요가 있을 수 있다.)\n협력자가 신규 커밋을 한 것을 확인할 수 있다.소유자 로컬 컴퓨터로 GitHub 원본 저장소의 변경사항을 다운로드하려면,\n소유자는 다음과 같이 입력한다:이제 저장소 3개 (소유자 로컬 저장소, 협력자 로컬 저장소, GitHub의 소유자 저장소) 모두 동기화 되었다.기본적인 협업 작업흐름실무에서 협업하는 저장소의 가장 최신 버전을 갖도록 확인하고 확인하는 것이 좋다.\n어떤 변경을 가하기 전에 git pull 명령어를 먼저 실행해야 한다.\n기본적인 협업 작업흐름은 다음과 같다.git pull origin master 명령어로 본인 로컬 저장소를 최신상태로 갱신한다.변경 작업을 수행하고 git add 명령어로 준비단계(staging area)로 보낸다.git commit -m 명령어로 변경사항을 커밋한다.GitHub에 git push origin master 명령어로 변경사항을 업로드한다.상당한 변경사항을 포함한 단 한번의 커밋보다 작은 변화를 준 커밋을 많이 하는 것이 좋다:\n작은 커밋이 가독성도 좋고 리뷰하기도 더 편하다.역할을 바꾸고 반복한다.역할을 바꿔서 전체 과정을 반복한다.변경사항 리뷰협력자에게 어떤 정보도 주지않고 소유자가 저장소에 커밋을 푸쉬했다.\n협력자는 명령라인으로 무엇이 변경되었는지 어떻게 알 수 있을까요?해답명령라인에서 협력자는 로컬 저장소에 원격 저장소 변경사항을\ngit fetch origin master 명려어를 사용해서 가져올 수 있다.\n하지만, 그 자체로 병합(merge)되는 것은 아니다.\ngit diff master origin/master 명령어를 실행해서,\n협력자는 터미널에 변경사항을 확인할 수 있다.GitHub에서도 협력자는 포크된 저장소로 가서 “branch 1 commit behind -Repository:master.”\n메시지를 볼 수 있다.\nCompare 아이콘과 링크가 걸려있다. Compare 페이지에서\n협력자는 base fork를 본인 저장소로 변경하고 나서, “compare across forks” 위에\n링크를 클릭한다. 마지막으로 head fork를 주 저장소로 변경한다.\n이 작업을 하게 되면 차이가 나는 모든 커밋을 볼 수 있게 된다.GitHub에서 변경사항 주석(comment)달기협력자는 소유자가 변경한 한 줄에 대해 질문을 가질 수 있고,\n일부 제안사항도 있다.GitHub으로 커밋 차이에 대해 주석을 다는 것도 가능하다.\n파란색 주석 아이콘(comment icon)을 클릭하면 주석 윈도우(comment window)을 열 수 있다.협력자는 GitHub 인터페이스를 사용해서 코멘트와 제안을 남길 수 있다.버전 이력, 백업, 그리고 버전 제어일부 백업 소프트웨어는 파일 버전에 대한 이력을 기록하고 있다.\n도한, 특정 버전을 복구하는 기능도 제공하고 있다.\n이러한 기능이 버전 제어와 어떻게 다른가?버전제어, Git, GitHub을 사용하는 좋은 점은 무엇인가?","code":"$ git clone https://github.com/vlad/planets.git ~/Desktop/vlad-planets$ cd ~/Desktop/vlad-planets\n$ nano pluto.txt\n$ cat pluto.txt\n\nIt is so a planet!$ git add pluto.txt\n$ git commit -m \"Add notes about Pluto\"\n\n 1 file changed, 1 insertion(+)\n create mode 100644 pluto.txt$ git push origin master\n\nCounting objects: 4, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 306 bytes, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo https://github.com/vlad/planets.git\n   9272da5..29aba7c  master -> master$ git pull origin master\n\nremote: Counting objects: 4, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 0), reused 3 (delta 0)\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\nUpdating 9272da5..29aba7c\nFast-forward\n pluto.txt | 1 +\n 1 file changed, 1 insertion(+)\n create mode 100644 pluto.txt"},{"path":"git-conflict.html","id":"git-conflict","chapter":"16 .  충돌 (Conflicts)","heading":"16 .  충돌 (Conflicts)","text":"사람들이 병렬로 작업을 할 수 있게 됨에 따라,\n누군가 다른 사람 작업영역에 발을 들여 넣을 가능성이 생겼다.\n혼자서 작업할 경우에도 이런 현상이 발생한다:\n소프트웨어 개발을 개인 노트북과 연구실 서버에서 작업한다면,\n각 작업본에 다른 변경사항을 만들 수 있다.\n버젼 제어(version control)가 겹치는 변경사항을\n해결(resolve)하는 툴을 제공함으로서,\n이러한 충돌(conflicts)을 관리할 수 있게 돕는다.충돌을 어떻게 해소할 수 있는지 확인하기 위해서,\n먼저 파일을 하나 생성하자.\nmars.txt 파일은 현재 두 협업하는 사람의 planets 저장소 사본에서는 다음과 같이 보인다:파트너 사본에만 한 줄을 추가하자:그리고 나서, 변경사항을 GitHub에 푸쉬하자:이제 또다른 파트너가 GitHub에서 갱신(update)하지 않고,\n본인 사본에 다른 변경사항을 작업한다:로컬 저장소에 변경사항을 커밋할 수 있다:하지만, Git이 GitHub에는 푸쉬할 수 없게 한다:충돌하는 변경사항Git이 푸쉬를 거절한다.\n이유는 로컬 브랜로 반영되지 않는 신규 업데이터트가 원격 저장소에 있음을 Git이 탐지했기 때문이다.\n즉, 본인이 작업한 변경사항이 다른 사람이 작업한 변경사항과 중첩되는 것을 Git이 탐지해서,\n앞에서 작업한 것을 뭉개지 않도록 정지시킨다.\n이제 해야될 작업은 GitHub에서 변경사항을 풀(Pull)해서 가져오고,\n현재 작업중인 작업본과 병합(merge)해서 푸쉬한다.\n풀(Pull)부터 시작하자:git pull 명령어는 로컬 저장소를 갱신할 때 원격 저장소에 이미 반영된 변경사항을 포함시키도록 한다.\n원격 저장소 브랜치에서 변경사항을 가져온(fetch) 후에,\n로컬 저장소 사본의 변경사항이 원격 저장소 사본과 겹치는 것을 탐지해냈다.\n따라서, 앞서 작업한 것이 뭉개지지 않도록 서로 다른 두 버젼의 병합(merge)을 승인하지 않고 거절한 것이다.\n해당 파일에 충돌나는 부분을 다음과 같이 표식해 놓는다:<<<<<<< HEAD으로 시작되는 부분에 본인 변경사항이 나와있다.\nGit이 자동으로 =======을 넣어서 충돌나는 변경사항 사이에 구분자로 넣고,\n>>>>>>>기호는 GitHub에서 다운로드된 파일 내용의 마지막을 표시한다.\n(>>>>>>> 표시자 다음에 문자와 숫자로 구성된 문자열로 방금 다운로드한 커밋번호도 식별자로 제시한다.)파일을 편집해서 표시자/구분자를 제거하고 변경사항을 일치하는 것은 전적으로 여러분에게 달려있다.\n원하는 무엇이든지 할 수 있다:\n예를 들어, 로컬 저장소의 변경사항을 반영하든,\n원격 저장소의 변경사항을 반영하든,\n로컬과 원격 저장소의 내용을 대체하는 새로운 것을 작성하든,\n혹은 변경사항을 완전히 제거하는 것도 가능하다.\n로컬과 원격 모두 교체해서 다음과 같이 파일이 보이도록 하자:병합을 마무리하기 위해서,\n병합으로 생성된 변경사항을 mars.txt 파일에 추가하고 커밋한다:이제 변경사항을 GitHub에 푸쉬할 수 있다:Git이 병합하면서 수행한 것을 모두 추적하고 있어서,\n수작업으로 다시 고칠 필요는 없다.\n처음 변경사항을 만든 협력자 프로그래머가 다시 풀하게 되면:병합된 파일을 얻게 된다:다시 병합할 필요는 없는데,\n다른 누군가 작업을 했다는 것을 Git가 알기 때문이다.충돌을 해소하는 Git 기능은 매우 유용하지만,\n충돌해소에는 시간과 노력이 수반되고, 충돌이 올바르게 해소되지 않게 되면\n오류가 스며들게 된다.\n프로젝트 와중에 상당량의 충돌을 해소하는데 시간을 쓰고 있다고 생각되면,\n충돌을 줄일 수 있는 기술적인 접근법도 고려해보는 것이 좋겠다.좀더 자주 upstream을 풀(Pull)하기, 특히 신규 작업을 시작하기 전이라면 더욱 그렇다.작업을 구별하기 위해서 토픽 브랜치를 사용해서, 작업을 완료하면 마스터(master) 브랜치에 병합시킨다.좀더 작게 원자수준 커밋을 한다.논리적으로 적절하다면, 큰 파일을 좀더 작은 것으로 쪼갠다. 그렇게 함으로써\n두 저작자가 동시에 동일한 파일을 변경하는 것을 줄일 수 있을 듯 싶다.프로젝트 관리 전략으로 충돌(conflicts)을 최소화할 수도 있다:동료 협력자와 누가 어떤 분야에 책임이 있는지 명확히 한다.동료 협력자와 작업순서를 협의해서, 동일한 라인에 변경사항이 있을 수 있는 작업이 동시에 작업되지 않게 시간차를 둔다.충돌이 문체변동(탭 vs 2 공백) 때문이라면, 프로젝트 관례를 수립하고,\n코딩 스타일 도구(htmltidy, perltidy, rubocop 등)를 사용해서 필요한 경우 강제한다.본인이 생성한 충돌 해소하기강사가 생성한 저장소를 복제하세요.\n저장소에 새 파일을 추가하고,\n기존 파일을 변경하세요. (강사가 변경할 기존 파일이 어느 것인지 알려줄 것이다.)\n강사의 말에 따라 충돌을 생성하는 연습을 위해서,\n저장소에서 변경사항을 가져오도록 풀(Pull)하세요.\n그리고 충돌을 해소하고 해결해 보세요.텍스트 파일이 아닌 충돌버젼 제어 저장소의 이미지 파일이나 혹은 다른 텍스트가 아닌 파일에서 충돌이 발생할 때,\nGit는 무엇을 하나요?해답먼저 시도해 보자.\n드라큘라가 화성 표면에서 사진을 찍어 mars.jpg로 저장했다고 가정한다.화성 이미지 파일이 없다면 다음과 같이 더미 바이너리 파일을 생성할 수도 있다.ls 명령어를 사용해서 파일 크기가 1 킬로바이트임이 확인된다.\n/dev/urandom 특수 파일에서 불러온 임의 바이트로 꽉 차있다.이제, 드라큘라가 mars.jpg 파일을 본인 저장소에 저장한다고 상정한다:늑대인간도 비슷한 시점에 유사한 사진을 추가했다고 가정한다.\n늑대인간의 사진은 화성하늘 사진인데, 이름도 mars.jpg로 동일하다.\n드라큘라가 푸쉬하게 되면 유사한 메시지를 받게 된다:풀을 먼저한 뒤에 충돌나는 것을 해소한다는 것을 학습했다:이미지나 기타 바이너리 파일에 충돌이 생길 때,\nGit은 다음과 같은 메시지를 출력한다:이번에도 충돌 메시지가 mars.txt에 나온 것과 거의 동일하다.\n하지만, 중요한 추가 라인 한줄이 있다:Git은 자동으로 텍스트 파일에 했던 것처럼 이미지 파일에 충돌지점 표식을\n끼워넣을 수 없다.\n그래서 이미지 파일을 편집하는 대신에,\n간직하고자 하는 버전을 쳇아웃(checkout)하고 나서 해당 버전을 추가(add)하고 커밋한다.중요한 라인에, mars.jpg 두가지 버전에 대해서\n커밋 식별자(commit identifier)를 Git이 제시하고 있다.\n현재 작업 버젼은 HEAD이고, 늑대인간 작업버전은 439dc8c0...이다.\n본인 작업버젼을 사용하고자 하면, git checkout 명령어를 사용한다:대신에 늑대인간 버젼을 사용하려고 하면,\ngit checkout 명령어를 늑대인간 439dc8c0 커밋 식별자와 함께 사용하면 된다:이미지 모두 보관할 수도 있다.\n동일한 이미지명으로 보관할 수는 없다는 것이 중요하다.\n순차적으로 각 버젼을 쳇아웃(checkout)하고 나서 이미지명을 변경한다.\n그리고 나서 이름을 변경한 버젼을 추가한다.\n먼저, 각 이미지를 쳇아웃하고 이름을 변경하자:그리고 나서, mars.jpg 이전 파일을 삭제하고\n신규 파일 두개를 추가한다:이제 화성 이미지 파일 두개가 저장소에서 확인되지만 mars.jpg 파일은 더이상 존재하지 않는다.일반적인 작업 시간원격 Git 저장소를 활용하여 공동 프로젝트로 작업하는 컴퓨터 앞에 않아있다.\n작업시간동안에 다음 동작을 취하지만, 작업순서는 다르다:변경한다(make change): numbers.txt 텍스트 파일에 숫자 100을 추가.원격 저장소 갱신시키기(Update remote): 로컬 저장소와 매칭되어 동기화시킴.축하하기(Celebrate): 맥주로 성공을 자축함.로컬 저장소 갱신시키기(Update local): 원격 저장소와 매칭되어 동기화시킴.변경사항 준비영역으로 보내기(Stage change): 커밋대상으로 추가하기.변경사항(Commit change): 로컬 저장소에 커밋하기어떤 순서로 작업을 수행해야 충돌이 날 가능성을 최소화할 수 있을까?\n아래표 action 칼럼에 순서대로 상기 명령어를 적어 본다.작업 순서를 정했으면, command 칼럼에 대응되는 명령어를 적어본다.\n일부 단계를 시작하는데 도움이 되도록 채워져 있다.해답","code":"$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nThis line added to Wolfman's copy$ git add mars.txt\n$ git commit -m \"Add a line in our home copy\"\n\n[master 5ae9631] Add a line in our home copy\n 1 file changed, 1 insertion(+)$ git push origin master\n\nCounting objects: 5, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (3/3), done.\nWriting objects: 100% (3/3), 352 bytes, done.\nTotal 3 (delta 1), reused 0 (delta 0)\nTo https://github.com/vlad/planets\n   29aba7c..dabb4c8  master -> master$ nano mars.txt\n$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nWe added a different line in the other copy$ git add mars.txt\n$ git commit -m \"Add a line in my copy\"\n\n[master 07ebc69] Add a line in my copy\n 1 file changed, 1 insertion(+)$ git push origin master\n\nTo https://github.com/vlad/planets.git\n ! [rejected]        master -> master (non-fast-forward)\nerror: failed to push some refs to 'https://github.com/vlad/planets.git'\nhint: Updates were rejected because the tip of your current branch is behind\nhint: its remote counterpart. Merge the remote changes (e.g. 'git pull')\nhint: before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.$ git pull origin master\n\nremote: Counting objects: 5, done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 3 (delta 1), reused 3 (delta 1)\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\nAuto-merging mars.txt\nCONFLICT (content): Merge conflict in mars.txt\nAutomatic merge failed; fix conflicts and then commit the result.$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\n<<<<<<< HEAD\nWe added a different line in the other copy\n=======\nThis line added to Wolfman's copy\n>>>>>>> dabb4c8c450e8475aee9b14b4383acc99f42af1d$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nWe removed the conflict on this line$ git add mars.txt\n$ git status\n\nOn branch master\nAll conflicts fixed but you are still merging.\n  (use \"git commit\" to conclude merge)\n\nChanges to be committed:\n\n    modified:   mars.txt\n$ git commit -m \"Merge changes from GitHub\"\n\n[master 2abf2b1] Merge changes from GitHub$ git push origin master\n\nCounting objects: 10, done.\nDelta compression using up to 4 threads.\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (6/6), 697 bytes, done.\nTotal 6 (delta 2), reused 0 (delta 0)\nTo https://github.com/vlad/planets.git\n   dabb4c8..2abf2b1  master -> master$ git pull origin master\n\nremote: Counting objects: 10, done.\nremote: Compressing objects: 100% (4/4), done.\nremote: Total 6 (delta 2), reused 6 (delta 2)\nUnpacking objects: 100% (6/6), done.\nFrom https://github.com/vlad/planets\n * branch            master     -> FETCH_HEAD\nUpdating dabb4c8..2abf2b1\nFast-forward\n mars.txt | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)$ cat mars.txt\n\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nWe removed the conflict on this line$ head --bytes 1024 /dev/urandom > mars.jpg\n$ ls -lh mars.jpg\n\n\n-rw-r--r-- 1 vlad 57095 1.0K Mar  8 20:24 mars.jpg$ git add mars.jpg\n$ git commit -m \"Add picture of Martian surface\"\n\n[master 8e4115c] Add picture of Martian surface\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 mars.jpg$ git push origin master\n\nTo https://github.com/vlad/planets.git\n ! [rejected]        master -> master (fetch first)\nerror: failed to push some refs to 'https://github.com/vlad/planets.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.$ git pull origin master$ git pull origin master\nremote: Counting objects: 3, done.\nremote: Compressing objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 0 (delta 0)\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/vlad/planets.git\n * branch            master     -> FETCH_HEAD\n   6a67967..439dc8c  master     -> origin/master\nwarning: Cannot merge binary files: mars.jpg (HEAD vs. 439dc8c08869c342438f6dc4a2b615b05b93c76e)\nAuto-merging mars.jpg\nCONFLICT (add/add): Merge conflict in mars.jpg\nAutomatic merge failed; fix conflicts and then commit the result.warning: Cannot merge binary files: mars.jpg (HEAD vs. 439dc8c08869c342438f6dc4a2b615b05b93c76e)$ git checkout HEAD mars.jpg\n$ git add mars.jpg\n$ git commit -m \"Use image of surface instead of sky\"\n\n[master 21032c3] Use image of surface instead of sky$ git checkout 439dc8c0 mars.jpg\n$ git add mars.jpg\n$ git commit -m \"Use image of sky instead of surface\"\n\n[master da21b34] Use image of sky instead of surface$ git checkout HEAD mars.jpg\n$ git mv mars.jpg mars-surface.jpg\n$ git checkout 439dc8c0 mars.jpg\n$ mv mars.jpg mars-sky.jpg$ git rm mars.jpg\n$ git add mars-surface.jpg\n$ git add mars-sky.jpg\n$ git commit -m \"Use two images: surface and sky\"\n\n[master 94ae08c] Use two images: surface and sky\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 mars-sky.jpg\n rename mars.jpg => mars-surface.jpg (100%)"},{"path":"git-open.html","id":"git-open","chapter":"17 .  공개 과학 (Open Science)","heading":"17 .  공개 과학 (Open Science)","text":"“공개(open)”의 반대는 “폐쇄(closed)”가 아니다. (opposite “open” isn’t “closed”.)\n“공개(open)”의 반대는 “망한(broken)” 것이다. (opposite “open” “broken”.)정보의 자유 공유는 과학에서 이상적일지 모르지만, 현실은 좀더 복잡하다. 현재, 보통 실무사례는 다음과 같다:과학자가 데이터를 수집하고 학과에 가끔 백업되는 컴퓨터에 저장한다.데이터를 분석하기 위해서 작은 프로그램을 작성하고 수정한다. (프로그램도 연구원의 로컬 노트북에 저장된다.)적당한 분석 결과가 생성되자 마자, 작성해서 논문을 제출한다.\n데이터를 논문에 포함할 수도 있다. (점점 많은 저널이 데이터를 요구한다.) 하지만, 아마도 프로그램 코드는 포함하지 않을 것이다.시간이 흐른다.저널에서는 연구원 분야의 익명으로된 소수의 사람들에게서 받아 검토(review)결과를 보낸다. 검토 결과를 충족하도록 논문을 수정한다.\n수정하는 동안에 앞서 작성한 프로그램, 스크립트를 변경해서 다시 제출한다.좀더 많은 시간이 흐른다.종국에 논문이 출판된다.\n논문에 데이터 온라인 사본 링크를 포함할 수도 있다.\n하지만, 논문은 유료로 돈을 내야만 접근가능하다는 장벽(paywall)에 막혀있다:\n개인 혹은 기관 접근 권한을 가진 사람만이 논문을 읽을 수 있다.하지만, 점점 더 많은 과학자들에게, 프로세스는 다음과 같다:과학자가 수집한 데이터가 수집되는 즉시, figshare 혹은 Zenodo같은 공개 접근 저장소에 저장된다.\n그리고 디지털 객체 식별자(Digital Object Identifier, DOI)가 부여된다.\n혹은 데이터를 이미 게시하고 Dryad에 저장한다.과학자가 작업물을 보관할 저장소를 GitHub에 생성한다.분석작업을 수행하면서, 스크립트의 변경사항을 (아마도 몇몇 산출 결과도 포함해서) 저장소에 푸쉬한다.\n논문을 위한 저장소를 다목적으로 사용한다; 이 저장소가 다른 동료 과학자와 협업하는 허브가 된다.논문 상태에 만족할 정도로 진행되면,\narXiv 혹은 다른 사전 출력 서비스에 게시하고, 다른 동료 과학자를 초대해서 피드백을 받는다.피드백에 기초해서 저널에 논문을 마지막으로 제출하기 전 몇번의 수정사항을 게시할 수도 있다.출판된 논문은 사전출판논문, 코드, 그리고 데이터 저장소의 링크를 포함한다.\n그렇게 함으로써 다른 과학자가 본인 연구의 시작점으로 삼아서 연구를 쉽게 연결해서 수행할 수 있게 된다.이러한 공개 연구 모형은 발견을 가속시킨다.\n연구 작업이 더 많이 공개될수록,\n더 많이 인용되고 재사용된다(widely cited re-used).\n하지만, 이런 방식으로 작업하고 연구하고자 하는 사람들은 실무에서 “공개(open)”가 정확하게 의미하는 바에 대해서 몇가지 결정을 내릴 필요가 있다.\n공개 과학(Open Science)에 관한 다른 측면에 대해서 이 책을 참고한다.이것이 버젼 제어(version control)를 가르치는 (많은) 이유 중의 하나다.\n버젼제어가 꾸준히 사용될 때,\n컴퓨터 작업에 대한 공유가능한 전자연구노트로 활동함으로써 “방법”에 대한 질문에 답을 한다:누가 언제 무엇을 했는지를 포함해서, 작업에 대한 개념적 단계가 문서화된다.\n모든 단계는 (커밋 ID)식별자로 도장이 찍힌다. 식별자는 의도와 목적을 갖는 중복되지 않고 유일하다.정당성(rationale), 아이디어, 다른 지적 작업에 대한 문서화를 이것에서 파생된 변경사항과 묶을 수 있다.중복되지 않고 유일하며 복구가능한 방식으로 컴퓨터 작업 결과물을 얻어서 연구에 사용할 것을 조회할 수 있다.Git같은 분산된 버젼제어 시스템으로,\n버젼제어 저장소는 영속성을 쉽게 얻을 수 있고, 전체 이력을 담아낼 수 있다.코드를 인용가능하게 만들기버젼제어 저장소에 올라온 모든 것(데이터, 코드, 논문 등)은 인용가능한 객체로 변환시킬 수 있다.\nlesson 12: 인용(Citation)에서 인용하는 방법에 대해서 학습하게 된다.내 작업을 어떻게 재현가능하게 만들 수 있을까?연구실 동료중 한명에게 논문에 나온 내용과 웹으로만\n최근에 본인이 성취한 결과를 재현할 수 있는지 물어본다.\n동료 결과물 중 하나에 대해서도 같은 작업을 수행해 본다.\n그리고 나서, 일하고 있는 연구실에 나온 결과물에 대해서도\n시도를 해본다.적절한 데이터 저장소를 찾는 방법?2~3분정도 인터넷을 검색하고 앞에서 언급된 데이터 저장소를 조사해 본다:\nFigshare, Zenodo,\nDryad.\n전공분야에 따라, 본인 전공분야별로 잘 알려진 저장소가 도움이 될 수 있다.\nNature에서 추천한 데이터 저장소도\n유용할 수 있다.주변 동료와 현재 작업에 사용하고 있는 데이터 저장소에 대해서 토론해 보고,\n이유도 설명해 보자.","code":""},{"path":"git-licensing.html","id":"git-licensing","chapter":"18 .  라이선싱 (Licensing)","heading":"18 .  라이선싱 (Licensing)","text":"","code":""},{"path":"git-licensing.html","id":"git-license-sw","chapter":"18 .  라이선싱 (Licensing)","heading":"18.1 소프트웨어 라이선스","text":"소스코드, 원고, 다른 창의적 저작물을 갖는 저장소가 공개될 때,\n저장소 기반 디렉토리에 LICENSE 혹은 LICENSE.txt 파일을 포함해서 콘텐츠가 어떤 라이선스로 이용가능한지를 명확히 기술해야된다.\n이유는 소스코드가 창의적 저작물로서, 자동적으로 지적재산(따라서 저작권)보호에 대상에 부합되기 때문이다.\n자유로이 이용가능한 것으로 보여지거나, 명시적으로 광고되는 코드는 그런 보호를 유예하지 않는다.\n따라서, 라이선스 문장이 없는 코드를 (재)사용하는 누구나 스스로 위험에 처하게 된다.\n왜냐하면 소프트웨어 코드 저자가 항상 일방향으로 재사용을 불법화할 수 있기 때문이다.\n즉, 저작권 소유자가 당신을 저작권법 위반으로 고소할 수 있다.라이선스는 그렇지 않다면 보유하지 못할 권리를 다른 사람(라이선스 허여자, licensee)에게 부여함으로써 이 문제를 해결한다.\n어떤 조건아래서 무슨 권리가 부여될지는 라이선스마다 다소 차이가 난다.\n독점적 라이선스와 대조하여, Open Source Initiative에서 공인된\n오픈 라이선스(open licences)는 최소한 다음에 나온 권리를 모두 부여한다.\n이런 권리를 오픈 소스 정의(Open Source Definition)로 부른다.:소스코드는 제약없이 이용가능하고, 사용되고, 재배포될 수 있다.\n종합 배포의 일부로서도 포함된다.변형 혹은 다른 파생 저작물도 허락되고, 또한 재배포될 수 있다.이런 권리를 누가 받느냐의 질문이 차별의 조건이 되지 않는다.\n예를 들어 상업적 혹은 학술적처럼 노력 분야에 의해서가 아님도 포함된다.특히, 지금까지 라이선스 몇개가 인기를 얻고 있는데,\nchoosealicense.com 웹사이트에서 본인 상황에 적합한\n일반적인 라이선스를 선택하는데 도움이 된다. 주요한 고려사항에는 다음이 포함된다:특허권을 주장하고자 하는가?파생 저작물을 배포하는데 다른 사람도 소스코드를 배포하도록 강제할 것인가?라이선싱하는 콘텐트가 소스코드인가?이왕이면 소스코드도 라이선스할 것인가?적절한 라이선스를 가장 잘 선택하는 것이 상당히 많은 가능한 조합이 있어 주눅이 들 수도 있다.\n실무에서, 일부 라이선스만 지금까지 가장 인기가 있고, 다음이 그 범주에 포함된다:GNU 일반공중 라이선스\n(GPL),MIT 라이선스,BSD 라이선스,아파치 라이선스, 버젼 2.0.GPL은 다른 대부분의 공개소스 라이선스와 다른데,\n전염성이 있는(infective) 특징이 있다: 코드의 수정된 버젼을 배포하는 누구나 혹은 GPL 코드를 포함한 어느 것이든지, 자신의 코드도 동일하게 자유로이 공개가능하게 만들어야 한다.흔히 사용되는 라이선서를 선택하는 것이 기여자나 사용자의 삶을 편하게 한다.\n왜냐하면, 기여자나 사용자 모두 해당 라이선스에 친숙해서 사용할 때 상당한 양의 전문용어를\n꼼꼼히 살펴볼 필요가 없기 때문이다.Open Source Initiative와 Free Software Foundation 모두\n좋은 선택이 될 수 있는 라이선스 목록을 유지관리하고 있다.코드를 작성하는 과학자 관점에서 라이선싱과 라이선싱 선택지에 대한 전반적인 정보를\n이 기사를 통해서 살펴볼 수 있다.결국 가장 중요한 것은 라이선스가 무엇인지에 대해 분명한 문장이 있는지와 라이선스가 OSI와 FSF에서 승인되고 이미 검증된 것인지 여부다.\n또한, 저장소에 공개된 것이 아닐지라도,\n처음부터 최선으로 라이선스를 선택해야 된다.\n결정을 미루는 것은 나중에 더 복잡하게 된다.\n왜냐하면, 매번 새로운 협력자가 기여하기 시작하면, 협력자도 저작권을 갖게된다.\n따라서, 라이선스를 고르자 마자, 승인을 득해야할 필요가 있기 때문이다.본인이 오픈 라이선스를 사용할 수 있나요?여러분이 작성하고 있는 소프트웨어에 오픈소스 소프트웨어 라이선스를 적용할 수 있는지 알아본다.\n여러분이 라이선스 적용을 일방적으로 할 수 있는가?\n혹은 여러분의 기관이나 조직의 다른 사람에게서 허락이 필요한가?\n만약 그렇다면 누굴까?본인은 어떤 라이선스를 이미 승인했나요?(금번 워크샵을 포함해서) 매일 사용하는 대다수 소프트웨어는 오픈-소스 소프트웨어로\n출시되었다.\n아래 목록 혹은 본인이 직접 고른 GitHub 사이트에서 프로젝트를 하나 고른다.\n라이선스를 찾아(보통 LICENSE 혹은 COPYING 이름이 붙은 파일)보고,\n소프트웨어 사용을 어떻게 제약하는지 살펴보자.\n이번 세션에서 논의된 라이선스 중 하나인가?\n차이점은 어떻게 나는가?Git, 소스코드 관리 도구CPython, 파이썬 언어 구현Jupyter, 웹기반 파이썬 노트북 프로젝트EtherPad, 실시간 협업 편집기","code":""},{"path":"git-licensing.html","id":"git-licensing-contents","chapter":"18 .  라이선싱 (Licensing)","heading":"18.2 콘텐츠 라이선스","text":"만약 저장소 콘텐츠가 소프트웨어가 아닌 데이터, 창의적 저작물(매뉴얼, 기술 보고서, 원고) 같은 연구제품이 포함되면,\n소프트웨어를 위해 설계된 라이선스 대부분은 적합하지는 못하다.데이터: 대부분 국가사법권에서 데이터 유형 대부분은 자연에 대한 사실로 간주된다.\n그럼으로, 저작권 보호를 받을 자격이 없다.(단, 아마도 사진과 의료영상정보 등은 예외)\n따라서, 저작자 표시로 사회적 혹은 학자적 기대치를 알리려고, 저작권을 정의로 주장하는 방식으로 라이선스를 사용하는 것은 단지 법적으로 혼탁한 상황만 조장할 뿐이다.\n크리에이티브 커먼즈 제로(Creative Commons Zero, CC0) 처럼 공중도메인 권리포기를 지지하는 법적 표시를 분명히 하는 것이 더 낫다. Dryad 데이터 저장소는 사실 이를 요구하고 있다.데이터: 대부분 국가사법권에서 데이터 유형 대부분은 자연에 대한 사실로 간주된다.\n그럼으로, 저작권 보호를 받을 자격이 없다.(단, 아마도 사진과 의료영상정보 등은 예외)\n따라서, 저작자 표시로 사회적 혹은 학자적 기대치를 알리려고, 저작권을 정의로 주장하는 방식으로 라이선스를 사용하는 것은 단지 법적으로 혼탁한 상황만 조장할 뿐이다.\n크리에이티브 커먼즈 제로(Creative Commons Zero, CC0) 처럼 공중도메인 권리포기를 지지하는 법적 표시를 분명히 하는 것이 더 낫다. Dryad 데이터 저장소는 사실 이를 요구하고 있다.창의적 저작물(Creative works): 매뉴얼, 보고서, 원고, 기타 창의적 저작물은 지적재산 보호 대상이 된다. 따라서 소프트웨어와 마찬가지로 자동으로 저작권으로 보호된다. 크리에이티브 커먼즈(Creative Commons) 조직이 기본 제약사항 4개를 조합해서 라이선스 집합을 마련했다:\n저작자 표시(Attribution): 파생 저작물에 대해서 최초 저작자의 이름, 출처 등의 정보를 반드시 표시해야 한다.\n변경 금지(Derivative): 저작물을 복사할 수도 있으나 저작물을 변경 혹은 저작물을 이용하여 2차적 저작물로 제작을 금한다.\n동일조건변경허락(Share Alike): 2차적 저작물을 제작할 수 있으나, 2차적 저작물은 원래 저작물과 동일한 라이선스를 적용한다.\n비영리(Noncommercial): 저작물을 영리 목적으로 사용할 수 없음. 영리 목적을 위해서는 별도의 계약이 필요하다.\n창의적 저작물(Creative works): 매뉴얼, 보고서, 원고, 기타 창의적 저작물은 지적재산 보호 대상이 된다. 따라서 소프트웨어와 마찬가지로 자동으로 저작권으로 보호된다. 크리에이티브 커먼즈(Creative Commons) 조직이 기본 제약사항 4개를 조합해서 라이선스 집합을 마련했다:저작자 표시(Attribution): 파생 저작물에 대해서 최초 저작자의 이름, 출처 등의 정보를 반드시 표시해야 한다.변경 금지(Derivative): 저작물을 복사할 수도 있으나 저작물을 변경 혹은 저작물을 이용하여 2차적 저작물로 제작을 금한다.동일조건변경허락(Share Alike): 2차적 저작물을 제작할 수 있으나, 2차적 저작물은 원래 저작물과 동일한 라이선스를 적용한다.비영리(Noncommercial): 저작물을 영리 목적으로 사용할 수 없음. 영리 목적을 위해서는 별도의 계약이 필요하다.출처표시 (CC-)와 동일조건변경허락(CC--SA) 라이선스만이 “오픈 라이선스”로 간주된다.소프트웨어 카펜트리는 가능하면 폭넓게 재사용될 수 있도록 수업자료에 대해서는 CC-, 코드에는 MIT 라이선스를 사용한다.\n다시 한번, 가장 중요한 것은 프로젝트 루트 디렉토리에 있는 LICENSE 파일에 라이선스가 무엇인지 분명하게 언급한다.\n본인 프로젝트를 참조하는 방법을 기술하는데 CITATION 혹은 CITATION.txt 파일을 포함할 수도 있다. 소프트웨어 카펜트리 사례는 다음과 같다:","code":"To reference Software Carpentry in publications, please cite both of the following:\n\nGreg Wilson: \"Software Carpentry: Lessons Learned\". arXiv:1307.5448, July 2013.\n\n@online{wilson-software-carpentry-2013,\n  author      = {Greg Wilson},\n  title       = {Software Carpentry: Lessons Learned},\n  version     = {1},\n  date        = {2013-07-20},\n  eprinttype  = {arxiv},\n  eprint      = {1307.5448}\n}"},{"path":"git-hosting.html","id":"git-hosting","chapter":"19 .  호스팅 (Hosting)","heading":"19 .  호스팅 (Hosting)","text":"저작물이나 작업을 공개하고자 하는 그룹에서 가지는 두번째 큰 질문은 코드와 데이터를 어디에 호스팅할지 정하는 것이다.\n방법중 하나는 연구실, 학과, 혹은 대학이 서버를 제공하여 계정관리와 백업 등등을 관리하는 것이다.\n주된 장점은 누가 무엇을 소유하는지 명확하다.\n특히 민감한 정보(예를 들어, 사람에 대한 실험정보 혹은 특허 출원에 사용될 수도 있는 정보)가 있다면 중요하다.\n큰 단점은 서비스 제공 비용과 수명이다:\n데이터를 수집하는데 10년을 보낸 과학자가 지금부터 10년 후에도 여전히 이용가능하기를 원하지만, 학교 인프라를 지원하는 대부분의 연구기금의 수명이 턱없이 짧다.또다른 선택지는 도메인을 구입하고 호스팅하는데 ISP(인터넷 서비스 제공자, Internet service provider)에 비용을 지불한다.\n이 접근법은 개인이나 그룹에게 좀더 많은 제어권을 주고 학교나 기관을 바꿀 때 생기는 문제도 비켜갈 수 있다.\n하지만, 위나 아래 선택지보다 초기 설정하는데 더 많은 시간과 노력이 요구된다.세번째 선택지는 GitHub, BitBucket, 혹은\nSourceForge 같은 공개 호스팅 서비스를 채용하는 것이다.\n웹 인터페이스를 통해서 저장소 코드를 생성하고, 보고, 편집할 수 있게 한다.\n이러한 서비스는 이슈추적, 위키 페이지, 이메일 통보, 코드 리뷰를 포함한 커뮤니케이션과 프로젝트 관리 도구도 제공한다.\n이러한 서비스는 규모의 경제와 네트워크 효과로 모두 이익을 볼 수 있다: 즉, 동일한 표준을 갖는 작은 많은 서비스를 실행하는 것보다 큰 서비스 하나를 실행하는 것이 더 쉽다.\n또한, 사람들이 협업하기도 더 쉽다.\n대중적인 서비스를 사용하면 이미 동일한 서비스를 사용하는 커뮤니티와 본인 프로젝트를 연결하는데 도움이 된다.예로서, 소프트웨어 카펜트리는 GitHub에 있어서,\n해당 페이지에 대한 소스코드를 찾아볼 수 있다.\nGitHub 계정을 갖는 누구나 해당 페이지에 변경사항을 제안할 수 있다.GitHub 저장소에서 Zenodo에 릴리스(release)를 연결하면\nDOI를 부여할 수도 있다.\n예를 들어, 10.5281/zenodo.57467이 “Git 소개”에 대해 주조된 DOI다.규모가 크고 잘 정립된 서비스를 사용하는 것이 빠르게 강력한 도구의 장점을 흡수하는데 도움을 줄 수도 있다.\n지속적 통합(Continuous integration, CI)이 그런 도구 중 하나로 자동으로 소프트웨어 빌드를 돌리고 코드가 커밋되거나 풀요청이 제출될 때마다 실행된다.\n온라인 호스팅 서비스와 CI를 직접 통합이 의미하는 바는, 어떤 풀요청에도 해당 정보가 존재해서 코드 완결성과 품질 표준을 유지하는데 도움을 준다.\n여전히 CI가 자가 구축한 호스팅 상황에도 이용가능하지만,\n온라인 서비스 사용과 연계되면 초기설정과 유지보수 업무를 줄일 수 있다.\n더욱이, 이러한 도구가 오픈소스 프로젝트에 무료로 제공되기도 한다.\n사설 저장소에 대해서만 비용 일부를 지불하고 이용가능하다.제도적 장벽 (Institutional Barriers)공유가 과학에는 이상적이지만,\n많은 기관에서 공유에 제약을 가한다.\n예를 들어 잠재적으로 특허가능한 지적재산을 보호하는데 말이다.\n만약 여러분이 그런 제약과 마주한다면,\n특정 프로젝트 혹은 도메인에 예외를 요청하거나,\n제도 혁파를 통해서 더 공개된 과학을 지지하도록 좀더\n앞서 나가는데 근본적인 동기에 관해 질의하는 것이 더 생산적일 수 있다.본인 작업을 공개할 수 있을까?본인 작업을 공개 저장소에 공개할 수 있는지 알아보자.\n공개 작업을 일방적으로 할 수 있을까?\n혹은 속한 조직의 누군가로부터 허락이 필요한가?\n만약 그렇다면 조직의 누굴까?본인 작업을 어디에 공개할 수 있을까?본인 논문, 데이터, 소프트웨어를 공유하려면 이용가능한 저장소가\n소속기관에 갖추어져 있는가?\n소속기관 저장소는 arXiV, figshare, GitHub GitLab와\n같은 데이터 저장소 서비스와 비교하여 어떤 차이점이 있는가?","code":""},{"path":"git-korean.html","id":"git-korean","chapter":"20 .  Git 추가설정","heading":"20 .  Git 추가설정","text":"","code":""},{"path":"git-korean.html","id":"local-PC-ssh-keys","chapter":"20 .  Git 추가설정","heading":"20.1 로컬 PC와 SSH 키(Key) 연결","text":"GitHub에 저장소(repository)를 만들고 여러 PC에서 작업을 진행할 경우 GitHub에 인증작업을 거쳐 진행하는 것이 여러모로 편리하다. 그중 하나의 방식이 공개키(public key)를 GitHub에 등록시켜 작업을 하는 것이 여기에 포함된다.먼저 윈도우를 사용할 경우 Git windows를 다운로드 받아 설치한다.ssh-keygen 명령어로 공개키/비밀키를 생성한다.생성된 공개키를 GitHub 계정에 등록시킨다.","code":""},{"path":"git-korean.html","id":"local-PC-ssh-keys-generate","chapter":"20 .  Git 추가설정","heading":"20.2 SSH 공개키/비밀키 생성 1","text":"SSH 공개키/비밀키를 생성시키고 이를 GitHub 홈페이지에 등록한다.\n먼저 ssh-keygen 명령어에 매개변수 인자를 넣고 GitHub 전자우편주소도 함께 지정한다.ssh-keygen 명령어로 생성된 키를 GitHub에 등록한다.우측상단 [Settings] → [SSH GPG keys] → [New SSH key][New SSH key]를 클릭하게 되면 Title, Key를 넣는 입력부분이 보인다.\nTitle에 식별가능한 이름을 지정하고 앞서 생성한 id_rsa.pub 내용을 Key에 복사해서 붙여넣는다.","code":"$ ssh-keygen -t rsa -C “your_email@example.com”$ cat ~/.ssh/id_rsa.pub\n\nssh-rsa AAAxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxYxY9 email_address@mail.com"},{"path":"git-korean.html","id":"local-PC-ssh-keys-commit","chapter":"20 .  Git 추가설정","heading":"20.3 첫 커밋(commit)","text":"인증작업을 완료한 후에 저장소에서 작업할 파일을 처음 커밋(commit)하는 경우 git add, git commit -m명령어를 이어서 전달시키게 되면 커밋을 때리는 사람이 누구인지를 등록하는 절차가 발생된다. git config를 통해 전자우편과 사용자명을 등록하게 되면 커밋을 정상적으로 진행시킬 수 있게 된다.","code":"$ git config --global user.email \"you@example.com\"\n$ git config --global user.name \"Your Name\""},{"path":"git-korean.html","id":"local-PC-ssh-keys-push","chapter":"20 .  Git 추가설정","heading":"20.4 비밀번호 입력없이 푸쉬(push) 2","text":"다음 단계로 비밀번호 없이 커밋된 내용을 GitHub에 전달하는 방법은 자격인증(credential) 캐싱을 통한 간단한 방법이 있다. 물론 처음에는 사용자명과 비번을 입력하는 과정을 필수적으로 거치게 된다.캐쉬에 시간제한을 두어서 7200초 즉 2시간 보안을 강화시킨다.","code":"$ git config credential.helper store\n$ git push https://github.com/repo.git\n\nUsername for 'https://github.com': <USERNAME>\nPassword for 'https://USERNAME@github.com': <PASSWORD>$ git config --global credential.helper 'cache --timeout 7200'"},{"path":"r-intro.html","id":"r-intro","chapter":"21 .  R과 RStudio 소개","heading":"21 .  R과 RStudio 소개","text":"","code":""},{"path":"r-intro.html","id":"r-motive","chapter":"21 .  R과 RStudio 소개","heading":"21.1 동기 모티브","text":"과학은 다단계 과정이다: 실험을 설계하고 데이터를 수집하게 되면, 실제로 재미난 일이 시작된다.\n이번 학습을 통해서 R과 RStudio를 사용해서 이런 과정을 시작하는 방법을 학습할 것이다.\n원데이터(raw data)로 시작해서 탐색적 데이터 분석을 수행하고 분석결과를 시각화하는 방법을 학습할 것이다.\n세월에 따른 국가별 인구 정보를 담고 있는 gapminder.org로부터 나온 데이터셋을 가지고 학습을 진행한다.\n원데이터를 R로 불러올 수 있나요? 세네갈에 대한 인구를 시각화할 수 있나요?\n아시아 대륙 국가에 대해 평균 소득을 계산할 수 있나요?\n학습 말미에는 1분도 되지 않는 시간내에 모든 국가에 대해 인구수를 시각화할 수 있게 된다.","code":""},{"path":"r-intro.html","id":"r-before","chapter":"21 .  R과 RStudio 소개","heading":"21.2 워크샵 시작 전에","text":"노트북 컴퓨터에 최신 R과 RStudio가 설치되었는지 확인한다.\n이것이 중요한데 이유는 설치된 R 버전이 최신이 아닌 경우 워크샵에 사용되는 팩키지가 제대로 설치되지 않거나 전혀 설치되지 않기 때문이다.최신 R 버전 다운로드\nRStudio 다운로드 및 설치","code":""},{"path":"r-intro.html","id":"r-rstudio","chapter":"21 .  R과 RStudio 소개","heading":"21.3 RStudio 소개","text":"소프트웨어 카펜트리 R교육에 오신 것을 환영합니다.이번 R 수업시간을 통해서, R 언어 기본기 뿐만 아니라 저녁이 있는 삶(make life easier)을 가능토록\n과학 프로젝트에 코드를 구조화하는 모범 활용사례도 교육한다.도구로 RStudio 를 사용한다: 자유로이 사용가능하고, 무료이며, 오픈 소스\nR과 통합된 개발 환경을 제공한다.\nRStudio는 편집기가 내장되어 있고, (서버 포함) 모든 플랫폼에서 동작하고,\n버젼 제어 및 프로젝트 관리 같은 많은 앞선 기능을 제공한다.기본 배치RStudio를 처음 열게 되면, 창 3개가 반갑게 여러분을 맞이한다:인터랙티브 R 콘솔 : 좌측 전체작업공간(Workspace)/이력 (History) : 우측상단 탭파일(File)/그래프(Plot)/팩키지(Package)/도움말(Help): 우측하단 탭RStudio 배치화면R 스크립트 같은 파일을 열게 되면, 편집창이 좌측 상단에 열린다..R 파일을 연 RStudio 배치화면","code":""},{"path":"r-intro.html","id":"r-rstudio-workflow","chapter":"21 .  R과 RStudio 소개","heading":"21.4 RStudio 내부 작업흐름","text":"RStudio 내부에서 작업하는 방식이 크게 두가지 있다.인터랙티브 R 콘솔에서 테스트하고 가지고 놀다가, 나중에 실행할 .R 파일에 복사해서 붙여넣는다.\n초기 시작하고 작은 테스트를 할 때 잘 작동한다.\n신속하게 노동 집약적인 개발이 된다.\n초기 시작하고 작은 테스트를 할 때 잘 작동한다.신속하게 노동 집약적인 개발이 된다..R 파일에서 작업을 시작하고, RStudio 명령어/단축키를 사용해서\n현재 라인, 선택된 라인 혹은 변경된 라인을 인터랙티브 R 콘솔에 밀어넣어 실행한다.\n시작하는 매우 훌륭한 방식이다; 작성된 모든 코드가 나중에 저장된다.\nRStudio 내부 혹은 R source() 함수를 사용해서 생성한 파일을 실행할 수 있다.\n시작하는 매우 훌륭한 방식이다; 작성된 모든 코드가 나중에 저장된다.RStudio 내부 혹은 R source() 함수를 사용해서 생성한 파일을 실행할 수 있다.꿀팁: 코드 일부 실행하기편집기 창에서 코드를 실행하는데 있어 상당한 유연성을 RStudio가 제공한다.\n버튼, 메뉴, 키보드 단축키, 세가지 방식이 있다.\n현재 라인을 실행하려면,편집기창 상단 Run 버튼을 클릭한다.“Code” 메뉴에서 “Run Lines” 를 선택한다.리눅스 혹은 윈도우에서 Ctrl+엔터(Ctrl+Return), 맥 OS X에서 Command+엔터(⌘+Return)\n단축키를 누른다. (단축키는 버튼 위에 마우스를 올리면 볼 수 있다).코드 블록을 실행하려면, 코드 블록을 선택하고 나서, Run 버튼을 누른다.\n방금전에 실행한 코드 블록 내부 일부 코드를 변경했다면,\n다시 코드 블록을 선택하고, Run 버튼을 누를 필요가 없다.\n바로 옆에 있는 버튼(Re-run previous region)을 누르면 된다.\n이 버튼은 방금전에 변경한 내용을 포함해서 이전 코드 블록을 실행시킨다.","code":""},{"path":"r-intro.html","id":"r-engine","chapter":"21 .  R과 RStudio 소개","heading":"21.5 R 소개","text":"R에서 상당한 시간을 R 인터랙티브 콘솔에서 사용한다.\n이곳이 여러분이 작성한 모든 코드를 실행하는 곳으로\nR 스크립트 파일에 추가하기 전에, 아이디어를 시험하는 유용한 환경이다.\nRStudio 콘솔은 R 명령-라인 환경에서 입력하는 곳과 동일하다.R 인터랙티브 세션에서 보게 되는 첫번째 사항은 정보가 쭉 나오고 나서,\n“>” 가 나타나고 커서가 깜빡인다.\n여러가지 면에서, 쉘 수업시간에 학습한 쉘 환경과 유사하다:\nREPL 루프(읽고, 평가하고, 출력하는 루프) 기본 아이디어 위에서 동작한다.\n명령어를 입력하면, R이 명령어를 실행하고 나서, 결과를 반환한다.","code":""},{"path":"r-intro.html","id":"r-engine-calculator","chapter":"21 .  R과 RStudio 소개","heading":"21.6 계산기로 R 사용하기","text":"R로 할 수 있는 가장 간단한 것이 산수다:R이 “[1]” 다음에 정답을 출력한다.\n지금 당장 “[1]”에 대해 걱정하지 말자. 나중에 설명이 나와 있다.\n지금은 일단 출력결과를 지칭한다고 생각한다.배쉬(bash) 처럼, 불완전한 명령어를 타이핑하면, R은 사용자가 명령어를 완성할 때까지 대기한다:1+ 다음에 엔터를 치게되면, R 세션이 “>” 대신에 “+” 을 보여준다.\n이것이 의미하는 바는 명령어가 완성될 때까지 대기한다는 것이다.\n명령어를 취소하고자 한다면, 단순히 “Esc” 키를 치게 되면, 다시 “>” 프롬프트로 되돌아 간다.꿀팁: 명령문 취소RStudio가 아니고 R 명령-라인을 사용하고 있다면, 명령문을 취소하는데\nESC 대신에 Ctrl+C(Ctrl+C) 사용이 필요하다.\n또한, 이런 사실은 맥 사용자에도 동일하게 적용된다!명령어 취소는 불완성된 명령어를 종료시키는데 그다지 유용하지는 않다:\n명령어 취소 기능을 실행되고 있는 코드를 멈추는데도 사용할 수 있다.\n(예를 들어, 예상한 것보다 훨씬 더 오래 시간이 소요되는 경우)\n혹은 현재 작성하고 있는 코드를 제거할 때도 사용한다.계산기로 R을 사용할 때, 연산 순위는 초중등학교에서 배운 것과 동일하다.가장 우선순위가 높은 것부터 낮은 순서는 다음과 같다:괄호: (, )멱승: ^ **나눗셈: /곱셈: *덧셈: +뺄셈: -괄호를 사용해서 연산작업을 한데 묶는데,\n이유는 의도한 바를 명확히 하거나, 기본설정과 차이가 날 때 평가순서를 강제하기 위해서다.꼭 필요하지 않을 때 괄호가 사용되면 읽기 힘들어 지기도 하지만,\n의도를 명확히 한다.\n나중에 여러분이 작성한 코드를 다른 사람이 읽게 됨을 기억하라.상기 코드 각 라인 뒤에 텍스트를 “주석”이라고 부른다.\n해쉬(혹은 번호기호)기호 # 다음에 오는 모든 것은 코드가 실행될 때 R에서 무시된다.매우 작거나 큰 숫자는 과학 표기법을 따른다:상기 표기법은 10^XX 곱한 것을 축약한 것이다.\n따라서, 2e-4은 2 * 10^(-4)을 축약한 것이다.숫자를 과학 표기법으로 작성할 수도 있다:","code":"\n1 + 100## [1] 101> 1 ++\n3 + 5 * 2## [1] 13\n(3 + 5) * 2## [1] 16\n(3 + (5 * (2 ^ 2))) # hard to read\n3 + 5 * 2 ^ 2       # clear, if you remember the rules\n3 + 5 * (2 ^ 2)     # if you forget some rules, this might help\n2/10000## [1] 2e-04\n5e3  # Note the lack of minus here## [1] 5000"},{"path":"r-intro.html","id":"r-math-function","chapter":"21 .  R과 RStudio 소개","heading":"21.7 수학 함수","text":"R에는 수많은 내장 수학함수가 존재한다.\n함수를 호출하려면, 함수명을 단순히 타이핑하고,\n괄호를 열고 닫으면 된다.\n괄호안에 타이핑하는 것을 함수 인자라고 부른다:R에 나온 함수 모두를 기억해야 된다는 걱정은 하지마라.\n구글이나 네이버, 다음에서 검색하면 된다.\n함수명 앞 글자를 기억하고 있다면 RStudio에서 탭 자동완성 기능을 사용한다.탭 자동완성이 R 자체 엔진보다 RStudio가 우월성을 갖는 분야로,\n자동완성 기능이 함수, 함수 인자, 함수가 전달받을 수 있는 값을 더 쉽게 찾을 수 있게 한다.명령문 앞에 ?을 타이핑하고 엔터를 치면 해당 명령어에 대한 도움말 페이지가 열린다.\n명령어에 대한 기술과 동작방식에 대한 정보를 제공할 뿐만 아니라,\n도움말 페이지 하단으로 스크롤해서 쭉 내리면 해당 명령어 사용법을 시연하는\n코드 예제가 나와 있다. 나중에 예제를 통해서 살펴볼 것이다.","code":"\nsin(1)  # 삼각함수## [1] 0.841\nlog(1)  # 자연로그## [1] 0\nlog10(10) # 지수가 10인 로그## [1] 1\nexp(0.5) # e^(1/2)## [1] 1.65"},{"path":"r-intro.html","id":"r-object","chapter":"21 .  R과 RStudio 소개","heading":"21.8 다양한 객체 비교하기","text":"R에서 비교 작업도 수행할 수 있다:꿀팁: 숫자 비교숫자 비교할 때 주의 사항: 정수가 아닌 경우, 절대로 == 비교를 사용하지 않는다.\n정수는 구체적으로 자연수만 표현할 수 있는 자료형이다.컴퓨터는 일정 정확도를 갖는 소수만 표현할 수 있다.\n그래서, R로 출력할 때 같아 보이는 두 숫자는 사실 겉으로 드러나지 않는\n표현이 다를 수 있다.따라서, 작은 오차범위(컴퓨터 허용오차, Machine Numberic Tolerance)만큼 차이가 난다\n대신에, .equal 함수를 사용한다.자세한 사항은 http://floating-point-gui.de/ 웹사이트 참조.","code":"\n1 == 1  # 같음 (\"is equal to\"로 읽음)## [1] TRUE\n1 != 2  # 같지 않음 (\"is not equal to\"로 읽음)## [1] TRUE\n1 <  2  # 보다 작음## [1] TRUE\n1 <= 1  # 작거나 같음## [1] TRUE\n1 > 0  # 보다 큼## [1] TRUE\n1 >= -9 # 같거나 큼## [1] TRUE"},{"path":"r-intro.html","id":"r-variable","chapter":"21 .  R과 RStudio 소개","heading":"21.9 변수와 대입","text":"할당 연산자(Assignment Operator), <-를 사용해서 변수에 값을 저장할 수 있다.\n예를 들어:변수에 할당하면, 값을 출력하지 않음에 유의한다.\n대신에, 나중에 사용하려고 변수라는 곳에 저장한다.\nx 변수에는 값 0.025가 담겨있다:좀더 구체적으로, 저장된 값은 부동소수점 수라고 불리는\n해당 분수를 소수 근사한 것이다.RStudio 우측 상단 창에서 Environment 탭을 클릭하면,\n변수x와 값이 저장된 것을 확인할 수 있다.\n변수 x는 숫자가 예상되는 어떤 연산작업에도 숫자자리에 사용될 수 있다:변수가 다시 할당될 수도 있음에 주목한다:x 변수에 0.025 값이 담겼지만, 현재는 담긴 값이 100 이 된다.변수에 대입되는 값에는 대입되는 변수도 포함될 수 있다:할당하는 우측편은 어떤 적법한 R 표현식도 될 수 있다.\n우측편은 대입이 일어나기 전에 완전한 평가가 이루어 진다.변수명에는 문자, 숫자, 밑줄, 구두점이 포함될 수 있다.\n변수명이 숫자로 시작되거나, 공백이 있으면 안된다.\n사람마다 긴 변수명에 대해 다른 관례를 사용한다. 다음에 관례가 나와있다.단어.사이.구두점단어_사이_밑줄낙타대문자 : camelCaseToSeparateWords어떤 관례를 사용하든 여러분 취향이지만, 일관성을 유지하라.변수에 대입할 때, 할당 = 연산자 사용도 가능하다:하지만, R 사용자 사이 그다지 많이 활용되지 않는다.\n가장 중요한 것은 사용하는 연산자에 일관성 유지하라.\n= 보다 <-을 사용하는 것이 덜 혼동스러운 경우가 있고,\n커뮤니티에서 가장 흔히 사용되는 기호다. 그래서 추천하는 것은 <- 이다.","code":"\nx <- 1/40\nx## [1] 0.025\nlog(x)## [1] -3.69\nx <- 100\nx <- x + 1 # 우측 상단 탭에서 RStudio가 x에 대한 정보가 어떻게 바뀌는지 주목한다.\nx = 1/40"},{"path":"r-intro.html","id":"r-challenge-one","chapter":"21 .  R과 RStudio 소개","heading":"21.10 도전과제 1","text":"다음 중 적법한 R 변수명은 어느것인가?도전과제 1 해답다음 사례는 R 변수로 사용될 수 있다:다음은 숨은 변수를 생성한다:다음은 변수를 생성하는데 사용할 수 없다:","code":"min_height\nmax.height\n_age\n.mass\nMaxLength\nmin-length\n2widths\ncelsius2kelvin\nmin_height\nmax.height\nMaxLength\ncelsius2kelvin\n.mass_age\nmin-length\n2widths"},{"path":"r-intro.html","id":"r-rstudio-vectorization","chapter":"21 .  R과 RStudio 소개","heading":"21.11 벡터화(Vectorization)","text":"인지해야 되는 마지막 사항은 R은 벡터화되었다는 사실이다.\n변수와 함수는 값으로 벡터를 갖을 수 있다는 의미다. 예를 들어,놀랍도록 강력한 기능이다; 이점에 대해, 다음 수업에서 좀더 깊이 다룰 예정이다.","code":"\n1:5## [1] 1 2 3 4 5\n2^(1:5)## [1]  2  4  8 16 32\nx <- 1:5\n2^x## [1]  2  4  8 16 32"},{"path":"r-intro.html","id":"r-rstudio-setup","chapter":"21 .  R과 RStudio 소개","heading":"21.12 환경 설정","text":"R 세션과 상호작용할 때 사용되는 몇가지 유용한 명령어가 있다.ls 명령어는 전역환경(작업하고 있는 R 세션)에 저장된 모든 변수와 함수 목록을 출력한다:꿀팀: 숨긴 객체유닉스 쉘처럼, ls는 기본디폴트 설정으로 “.”으로 시작되는 함수와 변수를 숨긴다.\n모든 객체 목록을 보려면, ls(.names=TRUE) 타이핑하면 된다.여기서 ls 명령어에 어떤 인자도 전달하지 않았음에 주목한다.\n하지만, R에 함수를 호출하려면 괄호는 여전히 전달해야 된다.ls만 그 자체로 타이핑하면, R은 해당 함수에 대한 소스코드만 출력한다!rm 명령어를 사용해서 더이상 사용할 필요가 없는 객체를 삭제한다:작업 환경에 너무 많은 객체가 있고, 전부 삭제하고자 한다면,\nrm 함수에 ls 결과를 전달하면 된다:상기 예제에서, 명령어 두개를 조합했다.\n연산 우선순위처럼, 가장안쪽 괄호 내부에 있는 것이 먼저 평가되고, 쭉 이어서 평가된다.상기 예제에서, ls 결과가 rm 삭제 명령어 list 인자로 사용되도록 지정했다.\n값을 이름으로 인자에 할당할 때, = 연산자를 사용해야만 한다!대신에 <-가 사용되면, 의도하지 못한 역효과가 발생되거나, 오류 메시지만 얻게 된다:꿀팁: 경고 vs. 오류R이 예상하지 못한 무언가 수행할 때 주위를 기울이다!\nR이 연산작업을 더이상 진행할 수 없을 때 상기와 같이 오류를 던진다.다른 한편으로 경고는 일반적으로 함수는 실행된다. 하지만,\n함수는 아마도 예상한 것처럼 동작하지 않을 것이다.두가지 경우 몯, R이 출력해서 전해주는 메시지가 문제 해결에 대한 단서를 줄 것이다.","code":"\nls()## [1] \"con\" \"x\"\nls## function (name, pos = -1L, envir = as.environment(pos), all.names = FALSE, \n##     pattern, sorted = TRUE) \n## {\n##     if (!missing(name)) {\n##         pos <- tryCatch(name, error = function(e) e)\n##         if (inherits(pos, \"error\")) {\n##             name <- substitute(name)\n##             if (!is.character(name)) \n##                 name <- deparse(name)\n##             warning(gettextf(\"%s converted to character string\", \n##                 sQuote(name)), domain = NA)\n##             pos <- name\n##         }\n##     }\n##     all.names <- .Internal(ls(envir, all.names, sorted))\n##     if (!missing(pattern)) {\n##         if ((ll <- length(grep(\"[\", pattern, fixed = TRUE))) && \n##             ll != length(grep(\"]\", pattern, fixed = TRUE))) {\n##             if (pattern == \"[\") {\n##                 pattern <- \"\\\\[\"\n##                 warning(\"replaced regular expression pattern '[' by  '\\\\\\\\['\")\n##             }\n##             else if (length(grep(\"[^\\\\\\\\]\\\\[<-\", pattern))) {\n##                 pattern <- sub(\"\\\\[<-\", \"\\\\\\\\\\\\[<-\", pattern)\n##                 warning(\"replaced '[<-' by '\\\\\\\\[<-' in regular expression pattern\")\n##             }\n##         }\n##         grep(pattern, all.names, value = TRUE)\n##     }\n##     else all.names\n## }\n## <bytecode: 0x000001b44b16c498>\n## <environment: namespace:base>\nrm(x)\nrm(list = ls())\nrm(list <- ls())## Error in rm(list <- ls()): ... must contain names or character strings"},{"path":"r-intro.html","id":"r-pkg","chapter":"21 .  R과 RStudio 소개","heading":"21.13 R 팩키지","text":"팩키지를 작성하거나, 누군가 작성한 팩키지를 얻어 R에 함수추가도 가능하다.\n현 저작시점에, CRAN(comprehensive R archive network)에는 13,000개 이상 팩키지가 있다.\nR과 RStudio 모두 팩키지 관리 기능이 있다:installed.packages() 타이핑하면, 어떤 팩키지가 설치되어 있는지 확인할 수 있다.install.packages(\"packagename\") 타이핑하면, 팩키지를 설치할 수 있다.\n여기서 packagename은 팩키지명칭이 된다.update.packages() 타이핑하면, 설치된 팩키지를 갱신할 수 있다.remove.packages(\"packagename\") 타이핑하면, 팩키지를 제거한다.library(packagename) 명령어로 팩키지를 사용할 수 있게 한다.","code":""},{"path":"r-intro.html","id":"r-rstudio-chellenge-two","chapter":"21 .  R과 RStudio 소개","heading":"21.14 도전과제 2","text":"다음 프로그램에 나온 각 문장을 실행하게 되면, 각 변수 값에는 무슨 값이 담겨있을까요?도전과제 2에 대한 해답실행하게 되면 mass 변수에 47.5 값이 배정된다.age 변수에 122 값이 배정된다.상기 문장은 2.3을 47.5 에 곱하여 mass 변수에\n109.25 값이 배정된다.기존 변수 age 122 값에 20을 빼서 변수 age에는 102 값이 할당된다.","code":"\nmass <- 47.5\nage <- 122\nmass <- mass * 2.3\nage <- age - 20\nmass <- 47.5\nage <- 122\nmass <- mass * 2.3\nage <- age - 20"},{"path":"r-intro.html","id":"r-rstudio-chellenge-three","chapter":"21 .  R과 RStudio 소개","heading":"21.15 도전과제 3","text":"이전 도전과제 코드를 실행하고 난 후, mass와 age를 비교하는 코드를 작성한다.\nmass와 age 중 어는 것이 더 큰가?도전과제 3에 대한 해답상기 질문에 답하는 방식은 다음과 같이 > 을 사용하는 것이다:109.25 가 102 보다 큰 경우 TRUE를 반환한다.","code":"\nmass > age## [1] TRUE"},{"path":"r-intro.html","id":"r-rstudio-chellenge-four","chapter":"21 .  R과 RStudio 소개","heading":"21.16 도전과제 4","text":"mass와 age 변수를 지워서 작업환경을 청소하자.도전과제 4에 대한 해답rm 명령어를 사용해서 청소 작업을 수행한다.","code":"\nrm(age, mass)"},{"path":"r-intro.html","id":"r-rstudio-chellenge-five","chapter":"21 .  R과 RStudio 소개","heading":"21.17 도전과제 5","text":"ggplot2, plyr, gapminder 팩키지를 설치하라.도전과제 5에 대한 해답install.packages() 명령어를 사용해서 팩키지를 설치한다.","code":"\ninstall.packages(\"ggplot2\")\ninstall.packages(\"plyr\")\ninstall.packages(\"gapminder\")"},{"path":"r-project.html","id":"r-project","chapter":"22 .  RStudio 프로젝트 관리","heading":"22 .  RStudio 프로젝트 관리","text":"","code":""},{"path":"r-project.html","id":"r-project-intro","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.1 들어가며","text":"과학적 과정은 본질적으로 증분이다.\n프로젝트 대부분은 아무렇게 적은 노트필기, 일부 코드, 그리고 나서, 원고작성, 그리고 나면\n종국에 모든 것이 함께 섞여진다.\nManaging projects reproducible fashion just make science reproducible, makes life easier.\n대부분은 다음과 같이 프로젝트를 구조화하는 경향이 있다:흔한 프로젝트 디렉토리 구조항상 이런 방식을 회피해야 되는 이유는 많다:어느 데이터 버젼이 원본이고, 어느 데이터 버젼이 변경된 것인지 분간하기 정말 힘들다;다양한 확장자를 갖는 파일과 뒤섞일 때, 정말 엉망이 된다;아마도 실제 파일을 찾고, 해당 그래프를 생성하는데 사용된 정확한 프로그램 코드와\n맞는 그림을 연결시키는데 시간이 엄청 많이 소요될 것이다.프로젝트를 잘 배치하게 되면 궁극적으로 여러분의 삶을 편안하게 만들어 줄 것이다:데이터 정합성을 보장할 것이다;작성한 코드를 다른 사람(연구실 동료, 공동연구자, 지도교수)과 더 단순하게 공유할 수 있게 만든다;논문 제출할 때 코드를 쉽게 업로드할 수 있게 한다;휴가 뒤에, 프로젝트 백업을 더 손쉽게 한다.","code":""},{"path":"r-project.html","id":"r-project-solution","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.2 가능한 해결책","text":"다행스럽게도, 작업을 효과적으로 관리할 수 있게 도움이 되는 도구와 팩키지가 있다.RStudio의 가장 강력하고 유용한 측면 중 하나가 프로젝트 관리 기능이다.\n프로젝트 관리 기능을 사용해서, 모든 것이 갖춘 재현가능한 프로젝트를 생성한다.","code":""},{"path":"r-project.html","id":"r-project-challenge-one","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.3 도전과제","text":"모든 것을 갖춘 프로젝트 생성해보자.\nRStudio에서 새로운 프로젝트를 생성한다:“File” 메뉴를 클릭하고 나서, “New Project” 선택한다.“New Directory”를 클릭한다.“Empty Project”를 클릭한다.프로젝트를 저장할 디렉토리 명칭을 타이핑한다. 예를 들어, “my_project”.“Create git repository”에 대한 체크박스가 선택되었는지 확실히 한다.“Create Project” 버튼을 클릭한다.이제 프로젝트 디렉토리에서 R을 시작하거나, RStudio로 해당 프로젝트를 열게 되면,\n프로젝트에 모든 작업은 해당 디렉토리에 완전히 담겨지게 된다.","code":""},{"path":"r-project.html","id":"r-project-best-practice","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4 프로젝트 구성 모범 사례","text":"프로젝트를 구성하는 “가장 최선의” 방식이 없지만, 프로젝트 관리를 더 수월하게 하는데\n준수해야 되는 일반적인 원칙이 몇가지 있다:","code":""},{"path":"r-project.html","id":"r-project-data-read","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4.1 데이터는 읽기 전용","text":"아마도 이것이 프로젝트 설정에 대한 가장 중요한 목적이다.\n데이터는 일반적으로 수집하는데 시간이 많이 걸리고 비용이 많이 든다.\n(엑셀처럼) 인터랙티브하게 데이터를 작업하게 되면, 필연적으로 데이터에 변형이\n일어나고 데이터 출처와, 수집이 이루어진 뒤에 어떻게\n변형되었는지 확인을 할 수 없게 된다.\n따라서, 데이터를 “읽기-전용(Read-)”으로 다룬다.","code":""},{"path":"r-project.html","id":"r-project-data-cleansing","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4.2 데이터 정제","text":"많은 경우에, 데이터가 “지저분하다”:\n상당한 전처리 과정을 거쳐야 R 형식(혹은 다른 프로그래밍 언어)으로 유용하게 사용될 수 있다.\n이런 작업이 “데이터 정제작업”(Data Munging, Data Wrangling)이라고 불린다.\n별도 디렉토리에 데이터 정제 스크립트를 보관하고,\n“정제된” 데이터셋을 보관하는 두번째 “읽기-전용” 데이터 디렉토리를 생성하는 것도 유용하다.","code":""},{"path":"r-project.html","id":"r-project-artifacts","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4.3 자동생성 산출물은 일회용품","text":"작성한 스크립트로 자동생성된 어떤 것이든 일회용품처럼 처리해만 된다:\n작성한 스크립트가 모두 다시 자동생성할 수 있어야만 된다.자동출력된 산출물을 관리하는 다른 방식은 많다.\n각기 다른 분석마다 다른 하위디렉토리에 출력결과를 저장하는 것이 유용하다.\n나중을 위해서 이런 접근법이 더 수월한데, 대부분의 분석이 탐색적이고, 최종 프로젝트에\n채택되지도 않기 때문이고, 일부 분석 결과는 프로젝트 중간에 공유되기도 한다.꿀팁: 과학적 컴퓨팅 위한 적정 관행Good Enough Practices Scientific Computing에서 프로젝트 구조화에 대한 다음과 같은 추천사항을 제시하고 있다:프로젝트명을 따서 자체 디렉토리를 갖도록 각 프로젝트를 배치한다.doc 디렉토리에 프로젝트와 연관된 텍스트 문서를 배치한다.data 디렉토리에 원본데이터와 메타데이터를 배치하고 results 디렉토리에 분석과정에서 생성되는 파일을 배치시킨다.src 디렉토리에 프로젝트 스크립트와 프로그램 소스 코드를 배치하고, bin 디렉토리에 로컬 컴퓨터에서 컴파일 되거나 외부에서 가져온 프로그램을 배치한다.모든 파일이름을 콘텐츠 혹은 함수를 적절히 반영하도록 이름 짓는다.","code":""},{"path":"r-project.html","id":"r-project-reuse","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4.4 재사용 함수 정의와 응용활용을 구별","text":"R로 작업하는 가장 효과적인 방법이 인터랙티브 세션에서 여러가지 작업을 하다가,\n제대로 동작하고 원하는 기능이 구현되면 .R 스크립트 파일로 명령어를 복사해서 넣는 것이다.\nhistory 명령어를 사용해서 지금까지 입력한 모든 명령어를 저장할 수도 있다.\n하지만, 명령어 90%가 시행착오라 그다지 유용하지 않을 수 있다.프로젝트가 새롭고 참신할 때, 스크립트 파일에 대체로 직접 실행되는 코드 라인이 많이 포함되어 있다.\n코드 성숙도가 높아짐에 따라, 재사용가능한 코드 덩어리를 함수로 뽑아낸다.\n이런 함수를 별도 디렉토리에 몰아 넣는 것도 좋은 아이디어다;\n여러 분석에 걸쳐 폭넓게 재사용되는 유용한 디렉토리와 분석 스크립트를 저장하는 디렉토리.꿀팁: 중복 회피하기다수 프로젝트에서 데이터와 분석 스크립트를 사용하는 경우가 있다.\n일반적으로, 중복을 피해서, 공간도 절약하고, 여러 곳에 코드를 갱신하는 수고도 회피하고자 한다.이런 경우, “기호 연결(Symbolic Link)”가 유용한다.\n본질적으로 파이시스템 어딘가 있는 파일에 대한 단축키다.\n리눅스나 맥 OS X에서는 ln -s 명령어를 사용하고,\n윈도우에서는 단축키를 생성하거나, mklink 명령어를 윈도우 터미널에서 사용한다.","code":""},{"path":"r-project.html","id":"r-project-save-data","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.4.5 데이터 디렉토리에 데이터 저장","text":"이제 멋진 디렉토리 구조를 갖추어서, data/ 디렉토리에 데이터 파일을 위치/저장한다.","code":""},{"path":"r-project.html","id":"r-project-challenge-good","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.5 도전 과제 1","text":"gapminder 데이터를 웹사이트\n에서 다운로드 한다.파일을 다운로드한다 (CTRL + S, 마우스 우클릭 -> “Save ”, 혹은 File -> “Save page ”)gapminder-FiveYearData.csv 파일명으로 저장된 것인지 확인한다.프로젝트 내부 data/ 디렉토리에 파일을 저장한다.나중에 데이터를 불러 적재하고 검사작업을 진행한다.","code":""},{"path":"r-project.html","id":"r-project-git","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.5.1 버전 제어","text":"프로젝트와 버전 제어를 사용하는 것이 중요하다.","code":""},{"path":"r-project.html","id":"r-project-challenge-two","chapter":"22 .  RStudio 프로젝트 관리","heading":"22.6 도전 과제 1","text":"데이터를 R에 올리기 전에, 프롬프트 명령라인에서 데이터셋에 대한 전반적인 아이디어를 획득하는 것이 좋다.\nR에 데이터를 올리는 방법을 결정할 때 데이터셋에 대해 더 잘 이해하는 것이 수월하게 된다.\n다음 질문에 답을 하는데 명령라인 쉘을 사용하라.\n1. 파일 크기는 얼마나 되는가?\n2. 데이터 행수는 얼마나 되는가?\n3. 데이터 파일에는 어떤 유형의 값이 저장되어 있는가?도전과게 2에 대한 해답쉘에 다음 명령어를 실행한다.:파일 크기는 80K.1705 줄이다. 데이터는 다음과 같이 생겼다:꿀팁: R Studio에서 명령라인**Tools -> Shell...** 메뉴를 통해서 RStudio에서 쉘을 띄울 수 있다.","code":"ls -lh data/gapminder_data.csv## -rw-r--r-- 1 statkclee 없음 80K May 12 23:26 data/gapminder_data.csvwc -l data/gapminder_data.csv## 1705 data/gapminder_data.csvhead data/gapminder_data.csv## country,year,pop,continent,lifeExp,gdpPercap\n## Afghanistan,1952,8425333,Asia,28.801,779.4453145\n## Afghanistan,1957,9240934,Asia,30.332,820.8530296\n## Afghanistan,1962,10267083,Asia,31.997,853.10071\n## Afghanistan,1967,11537966,Asia,34.02,836.1971382\n## Afghanistan,1972,13079460,Asia,36.088,739.9811058\n## Afghanistan,1977,14880372,Asia,38.438,786.11336\n## Afghanistan,1982,12881816,Asia,39.854,978.0114388\n## Afghanistan,1987,13867957,Asia,40.822,852.3959448\n## Afghanistan,1992,16317921,Asia,41.674,649.3413952"},{"path":"r-help.html","id":"r-help","chapter":"23 .  도움 청하기","heading":"23 .  도움 청하기","text":"","code":""},{"path":"r-help.html","id":"r-help-read","chapter":"23 .  도움 청하기","heading":"23.1 도움말 파일 읽기","text":"R과 모든 팩키지는 함수에 대한 도움말 파일을 제공한다.\n네임스페이스(인터랙티브 R 세션)에 적재된 팩키지에 있는 특정 함수에 대한 도움말은 다음과 같이 찾는다:RStudio에 도움말 페이지에 도움말이 표시된다. (혹은 R 자체로 일반 텍스트로 표시된다)각 도움말 페이지는 절(section)로 구분된다:기술(Description): 함수가 어떤 작업을 수행하는가에 대한 충분한 기술사용법(Usage): 함수 인자와 기본디폴트 설정값인자(Arguments): 각 인자가 예상하는 데이터 설명상세 설명(Details): 알고 있어야 되는 중요한 구체적인 설명값(Value): 함수가 반환하는 데이터함께 보기(See Also): 유용할 수 있는 연관된 함수.예제(Examples): 함수 사용법에 대한 예제들.함수마다 상이한 절을 갖추고 있다.\n하지만, 상기 항목이 알고 있어야 하는 핵심 내용이다.꿀팁: 도움말 파일 불러 읽어오기R에 대해 가장 기죽게 되는 한 측면이 엄청난 함수 갯수다.\n모든 함수에 대한 올바른 사용법을 기억하지 못하면,\n엄두가 나지 않을 것이다.\n운좋게도, 도움말 파일로 인해 기억할 필요가 없다!","code":"\n?function_name\nhelp(function_name)"},{"path":"r-help.html","id":"r-help-special","chapter":"23 .  도움 청하기","heading":"23.2 특수 연산자","text":"특수 연산자에 대한 도움말을 찾으려면, 인용부호를 사용한다:","code":"\n?\"<-\""},{"path":"r-help.html","id":"r-help-pkg","chapter":"23 .  도움 청하기","heading":"23.3 팩키지 도움말 얻기","text":"많은 팩키지에 “소품문(vignettes)”이 따라온다: 활용법과 풍부한 예제를 담은 문서.\n어떤 인자도 없이, vignette() 명령어를 입력하면 설치된 모든 팩키지에 대한\n모든 소품문 목록이 출력된다;\nvignette(package=\"package-name\") 명령어는 package-name 팩키지명에 대한\n이용가능한 모든 소품문 목록을 출력하고, vignette(\"vignette-name\")\n명령어는 특정된 소품문을 연다.팩키지에 어떤 소품문도 포함되지 않는다면, 일반적으로\nhelp(\"package-name\") 명령어를 타이핑해서 도움말을 얻는다.","code":""},{"path":"r-help.html","id":"r-help-function","chapter":"23 .  도움 청하기","heading":"23.4 함수가 정확하게 기억나지 않을 때","text":"함수가 어느 팩키지에 있는지 확신을 못하거나, 구체적인 철자법을 모르는 경우,\n퍼지 검색(fuzzy search)을 실행한다:","code":"\n??function_name"},{"path":"r-help.html","id":"r-help-no-idea","chapter":"23 .  도움 청하기","heading":"23.5 어디서 시작해야 될지 아무 생각이 없을 때","text":"어떤 함수 혹은 팩키지가 필요한지 모르는 경우,\nCRAN Task Views 사이트가\n좋은 시작점이 된다. 유지관리되는 팩키지 목록이 필드로 묶여 잘 정리되어 있다.","code":""},{"path":"r-help.html","id":"r-help-not-working","chapter":"23 .  도움 청하기","heading":"23.6 코드가 동작않을 때: 동료에게 도움 구함","text":"함수 사용에 어려움이 있는 경우, 10 에 9 경우에 찾는 정답이\n이미 Stack Overflow에 답글이 달려 있다.\n검색할 때 [r] 태그를 사용한다:원하는 답을 찾지 못한 경우, 동료에게 질문을 만드는데 몇가지 유용한 함수가 있다:dput() 함수는 작업하고 있는 데이터를 텍스트 파일 형식으로 덤프해서 저장한다.\n그래서 다른 사람 R 세션으로 복사해서 붙여넣기 좋게 돕는다.sessionInfo()는 R 현재 버젼 정보과 함께 적재된 팩키지 정보를 출력한다.\n이 정보가 다른 사람이 여러분 문제를 재현하고 디버그하는데 유용할 수 있다.","code":"\n?dput\nsessionInfo()## R version 4.2.0 (2022-04-22 ucrt)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 10 x64 (build 19043)\n## \n## Matrix products: default\n## \n## locale:\n## [1] LC_COLLATE=Korean_Korea.utf8  LC_CTYPE=Korean_Korea.utf8   \n## [3] LC_MONETARY=Korean_Korea.utf8 LC_NUMERIC=C                 \n## [5] LC_TIME=Korean_Korea.utf8    \n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.8     purrr_0.3.4    \n##  [5] readr_2.1.2     tidyr_1.2.0     tibble_3.1.6    ggplot2_3.3.5  \n##  [9] tidyverse_1.3.1 DBI_1.1.2      \n## \n## loaded via a namespace (and not attached):\n##  [1] Rcpp_1.0.8.3     lubridate_1.8.0  assertthat_0.2.1 digest_0.6.29   \n##  [5] utf8_1.2.2       R6_2.5.1         cellranger_1.1.0 backports_1.4.1 \n##  [9] reprex_2.0.1     RSQLite_2.2.12   evaluate_0.15    httr_1.4.2      \n## [13] pillar_1.7.0     rlang_1.0.2      readxl_1.4.0     rstudioapi_0.13 \n## [17] blob_1.2.3       jquerylib_0.1.4  rmarkdown_2.13   bit_4.0.4       \n## [21] munsell_0.5.0    broom_0.8.0      compiler_4.2.0   modelr_0.1.8    \n## [25] xfun_0.30        pkgconfig_2.0.3  htmltools_0.5.2  downlit_0.4.0   \n## [29] tidyselect_1.1.2 bookdown_0.26    fansi_1.0.3      crayon_1.5.1    \n## [33] tzdb_0.3.0       dbplyr_2.1.1     withr_2.5.0      grid_4.2.0      \n## [37] jsonlite_1.8.0   gtable_0.3.0     lifecycle_1.0.1  magrittr_2.0.3  \n## [41] scales_1.2.0     cli_3.2.0        stringi_1.7.6    cachem_1.0.6    \n## [45] fs_1.5.2         xml2_1.3.3       bslib_0.3.1      ellipsis_0.3.2  \n## [49] generics_0.1.2   vctrs_0.4.1      tools_4.2.0      bit64_4.0.5     \n## [53] glue_1.6.2       hms_1.1.1        fastmap_1.1.0    yaml_2.3.5      \n## [57] colorspace_2.0-3 rvest_1.0.2      memoise_2.0.1    knitr_1.38      \n## [61] haven_2.5.0      sass_0.4.1"},{"path":"r-help.html","id":"r-help-challenge-one","chapter":"23 .  도움 청하기","heading":"23.7 도전과제 1","text":"c 연결함수에 대한 도움말을 살펴본다.\n다음 명령어를 실행하면, 어떤 종류 벡터가 생성될 것으로 예상되는가:도전과제 1에 대한 해답c() 함수는 벡터를 생성하는데 벡터내 모든 원소는 동일한 자료형태여야 한다.\n첫번째의 경우 모든 원소는 숫자형이다. 두번째의 경우 모두 문자형이다.\n세번째의 경우 문자형이다: 숫자형은 문자로 강제변환(coerced) 된다.","code":"c(1, 2, 3)\nc('d', 'e', 'f')\nc(1, 2, 'f')`"},{"path":"r-help.html","id":"r-help-challenge-two","chapter":"23 .  도움 청하기","heading":"23.8 도전과제 2","text":"paste 함수에 대한 도움말을 살펴본다.\n나중에 이 함수를 사용할 것이다.\nsep 와 collapse 인자 사이에 차이는 무엇인가?도전과제 2에 대한 해답paste() 함수에 대한 도움말은 다음 명령어를 사용한다:sep, collapse 함수 차이는 다소 난해하다.\npaste 함수는 임의 숫자 인자를 받는데 각가은 임의 길이를 갖는 벡터가 될 수 있다.\nsep 인자는 결합되는 요소들 사이에 문자를 지정한다; 기본디폴트로 공백이 된다.\n반환되는 결과는 벡터로 된다. 반대로 collapse는 원소를 결합한 후에 해당 구분자를\n이용하여 축약되어 하나의 문자열이 된다. 예를 들어,(추가 정보가 필요한 경우,\npaste 도움말 페이지 하단에 예제를 참조한다.\n혹은 example('paste') 명령어를 실행한다.","code":"\nhelp(\"paste\")\n?paste\npaste(c(\"a\",\"b\"), \"c\")## [1] \"a c\" \"b c\"\npaste(c(\"a\",\"b\"), \"c\", sep = \",\")## [1] \"a,c\" \"b,c\"\npaste(c(\"a\",\"b\"), \"c\", collapse = \"|\")## [1] \"a c|b c\"\npaste(c(\"a\",\"b\"), \"c\", sep = \",\", collapse = \"|\")## [1] \"a,c|b,c\""},{"path":"r-help.html","id":"r-help-challenge-three","chapter":"23 .  도움 청하기","heading":"23.9 도전과제 3","text":"칼럼이 탭(“)와 소수점(”.”)으로 구분되는 csv 파일을 불러올 수 있는 함수(연관된 모수)를 찾아내는데\n도움말을 사용해보자.\n소수점 구분자에 대한 확인이 중요한데 전세계 동료와 공동작업을 한다면 더욱 그렇다.\n왜냐하면 다른 나라는 소수점 표기에 다른 관례를 사용하기 때문이다(예를 들어, 콤마 vs 점)\n힌트: ??csv 명령어를 사용해서 csv 관련 함수를 찾아낸다.도전과제 3에 대한 해답소수점 구분자를 갖는 탭 구분 파일을 읽어 오는 표준 R 함수는 read.delim()이다.\nread.table(file, sep=\"\\t\") 명령어로 작업을 수행할 수 있다.\nread.table() 함수에 소수점이 기본설정된 구분자이며,\n데이터파일에 hash (#) 문자를 갖가 포함되어 있다면 comment.char 인자도 변경해야 한다.","code":""},{"path":"r-help.html","id":"r-help-website","chapter":"23 .  도움 청하기","heading":"23.10 도움 되는 웹사이트","text":"Quick RRStudio cheat sheetsCookbook R","code":""},{"path":"r-data-structure.html","id":"r-data-structure","chapter":"24 .  자료구조","heading":"24 .  자료구조","text":"R의 가장 강력한 기능중 하나는 표형식 데이터를 다룰 수 있는 능력이다 -\n이미 스프레드쉬트나 CSV 파일을 갖고 있을 수 있다.\ndata/ 디렉토리에 feline-data.csv 파일을 생성하면서 학습을 시작해 보자:새로 생성한 feline-data.csv 파일 내부는 다음과 같다:꿀팁: R에서 텍스트 파일 편집대안으로, data/feline-data.csv 파일을 생성하는데 나노 편집기(Nano)를 사용하거나,\nRStudio File -> New File -> Text File 메뉴를 사용할 수 있다.다음 명령어를 통해서 R로 데이터를 불러 가져온다:read.table 함수를 사용해서 텍스트 파일에 저장된 표형식 데이터를 불러오는데 사용한다.\n표형식 데이터는 CSV (csv = 콤마구분 값) 같은 구분 문자(punctuation characters)로 칼럼이 구분된다.\ncsv 파일에 데이터를 구분하는데 가장 일반적으로 사용되는 구분 문자가 탭과 콤마다.\nR에서 사용의 편리성을 위해서 read.table 함수에 두가지 다른 버전 함수를 제공한다.\nread.csv가 콤마로 구분되는 데이터를 읽어들이는데 사용하고, read.delim 함수가\n탭으로 구분되는 데이터를 읽어오는데 사용된다. read.csv 함수가 둘중에 더 많이 사용된다.\n필요한 경우 read.csv, read.delim 함수 모두 구분문자를 오버라이드해서 사용하는 것도 가능하다.데이터프레임에 $ 연산자를 사용해서 칼럼을 뽑아내면서 데이터셋에서 바로 탐색을 시작하는 것도 가능하다.칼럼에 다른 연산자 적용도 할 수 있다:이번에 다음은 어떤가?상기 문장에서 발생된 것을 이해하는 것이 R로 데이터 분석을 성공적으로 수행하는데 중요하다.","code":"\ncats <- data.frame(coat = c(\"calico\", \"black\", \"tabby\"), \n                    weight = c(2.1, 5.0,3.2), \n                    likes_string = c(1, 0, 1))\nwrite.csv(x = cats, file = \"data/feline-data.csv\", row.names = FALSE)coat,weight,likes_string\ncalico,2.1,1\nblack,5.0,0\ntabby,3.2,1\ncats <- read.csv(file = \"data/feline-data.csv\")\ncats##     coat weight likes_string\n## 1 calico    2.1            1\n## 2  black    5.0            0\n## 3  tabby    3.2            1\ncats$weight## [1] 2.1 5.0 3.2\ncats$coat## [1] \"calico\" \"black\"  \"tabby\"\n## 내 고양이 몸무게가 2 kg 불었다고 다음과 같이 표현할 수 있다:\ncats$weight + 2## [1] 4.1 7.0 5.2\npaste(\"My cat is\", cats$coat)## [1] \"My cat is calico\" \"My cat is black\"  \"My cat is tabby\"\ncats$weight + cats$coat## Error in cats$weight + cats$coat: non-numeric argument to binary operator"},{"path":"r-data-structure.html","id":"data-structure-type","chapter":"24 .  자료구조","heading":"24.1 자료형","text":"2.1 더하기 \"black\"이 말이 되지 않기 때문에 마지막 문장이 오류를 뱉어낼 것이라고 추측한다면,\n제대로 이해하고 있는 것이다. 이미 자료형(data type)으로 불리는 프로그래밍의 중요한 개념에 대한\n직관을 갖추고 있는 것이다.\n데이터 자료형이 무엇인지 다음을 통해 물어보게 된다:다섯가지 주요 자료형이 있다: 실수형(double), 정수형(integer), 복소수형(complex), 논리형(logical), 문자형(character).분석이 얼마나 복잡해지냐에 관계없이, R에서 모든 데이터는 이러한 기본 자료형 중 하나로 해석된다.\n이러한 엄격함이 정말로 중요한 결과를 잉태하게 된다.사용자가 또다른 고양이에 대한 상세내용을 추가했고, 추가 정보는\ndata/feline-data_v2.csv 파일에 저장되어 있다.앞서와 마찬가지로 새로운 고양이 데이터를 불러와서 weight 칼럼에 데이터 자료형이 무엇인지 확인한다:이러면 안되는데, 고양이 몸무게가 더이상 실수형 자료형이 아니다!\n앞서 수행했던 동일한 수학연산을 취하게 되면 문제에 봉착한다:무슨 일이 일어난 걸까? R이 csv 파일을 불러올 때,\n칼럼에 모든 것이 동일한 자료형이 되는 것을 요구한다;\n칼럼에 모든 원소가 실수형으로 인식되지 않으면, 칼럼에 어떤 원소도 실수형이 될 수 없다.\n고양이 데이터를 불러온 테이블을 데이터프레임(data.frame)이라고 부르고, 자료구조(data structure)로 불리는\n첫번째 사례가 된다. 즉, 자료구조는 기본 자료형에서 R이 생성할 줄 아는 구조가 된다.class 함수를 호출해서 데이터프레임인지를 알 수 있다:R에서 데이터를 성공적으로 사용하려면, 기본 자료구조가 무엇인지, 어떻게 동작하는지 이해할 필요가 있다.\n지금으로서는 추가된 마지막 줄을 제거하고 좀더 살펴보도록 하자:feline-data.csv:RStudio로 다시 돌아와서:","code":"\ntypeof(cats$weight)## [1] \"double\"\ntypeof(3.14)## [1] \"double\"\ntypeof(1L) # The L suffix forces the number to be an integer, since by default R uses float numbers## [1] \"integer\"\ntypeof(1+1i)## [1] \"complex\"\ntypeof(TRUE)## [1] \"logical\"\ntypeof('banana')## [1] \"character\"\nfile.show(\"data/feline-data_v2.csv\")coat,weight,likes_string\ncalico,2.1,1\nblack,5.0,0\ntabby,3.2,1\ntabby,2.3 or 2.4,1\ncats <- read.csv(file=\"data/feline-data_v2.csv\")\ntypeof(cats$weight)## [1] \"character\"\ncats$weight + 2## Error in cats$weight + 2: non-numeric argument to binary operator\nclass(cats)## [1] \"data.frame\"coat,weight,likes_string\ncalico,2.1,1\nblack,5.0,0\ntabby,3.2,1\ncats <- read.csv(file=\"data/feline-data.csv\")"},{"path":"r-data-structure.html","id":"ds-coercion","chapter":"24 .  자료구조","heading":"24.2 벡터와 자료형 강제변환","text":"강제변환(Type Coercion)을 보다 잘 이해하기 위해서, 또 다른 자료구조를 만나보자: 벡터(vector).R에서 벡터는 본질적으로 무언가 순서를 갖는 리스트로, 특별한 성질을 갖는데 벡터에 모든 것은\n동일한 자료형을 갖는다는 점이다. 자료형을 지정하지 않게 되면, 기본디폴트 설정은 논리형(logical)이 되거나;\n자료형에 관계없이 공벡터를 선언할 수 있다.자료가 벡터인지 다음과 같이 확인한다:상기 명령어로부터 다소 암호스러운 출력결과가 나오는데 해당 벡터에서 발견된 기본 자료형은\n이 경우 chr 문자; 벡터에 나와있는 숫자는 벡터의 인덱스로 이 경우 [1:3];\n그리고 벡터에 실제로 들어있는 몇가지 예로, 이 경우 빈 문자열이 된다.\n유사하게 다음을 실행하게 되면;cats$weight도 벡터임을 알 수 있다 - R 데이터프레임으로 불러온 데이터 칼럼은 모두 벡터다, 그리고\n이러한 연유로 칼럼에 있는 모든 원소는 동일한 자료형을 갖게 강제하는 이유가 된다.토론 1왜 R에서는 데이터 칼럼에 무엇을 넣는지에 대해서 고집스럽게 주장을 할까?\n이러한 점은 어떻게 우리에게 도움이 될까?토론 1칼럼에 모든 것을 동일하게 둠으로써, 데이터에 관해서 단순한 가정을 할 수 있게 한다;\n만약 칼럼의 첫번째 입력값이 숫자라면, 모든 입력값을 숫자로 해석할 수 있게 되고,\n그렇게 함으로써 모든 것을 확인할 필요가 없게 된다.\n깨끗한 데이터(clean data)라고 사람들이 회자할 때, 사람들이 의미하는 것이 이러한 일관성이다.\n장기적으로 엄격한 일관성이 R에서 우리 삶을 풍요롭고 수월하게 만들 것이다.결합 함수(c())를 사용해서 벡터를 생성할 수 있다:지금까지 학습한 것을 바탕으로, 다음 문장은 어떤 결과를 출력하게 될까?이것을 자료형 강제변환(type coercion)라고 부른다.\n이것이 많은 놀라움의 원천이고, 왜 기본 자료형에 대해서 인지하고 있어야 되는 이유가 되고,\nR이 해석하는 방식도 알아야 된다.\nR에서 혼합된 자료형(상기 예제는 숫자와 문자)의 경우 단하나의 벡터로 변환시킬 때, 모든 자료를 동일한 자료형으로 강제 변환시킨다.\n다음을 생각해 보자.강제 변환규칙은 다음과 같이 적용된다: 논리형 -> 정수형 -> 숫자형 -> 복소수형 ->\n문자형. 여기서 -> 표현은 다음으로 변환된다로 읽힌다.\n이런 자동 변환규칙에 거슬러 자료형을 강제로 변환시키려면 . 함수를 사용한다:R이 기본 자료형을 다른 자료형으로 강제 변환할 때, 놀라운 일이 생겨난다!\n자료형 강제변환에 대한 핵심사항은 차치하고 중요한 점은 다음과 같다:\n본인 데이터가 생각한 바와 다르게 보인다면, 자료형 강제변환이 원인으로 지목되는 것이 당연하다;\n벡터와 데이터프레임의 칼럼 자료형이 동일하도록 확실히 하라.\n그렇지 않으면 끔찍한 놀라운 경험을 하게 될 것이다!하지만, 경우에 따라서는 자료형 강제변환이 매우 유용할 수도 있다!\n예를 들어, cats 데이터프레임 likes_string 칼럼은 숫자형이지만,\n1과, 0이 실제로 TRUE와 FALSE를 표현한다는 것을 알고 있다.\n이 경우 두 상태(TRUE 혹은 FALSE)를 갖는 논리형 자료형을 사용해야 한다.\n.logical 함수를 사용해서 칼럼을 논리형(logical)으로 ‘강제변환(coerce)’ 시킨다:결합 함수(c())는 기존 벡터에 무언가 추가하는 역할을 수행한다:숫자 순열도 생성할 수 있다:벡터에 관해 궁금한 점도 물어볼 수 있다:마지막으로, 벡터의 각 원소에 명칭을 부여하는 것도 가능하다:","code":"\nmy_vector <- vector(length = 3)\nmy_vector## [1] FALSE FALSE FALSE\nanother_vector <- vector(mode='character', length=3)\nanother_vector## [1] \"\" \"\" \"\"\nstr(another_vector)##  chr [1:3] \"\" \"\" \"\"\nstr(cats$weight)##  num [1:3] 2.1 5 3.2\ncombine_vector <- c(2,6,3)\ncombine_vector## [1] 2 6 3\nquiz_vector <- c(2,6,'3')\ncoercion_vector <- c('a', TRUE)\ncoercion_vector## [1] \"a\"    \"TRUE\"\nanother_coercion_vector <- c(0, TRUE)\nanother_coercion_vector## [1] 0 1\ncharacter_vector_example <- c('0','2','4')\ncharacter_vector_example## [1] \"0\" \"2\" \"4\"\ncharacter_coerced_to_numeric <- as.numeric(character_vector_example)\ncharacter_coerced_to_numeric## [1] 0 2 4\nnumeric_coerced_to_logical <- as.logical(character_coerced_to_numeric)\nnumeric_coerced_to_logical## [1] FALSE  TRUE  TRUE\ncats$likes_string## [1] 1 0 1\ncats$likes_string <- as.logical(cats$likes_string)\ncats$likes_string## [1]  TRUE FALSE  TRUE\nab_vector <- c('a', 'b')\nab_vector## [1] \"a\" \"b\"\ncombine_example <- c(ab_vector, 'SWC')\ncombine_example## [1] \"a\"   \"b\"   \"SWC\"\nmySeries <- 1:10\nmySeries##  [1]  1  2  3  4  5  6  7  8  9 10\nseq(10)##  [1]  1  2  3  4  5  6  7  8  9 10\nseq(1,10, by=0.1)##  [1]  1.0  1.1  1.2  1.3  1.4  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4\n## [16]  2.5  2.6  2.7  2.8  2.9  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9\n## [31]  4.0  4.1  4.2  4.3  4.4  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4\n## [46]  5.5  5.6  5.7  5.8  5.9  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9\n## [61]  7.0  7.1  7.2  7.3  7.4  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4\n## [76]  8.5  8.6  8.7  8.8  8.9  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9\n## [91] 10.0\nsequence_example <- seq(10)\nhead(sequence_example, n=2)## [1] 1 2\ntail(sequence_example, n=4)## [1]  7  8  9 10\nlength(sequence_example)## [1] 10\nclass(sequence_example)## [1] \"integer\"\ntypeof(sequence_example)## [1] \"integer\"\nmy_example <- 5:8\nnames(my_example) <- c(\"a\", \"b\", \"c\", \"d\")\nmy_example## a b c d \n## 5 6 7 8\nnames(my_example)## [1] \"a\" \"b\" \"c\" \"d\""},{"path":"r-data-structure.html","id":"r-data-structure-challenge-1","chapter":"24 .  자료구조","heading":"24.3 도전과제 1","text":"1 부터 26까지 숫자를 갖는 벡터를 생성하면서 시작해 보자.\n생성한 벡터에 2를 곱해서 다시 자신에게 할당한다.\n벡터에 부터 Z까지 이름을 부여한다.\n(힌트: LETTERS라는 내장벡터가 있다.)도전과제 1에 대한 해답","code":"\nx <- 1:26\nx <- x * 2\nnames(x) <- LETTERS"},{"path":"r-data-structure.html","id":"ds-dataframe","chapter":"24 .  자료구조","heading":"24.4 데이터프레임","text":"데이터프레임(Data Frames)의 칼럼이 벡터라고 앞에서 언급했다:말이 된다. 다음은 어떤가?","code":"\nstr(cats$weight)##  num [1:3] 2.1 5 3.2\nstr(cats$likes_string)##  logi [1:3] TRUE FALSE TRUE\nstr(cats$coat)##  Factor w/ 3 levels \"black\",\"calico\",..: 2 1 3"},{"path":"r-data-structure.html","id":"ds-factor","chapter":"24 .  자료구조","heading":"24.5 범주형","text":"또다른 중요한 자료구조가 범주형(factor)이다.\n범주형은 보통 문자 데이터처럼 생겼다.\n하지만, 일반적으로 범주형 정보를 나타내는데 사용된다.\n예를 들어, 연구중인 모든 고양이에 대한 색상을 문자열 벡터로 만들어보자:문자열 벡터를 요인형으로 바꾸면 다음과 같다:이제 R은 데이터에 3가지 가능한 범주가 있음을 파악하게 되었다 -\n하지만, 놀라운 것도 함께 수행했다; 문자열을 출력하는 대신에,\n숫자가 대량으로 출도되었다.\nR은 내부적으로 사람이 읽을 수 있는 범주를 숫자 인덱스로 치환시킨다.\n이런 기능은 대다수 통계 계산에서 범주형 데이터를 숫자형으로 표현되는 기능을 활용하기 때문에\n꼭 필요하다.","code":"\ncoats <- c('tabby', 'tortoiseshell', 'tortoiseshell', 'black', 'tabby')\ncoats## [1] \"tabby\"         \"tortoiseshell\" \"tortoiseshell\" \"black\"        \n## [5] \"tabby\"\nstr(coats)##  chr [1:5] \"tabby\" \"tortoiseshell\" \"tortoiseshell\" \"black\" \"tabby\"\nCATegories <- factor(coats)\nclass(CATegories)## [1] \"factor\"\nstr(CATegories)##  Factor w/ 3 levels \"black\",\"tabby\",..: 2 3 3 1 2\ntypeof(coats)## [1] \"character\"\ntypeof(CATegories)## [1] \"integer\""},{"path":"r-data-structure.html","id":"ds-challenge-two","chapter":"24 .  자료구조","heading":"24.6 도전과제 2","text":"cats 데이터프레임에 요인형 칼럼이 있나요? 요인형 칼럼의 이름은 무엇인가요?\n?read.csv 명령어를 사용해서 텍스트 칼럼을 요인형 대신에 문자형으로 그대로 유지시키는\n방법을 찾아내세요; 그리고 나서 cat 데이터프레임의 요인이 실제로 문자벡터임을\n확인하는 명령문을 작성하시오.도전과제 2에 대한 해답해법으로 stringAsFactors 인자를 사용하면 된다.:또다른 해법은 colClasses 인자를 사용해서 칼럼을 좀더 면밀히 제어하는 것이다.주의: 도움말 파일이 이해하기 어렵다는 학생이 다수 있다;\n도움말 파일을 이해하기 어렵다는 것이 일반적이라서,\n확신하지는 못하더라도, 문맥에 기초하여 최대한 추측하도록 용기를 주도록 한다.모형 함수에서 기준 수준(baseline level)이 무엇인지 파악하는 것이 중요하다.\n요인의 첫번째 범주로 가정하지만, 기본디폴트는 알파벳순으로 정해지게 되어 있다.\n수준을 다음과 같이 지정해서 변경할 수 있다:상기 경우 “control”를 1로, “case”를 2로 명시적으로 지정하도록 했다.\n이러한 지정이 통계 모형 결과를 해석하는데 있어 매우 중요하다.","code":"\ncats <- read.csv(file=\"data/feline-data.csv\", stringsAsFactors=FALSE)\nstr(cats$coat)\ncats <- read.csv(file=\"data/feline-data.csv\", colClasses=c(NA, NA, \"character\"))\nstr(cats$coat)\nmydata <- c(\"case\", \"control\", \"control\", \"case\")\nfactor_ordering_example <- factor(mydata, levels = c(\"control\", \"case\"))\nstr(factor_ordering_example)##  Factor w/ 2 levels \"control\",\"case\": 2 1 1 2"},{"path":"r-data-structure.html","id":"ds-list","chapter":"24 .  자료구조","heading":"24.7 리스트","text":"데이터 과학자로서 알고 있어야 되는 또다른 자료구조가 리스트(list)다.\n리스트는 다른 자료형과 비교하여 몇가지 점에서 더 단순하다.\n왜냐하면 원하는 무엇이든 넣을 수 있기 때문이다:데이터프레임에서 다소 놀라운 것을 이제 이해할 수 있다; 다음을 실행하게 되면 무슨 일이 발생될가:데이터프레임은 ‘내부적으로(hood)’ 리스트라는 것을 알 수 있다 -\n이유는 데이터프레임이 실제로 벡터와 요인으로 구성된 리스트이기 때문이다.\n벡터와 요인으로 뒤섞인 칼럼을 붙잡아 두려면, 데이터프레임은\n모든 칼럼을 유사한 표에 담을 수 있는 벡터보다 더 유연할 필요가 있다.\n다른 말로, data.frame은 모든 벡터가 동일한 길이를 갖는 특별한 리스트로\n정의할 수 있다.cats 사례에서는 정수형, 숫자형, 논리형 변수로 구성된다.\n이미 살펴봤듯이, 데이터프레임 각 칼럼은 벡터다.각 행은 다른 변수의 관측점(observation)으로 그 자체로 데이터프레임이다.\n따라서, 서로 다른 자료형을 갖는 원소로 구성되어진다.","code":"\nlist_example <- list(1, \"a\", TRUE, 1+4i)\nlist_example## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] \"a\"\n## \n## [[3]]\n## [1] TRUE\n## \n## [[4]]\n## [1] 1+4i\nanother_list <- list(title = \"Numbers\", numbers = 1:10, data = TRUE )\nanother_list## $title\n## [1] \"Numbers\"\n## \n## $numbers\n##  [1]  1  2  3  4  5  6  7  8  9 10\n## \n## $data\n## [1] TRUE\ntypeof(cats)## [1] \"list\"\ncats$coat## [1] calico black  tabby \n## Levels: black calico tabby\ncats[,1]## [1] calico black  tabby \n## Levels: black calico tabby\ntypeof(cats[,1])## [1] \"integer\"\nstr(cats[,1])##  Factor w/ 3 levels \"black\",\"calico\",..: 2 1 3\ncats[1,]##     coat weight likes_string\n## 1 calico    2.1         TRUE\ntypeof(cats[1,])## [1] \"list\"\nstr(cats[1,])## 'data.frame':    1 obs. of  3 variables:\n##  $ coat        : Factor w/ 3 levels \"black\",\"calico\",..: 2\n##  $ weight      : num 2.1\n##  $ likes_string: logi TRUE"},{"path":"r-data-structure.html","id":"ds-challenge-three","chapter":"24 .  자료구조","heading":"24.8 도전과제 3","text":"데이터프레임에서 변수와 관측점과 원소를 호출하는 미모하지만 다른 방식이 존재한다:cats[1]cats[[1]]cats$coatcats[\"coat\"]cats[1, 1]cats[, 1]cats[1, ]상기 예제를 시도해보고, 각각이 반환하는 것을 설명해 본다.\n힌트: typeof() 함수를 사용해서 각각의 경우에 반환되는 것을 꼼꼼히 살펴본다.도전과제 3에 대한 해답데이터프레임을 벡터로 구성된 리스트로 간주할 수 있다.\n단일 꺾쇠 [1]은 리스트의 첫번째 원소를 리스트로 반환한다.\n이번 경우, 데이터프레임의 첫번째 칼럼이 된다.이중 꺾쇠 [[1]]은 리스트의 원소 내용물을 반환한다.\n이번 경우, 리스트가 아닌 요인형 벡터로 첫번째 칼럼 내용물을 반환한다.명칭으로 항목을 끄집어내는데 $ 기호를 사용한다.\n_coat_가 데이터프레임의 첫번째 칼럼으로 요인형 벡터가 반환된다.[\"coat\"] 방식은 칼럼 인덱스를 명칭으로 바꾸고 동시에 꺾쇠를 사용한 경우다.\n예제 1과 마찬가지로 반환되는 객체는 리스트가 된다.단일 꺾쇠를 사용했는데 이번에는 행과 열의 좌표도 넣어 전달했다.\n반환되는 객체는 첫번째 행, 첫번째 열에 교차하는 값이 된다.\n반환되는 객체는 정수형이지만, 요인형 벡터의 일부분이라 정수값과 연관된\n라벨 “calico”도 함께 출력한다.앞선 예제와 마찬가지로 꺾쇠를 하나만 사용했고, 행과 열 좌표도 전달했다.\n행좌표를 지정하지 않은 경우, R에서 결측값은 해당 칼럼 벡터의 모든 원소로 해석된다.다시 한번, 꺽쇠를 하나만 사용했고, 행과 열 좌표도 전달했다.\n칼럼 좌표가 지정되어 있지 않기 때문에, 첫번째 행의 모든 값을 포함하는 리스트가 반환된다.","code":"\ncats[1]##     coat\n## 1 calico\n## 2  black\n## 3  tabby\ncats[[1]]## [1] calico black  tabby \n## Levels: black calico tabby\ncats$coat## [1] calico black  tabby \n## Levels: black calico tabby\ncats[\"coat\"]##     coat\n## 1 calico\n## 2  black\n## 3  tabby\ncats[1, 1]## [1] calico\n## Levels: black calico tabby\ncats[, 1]## [1] calico black  tabby \n## Levels: black calico tabby\ncats[1, ]##     coat weight likes_string\n## 1 calico    2.1         TRUE"},{"path":"r-data-structure.html","id":"ds-matrix","chapter":"24 .  자료구조","heading":"24.9 행렬","text":"마지막으로 중요한 자료형이 행렬(Matrices)이다. 0으로 가득찬 행렬을 다음과 같이 선언한다:다른 자료구조와 마찬가지로, 행렬에 질문을 다음과 같이 던질 수 있다:","code":"\nmatrix_example <- matrix(0, ncol=6, nrow=3)\nmatrix_example##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    0    0    0    0    0    0\n## [2,]    0    0    0    0    0    0\n## [3,]    0    0    0    0    0    0\nclass(matrix_example)## [1] \"matrix\" \"array\"\ntypeof(matrix_example)## [1] \"double\"\nstr(matrix_example)##  num [1:3, 1:6] 0 0 0 0 0 0 0 0 0 0 ...\ndim(matrix_example)## [1] 3 6\nnrow(matrix_example)## [1] 3\nncol(matrix_example)## [1] 6"},{"path":"r-data-structure.html","id":"ds-challenge-four","chapter":"24 .  자료구조","heading":"24.10 도전과제 4","text":"length(matrix_example) 실행결과는 어떻게 나올까?\n시도해보자.\n생각한 것과 일치하는가? 왜 그런가/ 왜 그렇지 않는가?도전과제 4에 대한 해답length(matrix_example) 실행결과는 어떻게 나올까?행렬은 차원 속성이 추가된 벡터라서,\nlength() 함수는 행렬의 전체 원소 갯수를 반환시킨다.","code":"\nmatrix_example <- matrix(0, ncol=6, nrow=3)\nlength(matrix_example)## [1] 18"},{"path":"r-data-structure.html","id":"r-challenge-five","chapter":"24 .  자료구조","heading":"24.11 도전과제 5","text":"또다른 행렬을 만들어 보자.\n이번에는 1:50 숫자를 담고 있는 칼럼이 5, 행이 10일 행렬이다.\nmatrix() 함수로 칼럼기준으로 혹은 행기준으로 채울 수 있나요?\n행과 열을 바꿔 변경할 수 있는 방법을 찾아보자.\n(힌트: matrix 도움말 문서를 참조한다!)도전과제 5에 대한 해답또다른 행렬을 만들어 보자.\n이번에는 1:50 숫자를 담고 있는 칼럼이 5, 행이 10일 행렬이다.\nmatrix() 함수로 칼럼기준으로 혹은 행기준으로 채울 수 있나요?\n행과 열을 바꿔 변경할 수 있는 방법을 찾아보자.\n(힌트: matrix 도움말 문서를 참조한다!)","code":"\nx <- matrix(1:50, ncol=5, nrow=10)\nx <- matrix(1:50, ncol=5, nrow=10, byrow = TRUE) # to fill by row"},{"path":"r-data-structure.html","id":"r-challenge-six","chapter":"24 .  자료구조","heading":"24.12 도전과제 6","text":"이번 워크샵에서 다룬 각 섹션별 문자벡터를 포함하는 길이 2을 갖는 리스트를 생성하시오.자료형(Data types)자료구조(Data structures)지금까지 살펴본 자료형(data type)과 자료구조(data structure)를 명칭으로 갖는\n문자 벡터를 채워넣는다.도전과제 6에 대한 해답주목: 칠판이나 벽에 자료형과 자료구조를 모두 적어두는 것이 도움이 될 수 있다 -\n워크샵 동안 참여자들에게 기본 자료형과 구조의 중요성을 상기할 수 있기 때문이다.","code":"\ndataTypes <- c('double', 'complex', 'integer', 'character', 'logical')\ndataStructures <- c('data.frame', 'vector', 'factor', 'list', 'matrix')\nanswer <- list(dataTypes, dataStructures)"},{"path":"r-data-structure.html","id":"r-challenge-seven","chapter":"24 .  자료구조","heading":"24.13 도전과제 7","text":"아래 행렬의 출력 결과를 생각해보자:이 행렬을 작성하는 올바른 명령어는 다음 중 무엇일까?\n직접 타이핑하기 전에 각 명령어를 살펴보고, 정답을 생각해보자.\n다른 명령어는 어던 행렬을 만들어낼지도 생각해본다.matrix(c(4, 1, 9, 5, 10, 7), nrow = 3)matrix(c(4, 9, 10, 1, 5, 7), ncol = 2, byrow = TRUE)matrix(c(4, 9, 10, 1, 5, 7), nrow = 2)matrix(c(4, 1, 9, 5, 10, 7), ncol = 2, byrow = TRUE)도전과제 7에 대한 해답아래 행렬의 출력 결과를 생각해보자:이 행렬을 작성하는 올바른 명령어는 다음 중 무엇일까?\n직접 타이핑하기 전에 각 명령어를 살펴보고, 정답을 생각해보자.\n다른 명령어는 어던 행렬을 만들어낼지도 생각해본다.","code":"##      [,1] [,2]\n## [1,]    4    1\n## [2,]    9    5\n## [3,]   10    7##      [,1] [,2]\n## [1,]    4    1\n## [2,]    9    5\n## [3,]   10    7\nmatrix(c(4, 1, 9, 5, 10, 7), ncol = 2, byrow = TRUE)"},{"path":"r-dataframe.html","id":"r-dataframe","chapter":"25 .  데이터프레임 탐색","heading":"25 .  데이터프레임 탐색","text":"현 시점에서 모든 것을 살펴봤다: 마지막 수업에서, R의 모든 기본 자료형과 자료구조에 대한 여행을 마쳤다.\n여러분이 수행하는 모든 작업은 이러한 도구를 조작하는 것이 된다.\n하지만, 거의 대부분 쇼의 진정한 스타는 데이터프레임이다 - csv 파일에 정보를 불러와서 생성시킨 테이블.\n이번 수업에서 데이터프레임으로 작업하는 방법에 대해 좀더 학습할 것이다.","code":""},{"path":"r-dataframe.html","id":"r-dataframe-add","chapter":"25 .  데이터프레임 탐색","heading":"25.1 행과 열을 추가","text":"데이터프레임의 칼럼은 벡터라는 것을 배웠다.\n따라서, 데이터는 칼럼에서 자료형의 일관성을 유지해야 한다.\n이를테면, 칼럼을 새로 추가하려면 벡터를 새로 만들어서 시작한다:age를 칼럼으로 다음과 같이 추가한다:데이터프레임의 행의 갯수와 다른 갯수를 갖는 age 벡터를 추가하게되면 추가되지 않고 오류가 발생됨에 주의한다:왜 정상동작이 되지 않을까?\nR은 테이블의 모든 행마다, 신규 칼럼에서도 원소 하나가 있길 원한다:그래서, 정상 동작하려면 nrow(cats) = length(age)이 되어야 한다.\ncats 콘텐츠를 새로운 데이터프레임으로 덮어써보자.이제 행을 추가하면 어떻게 될까?\n이미 데이터프레임의 행이 리스트라는 사실을 알고 있다:","code":"\nlibrary(tidyverse)\n\ncats <- read_csv(\"data/feline-data.csv\")\nage <- c(2, 3, 5)\ncats## # A tibble: 3 × 3\n##   coat   weight likes_string\n##   <chr>   <dbl>        <dbl>\n## 1 calico    2.1            1\n## 2 black     5              0\n## 3 tabby     3.2            1\ncbind(cats, age)##     coat weight likes_string age\n## 1 calico    2.1            1   2\n## 2  black    5.0            0   3\n## 3  tabby    3.2            1   5\nage <- c(2, 3, 5, 12)\ncbind(cats, age)## Error in data.frame(..., check.names = FALSE): arguments imply differing number of rows: 3, 4\nage <- c(2, 3)\ncbind(cats, age)## Error in data.frame(..., check.names = FALSE): arguments imply differing number of rows: 3, 2\nnrow(cats)## [1] 3\nlength(age)## [1] 2\nage <- c(2, 3, 5)\ncats <- cbind(cats, age)\nnewRow <- list(\"tortoiseshell\", 3.3, TRUE, 9)\ncats <- rbind(cats, newRow)"},{"path":"r-dataframe.html","id":"r-dataframe-factor","chapter":"25 .  데이터프레임 탐색","heading":"25.2 요인 (Factors)","text":"살펴볼 것이 하나더 있다: 요인(factor)에서 각기 다른 값을 수준(level)이라고 한다.\n요인형 “coat” 변수는 수준이 3으로 구성된다: “black”, “calico”, “tabby”.\nR은 세가지 수준 중 하나와 매칭되는 값만 받아들인다.\n완전 새로운 값을 추가하게 되면, 추가되는 신규 값은 NA가 된다.경고 메시지를 통해서 coat 요인변수에 “tortoiseshell” 값을 추가하는데 성공하지 못했다고 알려준다.\n하지만, 3.3 (숫자형), TRUE (논리형), 9 (숫자형) 모두 weight, likes_string, age 변수에\n성공적으로 추가된다. 왜냐하면 변수가 요인형이 아니라서 그렇다.\n“tortoiseshell”을 coat 요인변수에 성공적으로 추가하려면, 요인의 수준(level)로 “tortoiseshell”을 추가하면 된다:대안으로, 요인형 벡터를 문자형 벡터로 변환시키면 된다;\n요인변수의 범주를 잃게 되지만, 요인 수준을 조심스럽게 다룰 필요없이,\n칼럼에 추가하고자 하는 임의 단어를 추가하면 된다:","code":"\nlevels(cats$coat)## NULL\nlevels(cats$coat) <- c(levels(cats$coat), \"tortoiseshell\")\ncats <- rbind(cats, list(\"tortoiseshell\", 3.3, TRUE, 9))\nstr(cats)## 'data.frame':    5 obs. of  4 variables:\n##  $ coat        : Factor w/ 1 level \"tortoiseshell\": NA NA NA 1 1\n##  $ weight      : num  2.1 5 3.2 3.3 3.3\n##  $ likes_string: num  1 0 1 1 1\n##  $ age         : num  2 3 5 9 9\ncats$coat <- as.character(cats$coat)\nstr(cats)## 'data.frame':    5 obs. of  4 variables:\n##  $ coat        : chr  NA NA NA \"tortoiseshell\" ...\n##  $ weight      : num  2.1 5 3.2 3.3 3.3\n##  $ likes_string: num  1 0 1 1 1\n##  $ age         : num  2 3 5 9 9"},{"path":"r-dataframe.html","id":"r-dataframe-challenge-one","chapter":"25 .  데이터프레임 탐색","heading":"25.3 도전과제 1","text":"cats$age 벡터에 7을 곱해서 human_age 벡터를 생성하자.human_age를 요인형으로 변환시키자..numeric() 함수를 사용해서 human_age 벡털르 다시 숫자형 벡터로 변환시킨다.\n이제 7로 나눠서 원래 고양이 나이로 되돌리자. 무슨 일이 생겼는지 설명하자.도전과제 1에 대한 해답human_age <- cats$age * 7human_age <- factor(human_age). .factor(human_age) works just well..numeric(human_age)을 실행하면 1 2 3 4 4이 된다.왜냐하면 요인형 변수는 정수형(여기서 1:4)으로 자료를 저장하기 때문이다.\n정수 라벨과 연관된 값은 여기서 28, 35, 56, 63이다.\n요인형 변수를 숫자형 벡터로 변환시키면 라벨이 아니라 그 밑단의 정수를 반환시킨다.\n원래 숫자를 원하는 경우, human_age를 문자형 벡터로 변환시키고 나서 숫자형 벡터로 변환시키면 된다.(왜 이방식은 정장 동작할까?)\n실수로 숫자만 담긴 칼럼 어딘가 문자가 포함된 csv 파일로 작업할 때 이런 일이 실제로 종종 일어난다.\n데이터를 불러 읽어올 때 stringsAsFactors=FALSE 설정을 잊지말자.","code":""},{"path":"r-dataframe.html","id":"r-dataframe-remove","chapter":"25 .  데이터프레임 탐색","heading":"25.4 행 제거","text":"이제 데이터프레임에 행과 열을 추가하는 방법을 알게 되었다 - 하지만,\n데이터프레임에 “tortoiseshell” 고양이를 처음으로 추가하면서, 우연히\n쓰레기 행을 추가시켰다:데이터프레임에 문제가 되는 행을 마이너스해서 빼자:-4, 다음에 아무것도 적시하지 않아서 4번째 행 전체를 제거함에 주목한다.주목: 벡터 내부에 행 다수를 넣어 한번에 행을 제거할 수도 있다: cats[c(-4,-5), ]대안으로, NA 값을 갖는 모든 행을 제거시킨다:출력결과를 cats에 다시 대입하여 변경사항이 데이터프레임이 영구히 남도록 조치한다:","code":"\ncats##            coat weight likes_string age\n## 1          <NA>    2.1            1   2\n## 2          <NA>    5.0            0   3\n## 3          <NA>    3.2            1   5\n## 4 tortoiseshell    3.3            1   9\n## 5 tortoiseshell    3.3            1   9\ncats[-4, ]##            coat weight likes_string age\n## 1          <NA>    2.1            1   2\n## 2          <NA>    5.0            0   3\n## 3          <NA>    3.2            1   5\n## 5 tortoiseshell    3.3            1   9\nna.omit(cats)##            coat weight likes_string age\n## 4 tortoiseshell    3.3            1   9\n## 5 tortoiseshell    3.3            1   9\ncats <- na.omit(cats)"},{"path":"r-dataframe.html","id":"r-dataframe-column-remove","chapter":"25 .  데이터프레임 탐색","heading":"25.5 칼럼 제거","text":"데이터프레임의 칼럼도 제거할 수 있다.\n“age” 칼럼을 제거하고자 한다면 어떨까?\n변수명과 변수 인덱스, 두가지 방식으로 칼럼을 제거할 수 있다.,-4 앞에 아무것도 없는 것에 주목한다. 모든 행을 간직한다는 의미를 갖는다.대안으로, 색인명을 사용해서 컬럼을 제거할 수도 있다.","code":"\ncats[,-4]##            coat weight likes_string\n## 4 tortoiseshell    3.3            1\n## 5 tortoiseshell    3.3            1\ndrop <- names(cats) %in% c(\"age\")\ncats[,!drop]##            coat weight likes_string\n## 4 tortoiseshell    3.3            1\n## 5 tortoiseshell    3.3            1"},{"path":"r-dataframe.html","id":"r-dataframe-rbind","chapter":"25 .  데이터프레임 탐색","heading":"25.6 dataframe 덧붙이기","text":"데이터프레임(dataframe)에 데이터를 추가시킬 때 기억할 것은 칼럼은 벡터, 행은 리스트라는 사실이다.\nrbind() 함수를 사용해서 데이터프레임 두개를 본드로 붙이듯이 결합시킬 수 있다:행명칭(rownames)이 불필요하게 복잡해져, 행명칭을 제거하면,\n자동적으로 R이 순차적으로 행명칭을 부여시킨다.","code":"\ncats <- rbind(cats, cats)\ncats##             coat weight likes_string age\n## 4  tortoiseshell    3.3            1   9\n## 5  tortoiseshell    3.3            1   9\n## 41 tortoiseshell    3.3            1   9\n## 51 tortoiseshell    3.3            1   9\nrownames(cats) <- NULL\ncats##            coat weight likes_string age\n## 1 tortoiseshell    3.3            1   9\n## 2 tortoiseshell    3.3            1   9\n## 3 tortoiseshell    3.3            1   9\n## 4 tortoiseshell    3.3            1   9"},{"path":"r-dataframe.html","id":"r-dataframe-challenge-two","chapter":"25 .  데이터프레임 탐색","heading":"25.7 도전과제 2","text":"다음 구문을 사용해서 R 내부에서 직접 데이터프레임을 새로 만들 수 있다:다음 정보를 갖는 데이터프레임을 직접 제작해 보자:이름(first name)성(last name)좋아하는 숫자rbind를 사용해서 옆사람을 항목에 추가한다.\n마지막으로 cbind()함수를 사용해서 “지금이 커피시간인가요?”라는 질문의 답을 칼럼으로 추가한다.도전과제 2에 대한 해답","code":"\ndf <- data.frame(id = c(\"a\", \"b\", \"c\"),\n                 x = 1:3,\n                 y = c(TRUE, TRUE, FALSE),\n                 stringsAsFactors = FALSE)\ndf <- data.frame(first = c(\"Grace\"),\n                 last = c(\"Hopper\"),\n                 lucky_number = c(0),\n                 stringsAsFactors = FALSE)\ndf <- rbind(df, list(\"Marie\", \"Curie\", 238) )\ndf <- cbind(df, coffeetime = c(TRUE,TRUE))"},{"path":"r-dataframe.html","id":"r-dataframe-practice","chapter":"25 .  데이터프레임 탐색","heading":"25.8 현실적인 예제","text":"지금까지 고양이 데이털르 가지고 데이터프레임 조작에 대한 기본적인 사항을 살펴봤다.\n이제 학습한 기술을 사용해서 좀더 현실적인 데이터셋을 다뤄보자.\n앞에서 다운로드 받은 gapminder 데이터셋을 불러오자:기타 팁흔히 맞닥드리는 또다른 유형의 파일이 탭구분자를 갖는 파일(.tsv)이다. 탭을 구분자로 명세하는데, \"\\\\t\"을 사용하고, read.delim() 함수로 불러 읽어온다.파일을 download.file() 함수를 사용해서 인터넷으로부터 직접 본인 컴퓨터 폴더로 다운로드할 수 있다.\nread.csv() 함수를 실행해서 다운로드 받은 파일을 읽어온다. 예를 들어,대안으로, read.csv() 함수 내부에 파일 경로를 웹주소를 치환해서 인터넷에서 직접 파일을 불러올 수도 있다.\n이런 경우 로컬 컴퓨터에 csv 파일이 전혀 저장되지 않았다는 점을 주의한다. 예를 들어,readxl 팩키지를 사용해서,\n엑셀 스프레드쉬트를 평범한 텍스트로 변환하지 않고 직접 불러올 수도 있다.gapminder 데이터셋을 좀더 살펴보자; 항상 가장 먼저 해야되는 작업은\nstr 명령어로 데이터가 어떻게 생겼는지 확인하는 것이다:typeof() 함수로 데이터프레임 칼럼 각각을 면밀히 조사할 수도 있다:데이터프레임 차원에 정보를 얻어낼 수도 있다;\nstr(gapminder) 실행결과 gapminder 데이터프레임에 관측점 1704, 변수 6개가 있음을 상기한다.\n다음 코드 실행결과는 무엇일까? 그리고 왜 그렇게 되는가?공정한 추측은 아마도 데이터프레임 길이가 행의 길이(1704)라고 보는 것이다.\n하지만, 이번에는 다르다; 데이터프레임은 벡터와 요인으로 구성된 리스트라는 사실이다:length() 함수는 6을 제시하는데, 이유는 gapminder가 6개 칼럼을 갖는 리스트로 만들어졌기 때문이다.\n데이터셋에서 행과 열 숫자를 얻는데 다음 함수를 던져보자:혹은 한번에 보려면:또한, 모든 칼럼의 칼럼명이 무엇인지 파악하고자 하면 다음과 같이 질문을 던진다:현 단계에서, R이 제시하는 구조가 우리의 직관 혹은 예상과 부합되는지 묻어보는 것이 중요하다;\n각 칼럼에 대한 기본 자료형은 이해가 되는가?\n만약 납득이 가지 않는다면, 후속 작업에서 나쁜 놀라운 사실로 전환되기 전에 문제를 해결해야 한다.\n문제를 해결하는데, R이 데이터를 이해하는 방법과 데이터를 기록할 때 엄격한 일관성(strict consistency)의\n중요성에 관해 학습한 것을 동원한다.자료형과 자료구조가 타당해 보이게 되면, 데이터를 제대로 파고들어갈 시간이 되었다.\ngapminder 데이터 처음 몇줄을 살펴보자:","code":"\ngapminder <- read.csv(\"data/gapminder_data.csv\")\ndownload.file(\"https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder_data.csv\", \n               destfile = \"data/gapminder_data.csv\")\ngapminder <- read.csv(\"data/gapminder_data.csv\")\ngapminder <- read.csv(\"https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder_data.csv\")\nstr(gapminder)## 'data.frame':    1704 obs. of  6 variables:\n##  $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n##  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n##  $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n##  $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n##  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n##  $ gdpPercap: num  779 821 853 836 740 ...\ntypeof(gapminder$year)## [1] \"integer\"\ntypeof(gapminder$country)## [1] \"character\"\nstr(gapminder$country)##  chr [1:1704] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\nlength(gapminder)## [1] 6\ntypeof(gapminder)## [1] \"list\"\nnrow(gapminder)## [1] 1704\nncol(gapminder)## [1] 6\ndim(gapminder)## [1] 1704    6\ncolnames(gapminder)## [1] \"country\"   \"year\"      \"pop\"       \"continent\" \"lifeExp\"   \"gdpPercap\"\nhead(gapminder)##       country year      pop continent lifeExp gdpPercap\n## 1 Afghanistan 1952  8425333      Asia    28.8       779\n## 2 Afghanistan 1957  9240934      Asia    30.3       821\n## 3 Afghanistan 1962 10267083      Asia    32.0       853\n## 4 Afghanistan 1967 11537966      Asia    34.0       836\n## 5 Afghanistan 1972 13079460      Asia    36.1       740\n## 6 Afghanistan 1977 14880372      Asia    38.4       786"},{"path":"r-dataframe.html","id":"r-dataframe-challenge-three","chapter":"25 .  데이터프레임 탐색","heading":"25.9 도전과제 3","text":"데이터 마지막 몇줄, 중간 몇줄을 점검하는 것도 좋은 습관이다. 그런데 어떻게 점검할 수 있을까?\n중간 몇줄을 찾아보는 것이 너무 어렵지는 않지만, 임의로 몇줄을 추출할 수도 있다. 어떻게 할 수 있을까요?** 도전과제 3에 대한 해답\n마지막 몇줄을 점검하려면, R에 내장된 함수가 있어서 상대적으로 간단하다:데이터가 온전한지(혹은 관점에 따라 데이터가 온전하지 않은지)를 점검하는데 몇줄을 추출할 수 있을까요?꿀팁: 몇가지 방법이 존재한다.중첩함수(또다른 함수에 인자로 전달되는 함수)를 사용한 해법도 있다.\n새로운 개념처럼 들리지만, 사실 이미 사용하고 있다.\nmy_dataframe[rows, cols] 명령어는 데이터프레임을 화면에 뿌려준다.\n데이터프레임에 행이 얼마나 많은지 알지 못하는데 어떻게 마지막 행을 뽑아낼 수 있을까?\nR에 내장된 함수가 있다.\n(의사) 난수를 얻어보는 것은 어떨가? R은 난수추출 함수도 갖추고 있다.분석결과를 재현가능하게 확실하게 만들려면,\n코드를 스크립트 파일에 저장해서 나중에 다시 볼 수 있어야 한다.","code":"tail(gapminder)\ntail(gapminder, n = 15)gapminder[sample(nrow(gapminder), 5), ]"},{"path":"r-dataframe.html","id":"r-dataframe-challenge-four","chapter":"25 .  데이터프레임 탐색","heading":"25.10 도전과제 4","text":"file -> new file -> R script로 가서,\ngapminder 데이터셋을 불러오는 R 스크립틀르 작성한다.\nscripts/ 디렉토리에 저장하고 버전제어 시스템에도 추가한다.\n인자로 파일 경로명을 사용해서 source() 함수를 사용해서 스크립트를 실행하라.\n(혹은 RStudio “source” 버튼을 누른다)도전과제 4에 대한 해답\nscripts/load-gapminder.R 파일에 담긴 내용물은 다음과 같다:스크립트를 실행시키면 데이터를 gapminder 변수에 적재시킨다:","code":"\ndownload.file(\"https://raw.githubusercontent.com/swcarpentry/r-novice-gapminder/gh-pages/_episodes_rmd/data/gapminder_data.csv\",\n               destfile = \"data/gapminder_data.csv\")\ngapminder <- read.csv(file = \"data/gapminder_data.csv\")\nsource(file = \"scripts/load-gapminder.R\")"},{"path":"r-dataframe.html","id":"r-dataframe-challenge-five","chapter":"25 .  데이터프레임 탐색","heading":"25.11 도전과제 5","text":"str(gapminder) 출력결과를 다시 불러오자;\n이번에는 gapminder 데이터에 대해 str() 함수가 출력하는 모든 것이 의미하는 바를 설명한다.\n지금까지 학습한 요인, 리스트와 벡터 뿐만 아니라, colnames(), dim()와 같은 함수도 동원한다.\n이해하지 못한 부분이 있다면, 주면 동료와 상의한다!도전과제 5에 대한 해답gapminder 객체는 다음 칼럼을 갖는 데이터프레임이다.\n- country continent 변수는 요인형 벡터\n- year 변수는 정수형 벡터\n- pop, lifeExp, gdpPercap 변수는 숫자형 벡터","code":""},{"path":"r-subset.html","id":"r-subset","chapter":"26 .  부분집합 추출","heading":"26 .  부분집합 추출","text":"R에는 강력한 부분집합 연산자가 다수 구비되어 있다.\n이를 완전히 익히게 되면 어떤 유형의 데이터셋에 대해서도 복잡한 연산을 수월하게 수행할 수 있게 된다.어떤 유형의 객체에서 부분집합을 뽑아낼 수 있는 방식은 6가지가 있다.\n다른 자료구조에 대한 부분집합을 뽑아내는 연산자는 3가지가 있다.R의 핵심으로 가장 많은 일은 하는 것부터 시작해본다: 원자 숫자형 벡터(atomic vector)원자 벡터(Atomic vectors)R에서 문자열, 숫자, 논리 값을 갖는 간단한 벡터를 원자(atomic) 벡터라고 부르는데 이유는 더 이상 단순화할 수 없기 때문이다.이제 가지고 놀 마루타 벡터를 생성하자. 해당 벡터 내용물을 손에 넣는 방식은 무엇인가?","code":"\nx <- c(5.4, 6.2, 7.1, 4.8, 7.5)\nnames(x) <- c('a', 'b', 'c', 'd', 'e')\nx##   a   b   c   d   e \n## 5.4 6.2 7.1 4.8 7.5"},{"path":"r-subset.html","id":"subset-index","chapter":"26 .  부분집합 추출","heading":"26.1 색인 사용 요소 접근","text":"벡터 요소를 추출하는데, 대응되는 색인을 부여하는데, 1부터 시작된다:꺾쇠 괄호 연산자는 다른 어떤 함수와 비슷한다.\n원자 벡터(행렬)에 대해, “n번째 요소를 뽑아낸다”라는 의미다.한번에 다수 요소를 뽑아낼 수도 있다:혹은, 벡터 슬라이스로 뽑아낼 수도 있다:: 연산자는 왼쪽 요소부터 우측 요소까지 연속된 숫자를 생성한다.\n예를 들어, x[1:4] 은 x[c(1,2,3,4)]와 동등하다:동일한 원소를 여러번 추출하는 것도 가능하다:벡터를 벗어난 숫자를 뽑아내려고 하면, R은 결측값을 반환한다:길이 1을 갖는 벡터로 NA가 담겨있고, 명칭도 NA다.0번째 요소를 뽑아내려고 하면, 공벡터가 반환된다:R에서 벡터 번호매기는 것은 1에서 시작대다수 프로그래밍 언어(C와 파이썬)에서, 벡터 첫번째 요소는 색인 0을 갖는다.\nR에서, 첫번째 요소는 1 이다.","code":"\nx[1]##   a \n## 5.4\nx[4]##   d \n## 4.8\nx[c(1, 3)]##   a   c \n## 5.4 7.1\nx[1:4]##   a   b   c   d \n## 5.4 6.2 7.1 4.8\n1:4## [1] 1 2 3 4\nc(1, 2, 3, 4)## [1] 1 2 3 4\nx[c(1,1,3)]##   a   a   c \n## 5.4 5.4 7.1\nx[6]## <NA> \n##   NA\nx[0]## named numeric(0)"},{"path":"r-subset.html","id":"subset-skip-remove","chapter":"26 .  부분집합 추출","heading":"26.2 요소 건너뛰고 제거","text":"벡터 색인으로 음수를 사용하면, R은 명세된 숫자를 제외한 모든 요소를 반환한다:다수 요소를 건너뛸 수도 있다:꿀팁: 연산작업 순서초보자가 범하는 일반적인 실수는 벡터 슬라이스 건너뛰기 연산을 시도할 때 일어나다.\n먼저 사람 대부분은 순열을 다음과 같이 부정연산을 통해 변경하려 한다:다소 암호스런 오류가 제시된다:하지만, 연산작업 우선수위를 기억해보자.\n: 연산자는 사실 함수다.\n그래서, 일어난 상황은 -1을 첫번째 인자로 받고, 두번째 인자로 3을 받아서,\n연속된 숫자를 생성해낸다: c(-1, 0, 1, 2, 3).\n올바른 해법은 함수 호출을 괄호로 감싸는 것이다.\n- 연산자가 결과를 도출한다:벡터에서 요소를 제거하려면, 결과를 다시 벡터에 대입할 필요가 있다:","code":"\nx[-2]##   a   c   d   e \n## 5.4 7.1 4.8 7.5\nx[c(-1, -5)]  # or x[-c(1,5)]##   b   c   d \n## 6.2 7.1 4.8\nx[-1:3]## Error in x[-1:3]: only 0's may be mixed with negative subscripts\nx[-(1:3)]##   d   e \n## 4.8 7.5\nx <- x[-4]\nx##   a   b   c   e \n## 5.4 6.2 7.1 7.5"},{"path":"r-subset.html","id":"r-subset-challenge-one","chapter":"26 .  부분집합 추출","heading":"26.3 도전과제 1","text":"다음과 같이 코드가 주어졌다:다음 출력결과를 산출하는 적어도 서로 다른 명령어 2개 제시해보자:서로 다른 정답을 찾은 후에, 작업결과를 옆 사람과 비교한다. 서로 다른 전략을 취했나요?도전과제 1에 대한 해답","code":"\nx <- c(5.4, 6.2, 7.1, 4.8, 7.5)\nnames(x) <- c('a', 'b', 'c', 'd', 'e')\nprint(x)##   a   b   c   d   e \n## 5.4 6.2 7.1 4.8 7.5##   b   c   d \n## 6.2 7.1 4.8\nx[2:4]##   b   c   d \n## 6.2 7.1 4.8\nx[-c(1,5)]##   b   c   d \n## 6.2 7.1 4.8\nx[c(2,3,4)]##   b   c   d \n## 6.2 7.1 4.8"},{"path":"r-subset.html","id":"r-subset-by-name","chapter":"26 .  부분집합 추출","heading":"26.4 명칭으로 부분집합 추출","text":"색인 대신에 명칭을 사용해서, 요소를 뽑아낼 수 있다:명칭을 사용한 것이 객체에 대한 부분집합을 뽑아내는 훨씬 더 신뢰성 있는 방식이다:\n다양한 요소 위치는 부분집합을 뽑아내는 연산자를 연결해서 적용할 때 종종 변경되지만,\n명칭은 항상 동일하게 남게 마련이다!","code":"\nx <- c(a=5.4, b=6.2, c=7.1, d=4.8, e=7.5) # we can name a vector 'on the fly'\nx[c(\"a\", \"c\")]##   a   c \n## 5.4 7.1"},{"path":"r-subset.html","id":"r-subset-by-logical","chapter":"26 .  부분집합 추출","heading":"26.5 논리 연산자 부분집합 추출","text":"부분집합을 뽑아내는데 논리 벡터를 사용할 수도 있다:비교연산자(예를 들어, >, <, ==)로 논리 벡터가 생성되기 때문에,\n이를 사용해서 간결하게 벡터 부분집합을 추출할 수 있다: 다음 문장은\n앞선 문장과 동일한 결과를 출력한다.상기 문장을 분해하면, 첫째로 x>7을 평가해서, 논리벡터\nc(FALSE, FALSE, TRUE, FALSE, TRUE)을 만들어내고,\nTRUE 값에 대응되는 벡터 x 원소를 추출하게 된다:==을 사용해서 명칭으로 색인을 두어 추출하는 방식을 모사할 수 있다\n(비교로 = 대신에 ==을 사용함을 기억한다):꿀팁: 논리 조건 조합We often want combine multiple logical\ncriteria. example, might want find countries \nlocated Asia Europe life expectancies within certain\nrange. Several operations combining logical vectors exist R:&, “logical ” operator: returns TRUE left right\nTRUE.|, “logical ” operator: returns TRUE, either left right\n() TRUE.may sometimes see && || instead & |. two-character operators\nlook first element vector ignore \nremaining elements. general use two-character\noperators data analysis; save \nprogramming, .e. deciding whether execute statement.!, “logical ” operator: converts TRUE FALSE FALSE \nTRUE. can negate single logical condition (eg !TRUE becomes\nFALSE), whole vector conditions(eg !c(TRUE, FALSE) becomes\nc(FALSE, TRUE)).Additionally, can compare elements within single vector using \nfunction (returns TRUE every element vector TRUE)\nfunction (returns TRUE one elements \nvector TRUE).\n{: .callout}","code":"\nx[c(FALSE, FALSE, TRUE, FALSE, TRUE)]##   c   e \n## 7.1 7.5\nx[x > 7]##   c   e \n## 7.1 7.5\nx[names(x) == \"a\"]##   a \n## 5.4"},{"path":"r-subset.html","id":"r-subset-challenge-two","chapter":"26 .  부분집합 추출","heading":"26.6 도전과제 2","text":"코드가 다음과 같이 주어져 있다:x 값에서 4보다 크고, 7보다 작은 것을 추출하는 코드를 작성해보자.도전과제 2에 대한 해답꿀팁: 유일무이하지 않은 명칭(Non-unique names)벡터에 원소 다수가 동일 명칭을 갖을 수 있음에 유의해야만 된다.\n(데이터프레임에서, 칼럼이 동일한 명칭을 갖을 수 있다 —\nR에서 이런 점을 회피하려고 하지만 — 하지만, 행 명칭은 유일무이해야 된다.)\n다음 예제를 고려해보자:꿀팁: 연산자에 대한 도움말 얻기인용부호 내부에 찾고자 하는 연산자를 감싸서 도움말을 검색할 수 있다:\nhelp(\"%%\") 혹은 ?\"%%\".","code":"\nx <- c(5.4, 6.2, 7.1, 4.8, 7.5)\nnames(x) <- c('a', 'b', 'c', 'd', 'e')\nprint(x)##   a   b   c   d   e \n## 5.4 6.2 7.1 4.8 7.5\nx_subset <- x[x<7 & x>4]\nprint(x_subset)##   a   b   d \n## 5.4 6.2 4.8\nx <- 1:3\nx## [1] 1 2 3\nnames(x) <- c('a', 'a', 'a')\nx## a a a \n## 1 2 3\nx['a']  # only returns first value## a \n## 1\nx[names(x) == 'a']  # returns all three values## a a a \n## 1 2 3"},{"path":"r-subset.html","id":"subset-skip-with-names","chapter":"26 .  부분집합 추출","heading":"26.7 이름 갖는 원소 건너뛰기","text":"이름을 갖는 원소를 건너뛰거나 제거하는 것은 다소 더 어렵다.\n문자열에 마이너스를 붙여 이름이 붙은 원소를 건너뛰기 하고자 한다면,\nR이 불평을 하는데, 이유는 문자열에 마이너스를 어떻게 처리할지 모르기 때문이다:하지만, != 연산자를 사용하면 논리 벡터를 생성해서 원하는 바를 쟁취할 수 있다:다수 명칭을 갖는 인덱스로 건너뛰는 것도 그리 녹록하지 않다. \"\", \"c\" 원소를 누락시키고자 한다고 가정하고, 다음과 같이 시도해 보자:R이 뭔가 작업을 수행하는데, 주의가 필요하다는 경고를 보내고, 명확히 잘못된 답을 준다(벡터에 \"c\" 원소가 여전히 포함되어 있다)!이 경우에 !=이 실제로 하는 작업은 무엇일까? 정말 좋은 질문이다.","code":"\nx <- c(a=5.4, b=6.2, c=7.1, d=4.8, e=7.5) # we start again by naming a vector 'on the fly'\nx[-\"a\"]## Error in -\"a\": invalid argument to unary operator\nx[names(x) != \"a\"]##   b   c   d   e \n## 6.2 7.1 4.8 7.5\nx[names(x)!=c(\"a\",\"c\")]##   b   c   d   e \n## 6.2 7.1 4.8 7.5"},{"path":"r-subset.html","id":"subset-recycle","chapter":"26 .  부분집합 추출","heading":"26.7.1 재사용(Recycling)","text":"다음 코드에 대해서 비교연산 구성요소에 대해서 살펴보자:names(x)[3] != \"c\"이 명백히 false일때, 왜 R은 벡터의 세번째 원소에 FALSE를 던질까?\n!=을 사용할 때, R은 왼쪽편의 각 원자와 우측편의 대응 원자와 비교를 한다.\n다른 길이를 갖는 벡털르 비교할 때 무슨 일이 일어날까?동치성 테스트한 벡터가 다른 벡터보다 길이가 짧을 때, 재사용(recycle)이 발생된다:동치성 테스트: 재사용 결과이번 사례의 경우, R은 names(x)과 매칭이 되도록 필요한만큼 c(\"\", \"c\")을 반복한다.\n즉, c(\"\",\"c\",\"\",\"c\",\"\")이 된다.\n재사용된 \"\"이 names(x)의 세번째 원소와 매칭이 되지 않기 때문에 != 값은 TRUE가 된다.\n이번 경우에, 더 긴 벡터 길이가 5라서 짧은 벡터 길이 2의 배수가 되지 않기 때문에,\nR에서 경고 메시지를 띄운다.\n운이 나빠서 names(x)에 여섯번째 원소가 포함된다면, R은 조용하게 잘못된 작업을 수행하다.\n즉, 코드를 작성했던 분이 의도하지 않는 작업을 수행한다.\n이러한 재활용 규칙은 참 발견하기 어렵고 미묘한 버그를 만들어 낼 수 있다!\nR로 하여금 정말 원하는 바(우측편의 모든 원소와 매칭되는 왼쪽의 원소를 찾아내는 바)를 수행하도록 하는 방법은 %% 연산자를 사용하는 것이다.\n%% 연산자는 좌측편의 각 원소를 탐색하는데 이번 경우 x의 명칭을 찾아보고 “해당 원소가 두번째 인자에도 존재하는가?”라고 묻는다.\n여기서는 값을 제외하고자 하기 때문에 !연산자를 사용해서 “”을 부정하는 “”이 되도록 한다:","code":"\nnames(x) != c(\"a\", \"c\")## [1] FALSE  TRUE  TRUE  TRUE  TRUE\nx[! names(x) %in% c(\"a\",\"c\") ]##   b   d   e \n## 6.2 4.8 7.5"},{"path":"r-subset.html","id":"r-subset-challenge-three","chapter":"26 .  부분집합 추출","heading":"26.8 도전과제 3","text":"리스트 특정 원소와 매칭되는 원소를 뽑아내는 작업은 데이터 분석 작업에서\n매우 흔한 일이다. 예를 들어, gapminder 데이터셋에 country와 continent\n변수가 포함되어 있다. 두 척도 간에는 어떤 공통 정보도 없다.\n동남아시아에서 정보를 추출한다고 가정해보자:\n동남아시아에 속한 모든 국가에는 TRUE가 되고, 그렇지 않는 경우는 FALSE가 되는\n논리 벡터를 생성하는 연산을 어떻게 구성할 수 있을까?\n다음 데이터를 가지고 있다고 가정하자:==만 사용하는 경우 잘못된 방식으로 경고가 뜰 것이다;\n==와 |을 사용하는 경우 투박한 방식이 된다;\n%%을 사용하는 방법이 훨씬 깔끔하다.\n세가지 방식을 적용해서 원하는 바를 얻을 수 있는지 살펴보고,\n동작하는 방식(동작하지 않는 방식)을 설명해 보라.도전과제 3에 대한 해법countries==seAsia을 사용하는 것은 문제에 대한 틀린 방식이다.이유는 \"countries == seAsia : longer object length multiple shorter object length\" 경고를 주는 것은 물론이고,\n잘못된 오답을 주는데 이유는 seAsia 벡터의 재사용 값이 country에 매칭되는 값과 제대로 대응되지 않기 때문이다.문제에 대한 투박한 (하지만, 기술적으로 맞는) 방식은 다음과 같다.(혹은 countries==seAsia[1] | countries==seAsia[2] | ...).\n이런 코딩방식은 올바른 정답을 주지만, 얼마나 어색한지 바로 알 수 있다.\n(만약 좀더 긴 목록에서 국가를 선택하게 되면 어떨까?)이번 문제에 대한 최선의 방식은 countries %% seAsia와 같이 코드를 작성하는 것이다.\n정답이기도 하고 타이핑하기 쉽고 가독성도 높다.","code":"\nseAsia <- c(\"Myanmar\",\"Thailand\",\"Cambodia\",\"Vietnam\",\"Laos\")\n## read in the gapminder data that we downloaded in episode 2\ngapminder <- read.csv(\"data/gapminder_data.csv\", header=TRUE)\n## extract the `country` column from a data frame (we'll see this later);\n## convert from a factor to a character;\n## and get just the non-repeated elements\ncountries <- unique(as.character(gapminder$country))\n (countries==\"Myanmar\" | countries==\"Thailand\" |\n countries==\"Cambodia\" | countries == \"Vietnam\" | countries==\"Laos\")"},{"path":"r-subset.html","id":"subset-special-values","chapter":"26 .  부분집합 추출","heading":"26.9 특수값 처리하기","text":"어느 지점에 다다르면, R 함수에 처리할 수 없는 결측값, 무한값, 정의되지 않는 값을 갖는 데이터와 마주하게 된다.이런 유형의 데이터를 필터링하는데 사용되는 특수 함수가 있다:.na는 벡터, 행렬, 데이터프레임에 포함된 NA 위치를 반환한다.마찬가지로, .nan 와 .infinite 함수도 NaN 와 Inf 값에 대한 동일한 작업을 수행한다..finite 함수는 NA, NaN, Inf 값을 포함하지 않는 벡터, 행렬, 데이터프레임에 대한 모든 위치정보를 반환한다.na.omit는 벡터에서 모든 결측값을 필터링해서 제외시키다.","code":""},{"path":"r-subset.html","id":"subset-factor-extraction","chapter":"26 .  부분집합 추출","heading":"26.10 요인 부분집합 추출","text":"지금까지 벡터 부분집합을 뽑아내는 다양한 방식을 탐색했다.\n다른 자료구조에 대한 부분집합은 어떻게 뽑아낼 수 있을까?요인 부분집합 뽑아내기는 벡터 부분집합 뽑아내기와 동일한 방식으로 동작한다.중요한 주의점 하나는 건너뛰는 요소가 설사 해당 범주가 요인으로 존재하지 않더라도,\n수준(level)을 제거하지 않는다는 점이다:","code":"\nf <- factor(c(\"a\", \"a\", \"b\", \"c\", \"c\", \"d\"))\nf[f == \"a\"]## [1] a a\n## Levels: a b c d\nf[f %in% c(\"b\", \"c\")]## [1] b c c\n## Levels: a b c d\nf[1:3]## [1] a a b\n## Levels: a b c d\nf[-3]## [1] a a c c d\n## Levels: a b c d"},{"path":"r-subset.html","id":"subset-matrix","chapter":"26 .  부분집합 추출","heading":"26.11 행렬 부분집합 추출","text":"행렬의 경우도 [ 함수를 사용해서 부분집합을 뽑아낸다.\n이번 경우에는 인자를 두개 사용한다: 첫번째 인자는 행에 적용되고, 두번째 인자는 칼럼에 적용된다:첫번째 혹은 두번째 인자를 공백으로 남겨놓을 수도 있는데, 모든 행 혹은 칼럼을 각각 불러올 경우 사용한다:행 혹은 칼럼 하나만 접근하고자 하면, R이 자동으로 결과값을 벡터로 전환시킨다:결과값을 행렬로 그대로 유지하고자 한다면, 세번째 인자를 명세할 필요가 있다;\ndrop = FALSE:벡터와 달리, 행렬 외부 행과 칼럼을 접근하고자 하면, R이 오류를 던진다:꿀팁: 고차원 배열다차원 배열을 다룰 때, [에 넘겨지는 각 인자가 차원에 대응된다.\n예를 들어, 3D 배열에서 첫세개 인자는 각각 행, 열, 깊이 차원에 대응된다.행렬을 까면 정말 자료형이 벡터라서, 단지 인자 하나로만 부분집합을 추출할 수도 있다:보통 유용하지는 않다. 하지만, 행렬이 열우선형식(column-major format)으로 기본디폴트 설정으로 되어있음에 주목한다.\n즉, 벡터 요소가 칼럼방향으로 배열된다는 것을 의미한다:행렬을 행우선으로 쭉 펼치고자 한다면, byrow=TRUE를 사용한다:행과 칼럼 색인 대신에 행명칭(rownames)과 열명칭(column names)을 사용해서 배열 부분집합을 뽑아낼 수 있다.","code":"\nset.seed(1)\nm <- matrix(rnorm(6*4), ncol=4, nrow=6)\nm[3:4, c(3,1)]##         [,1]   [,2]\n## [1,]  1.1249 -0.836\n## [2,] -0.0449  1.595\nm[, c(3,4)]##         [,1]    [,2]\n## [1,] -0.6212  0.8212\n## [2,] -2.2147  0.5939\n## [3,]  1.1249  0.9190\n## [4,] -0.0449  0.7821\n## [5,] -0.0162  0.0746\n## [6,]  0.9438 -1.9894\nm[3,]## [1] -0.836  0.576  1.125  0.919\nm[3, , drop=FALSE]##        [,1]  [,2] [,3]  [,4]\n## [1,] -0.836 0.576 1.12 0.919\nm[, c(3,6)]## Error in m[, c(3, 6)]: subscript out of bounds\nm[5]## [1] 0.33\nmatrix(1:6, nrow=2, ncol=3)##      [,1] [,2] [,3]\n## [1,]    1    3    5\n## [2,]    2    4    6\nmatrix(1:6, nrow=2, ncol=3, byrow=TRUE)##      [,1] [,2] [,3]\n## [1,]    1    2    3\n## [2,]    4    5    6"},{"path":"r-subset.html","id":"subset-challenge-four","chapter":"26 .  부분집합 추출","heading":"26.12 도전과제 4","text":"코드가 다음과 같이 주어져 있다:다음 중 어떤 명령어가 값 11과 14를 추출하는 하는가?. m[2,4,2,5]\nB. m[2:5]\nC. m[4:5,2]\nD. m[2,c(4,5)]도전과제 4 해답D","code":"\nm <- matrix(1:18, nrow=3, ncol=6)\nprint(m)##      [,1] [,2] [,3] [,4] [,5] [,6]\n## [1,]    1    4    7   10   13   16\n## [2,]    2    5    8   11   14   17\n## [3,]    3    6    9   12   15   18"},{"path":"r-subset.html","id":"subset-list","chapter":"26 .  부분집합 추출","heading":"26.13 리스트 부분집합 추출","text":"이제 몇가지 새로운 부분집합을 뽑아내는 연산자를 소개한다.\n리스트 부분집합을 뽑아내는데 사용되는 함수가 세가지 있다;\n원자벡터와 행렬에서 살펴본 [, 그리고 [[, $이 있다.[을 사용하면, 항상 리스트만 반환한다.\n리스트 부분집합을 뽑아내고자 하지만, 원소는 뽑아내고 싶지 않다면, 아마도 [ 연산자를 사용할 것이다.상기 명령어는 원소 하나만 갖는 리스트를 반환한다.[ 연산자를 사용해서 원자벡터에 적용한 그대로 리스트 원소를 부분집합으로 뽑아낼 수 있다.\n하지만, 리스트가 재귀적으로 되어 있지 않다면, 비교 연산자는 동작하지 않는다.\n이유는 비교 연산자가 데이터 구조 내부 개별 요소가 아닌, 리스트 각 요소에 내재한 자료구조로 되어있기 때문이다.리스트 개별 원소를 추출하려면, 이중 꺾쇠 함수를 사용한다: [[.이제 결과값이 리스트가 아닌 벡터에 주목한다.한번에 요소 하나이상을 추출할 수는 없다:요소를 건너뛰는 것도 사용할 수 없다:하지만, 명칭을 사용해서 요소에 대한 부분집합으로 뽑아내거나, 요소를 추출할 때 사용할 수 있다:$ 함수는 명칭으로 요소를 뽑아내는데 사용되는 초간편 방법이다:","code":"\nxlist <- list(a = \"Software Carpentry\", b = 1:10, data = head(iris))\nxlist[1]## $a\n## [1] \"Software Carpentry\"\nxlist[1:2]## $a\n## [1] \"Software Carpentry\"\n## \n## $b\n##  [1]  1  2  3  4  5  6  7  8  9 10\nxlist[[1]]## [1] \"Software Carpentry\"\nxlist[[1:2]]## Error in xlist[[1:2]]: subscript out of bounds\nxlist[[-1]]## Error in xlist[[-1]]: invalid negative subscript in get1index <real>\nxlist[[\"a\"]]## [1] \"Software Carpentry\"\nxlist$data##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n## 1          5.1         3.5          1.4         0.2  setosa\n## 2          4.9         3.0          1.4         0.2  setosa\n## 3          4.7         3.2          1.3         0.2  setosa\n## 4          4.6         3.1          1.5         0.2  setosa\n## 5          5.0         3.6          1.4         0.2  setosa\n## 6          5.4         3.9          1.7         0.4  setosa"},{"path":"r-subset.html","id":"subset-challenge-five","chapter":"26 .  부분집합 추출","heading":"26.14 도전과제 5","text":"리스트가 다음과 같이 주어져 있다:리스트와 벡터 부분집합을 추출하는 지식을 활용해서, xlist에서 숫자 2를 추출한다.\n힌트: 숫자 2는 리스트 “b” 항목 내부에 담겨있다.도전과제 5 해답","code":"\nxlist <- list(a = \"Software Carpentry\", b = 1:10, data = head(iris))\nxlist$b[2]## [1] 2\nxlist[[2]][2]## [1] 2\nxlist[[\"b\"]][2]## [1] 2"},{"path":"r-subset.html","id":"subset-challenge-six","chapter":"26 .  부분집합 추출","heading":"26.15 도전과제 6","text":"선형 모형이 다음과 같이 주어져 있다:잔차 자유도를 추출하라.\n힌트: attributes() 함수가 도움을 줄 것이다.도전과제 6에 대한 해법","code":"\nmod <- aov(pop ~ lifeExp, data=gapminder)\nattributes(mod) ## `df.residual` is one of the names of `mod`\nmod$df.residual"},{"path":"r-subset.html","id":"subset-dataframe","chapter":"26 .  부분집합 추출","heading":"26.16 데이터프레임","text":"데이터프레임을 까면 내부는 리스트로 구성된 것이라는 점을 기억한다.\n그래서 유사한 규칙이 적용된다. 하지만, 데이터프레임도 2차원 객체다:[함수에 인자를 하나만 넣으면 리스트와 동일하게 동작한다.\n즉, 각 리스트 요소는 칼럼에 대응된다.\n작업결과 나오는 객체는 데이터프레임이다:유사하게, [[ 함수는 칼럼 한개만 추출하는데 동작된다:명칭으로 칼럼을 추출하는데 사용되는 편리한 단축어가 $이다:인자가 두개 있는 경우, [ 함수는 행렬에 대해서와 마찬가지로 동작한다:행 하나만 부분집합으로 뽑아내면, 결과는 데이터프레임이 되는데 이유는 각 요소가 혼합된 자료형으로 구성되었기 때문이다:하지만, 단일 칼럼에 대해서 결과는 벡터다. drop = FALSE를 세번째 인자로 넣으면 바꿀 수 있다.","code":"\nhead(gapminder[3])##        pop\n## 1  8425333\n## 2  9240934\n## 3 10267083\n## 4 11537966\n## 5 13079460\n## 6 14880372\nhead(gapminder[[\"lifeExp\"]])## [1] 28.8 30.3 32.0 34.0 36.1 38.4\nhead(gapminder$year)## [1] 1952 1957 1962 1967 1972 1977\ngapminder[1:3,]##       country year      pop continent lifeExp gdpPercap\n## 1 Afghanistan 1952  8425333      Asia    28.8       779\n## 2 Afghanistan 1957  9240934      Asia    30.3       821\n## 3 Afghanistan 1962 10267083      Asia    32.0       853\ngapminder[3,]##       country year      pop continent lifeExp gdpPercap\n## 3 Afghanistan 1962 10267083      Asia      32       853"},{"path":"r-subset.html","id":"subset-challenge-seven","chapter":"26 .  부분집합 추출","heading":"26.17 도전과제 7","text":"데이터프레임 부분집합을 뽑아내는 오류가 다음에 나와 있는데 이를 버그없이 수정하라:1957년에 수집된 관측점을 뽑아내라.1에서 4를 제외한 모든 칼럼을 뽑아내라.기대수명이 80세 이상 되는 행을 추출하라.첫번째 행과 4번째 5번째 칼럼(lifeExp, gdpPercap)을 뽑아내라.고급: 2002년과 2007년에 대한 정보를 담고 있는 행을 추출하라.도전과제 7에 대한 해법데이터프레임 부분집합을 뽑아내는 오류가 다음에 나와 있는데 이를 버그없이 수정하라:1957년에 수집된 관측점을 뽑아내라.\n\n# gapminder[gapminder$year = 1957,]\ngapminder[gapminder$year == 1957,]1957년에 수집된 관측점을 뽑아내라.1에서 4를 제외한 모든 칼럼을 뽑아내라.\n\n# gapminder[,-1:4]\ngapminder[,-c(1:4)]1에서 4를 제외한 모든 칼럼을 뽑아내라.기대수명이 80세 이상 되는 행을 추출하라.\n\n# gapminder[gapminder$lifeExp > 80]\ngapminder[gapminder$lifeExp > 80,]기대수명이 80세 이상 되는 행을 추출하라.첫번째 행과 4번째 5번째 칼럼(lifeExp, gdpPercap)을 뽑아내라.\n(continent lifeExp).\n\n# gapminder[1, 4, 5]\ngapminder[1, c(4, 5)]첫번째 행과 4번째 5번째 칼럼(lifeExp, gdpPercap)을 뽑아내라.\n(continent lifeExp).고급: 2002년과 2007년에 대한 정보를 담고 있는 행을 추출하라.\n\n# gapminder[gapminder$year == 2002 | 2007,]\ngapminder[gapminder$year == 2002 | gapminder$year == 2007,]\ngapminder[gapminder$year %% c(2002, 2007),]고급: 2002년과 2007년에 대한 정보를 담고 있는 행을 추출하라.","code":"gapminder[gapminder$year = 1957,]\ngapminder[,-1:4]\ngapminder[gapminder$lifeExp > 80]\ngapminder[1, 4, 5]\ngapminder[gapminder$year == 2002 | 2007,]\n# gapminder[gapminder$year = 1957,]\ngapminder[gapminder$year == 1957,]\n# gapminder[,-1:4]\ngapminder[,-c(1:4)]\n# gapminder[gapminder$lifeExp > 80]\ngapminder[gapminder$lifeExp > 80,]\n# gapminder[1, 4, 5]\ngapminder[1, c(4, 5)]\n# gapminder[gapminder$year == 2002 | 2007,]\ngapminder[gapminder$year == 2002 | gapminder$year == 2007,]\ngapminder[gapminder$year %in% c(2002, 2007),]"},{"path":"r-subset.html","id":"subset-challenge-eight","chapter":"26 .  부분집합 추출","heading":"26.18 도전과제 8","text":"gapminder[1:20] 명령어는 왜 오류를 반환하는가?\ngapminder[1:20,]와 어떻게 다른가?gapminder_small이라는 데이터프레임을 생성하는데 1에서 9까지 행과 19에서 23까지 행만 포함한다.\n이 작업을 하나 혹은 두 단계로 작성한다.도전과제 8에 대한 해답gapminder는 데이터프레임이라, 이차원에서 부분집합을 추출할 필요가 있다. gapminder[1:20, ] 명령어는 첫 20행과 모든 칼럼을 추출한다.gapminder는 데이터프레임이라, 이차원에서 부분집합을 추출할 필요가 있다. gapminder[1:20, ] 명령어는 첫 20행과 모든 칼럼을 추출한다.","code":"\ngapminder_small <- gapminder[c(1:9, 19:23),]"},{"path":"r-control-flow.html","id":"r-control-flow","chapter":"27 .  제어 흐름","heading":"27 .  제어 흐름","text":"종종 코딩할 때, 동작 흐름을 제어하고 싶을 때가 있다.\n한 조건 혹은 조건 집합이 만족될 때만 동작이 일어나게 설정함으로써 이런 작업을 수행한다.\n또 다른 방식으로, 특정 횟수만큼 동작이 일어나도록 설정할 수도 있다.R에서 흐름을 제어하는 방식이 몇가지 있다.\n조건문에 대해서, 가장 흔히 사용되는 접근법이 루프 구성체(loop construct)다:예를 들어, 변수 x가 특정값을 갖게 되면, 메시지를 출력하게 R에게 지시할 수도 있다:콘솔에 print 출력문이 아무것도 출력시키지 않는데,\n이유는 x가 10보다 크지 않기 때문이다.10보다 작은 값에 대해 메시지를 출력시키려면,\nelse문을 추가시키면 된다.else 를 사용하면 다수 조건을 테스트할 수도 있다.중요: R이 ()문을 내부 조건을 평가할 때, 논리 요소 즉, TRUE 혹은 FALSE를 찾는다.\n초심자에게 있어 이런 점이 두통을 유발할 수도 있다. 예를 들어:x 벡터가 FALSE라서 equal 메시지가 출력된다.","code":"# if\nif (condition is true) {\n  perform action\n}\n\n# if ... else\nif (condition is true) {\n  perform action\n} else {  # that is, if the condition is false,\n  perform alternative action\n}\nx <- 8\n\nif (x >= 10) {\n  print(\"x is greater than or equal to 10\")\n}\n\nx## [1] 8\nx <- 8\n\nif (x >= 10) {\n  print(\"x is greater than or equal to 10\")\n} else {\n  print(\"x is less than 10\")\n}## [1] \"x is less than 10\"\nx <- 8\n\nif (x >= 10) {\n  print(\"x is greater than or equal to 10\")\n} else if (x > 5) {\n  print(\"x is greater than 5, but less than 10\")\n} else {\n  print(\"x is less than 5\")\n}## [1] \"x is greater than 5, but less than 10\"\nx  <-  4 == 3\nif (x) {\n  \"4 equals 3\"\n} else {\n  \"4 does not equal 3\"          \n}## [1] \"4 does not equal 3\"\nx <- 4 == 3\nx## [1] FALSE"},{"path":"r-control-flow.html","id":"r-control-flow-challenge-one","chapter":"27 .  제어 흐름","heading":"27.1 도전과제 1","text":"문을 사용해서 gapminder 데이터셋에서 2002 년부터 어떤 레코드가 있는지 확인한 결과를\n적절한 메시지로 출력하게 하자. 2012 년에 대해서도 동일한 작업을 수행한다.도전과제 1에 대한 해답먼저 도전과제 1에 대한 해답을 살펴보자. () 함수를 사용하지는 않는다.\ngapminder$year 벡터의 원소가 2002와 같은지 확인값을 갖는 논리 벡터를 생성시킨다:그리고 나서, 2002년과 대응되는 gapminder 데이터프레임 행의 숫자를 센다:2002년에 대한 레코드 존재는 rows2002_number 숫자가 하나 혹은 그 이상인지 확인하는 것과 같다.함께 담으면 다음과 같이 정리된다:() 함수로 상기 작업은 신속히 처리될 수 있다.\n논리 조건을 다음과 같이 표현하여 작성할 수 있다:다음과 같은 경고 메시지가 나오는 사람이 있나요?작성한 조건문이 하나 이상 논리 요소를 갖는 벡터를 평가하게 되면, 함수는 쭉 실행되지만, 첫번째 요소에 대한 조건만 평가한다. 따라서, 조건문이 길이 1 이 되도록 확실히 할 필요가 있다.꿀팁: () 와 () 함수any() 함수는 벡터에 적어도 값 하나가 TRUE 가 되어야만 TRUE 값을 반환한다.\n그렇지 않은 경우 FALSE 값을 반환한다.\n이런 점은 %% 연산자에 유사한 방식으로 적용된다.\n() 함수는 명칭에서 나타나듯이,\n벡터에 모든 값이 TRUE 인 경우에만 TRUE 값을 반환한다.","code":"\ngapminder[(gapminder$year == 2002),]\nrows2002_number <- nrow(gapminder[(gapminder$year == 2002),])\nrows2002_number >= 1\nif(nrow(gapminder[(gapminder$year == 2002),]) >= 1){\n   print(\"Record(s) for the year 2002 found.\")\n}\nif(any(gapminder$year == 2002)){\n   print(\"Record(s) for the year 2002 found.\")\n}## Error in if (gapminder$year == 2012) {: the condition has length > 1"},{"path":"r-control-flow.html","id":"r-control-flow-for","chapter":"27 .  제어 흐름","heading":"27.2 연산 반복","text":"값을 담은 집합에 반복 작업을 수행할 때, 반복 순서가 중요하고,\n집합에 속한 원소 각각에 대해 동일한 연산을 수행하는 경우, () 루프가 제격이다.\n앞선 쉘 수업에서 () 루프를 살펴봤다.\n() 루프는 가장 유연하게 루프를 돌리는 연산이지만,\n유연성으로 인해 올바르게 사용하기도 가장 어렵다.\n반복작업 순서가 중요하지 않은 경우, () 루프 사용을 회피한다:\n즉, 반복할 때마다 연산작업이 이전 반복작업 결과에 의존하는 경우.() 루프에 대한 기본 구조는 다음과 같다:예를 들어:1:10 이 즉석에서 벡터를 생성된다;\n물론 다른 벡터도 반복시킬 수 있다.두개 이상을 한번에 반복할 경우,\n또 다른 () 루프를 () 루프내부에 중첩시킬 수도 있다.결과를 바로 출력하는 대신에, 루프 출력결과를 새로운 객체에 대입시킬 수도 있다.이러한 접근법은 유용할 수도 있지만, ‘실행결과를 키워나감’ (실행결과 객체를 점진적으로 키워나감) 이런 전략은 컴퓨터 계산 측면으로 보면 비효율적이다.\n그래서, 많은 값을 반복할 때는 회피한다.꿀팁: 실행결과를 키워나가지 말라!초보자나 경험 많은 R 사용자 모두 저지르는 가장 큰 실수 중 하나가 실행결과 객체(벡터, 리스트, 행렬, 데이터프레임)를 루프를 돌리면서 키워나가는 것이다.\n컴퓨터는 이런 것을 처리하는데 매우 좋지 못하다.\n그래서 연산 속도가 급격히 늦어질 수 있다.\n미리 적절한 차원을 갖는 빈 연산결과 저장 객체를 정의하는 것이 훨씬 낫다.\n그래서, 상기처럼 실행결과를 저장할 행렬을 미리 알고 있다면,\n5 칼럼과 5 열로 구성된 빈 행렬를 생성하고 나서, 매번 반복을 돌릴 때마다 적절한 위치에 실행결과를 저장한다.고성능 R코드 작성과 성능비교더 좋은 방식은 값을 채워넣기 전에 (빈) 출력결과를 저장할 객체를 정의하는 것이다. 이번 예제의 경우, 더 복잡해 보이지만, 헐씬 더 효율적이다.꿀팁: 루프때로는 특정 조건이 만족될 때까지 연산작업을 반복할 필요도 있다.\n이런 작업은 () 루프로 수행한다.예제로, 0.1 보다 작은 난수가 나올 때까지 0 과 1 사이 균등 분포(runif() 함수)에서 난수를 뽑아내는 루프코드가 다음에 나와 있따.() 루프가 항상 적절한 것은 아니다. 조건이 절대 만족되지 않는 경우가 있어, 무한 루프에 빠지지 않도록 특별히 유의해야 된다.","code":"for(iterator in set of values){\n  do a thing\n}\nfor(i in 1:10){\n  print(i)\n}## [1] 1\n## [1] 2\n## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n## [1] 8\n## [1] 9\n## [1] 10\nfor(i in 1:5){\n  for(j in c('a', 'b', 'c', 'd', 'e')){\n    print(paste(i,j))\n  }\n}## [1] \"1 a\"\n## [1] \"1 b\"\n## [1] \"1 c\"\n## [1] \"1 d\"\n## [1] \"1 e\"\n## [1] \"2 a\"\n## [1] \"2 b\"\n## [1] \"2 c\"\n## [1] \"2 d\"\n## [1] \"2 e\"\n## [1] \"3 a\"\n## [1] \"3 b\"\n## [1] \"3 c\"\n## [1] \"3 d\"\n## [1] \"3 e\"\n## [1] \"4 a\"\n## [1] \"4 b\"\n## [1] \"4 c\"\n## [1] \"4 d\"\n## [1] \"4 e\"\n## [1] \"5 a\"\n## [1] \"5 b\"\n## [1] \"5 c\"\n## [1] \"5 d\"\n## [1] \"5 e\"\noutput_vector <- c()\nfor(i in 1:5){\n  for(j in c('a', 'b', 'c', 'd', 'e')){\n    temp_output <- paste(i, j)\n    output_vector <- c(output_vector, temp_output)\n  }\n}\noutput_vector##  [1] \"1 a\" \"1 b\" \"1 c\" \"1 d\" \"1 e\" \"2 a\" \"2 b\" \"2 c\" \"2 d\" \"2 e\" \"3 a\" \"3 b\"\n## [13] \"3 c\" \"3 d\" \"3 e\" \"4 a\" \"4 b\" \"4 c\" \"4 d\" \"4 e\" \"5 a\" \"5 b\" \"5 c\" \"5 d\"\n## [25] \"5 e\"\noutput_matrix <- matrix(nrow=5, ncol=5)\nj_vector <- c('a', 'b', 'c', 'd', 'e')\nfor(i in 1:5){\n  for(j in 1:5){\n    temp_j_value <- j_vector[j]\n    temp_output <- paste(i, temp_j_value)\n    output_matrix[i, j] <- temp_output\n  }\n}\noutput_vector2 <- as.vector(output_matrix)\noutput_vector2##  [1] \"1 a\" \"2 a\" \"3 a\" \"4 a\" \"5 a\" \"1 b\" \"2 b\" \"3 b\" \"4 b\" \"5 b\" \"1 c\" \"2 c\"\n## [13] \"3 c\" \"4 c\" \"5 c\" \"1 d\" \"2 d\" \"3 d\" \"4 d\" \"5 d\" \"1 e\" \"2 e\" \"3 e\" \"4 e\"\n## [25] \"5 e\"while(this condition is true){\n  do a thing\n}z <- 1\nwhile(z > 0.1){\n  z <- runif(1)\n  print(z)\n}"},{"path":"r-control-flow.html","id":"r-control-flow-challenge-two","chapter":"27 .  제어 흐름","heading":"27.3 도전과제 2","text":"output_vector 와 output_vector2 객체를 비교하라.\n두 객체는 동일한가? 만약 동일하지 않나면, 왜 동일하지 않을까?\n코드 마지막 블록을 변경해서 어떻게 output_vector2 를 output_vector 와 같도록 만들 수 있을까?도전과제 2에 대한 해답all() 함수를 사용해서 두 벡터가 동일한지 검사할 수 있다.하지만, output_vector 벡터 모든 요소가 output_vector2에 있기도 하다:바꿔서 검사해도 마찬가지다:따라서 output_vector 와 output_vector2 벡터 원소가 단지 다른 순서로 정렬된 사실을 확인하게 된다.\n원소 배치가 틀어진 이유는 .vector() 함수 연산이 입력행렬을 칼럼을 기준으로 작업했기 때문이다.\noutput_matrix 행렬을 살펴보면, 행기준으로 원소를 배열시키면 됨을 알 수 있다.\n해법은 output_matrix 입력 행렬을 전치시키는 것이다. t() 함수 혹은 입력 원소 순서를 밖는 것을 통해서 원하는 작업을 완수할 수 있따.첫번째 해법은 원본 행렬을다음과 같이 바꾸는 것이다.두번째 해법은 다읔과 같이 행렬 원소 위치를다음과 같이 바꾸는 것이다.","code":"\nall(output_vector == output_vector2)\nall(output_vector %in% output_vector2)\nall(output_vector2 %in% output_vector)\noutput_vector2 <- as.vector(output_matrix)\noutput_vector2 <- as.vector(t(output_matrix))\noutput_matrix[i, j] <- temp_output\noutput_matrix[j, i] <- temp_output"},{"path":"r-control-flow.html","id":"r-control-flow-challenge-three","chapter":"27 .  제어 흐름","heading":"27.4 도전과제 3","text":"gapminder 데이터 루프를 대륙별로 돌리는 스크립트를 작성한다.\n그리고 나서 평균 기대수명이 50년 보다 길거나 짧은지 결과를 출력한다.도전과제 3에 대한 해답1 단계: 대륙 벡터(continent)에서 유일무이한 값을 모두 추출한다.2 단계: 각 대륙별로 루프를 돌리는데 gapminder 데이터에 subset() 함수로 각 대륙별 부분 데이터셋을 추출하고 평균 기대수명을 계산한다.\n상기 작업과정을 다음과 같이 구현할 수 있다.‘continent’ 유일무이한 값 각각에 대해 루프를 돌린다.각 대륙별 부분 데이터셋별로 계산된 기대수명값을 임시 변수에 저장시킨다.(tmp)평균 기대수명을 계산해서 출력결과를 화면에 뿌려주는 형태로 사용자에게 반환시킨다:3 단계: 평균 기대수명이 50보다 적거나 큰 경우만 결과를 출력시킨다. 이런 경우,\n결과를 출력시키기 전에 조건을 추가한다.\n조건을 출력전에 추가해서 산출된 평균 기대수명이 기준치보다 높거나 낮은지를 평가하고\n해당 조건에 맞춰 결과를 출력시킨다.\n앞서 작성한 코드에 (3)을 반영하여 코드를 수정한다:3a. 계산된 평균 기대수명 기준치(50년)보다 적은 경우\n평균 기대수명이 기준치보다 낮은 대륙을 반환시킨다. 그렇지 않은 경우도,\n평균 기대수명이 기준치보다 높은 대륙을 반환시키는 코드를 작성한다;","code":"\ngapminder <- read.csv(\"data/gapminder_data.csv\")\nunique(gapminder$continent)\nfor( iContinent in unique(gapminder$continent) ){\n   tmp <- mean(subset(gapminder, continent==iContinent)$lifeExp)\n   cat(\"Average Life Expectancy in\", iContinent, \"is\", tmp, \"\\n\")\n   rm(tmp)\n}\nthresholdValue <- 50\n\nfor( iContinent in unique(gapminder$continent) ){\n   tmp <- mean(subset(gapminder, continent==iContinent)$lifeExp)\n   \n   if(tmp < thresholdValue){\n       cat(\"Average Life Expectancy in\", iContinent, \"is less than\", thresholdValue, \"\\n\")\n   }\n   else{\n       cat(\"Average Life Expectancy in\", iContinent, \"is greater than\", thresholdValue, \"\\n\")\n        } # end if else condition\n   rm(tmp)\n   } # end for loop"},{"path":"r-control-flow.html","id":"r-control-flow-challenge-four","chapter":"27 .  제어 흐름","heading":"27.5 도전과제 4","text":"도전과제 3 에서 나온 스크립트를 변경해서 각 국각별로 루프를 돌린다.\n이번에는 예상수명이 50 년보다 짧은지, 50 년에서 70 년 사이, 70 년 이상인지 결과를 출력한다.도전과제 4에 대한 해답도전과제 해답을 변경하여 lowerThreshold, upperThreshold 두개 기준값을 추가시키고,\n-else문을 확장시킨다.","code":"\n lowerThreshold <- 50\n upperThreshold <- 70\n \nfor( iCountry in unique(gapminder$country) ){\n    tmp <- mean(subset(gapminder, country==iCountry)$lifeExp)\n    \n    if(tmp < lowerThreshold){\n        cat(\"Average Life Expectancy in\", iCountry, \"is less than\", lowerThreshold, \"\\n\")\n    }\n    else if(tmp > lowerThreshold && tmp < upperThreshold){\n        cat(\"Average Life Expectancy in\", iCountry, \"is between\", lowerThreshold, \"and\", upperThreshold, \"\\n\")\n    }\n    else{\n        cat(\"Average Life Expectancy in\", iCountry, \"is greater than\", upperThreshold, \"\\n\")\n    }\n    rm(tmp)\n}"},{"path":"r-control-flow.html","id":"r-control-flow-challenge-five","chapter":"27 .  제어 흐름","heading":"27.6 도전과제 5 - 고급","text":"gapminder 데이터셋에서 각 국가별로 루프를 돌리는 스크립트를 작성한다.\n국가명이 ‘B’ 로 시작하는지 테스트하고,\n만약 평균 기대수명이 50 년보다 작은 경우 선그래프로 시간에 대해 기대수명을 그래프를 그린다.도전과제 5에 대한 해답유닉스 쉘 학습에서 소개된 grep 명령어를 사용해서 “B”로 시작하는 국가를 찾는다.\n먼저 “B”로 시작하는 국가를 찾는 방법을 이해하자.\n유닉스 쉘 학습에 소개된 내용을 따라 다음과 같이 작성하고 싶을 것이다.하지만, 상기 명령어를 평가하게 되면, “B”으로 시작되는 요인변수 country의 인덱스만 반환시킨다.\n해당 값을 얻으려면, grep 명령어 내부에 value=TRUE 옵션을 추가시키면 된다:candidateCountries 변수에 “B”로 시작되는 국가를 저장시킨다.\n그리고 나서, 변수에 포함된 원소 각각을 루프 돌린다.\n루프 내부에, 각 국가별로 평균 기대수명을 평가한다.\n만약 평균 기대수명이 50보다 낮은 경우 연도별 평균 기대수명이 변하는 것을 Base 플롯으로 시각화한다:","code":"\ngrep(\"^B\", unique(gapminder$country))\ngrep(\"^B\", unique(gapminder$country), value=TRUE)\nthresholdValue <- 50\ncandidateCountries <- grep(\"^B\", unique(gapminder$country), value=TRUE)\n\nfor( iCountry in candidateCountries){\n    tmp <- mean(subset(gapminder, country==iCountry)$lifeExp)\n    \n    if(tmp < thresholdValue){\n        cat(\"Average Life Expectancy in\", iCountry, \"is less than\", thresholdValue, \"plotting life expectancy graph... \\n\")\n        \n        with(subset(gapminder, country==iCountry),\n                plot(year,lifeExp,\n                     type=\"o\",\n                     main = paste(\"Life Expectancy in\", iCountry, \"over time\"),\n                     ylab = \"Life Expectancy\",\n                     xlab = \"Year\"\n                   ) # end plot\n              ) # end with\n    } # end for loop\n    rm(tmp)\n }"},{"path":"r-ggplot.html","id":"r-ggplot","chapter":"28 .  논문 품질 그래프 생성","heading":"28 .  논문 품질 그래프 생성","text":"데이터를 도식화하는 것이 변수간 다양한 관계를 재빨리 탐색하는 최상의 방식 중 하나다.R에는 세가지 주류 도식화 시스템이 존재한다: Base 도식화 시스템, lattice\n팩키지, ggplot2 팩키지.금일, ggplot2 팩키지를 학습할 것인데 이유는 논문 품질 그래프를 생성하는데\n가장 효과적이기 때문이다.ggplot2는 그래픽 문법(grammar graphics)에 기반했다.\n즉, 어떤 그래프도 동일한 구성요소 집합으로 표현된다:\n데이터셋, 좌표 시스템, geoms 집합 – 데이터 점에 대한 시각적 표현.ggplot2를 이해하는 핵심은 그림을 계층으로 사고하는 것이다:\n포토샵(Photoshop), 일러스트레이터(Illustrator), 잉크스케이프(Inkscape.) 같은 이미지 편집 프로그램으로 작업하는 것과 같다.예제를 가지고 시작해본다:그래서, 처음으로 수행하는 작업은 ggplot 함수를 호출하는 것이다.\n이 함수가 R에게 새로운 그림을 생성하고,\nggplot 함수에 전달하는 어떤 인자도 해당 그림에 전역 선택옵션(그림에 있는 모든 계층에 적용)임을 전달한다.ggplot에 인자를 두개 전달했다.\n먼저, ggplot에 그림에 사용할 데이터가 무엇인지 전달한다;\n번 예제에서 앞에서 불러온 gapminder데이터.\n두번째 인자를 aes함수에 전달했는데,\nggplot에게 데이터에 나온 변수를 도식화하는 그림의 미학적인 속성에 매핑하는 방법을 전달한다;\n이번 경우에는 x와 y 위치. 여기서 ggplot에 gapminder데이터프레임 “lifeExp” 칼럼을 x-축에,\n“gdpPercap” 칼럼을 y-축에 도식화한다.\n명시적으로 aes에 칼럼명을 전달(예를 들어, x = gapminder[, “lifeExp”])하지 않은 것에 주목한다.  이것이 가능한 이유는ggplot` 함수가 데이터에 존재하는 칼럼을 식별할만큼 똑똑하기 때문이다!그 자체로, ggplot함수를 호출한다고 도식화가 바로 되는 것은 아니다:ggplot 함수에 데이터를 시각적으로 표현하는 방법을 전달할 필요가 있다.\ngeom 계층을 추가해서 작업이 수행된다. 본 사례에서, geom_point를 사용했다;\nx와 y 사이 관계를 시각적으로 산점도 형태로 표현하도록 ggplot에게 전달한다:","code":"\nlibrary(\"ggplot2\")\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp))\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point()"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-one","chapter":"28 .  논문 품질 그래프 생성","heading":"28.1 도전과제 1","text":"상기예제를 변경해서, 기대수명이 시간에 따라 어떻게\n변해왔는지 시각화하는 그림을 생성한다:힌트: gapminder 데이터셋에 “year”라는 칼럼이 있는데, x-축에 나타나야 된다.도전과제 1에 대한 해답한가지 해법은 다음과 같다:","code":"\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) + geom_point()\nggplot(data = gapminder, aes(x = year, y = lifeExp)) + geom_point()"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-two","chapter":"28 .  논문 품질 그래프 생성","heading":"28.2 도전과제 2","text":"이전 예제와 도전과제에서, aes 함수를 사용해서 geom 산점도로 x 와 y 지점을\n각 점에 대해 표현했다.\n변경할 수 있는 또다른 미학적 속성은 각 점에 대한 색깔이다.\n앞선 도전과제 코드를 변경해서 “continent” 대륙별로 각 점에 색을 입힌다.\n데이터에서 어떤 경향성을 볼 수 있는가? 예상했던 경향성인가?도전과제 2에 대한 해답앞선 예제와 도전과제에서 x 와 y의 각 점에 대한 좌표로 geom 산점도를\naes함수에 사용했다.\naesthetic의 또다른 특성으로 점에 대한 색상을 변경할 수 있다는 점이다.\n“continent” 칼럼을 색상(color)에 적용해서 이전 도전과제 코드에 접목시켜보자.\n데이터에서 어떤 추세를 볼 수 있는가? 추세가 예상했던 것인가?","code":"\nggplot(data = gapminder, aes(x = year, y = lifeExp, color=continent)) +\n  geom_point()"},{"path":"r-ggplot.html","id":"r-ggplot-layer","chapter":"28 .  논문 품질 그래프 생성","heading":"28.3 계층(Layers)","text":"산점도가 아마도 시간에 따라 변하는 정보를 시각화하는데 최선은 아니다.\n대신에, ggplot에 선그래프(line plot)로 데이터를 시각화한다:geom_point 계층을 추가하는 대신에, geom_line 계층을 추가했다.\naes로 by를 추가해서, ggplot이 각 국가를 직선으로 연결해서 도식화한다.하지만, 직선과 점을 함께 시각화하려고 하면 어떨까?\n단순히, 또다른 계층을 그림에 추가하면 된다:각 계층은 이전 계층 위에 도식화됨에 주목한다.\n이번 예제에서, 점이 직선 위에 도식화되었다.\n다음에 도식화한 산출물이 나와있다:이번 예제에서, aesthetic인 색상 매핑이 ggplot에 전역으로 설정된 점 선택옵션에서\ngeom_line 계층으로 이동했다. 그래서, 해당 점에는 더이상 적용되지 않는다.\n이제 분명하게 직선 위에 점이 도식화된 것을 확인할 수 있다.꿀팁: aesthetic에 매핑대신에 값을 설정지금까지 (색상같은) aesthetic 를 데이터의 변수로 매핑(mapping)해서 사용하는 법을 살펴봤다.\n예를 들어, geom_line(aes(color=continent))을 사용하면, ggplot에서 자동으로 각 대륙별로 다른 색상을 입힌다.\n그런데, 모든 선을 파란색으로 바꾸고자 하면 어떨까? geom_line(aes(color=\"blue\")) 명령어가 동작해야 된다고 생각하지만,\n사실은 그렇지 않다.특정 변수에 대한 매핑을 생성하지 않았기 대문에,\naes() 함수 밖으로 색상을 명세하는 부분을 예를 들어, geom_line(color=\"blue\")와 같이 빼내기만 하면 된다.","code":"\nggplot(data = gapminder, aes(x=year, y=lifeExp, by=country, color=continent)) +\n  geom_line()\nggplot(data = gapminder, aes(x=year, y=lifeExp, by=country, color=continent)) +\n  geom_line() + geom_point()\nggplot(data = gapminder, aes(x=year, y=lifeExp, by=country)) +\n  geom_line(aes(color=continent)) + geom_point()"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-three","chapter":"28 .  논문 품질 그래프 생성","heading":"28.4 도전과제 3","text":"앞선 예제에서 점과 직선 계층 코딩 순서를 뒤바꾼다. 어떻게 될까요?도전과제 3에 대한 해답앞선 예제에서 점과 직선 계층 코딩 순서를 뒤바꾼다. 어떻게 될까요?선이 점 위에 올라온다!","code":"\nggplot(data = gapminder, aes(x=year, y=lifeExp, by=country)) +\n geom_point() + geom_line(aes(color=continent))"},{"path":"r-ggplot.html","id":"r-ggplot-transformation","chapter":"28 .  논문 품질 그래프 생성","heading":"28.5 변환과 통계량","text":"변환(Transformations)과 통계량(statistics)을 살펴보자.\nggplot으로 데이터 위에 통계적 모형을 쉽게 겹치게 할 수 있다.\n이를 시연하기 위해서, 첫번째 예제로 되돌아간다:현재, 일인당 GDP에 일부 심각한 이상점이 있어 점사이 내재된 관계를 보기 힘들다.\nscale 척도함수를 사용해서 y-축 척도를 변경한다.\n이것을 통해 데이터 값과 aesthetic 시각값 사이 매핑을 제어한다.\nalpha 함수를 통해 투명도도 조정할 수 있다.\n군집으로 많은 데이터가 모아진 경우 특히 투명도 조절을 유용하다.그림에 렌더링하기 전에 log10 함수가 gdpPercap 칼럼값에 변환을 시켰다.\n그래서, 각 자리수 10은 변환된 척도에 1씩 증가에 대응된다.\n예를 들어, 1인당 GDP 1,000은 y-축에 3, 10,000은 y-축에 4에 대응된다.\n로그 변환은 x-축에 흩어진 데이터 시각화를 쉽게 도와준다.꿀팁: aesthetic에 매핑대신에 값을 설정geom_point(alpha = 0.5) 을 사용한 것에 주목한다.\n앞서 언급했듯이, aes() 함수 외부에서 설정된 것은 모든 점에 대해서 지정한 값이 적용되게 된다.\n투명도 지정은 이 경우 원하는 바로 문제가 전혀 없다.\n하지만, 다른 aesthetic 설정처럼, alpha 투명도를 데이터의 변수에 매핑시킬 수도 있다.\n예를 들어, 각 대륙별로 다른 투명도를 적용시키고자 하면, geom_point(aes(alpha = continent)) 코딩하는 것도 가능하다.또다른 계층(geom_smooth)을 추가해서 관계를 단순히 적합시킬 수 있다:굵은 선은 geom_smooth 계층에 aesthetic 크기를 설정해서 조정할 수 있다:미학적인 항목을 명세할 수 있는 방식이 두개 있다.\n바로 앞에서 geom_smooth 함수에 인자로 전달해서 크기에 대한 미학적인 설정을 했다.\n앞에서는 aes 함수를 사용해서 데이터 변수와 시각적 표현 사이 매핑으로 정의했다.","code":"\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp, color=continent)) +\n  geom_point()\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point(alpha = 0.5) + scale_x_log10()\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() + scale_x_log10() + geom_smooth(method=\"lm\")\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n  geom_point() + scale_x_log10() + geom_smooth(method=\"lm\", size=1.5)"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-four-a","chapter":"28 .  논문 품질 그래프 생성","heading":"28.6 도전과제 4a","text":"바로 앞 예제에서 점 계층에 나온 점 크기와 색상을 변경하라.\n힌트: aes 함수를 사용하지 않는다.도전과제 4a에 대한 해답바로 앞 예제에서 점 계층에 나온 점 크기와 색상을 변경하라.힌트: aes 함수를 사용하지 않는다.","code":"\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp)) +\n geom_point(size=3, color=\"orange\") + scale_x_log10() +\n geom_smooth(method=\"lm\", size=1.5)"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-four-b","chapter":"28 .  논문 품질 그래프 생성","heading":"28.7 도전과제 4b","text":"도전과제 4a를 변경하는데,\n점들이 다른 형태(shape)를 갖고 대륙별로 색상을 달리하는데\n대륙별로 추세선을 반영한다.힌트: 색상 인자를 aesthetic 내부로 위치시킨다.도전과제 4b에 대한 해답도전과제 4a를 변경하는데,\n점들이 다른 형태(shape)를 갖고 대륙별로 색상을 달리하는데\n대륙별로 추세선을 반영한다.\n힌트: 색상 인자를 aesthetic 내부로 위치시킨다.","code":"\nggplot(data = gapminder, aes(x = gdpPercap, y = lifeExp, color = continent)) +\ngeom_point(size=3, shape=17) + scale_x_log10() +\ngeom_smooth(method=\"lm\", size=1.5)"},{"path":"r-ggplot.html","id":"r-ggplot-multi-panel","chapter":"28 .  논문 품질 그래프 생성","heading":"28.8 다중-창(Multi-Panel) 그림","text":"앞에서 그림 하나에 모든 국가에 대해 시간의 변화에 따른 기대수명 변화를 시각화했다.\n대안으로, 패싯(facet) 창 계층을 추가해서, 그림을 여러개 창으로 쪼갤 수도 있다:\n“” 혹은 “Z”로 시작하는 국가명을 갖는 나라만 집중해 보자.팁(Tip)데이터 부분집합(subset)을 추출하고 시작해 나간다.\nsubstr 함수를 사용해서 문자열의 일부를 뽑아낸다; 이 경우에,\ngapminder$country 벡터의 시작과 끝 위치 문자가 된다.\n%% 연산자를 통해서 조건을 만족하는 긴 코드 대신에 다중 비교를\n간단히 수행한다.\n(이 경우, starts.%% c(\"\", \"Z\") 코드는\nstarts.== \"\" | starts.== \"Z\")와 동일하다)facet_wrap 계층은 “공식(formula)”을 인자로 받는데, (~) 틸드로 표기한다.\ngapminder 데이터셋 국가별 칼럼의 유일한 값 각각에 대해 별도 창을 통해 도식화한다.","code":"\nstarts.with <- substr(gapminder$country, start = 1, stop = 1)\naz.countries <- gapminder[starts.with %in% c(\"A\", \"Z\"), ]\nggplot(data = az.countries, aes(x = year, y = lifeExp, color=continent)) +\n  geom_line() + facet_wrap( ~ country)"},{"path":"r-ggplot.html","id":"r-ggplot-text","chapter":"28 .  논문 품질 그래프 생성","heading":"28.9 텍스트 변경","text":"논문 출판으로 그림을 깔끔하게 만들려면, 텍스트 요소를 일부 변경할 필요가 있다.\nx-축이 너무 난잡하고, y-축은 데이터프레임 칼럼명이 아닌 “Life expectancy”으로 적혀야 된다.몇개 다른 계층을 추가함으로써 텍스트를 변경할 수 있다.\ntheme 계층은 각 축에 대한 텍스트, 전반적인 텍스트 크기를 제어한다.\n축, 그래프 제목, 범례는 labs() 함수를 사용해서 설정하다.\n범례 제목은 aes() 함수에서 명세한 것과 동일한 명칭을 사용한다.\n따라서, 색상 범례 제목은 color = \"Continent\"이 되는 반면에,\n채우기(fill) 범례는 fill = \"MyTitle\"으로 설정하게 된다.","code":"\nggplot(data = az.countries, aes(x = year, y = lifeExp, color=continent)) +\n  geom_line() + facet_wrap( ~ country) +\n  labs(\n    x = \"Year\",              # x axis title\n    y = \"Life expectancy\",   # y axis title\n    title = \"Figure 1\",      # main title of figure\n    color = \"Continent\"      # title of legend\n  ) +\n  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())"},{"path":"r-ggplot.html","id":"r-ggplot-export","chapter":"28 .  논문 품질 그래프 생성","heading":"28.10 그래프 내보내기","text":"ggsave() 함수를 사용해서 ggplot으로 생성시킨 그래프를 내보내서 로컬 컴퓨터에 저장할 수 있다.\n출판을 위한 고품질 그래픽 산출물을 생성하기 위해서\n그래프 크기와 해상도를 ggsave() 함수의 인자(width, height, dpi)로 넘기면 된다.\n앞서 생성한 그래프를 저장하려면,\n먼저 lifeExp_plot 변수에 그래프를 할당하고 나서,\nggsave() 함수에 png 형식으로 results 디렉토리에 저장하도록 지정한다.\n(현 작업디렉토리에 results/ 폴더가 생성되어 있어야 한다.)ggsave() 함수에 두가지 멋진 점이 있다.\n첫째는 기본설정값으로 가장 마지막 그래프가 지정되어 있어서,\nplot 인자를 생략하게 되면, 자동으로 ggplot으로 생성한 마지막 그래프가 저장된다.\n둘째로, 저장되는 그래프 이미지 형식이 파일명으로 전달하는 파일 확장자(예를 들어, .png 혹은 .pdf)에 따라 결정된다.\n필요한 경우, device 인자에 명시적으로 파일 형식을 지정할 수도 있다.지금까지 ggplot2 맛을 보았다. RStudio는 정말 유용한 cheat sheet를 통해서 다른 계층 사용법에 대한\n참고서로 충실한 정보를 제공하고 있고, ggplot2 웹사이트에 추가기능에 대한 상세한 정보가 공개되어 있다.마지막으로, 어떻게 수정을 해야하는지 아무런 생각이 없다면, 구글 검색을 통해서 결국 Stack Overflow 웹사이트에\n재사용 가능한 코드를 통해서 관련된 질문과 답변을 수월히 얻을 수 있다!","code":"\nlifeExp_plot <- ggplot(data = az.countries, aes(x = year, y = lifeExp, color=continent)) +\n  geom_line() + facet_wrap( ~ country) +\n  labs(\n    x = \"Year\",              # x axis title\n    y = \"Life expectancy\",   # y axis title\n    title = \"Figure 1\",      # main title of figure\n    color = \"Continent\"      # title of legend\n  ) +\n  theme(axis.text.x=element_blank(), axis.ticks.x=element_blank())\n\nggsave(filename = \"results/lifeExp.png\", plot = lifeExp_plot, width = 12, height = 10, dpi = 300, units = \"cm\")"},{"path":"r-ggplot.html","id":"r-ggplot-challenge-five","chapter":"28 .  논문 품질 그래프 생성","heading":"28.11 도전과제 5","text":"대륙별로 채워진 1인당 GPD 밀도 그래프를 생성하라.\n고급:\n- x-축을 변경해서 쭉 펼쳐진 데이터를 좀더 보기좋게 시각화하라.\n- 패싯 계층을 추가해서 연도별로 밀도 그래프를 창에 도식화하라.도전과제 5에 대한 해답대륙별로 채워진 1인당 GPD 밀도 그래프를 생성하라.고급:\n- x-축을 변경해서 쭉 펼쳐진 데이터를 좀더 보기좋게 시각화하라.\n- 패싯 계층을 추가해서 연도별로 밀도 그래프를 창에 도식화하라.","code":"\nggplot(data = gapminder, aes(x = gdpPercap, fill=continent)) +\n geom_density(alpha=0.6) + facet_wrap( ~ year) + scale_x_log10()"},{"path":"r-vectorization.html","id":"r-vectorization","chapter":"29 .  벡터화(Vectorization)","heading":"29 .  벡터화(Vectorization)","text":"R 함수 대부분은 벡터화되었다.\n즉, 한번에 각 요소에 대해 연산을 수행하도록 루프를 돌릴 필요없이\n함수가 벡터 모든 요소에 대해 연산작업을 수행한다.\n이렇게 되면 코드는 더욱 간결해지고, 가독성이 높아지고, 오류에 덜 노출된다.곱하기는 벡터 모든 요소에 일어난다.두 벡터를 더할 수도 있다:x 벡터 각 요소가 y 벡터 대응되는 요소에 더해진다:","code":"\nx <- 1:4\nx * 2## [1] 2 4 6 8\ny <- 6:9\nx + y## [1]  7  9 11 13x:  1  2  3  4\n    +  +  +  +\ny:  6  7  8  9\n---------------\n    7  9 11 13"},{"path":"r-vectorization.html","id":"r-vectorization-one","chapter":"29 .  벡터화(Vectorization)","heading":"29.1 도전과제 1","text":"gapminder 데이터셋 pop 칼럼에 벡터 연산을 시도해 본다.\ngapminder 데이터프레임에 신규 칼럼을 생성하는데, 백만명 단위로\n인구정보를 표현한다.\n데이터프레임에 head 혹은 tail 명령어를 적용해서\n실제로 제대로 동작하는지 확인한다.도전과제 1에 대한 해답gapminder 데이터셋 pop 칼럼에 벡터 연산을 시도해 본다.\ngapminder 데이터프레임에 신규 칼럼을 생성하는데, 백만명 단위로\n인구정보를 표현한다.\n데이터프레임에 head 혹은 tail 명령어를 적용해서\n실제로 제대로 동작하는지 확인한다.","code":"\ngapminder$pop_millions <- gapminder$pop / 1e6\nhead(gapminder)##       country year      pop continent lifeExp gdpPercap pop_millions\n## 1 Afghanistan 1952  8425333      Asia    28.8       779         8.43\n## 2 Afghanistan 1957  9240934      Asia    30.3       821         9.24\n## 3 Afghanistan 1962 10267083      Asia    32.0       853        10.27\n## 4 Afghanistan 1967 11537966      Asia    34.0       836        11.54\n## 5 Afghanistan 1972 13079460      Asia    36.1       740        13.08\n## 6 Afghanistan 1977 14880372      Asia    38.4       786        14.88"},{"path":"r-vectorization.html","id":"r-vectorization-two","chapter":"29 .  벡터화(Vectorization)","heading":"29.2 도전과제 2","text":"그래프 하나에, 모든 국가에 대해 백만 단위로 인구를 연도별로 도식화한다.\n어느 국가인지 식별하는 것은 신경쓰지 말자.\n상기 연습문제를 반복하면서, 중국(China), 인도(India), 인도네시아(Indonesia)에\n대해서만 도식화한다. 마찬가지로, 어는 국가인지 식별하는 것은\n신경쓰지 말자.도전과제 2에 대한 해답연도별 백만단위로 인구수를 그래프로 표현한느데 앞서 학습한 내용을 상기한다.비교 연산자, 논리 연산자, 그리고 많은 함수도 벡터화를 지원한다:비교 연산자논리 연산자꿀팁: 논리 벡터에 대한 유용한 일부 함수any() 함수는 벡터 요소 어떤 것이든 TRUE 참이면, TRUE를 반환한다.\n()함수는 벡터 요소 모두가 TRUE 참이면, TRUE를 반환한다.함수 대부분은 또한 벡터에 요소별(element-wise)로 연산작업을 수행한다:함수(Functions)벡터화 연산은 행렬(matrix)에 원소별로 연산작업을 수행한다:꿀팁: 원소별(element-wise) 곱셈 vs. 행렬 곱셈매우 중요: * 곱하기 연산은 요소별 곱셈 결과를 전달한다!\n행렬 곱셈을 하려면, %*% 연산자를 사용한다:행렬 대수에 관한 더 많은 정보는 Quick-R reference\nguide을 참조한다.","code":"\nggplot(gapminder, aes(x = year, y = pop_millions)) +\n geom_point()\ncountryset <- c(\"China\",\"India\",\"Indonesia\")\nggplot(gapminder[gapminder$country %in% countryset,],\n       aes(x = year, y = pop_millions)) +\n  geom_point()\nx > 2## [1] FALSE FALSE  TRUE  TRUE\na <- x > 3  # or, for clarity, a <- (x > 3)\na## [1] FALSE FALSE FALSE  TRUE\nx <- 1:4\nlog(x)## [1] 0.000 0.693 1.099 1.386\nm <- matrix(1:12, nrow=3, ncol=4)\nm * -1##      [,1] [,2] [,3] [,4]\n## [1,]   -1   -4   -7  -10\n## [2,]   -2   -5   -8  -11\n## [3,]   -3   -6   -9  -12\nm %*% matrix(1, nrow=4, ncol=1)##      [,1]\n## [1,]   22\n## [2,]   26\n## [3,]   30\nmatrix(1:4, nrow=1) %*% matrix(1:4, ncol=1)##      [,1]\n## [1,]   30"},{"path":"r-vectorization.html","id":"r-vectorization-three","chapter":"29 .  벡터화(Vectorization)","heading":"29.3 도전과제 3","text":"다음과 같은 행렬이 주어졌다:다음 명령어를 실행하면, 연산작업 결과가 어떻게 될지 생각한 것을 적어본다:m ^ -1m * c(1, 0, -1)m > c(0, 20)m * c(1, 0, -1, 2)예상한 출력결과가 나왔나요? 만약 그렇지 않다면, 조교(helper)를 부르세요!도전과제 3에 대한 해답다음과 같은 행렬이 주어졌다:다음 명령어를 실행하면, 연산작업 결과가 어떻게 될지 생각한 것을 적어본다:m ^ -1m * c(1, 0, -1)m > c(0, 20)","code":"\nm <- matrix(1:12, nrow=3, ncol=4)\nm##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    2    5    8   11\n## [3,]    3    6    9   12\nm <- matrix(1:12, nrow=3, ncol=4)\nm##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    2    5    8   11\n## [3,]    3    6    9   12##       [,1]  [,2]  [,3]   [,4]\n## [1,] 1.000 0.250 0.143 0.1000\n## [2,] 0.500 0.200 0.125 0.0909\n## [3,] 0.333 0.167 0.111 0.0833##      [,1] [,2] [,3] [,4]\n## [1,]    1    4    7   10\n## [2,]    0    0    0    0\n## [3,]   -3   -6   -9  -12##       [,1]  [,2]  [,3]  [,4]\n## [1,]  TRUE FALSE  TRUE FALSE\n## [2,] FALSE  TRUE FALSE  TRUE\n## [3,]  TRUE FALSE  TRUE FALSE"},{"path":"r-vectorization.html","id":"r-vectorization-four","chapter":"29 .  벡터화(Vectorization)","heading":"29.4 도전과제 4","text":"다음 연속된 분수 순열 합계를 구하는데 관심이 있다:이 모두를 타이핑하는 것은 지루하고, n 값이 매우 큰 경우 불가능하다.\n벡터화를 사용해서 n=100 일 때 x를 계산한다.\nn=10,000 일 때, 합은 얼마나 될까?도전과제 4에 대한 해답다음 연속된 분수 순열 합계를 구하는데 관심이 있다:이 모두를 타이핑하는 것은 지루하고, n 값이 매우 큰 경우 불가능하다.\n벡터화를 사용해서 n=100 일 때 x를 계산한다.\nn=10,000 일 때, 합은 얼마나 될까?함수를 사용해서 동일한 결과를 얻을 수도 있다:","code":"\n x = 1/(1^2) + 1/(2^2) + 1/(3^2) + ... + 1/(n^2)\n x = 1/(1^2) + 1/(2^2) + 1/(3^2) + ... + 1/(n^2)\nsum(1/(1:100)^2)## [1] 1.63\nsum(1/(1:1e04)^2)## [1] 1.64\nn <- 10000\nsum(1/(1:n)^2)## [1] 1.64\ninverse_sum_of_squares <- function(n) {\n  sum(1/(1:n)^2)\n}\ninverse_sum_of_squares(100)## [1] 1.63\ninverse_sum_of_squares(10000)## [1] 1.64\nn <- 10000\ninverse_sum_of_squares(n)## [1] 1.64"},{"path":"r-function.html","id":"r-function","chapter":"30 .  함수 설명","heading":"30 .  함수 설명","text":"분석할 데이터셋이 하나라면, 파일을 엑셀같은 스프레드쉬트로 불러와서\n간단한 통계량을 도식화하는 것이 아마도 훨씬 빠를 것이다.\n하지만, gapminder 데이터는 주기적으로 갱신되서,\n나중에 새로운 정보를 뽑아와서 분석작업을 다시 실행할 수도 있다.\n또한, 미래 특정 시점에 다양한 곳에서 유사한 데이터를 얻어올 수도 있다.이번 수업에서, 단일 명령어로 여러가지 연산작업을 반복하는\n함수 작성방법을 학습할 것이다.함수란 무엇인가?함수는 연속된 연산작업을 모아 전체를 하나로 만들고,\n향후 사용을 위해 보관된다. 함수는 다음 기능을 제공한다:기억할 수 있고 나중에 호출할 수 있는 명칭개별적인 연산을 기억할 필요에서 해방사전에 정의된 입력과 예상되는 출력더 큰 프로그래밍 환경에 풍부한 연계성프로그래밍 언어 대부분의 기본 구성요소로서,\n사용자 정의 함수는 어떠한 단일 추상화 못지 않는 중요한 “프로그래밍”으로 간주된다.\n함수를 작성할 수 있다면, 여러분은 컴퓨터 프로그래머다:","code":""},{"path":"r-function.html","id":"r-funciton-definition","chapter":"30 .  함수 설명","heading":"30.1 함수 정의하기","text":"새로운 R 스크립트 파일을 functions/ 디렉토리에 functions-lesson.R\n이름으로 저장하고 편집기에서 연다.화씨온도에서 캘빈온도로 변환하는 fahr_to_kelvin() 함수를 정의한다:function 출력을 대입하는 fahr_to_kelvin() 함수를 정의한다.\n인자 명칭 리스트는 괄호 안에 담겨진다.\n다음으로 함수 몸통부문\n(함수를 실행할 때 실행되는 문장)이\n괄호({}) 내부에 담겨진다.\n몸통부문 문장은 보통 공백 2 개로 들여쓰기한다.\n들여쓰면, 코드 가독성이 높아지지만, 코드 동작에는 영향을 끼치지 않는다.함수 생성을 요리책 저작하는 것처럼 생각하면 도움이된다.\n먼저, 함수가 필요로 하는 “식재료(ingredient)”를 정의한다.\n온도 변환기 함수에서, 함수에 사용할 식재료는 하나만 필요하다: “temp”.\n식재료를 쭉 나열한 후에, 식재료로 무엇을 할지 기술한다;\n이번 경우에, 식재료를 받아 일련의 수학 연산작업을 수행한다.함수를 호출할 때, 함수에 전달되는 값이 변수에 대입된다.\n그래서, 함수 내부에서 전달되는 값을 사용할 수 있다.\n함수 내부에서 반환문(return)을\n사용해서 호출한 쪽에 결과를 되돌려준다.꿀팁:R에만 있는 유일무이한 기능 하나가 반환문 return이 반듯이 필요하지 않다는 점이다.\nR은 자동적으로 함수 몸통부문 마지막 줄에 있는 어떤 변수나 반환시킨다.\n하지만 명확성을 위해서, 명시적으로 반환문 return을 정의한다.함수를 실행해보자.\n본인이 작성한 사용자 정의 함수 호출은 여타 다른 함수 호출과 차이가 없다:","code":"\nmy_sum <- function(a, b) {\n  the_sum <- a + b\n  return(the_sum)\n}\nfahr_to_kelvin <- function(temp) {\n  kelvin <- ((temp - 32) * (5 / 9)) + 273.15\n  return(kelvin)\n}\n# 빙점\nfahr_to_kelvin(32)## [1] 273\n# 끓는 점\nfahr_to_kelvin(212)## [1] 373"},{"path":"r-function.html","id":"r-function-challenge-one","chapter":"30 .  함수 설명","heading":"30.2 도전과제 1","text":"kelvin_to_celsius() 함수를 작성해서 캘빈온도를 받아 섭씨온도를 반환한다.\n힌트: 캘빈온도를 섭씨온도로 전환하려면, 273.15 을 뺀다.도전과제 1에 대한 해답kelvin_to_celsius() 함수를 작성해서 캘빈온도를 받아 섭씨온도를 반환한다.","code":"\nkelvin_to_celsius <- function(temp) {\n celsius <- temp - 273.15\n return(celsius)\n}"},{"path":"r-function.html","id":"r-function-composition","chapter":"30 .  함수 설명","heading":"30.3 함수 결합","text":"함수의 진정한 힘은 원하는 효과를 얻어 내는데 함수를 섞고, 매칭하고, 결합해서\n더 큰 덩어리로 구현함에 있다.화씨 온도에서 캘빈 온도로, 갤빈 온도에서 섭씨 온도로 온도를 전환하는 함수 두개를 정의한다:","code":"\nfahr_to_kelvin <- function(temp) {\n  kelvin <- ((temp - 32) * (5 / 9)) + 273.15\n  return(kelvin)\n}\n\nkelvin_to_celsius <- function(temp) {\n  celsius <- temp - 273.15\n  return(celsius)\n}"},{"path":"r-function.html","id":"r-function-challenge-two","chapter":"30 .  함수 설명","heading":"30.4 도전과제 2","text":"바로 위에 정의된 함수 두개를 재사용해서 화씨온도에서 바로 섭씨온도로\n변환하는 함수를 정의한다.\n(혹은, 본인이 원하면 자신이 직접 작성한 함수를 사용한다.)도전과제 2에 대한 해답바로 위에 정의된 함수 두개를 재사용해서 화씨온도에서 바로 섭씨온도로\n변환하는 함수를 정의한다.","code":"\nfahr_to_celsius <- function(temp) {\n  temp_k <- fahr_to_kelvin(temp)\n  result <- kelvin_to_celsius(temp_k)\n  return(result)\n}"},{"path":"r-function.html","id":"r-function-defensive","chapter":"30 .  함수 설명","heading":"30.5 방어적 프로그래밍","text":"R코드를 재사용가능하고 모듈화 되도록 만드는데 함수 작성이 효율적인 방법을 제공한다는 점에서 이제야\n참진가를 알게 되었다. 따라서, 함수가 의도된 방식으로 동작하도록 확실히 하는 것도 매우 중요하다.\n함수 매개변수(인자) 검사는 방어적 프로그래밍(defensive programming) 개념과 연관되어 있다.\n방어적 프로그래밍은 자주 조건을 검사하고, 무언가 잘못되면 오류를 던지도록 장려한다.\n이러한 검사를 단언문(assertion statement)라고 부른다. 왜냐하면 다음으로 넘어가기 전에\n조건이 TRUE 사실로 단언해야 되기 때문이다.\n이러한 특성이 디버깅을 더 수월하게 하는데 이유는 오류가 최초 생겨난 곳에 대해 더 나은 아이디어를\n제시해 주기 때문이다.","code":""},{"path":"r-function.html","id":"r-function-stopifnot","chapter":"30 .  함수 설명","heading":"30.5.1 stopifnot() 조건 검사","text":"화씨 온도를 켈빈 온도로 변환하는데 사용되는 자체 제작 함수 fahr_to_kelvin()을\n다시 살펴보면서 시작해보자. 함수가 다음과 같이 정의되었다:함수가 의도한 대로 동작하기 위해서, temp 인자는 숫자형(numeric) 값이 되어야 한다;\n그렇지 않은 경우, 온도를 변환하는 수학 연산 작업이 정상적으로 수행되지 않게 된다.\n오류를 생성시키는데, stop() 함수를 사용한다.\n예를 들어, temp 인자는 숫자형(numeric) 벡터가 되어야 하는데,\n문으로 조건을 검사해서 조건이 위반되면 오류를 던진다.\n이를 반영하여 다음과 같이 함수 기능을 강화시킬 수 있다:검사할 다수 조건과 인자가 있게 되면, 이 모두를 검사하는 코드가 많이 필요하게 된다.\n다행히, stopifnot() 편의 함수가 R에서 지원된다.\nTRUE 참으로 평가되어야 하는 요구사항을 쭉 나열한다; FALSE 거짓인 것이 하나\n발견되면 stopifnot() 함수는 오류를 던진다.\n이러한 조건을 나열하는 것이 함수에 대한 부가 문서로서 부차적인 역할을 담당도 한다.fahr_to_kelvin() 함수의 입력값을 검사하는 단언문을 추가해서\nstopifnot() 함수로 방어적 프로그래밍을 시도해보자.다음을 단언문으로 확인하자; temp 인자가 숫자 벡터다. 다음과 같이 코드를 작성하자:적절한 입력이 제시되면 정상적으로 동작한다.부적절한 입력이 제시되면 즉시 실패한다.","code":"\nfahr_to_kelvin <- function(temp) {\n  kelvin <- ((temp - 32) * (5 / 9)) + 273.15\n  return(kelvin)\n}\nfahr_to_kelvin <- function(temp) {\n  if (!is.numeric(temp)) {\n    stop(\"temp must be a numeric vector.\")\n  }\n  kelvin <- ((temp - 32) * (5 / 9)) + 273.15\n  return(kelvin)\n}\nfahr_to_kelvin <- function(temp) {\n  stopifnot(is.numeric(temp))\n  kelvin <- ((temp - 32) * (5 / 9)) + 273.15\n  return(kelvin)\n}\n# 빙점\nfahr_to_kelvin(temp = 32)## [1] 273\n# 숫자형 대신에 문자가 주어짐.\nfahr_to_kelvin(temp = as.factor(32))## Error in fahr_to_kelvin(temp = as.factor(32)): is.numeric(temp) is not TRUE"},{"path":"r-function.html","id":"r-function-challenge-three","chapter":"30 .  함수 설명","heading":"30.6 도전과제 3","text":"방어적 프로그래밍을 사용해서, temp 인자를 부적절하게 제시하게 되면\nfahr_to_celsius() 함수가 오류를 즉시 던지도록 작성한다.도전과제 3에 대한 해답stopifnot() 함수에 명시적으로 호출을 추가해서 앞서 정의한 함수를 확장시킨다.\nfahr_to_celsius() 함수는 다른 두 함수를 조합한 것이라서,\n두번째 함수에도 검사를 추가하는 것은 중복이 된다.","code":"\nfahr_to_celsius <- function(temp) {\n  stopifnot(is.numeric(temp))\n  temp_k <- fahr_to_kelvin(temp)\n  result <- kelvin_to_celsius(temp_k)\n  return(result)\n}"},{"path":"r-function.html","id":"r-function-composition-more","chapter":"30 .  함수 설명","heading":"30.7 함수조합","text":"이제 데이터셋에서 한 국가에 대한 국내총생산(GDP)를 계산하는 함수를 작성한다:function 출력을 대입하는 calcGDP() 함수를 정의한다.\n인자 명칭 리스트는 괄호 안에 담겨진다.\n다음으로 함수 몸통부문\n(함수를 실행할 때 실행되는 문장)이\n괄호({}) 내부에 담겨진다.몸통부문 문장을 공백 2 개로 들여쓰기한다.\n들여쓰면, 코드 가독성이 높아지지만, 코드 동작에는 영향을 끼치지 않는다.함수를 호출할 때, 함수에 전달되는 값이 인자에 대입된다.\n전달되는 값은 함수 몸통 내부에서 변수가 된다.함수 내부에서, return() 함수를 사용해서 결과를 함수밖으로 배출한다.\n반환 return() 함수는 선택옵션이다:\nR은 자동으로 함수 마지막 줄에 실행되는 어떤 명령어든 결과를 반환한다.그다지 유용한 정보는 아니다.\n인자를 일부 추가해서 연도별, 국가별 GDP를 추출한다.별도 R 스크립트 파일에 상기 함수를 작성했다면(좋은 아이디어!), source() 함수를\n사용해서 R 세션에 함수를 올려 적재할 수 있다:이제 함수에 상당히 많은 일을 하고 있네요.\n쉬운 말로 풀어쓰면, 연도 year 인자가 비어있지 않는다면,\n함수가 전달된 연도 정보로 부분집합 데이터를 생성하고 나서,\n국가 country 인자가 비어있지 않는다면,\n함수가 전달된 국가 정보로 부분집합 데이터를 생성한다.\n그리고 나서, 연도와 국가 인자에서 추출된 부분집합에 대해\nGDP를 계산한다.\n그리고 나서, 함수가 GDP를 신규 칼럼으로 추가해서 부분집합으로 뽑아낸 데이터셋에서\n추가하고 최종 결과로 반환한다.\n숫자 벡터로 쭉 뽑혀진 것보다 출력결과가 훨씬 더 유용한 정보를 제공함을 알 수 있다.연도를 인자로 명세할 때 어떤 일이 발생하는지 살펴보자:혹은 특정 국가를 인자로 전달하면 어떻게 되는지 살펴보자:혹은, 연도와 국가를 모두 인자로 전달하면 어떻게 되는지 살펴보자:함수 몸통부문을 살펴본다:위에서 인자 두개 year, country를 추가했다.\n함수 정의부에서 기본디폴트 인자를 모두 = 연산자를 사용해서 NULL로 설정했다.\n이것이 의미하는 바는 사용자가 달리 인자를 설정하지 않는다면,\n각 인자에 NULL 값을 인자로 넘기게 된다.여기서, 각기 추가되는 인자가 null 로 설정되었는지 검사한다.\nnull 이 아닌 경우, null이 아닌 인자로 부분집합 데이터로 뽑아내려고\ndat에 저장된 데이터셋을 덮어쓴다.추후에 좀더 유연하게 함수를 작성할 예정이다.\n따라서, GDP를 다음 질문에 대해 답할 수 있다:전체 데이터셋;단일 연도;단일 국가;단일 연도와 단일국가 조합.대신에 %% 연산자를 사용해서, 여러 연도와 국가를 인자에 넘길 수 있다.꿀팁: 값에 의한 전달R에 함수는 거의 항상 데이터 사본을 생성해서 함수 몸통 내부에서\n연산 작업을 수행한다.\n함수 내부 dat 데이터를 변경할 때,\n첫 인자로 전달한 원본 데이터가 아닌 dat에 저장된 gapminder 데이터셋\n사본을 조작하는 것이다.이를 “값에 의한 전달(pass--value)” 라고 부르며,\n코드 작성을 훨씬 더 안전하게 한다:\n함수 몸통부문 내부에서 어떤 변경을 하든, 함수 몸통부문에 한정된 것이라는 것을\n항상 확실히 할 수 있다.꿀팁: 함수 유효범위(Function scope)또한가지 중요한 개념이 유효범위(scoping)다:\n함수 몸통부문 내부에서 생성하거나 변경한 어떤 변수(혹은 함수!)는\n함수 실행 기간동안만 존재한다.\ncalcGDP 함수를 호출할 때, 변수 dat,\ngdp, new는 함수 몸통 내부에서만 존재한다.\n설사 인터랙티브 세션에서 동일한 명칭을 갖는 변수가 있더라도,\n함수가 시행될 때, 어떤 방식으로도 변경되지 않는다.마지막으로, 신규 부분집합 데이터셋에 GDP를 계산하고,\n신규 데이터프레임을 생성하고 동일한 명칭을 갖는 칼럼을 추가한다.\n즉, 나중에 함수를 호출할 때, 반환된 GDP 값에 대한 맥락을 찾아볼 수 있다는 것이다.\n앞서 숫자 벡터보다 이런 점에서 훨씬 더 낫다.","code":"\n# 데이터셋을 인자로 받아, 1인당 GDP 칼럼과 인구수 칼럼을 곱한다.\ncalcGDP <- function(dat) {\n  gdp <- dat$pop * dat$gdpPercap\n  return(gdp)\n}\ncalcGDP(head(gapminder))## [1] 6.57e+09 7.59e+09 8.76e+09 9.65e+09 9.68e+09 1.17e+10\n# 데이터셋을 인자로 받아, 1인당 GDP 칼럼과 인구수 칼럼을 곱한다.\ncalcGDP <- function(dat, year=NULL, country=NULL) {\n  if(!is.null(year)) {\n    dat <- dat[dat$year %in% year, ]\n  }\n  if (!is.null(country)) {\n    dat <- dat[dat$country %in% country,]\n  }\n  gdp <- dat$pop * dat$gdpPercap\n\n  new <- cbind(dat, gdp=gdp)\n  return(new)\n}\nsource(\"functions/functions-lesson.R\")\nhead(calcGDP(gapminder, year=2007))##        country year      pop continent lifeExp gdpPercap      gdp\n## 12 Afghanistan 2007 31889923      Asia    43.8       975 3.11e+10\n## 24     Albania 2007  3600523    Europe    76.4      5937 2.14e+10\n## 36     Algeria 2007 33333216    Africa    72.3      6223 2.07e+11\n## 48      Angola 2007 12420476    Africa    42.7      4797 5.96e+10\n## 60   Argentina 2007 40301927  Americas    75.3     12779 5.15e+11\n## 72   Australia 2007 20434176   Oceania    81.2     34435 7.04e+11\ncalcGDP(gapminder, country=\"Australia\")##      country year      pop continent lifeExp gdpPercap      gdp\n## 61 Australia 1952  8691212   Oceania    69.1     10040 8.73e+10\n## 62 Australia 1957  9712569   Oceania    70.3     10950 1.06e+11\n## 63 Australia 1962 10794968   Oceania    70.9     12217 1.32e+11\n## 64 Australia 1967 11872264   Oceania    71.1     14526 1.72e+11\n## 65 Australia 1972 13177000   Oceania    71.9     16789 2.21e+11\n## 66 Australia 1977 14074100   Oceania    73.5     18334 2.58e+11\n## 67 Australia 1982 15184200   Oceania    74.7     19477 2.96e+11\n## 68 Australia 1987 16257249   Oceania    76.3     21889 3.56e+11\n## 69 Australia 1992 17481977   Oceania    77.6     23425 4.10e+11\n## 70 Australia 1997 18565243   Oceania    78.8     26998 5.01e+11\n## 71 Australia 2002 19546792   Oceania    80.4     30688 6.00e+11\n## 72 Australia 2007 20434176   Oceania    81.2     34435 7.04e+11\ncalcGDP(gapminder, year=2007, country=\"Australia\")##      country year      pop continent lifeExp gdpPercap      gdp\n## 72 Australia 2007 20434176   Oceania    81.2     34435 7.04e+11calcGDP <- function(dat, year=NULL, country=NULL) {\n  if(!is.null(year)) {\n    dat <- dat[dat$year %in% year, ]\n  }\n  if (!is.null(country)) {\n    dat <- dat[dat$country %in% country,]\n  }  gdp <- dat$pop * dat$gdpPercap\n  new <- cbind(dat, gdp=gdp)\n  return(new)\n}"},{"path":"r-function.html","id":"r-function-challenge-four","chapter":"30 .  함수 설명","heading":"30.8 도전과제 4","text":"1987년 뉴질랜드 GPD를 계산하도록 GDP 함수를 테스트한다.\n1952년 뉴질랜드 GDP와 얼마나 차이날까?도전과제 4에 대한 해답1987년 뉴질랜드 GDP: 650500087031952년 뉴질랜드 GDP: 21058193787","code":"\n  calcGDP(gapminder, year = c(1952, 1987), country = \"New Zealand\")"},{"path":"r-function.html","id":"r-function-challenge-five","chapter":"30 .  함수 설명","heading":"30.9 도전과제 5","text":"paste 함수를 사용해서 텍스트를 결합할 수 있다, 즉:text 와 wrapper라는 벡터 인자 두개를 받는 fence라는 함수를 작성한다.\n함수는 wrapper로 둘러싼 텍스트를 출력한다:주목: paste 함수는 sep 라는 인자를 갖는데,\nsep 인자는 텍스트 사이 구분자를 명세한다.\n기본디폴트 설정은 공백이다: ” “. paste0 함수에 대한 기본디폴트 설정은 공백이 없음이다:”“.도전과제 5에 대한 해답text 와 wrapper라는 벡터 인자 두개를 받는 fence라는 함수를 작성한다.\n함수는 wrapper로 둘러싼 텍스트를 출력한다:꿀팁:더 복잡한 연산작업을 수행할 때, 정말 잘 활용될 수 있는 R에만 있는 유일무이한 기능이 있다.\n이러한 고급 개념으로 무장한 함수는 작성하지 않을 것이다.\n향후, R로 함수를 작성하는데 무리가 없다면,\nR Language Manual과 Hadley Wickham 저서 Advanced R Programming\n책에 포함된 환경을 참조한다.\nR은 프레임(frame) 대신에 “환경(environment)”을 용어로 사용한다.꿀팁: 테스트와 문서화함수를 테스트하고 문서화하는 것 모두 중요하다:\n문서화를 하게 되면 여러분과 다른 독자가 작성된 함수 목적과\n사용법을 이해하는데 도움이 된다.작성된 함수가 생각한 대로 실제로 동작하는지 확실히 하는 것도 중요하다.\n처음 시작할 때, 작업흐름은 아마도 다음과 같다:함수를 작성한다.함수 일부에 동작을 문서화하는 주석을 단다.소스 파일에 적재해서 불러온다.콘솔에서 예상한 대로 동작을 확인하는 실험을 한다.필요한 버그를 제거한다.깔끔하게 하고, 상기 과정을 반복한다.함수에 대한 공식 문서는 별도 .Rd 파일에 작성되는데,\n도움말 파일에서 보게 되는 문서로 변환된다.roxygen2 팩키지는 R 프로그래머가 함수 코드와 함께 문서를\n작성하게 돕고, 이 파일을 처리하게 되면 적절한 .Rd 파일로 떨군다.\n더 복잡한 R 프로젝트 코드를 작성할 때,\n문서를 작성하는 공식적인 방법으로 전환하면 된다.\n공식 자동화 테스트는 testthat 팩키지를 사용해서 작성된다.","code":"\nbest_practice <- c(\"Write\", \"programs\", \"for\", \"people\", \"not\", \"computers\")\npaste(best_practice, collapse=\" \")## [1] \"Write programs for people not computers\"\nfence(text=best_practice, wrapper=\"***\")\nfence <- function(text, wrapper){\n  text <- c(wrapper, text, wrapper)\n  result <- paste(text, collapse = \" \")\n  return(result)\n}\nbest_practice <- c(\"Write\", \"programs\", \"for\", \"people\", \"not\", \"computers\")\nfence(text=best_practice, wrapper=\"***\")## [1] \"*** Write programs for people not computers ***\""},{"path":"r-writing.html","id":"r-writing","chapter":"31 .  데이터 저장","heading":"31 .  데이터 저장","text":"","code":""},{"path":"r-writing.html","id":"r-saving-image","chapter":"31 .  데이터 저장","heading":"31.1 그래프 저장하기","text":"ggsave 명령어를 사용해서,\nggplot2에서 생성한 가장 최신 도식화 결과물을 저장하는 방법을 이미 살펴봤다.\n다시금 상기시키기 위해 명령어를 적어보면 다음과 같다:RStudio 내부에서 그래프로 저장할 경우,\n‘Plot’ 윈도우에서 ‘Export’ 내보내기 버튼을 사용한다.\n버튼을 클릭하면, .pdf, .png, .jpg 혹은 다른 이미지 형식으로 저장할지\n선택옵션을 제시된다.종종, ‘Plot’ 윈도우에 먼저 찍어보지 말고, 도표를 저장하고 싶을 때도 있다.\n아마도 여러 페이지에 걸친 pdf 문서를 생성하고 싶을 것이다:\n예를 들어, 각각은 다른 도표로 말이다.\n혹은, 다수 파일에서 부분집합으로 데이터를 뽑아내고,\n각 하위 데이터에 대해 도식화를 하고, 결과물을 도표로 저장하고자 한다.\n하지만, 각각에 대해 ‘Export’ 내보내기 버튼을 클릭하려고 루프를\n중단할 수는 없는 노릇이다.이런 경우, 더 유연한 접근법을 사용할 수 있다.\npdf 함수는 신류 pdf 장치를 생성한다.\npdf 함수에 여러 인자를 사용해서, 크기와 해상도를 조절할 수 있다.저장한 문서를 열어서 살펴본다.","code":"\nggsave(\"My_most_recent_plot.pdf\")\npdf(\"Life_Exp_vs_time.pdf\", width=12, height=4)\nggplot(data=gapminder, aes(x=year, y=lifeExp, colour=country)) +\n  geom_line() +\n  theme(legend.position = \"none\")\n\n# You then have to make sure to turn off the pdf device!\n\ndev.off()"},{"path":"r-writing.html","id":"r-writing-challenge-one","chapter":"31 .  데이터 저장","heading":"31.2 도전과제 1","text":"pdf 명령어를 다시 작성해서 pdf 파일에 두번째 페이지를 찍는다.\n각 창 패널에 대륙별로 데이터를 패싯 도표(힌트: facet_grid 사용)로 출력한다.도전과제 1에 대한 해답jpeg, png 등등 명령어도 다양한 형식으로 문서를 저장하는데,\n유사하게 사용하면 된다.","code":"\npdf(\"Life_Exp_vs_time.pdf\", width = 12, height = 4)\np <- ggplot(data = gapminder, aes(x = year, y = lifeExp, colour = country)) +\n  geom_line() +\n  theme(legend.position = \"none\")\np\np + facet_grid(. ~continent)\ndev.off()"},{"path":"r-writing.html","id":"r-writing-file","chapter":"31 .  데이터 저장","heading":"31.3 데이터를 파일 저장","text":"어느 시점이 되면, R에서 데이터를 내보내서 파일에 저장하기도 한다.이런 목적으로 write.table 함수를 사용하는데,\n앞서 살펴본 read.table 함수와 매우 유사하다.데이터 정제 스크립트를 생성하자.\ngapminder 데이터에서 Australia 호주만 집중한다:쉘로 다시 전환해서, 모든 것이 정상인지 데이터를 살펴본다:음… 엄밀하게 보면 원하는 바는 아니다.\n이 모든 인용부호는 어디서 왔을까?\n또한 행번호도 보이는데 무의미하다.도움말 파일을 살펴보고, 파일에 저장하는 방식을 변경해 본다.기본디폴트 설정으로 데이터를 파일에 저장할 때,\nR은 자동으로 인용부호로 문자벡터를 감싼다.\n행과 칼럼 명칭도 파일에 저장한다.다음과 같이 고쳐본다:쉘 기술을 사용해서 다시 데이터를 살펴본다:훨씬 좋아보인다!","code":"\naust_subset <- gapminder[gapminder$country == \"Australia\",]\n\nwrite.table(aust_subset,\n  file=\"data/gapminder-aus.csv\",\n  sep=\",\"\n)head data/gapminder-aus.csv\n\n\"country\",\"year\",\"pop\",\"continent\",\"lifeExp\",\"gdpPercap\"\n\"61\",\"Australia\",1952,8691212,\"Oceania\",69.12,10039.59564\n\"62\",\"Australia\",1957,9712569,\"Oceania\",70.33,10949.64959\n\"63\",\"Australia\",1962,10794968,\"Oceania\",70.93,12217.22686\n\"64\",\"Australia\",1967,11872264,\"Oceania\",71.1,14526.12465\n\"65\",\"Australia\",1972,13177000,\"Oceania\",71.93,16788.62948\n\"66\",\"Australia\",1977,14074100,\"Oceania\",73.49,18334.19751\n\"67\",\"Australia\",1982,15184200,\"Oceania\",74.74,19477.00928\n\"68\",\"Australia\",1987,16257249,\"Oceania\",76.32,21888.88903\n\"69\",\"Australia\",1992,17481977,\"Oceania\",77.56,23424.76683\n?write.table\nwrite.table(\n  gapminder[gapminder$country == \"Australia\",],\n  file=\"data/gapminder-aus.csv\",\n  sep=\",\", quote=FALSE, row.names=FALSE\n)head data/gapminder-aus.csv"},{"path":"r-writing.html","id":"r-writing-challenge-two","chapter":"31 .  데이터 저장","heading":"31.4 도전과제 2","text":"1990 년 이후 수집된 데이터를 gapminder 데이터에서\n부분집합으로 구성하는 데이터-정제 스크립트를 작성하라.\n상기 스크립트를 사용해서, 작업한 신규 부분집합 데이터를\ndata/ 디렉토리에 파일로 저장한다.도전과제 2에 대한 해답","code":"\nwrite.table(\n  gapminder[gapminder$year > 1990, ],\n  file = \"data/gapminder-after1990.csv\",\n  sep = \",\", quote = FALSE, row.names = FALSE\n)"},{"path":"r-plyr-split.html","id":"r-plyr-split","chapter":"32 .  plyr로 데이터프레임을 쪼개고 합치기","heading":"32 .  plyr로 데이터프레임을 쪼개고 합치기","text":"앞서, 함수를 사용해서 코드를 단순화하는 방법을 살펴봤다.\ngapminder 데이터셋을 인자로 받아, 인구(population)와 인당 GDP를 곱해 GPD를 계산하는\ncalcGDP 함수를 정의했다.\n추가적인 인자를 정의해서, year 연도별, country 국가별 필터를 적용할 수도 있다:데이터 작업을 할 때, 흔히 마주치는 작업이 집단별 그룹으로 묶어 계산하는 것이다.\n위에서, 단순히 두 칼럼을 곱해서 GDP를 계산했다.\n하지만, 대륙별로 평균 GDP를 계산하고자 한다면 어떨까?calcGDP를 실행하고 나서, 각 대륙별로 평균을 산출한다:하지만, 그다지 멋있지는 않다.\n그렇다. 함수를 사용해서, 반복되는 상당량 작업을 줄일 수 있었다.\n함수 사용은 멋있었다. 하지만, 여전히 반복이 있다.\n여러분이 직접 반복하게 되면, 일단 여러분 시간을 지금은 물론이고 그리고 나중에도 까먹게 되고,\n잠재적으로 버그가 스며들 여지를 남기게 된다.calcGDP처럼 유연성 있는 함수를 새로 작성할 수도 있지만,\n제대로 동작하는 함수를 개발하기까지 상당량 노력과 테스트가 필요하다.여기서 맞닥드린 추상화 문제를 “분할-적용-병합(split-apply-combine)” 전략이라고 부른다:Split apply combine데이터를 집단으로 분할(split)하고, 이번 경우에 대륙,\n해당 집단에 연산작업을 적용(apply)하고 나서,\n선택옵션으로 결과를 묶어 병합(combine)한다.","code":"\n# Takes a dataset and multiplies the population column\n# with the GDP per capita column.\ncalcGDP <- function(dat, year=NULL, country=NULL) {\n  if(!is.null(year)) {\n    dat <- dat[dat$year %in% year, ]\n  }\n  if (!is.null(country)) {\n    dat <- dat[dat$country %in% country,]\n  }\n  gdp <- dat$pop * dat$gdpPercap\n\n  new <- cbind(dat, gdp=gdp)\n  return(new)\n}\nwithGDP <- calcGDP(gapminder)\nmean(withGDP[withGDP$continent == \"Africa\", \"gdp\"])## [1] 2.09e+10\nmean(withGDP[withGDP$continent == \"Americas\", \"gdp\"])## [1] 3.79e+11\nmean(withGDP[withGDP$continent == \"Asia\", \"gdp\"])## [1] 2.27e+11"},{"path":"r-plyr-split.html","id":"r-plyr","chapter":"32 .  plyr로 데이터프레임을 쪼개고 합치기","heading":"32.1 plyr 팩키지","text":"R을 예전에 사용했다면, apply 함수 가족에 친숙할 수 있다.\nR 내장함수도 동작이 잘 되지만, “분할-적용-병합” 문제를 해결하는데 사용되는 또다른 방법을 소개한다.\nplyr 팩키지는 이런 유형의 문제를 해결하는데 훨씬 사용자 친화적인\n함수를 집합으로 제공한다.이전 도전과제에서 plyr 팩키지를 설치했다. 이제 plyr 불러와서 적재한다:plyr 팩키지에는 리스트(lists), 데이터프레임(data.frames), 배열(arrays, 행렬, n-차원 벡터)\n자료형 연산을 위한 함수가 있다. 함수 각각은 다음 작업을 수행한다:분할(split)하는 연산순서대로 각각 쪼갠 것에 함수를 적용(apply)한다.데이터 객체로 출력 데이터로 다시 병합(combine)한다.입력값으로 예상되는 자료구조와 출력값으로 반환되는 자료구조에 기반해서 함수명이 붙여졌다:\n[]rray, [l]ist, [d]ata.frame.\n첫번째 문자가 입력 자료구조, 두번째 문자가 출력 자료구조에 대응되고,\n함수 나머지에 “ply”를 붙인다.[]rray, [l]ist, [d]ata.frame 를 입력과 출력에 조합하면 핵심 **ply 함수 9개가 산출된다.\n분할과 적용 단계만 수행하고 병합단계를 거치지 않는 함수가 추가로 3개 있다.\n입력 데이터 자료형에 NULL 출력값(_)으로 표현된다. (아래 테이블 참조)여기서 “배열”에 대한 plyr이 다른 것과 다름에 주목한다.\nply에 사용되는 배열은 벡터 혹은 행렬을 포함할 수 있다.전체 apply 개요xxply 함수(daply, ddply, llply, laply, …) 각각은 동일한 구조를 갖고,\n4가지 주요 기능을 갖는다:함수명 첫글자는 입력 자료형, 함수 두번째 글자는 출력 자료형을 나타낸다..data - 처리될 자료객체를 나타낸다..variables - 분할(split)변수를 식별한다..fun - 각 그룹 집단에 연산작업을 위해 호출되는 함수.이제, 대륙별로 평균 GDP를 신속하게 계산할 수 있다:방금전 코드에서 일어난 사건을 복기해 보자:ddply 함수에 data.frame 데이터프레임을 집어넣고(함수명이 d로 시작),\n또다른 data.frame 데이터프레임을 반환한다(함수명 두번째 문자 d).전달한 첫번째 인자는 연산작업을 실행하고자 하는 데이터프레임이다: 이번 경우에 gapminder 데이터.\n먼저 calcGDP 함수를 호출해서, gapminder 데이터프레임에 gdp 칼럼을 추가한다.두번째 인자가 분할 조건을 명시한다: 이번 경우에, “대륙(continent)” 칼럼이다.\n부분집합(subsetting) 연산으로 이전에 수행했던 것처럼, 실제 칼럼 자체가 아니라,\n칼럼명만 부여했음에 주목한다. plyr 팩키지에 자세한 구현이 되어 있어, 칼럼명만 전달하면 된다.세번째 인자는 그룹 집단 각각에 적용하고자 하는 함수다.\n이번 경우에는, 짧은 함수를 자체 정의했다:\n데이터 각 부분집합은 함수 첫번째 인자, x에 저장되어 있다.\n이것을 람다 함수라고 부른다: 어디서도 정의하지 않았기 때문에, 이름이 없는 무명함수다.\nddply 함수가 호출되는 범위(scope)에만 존재한다.출력 자료구조를 달리하면 어떨까?","code":"\nlibrary(\"plyr\")\nxxply(.data, .variables, .fun)\nddply(\n .data = calcGDP(gapminder),\n .variables = \"continent\",\n .fun = function(x) mean(x$gdp)\n)##   continent       V1\n## 1    Africa 2.09e+10\n## 2  Americas 3.79e+11\n## 3      Asia 2.27e+11\n## 4    Europe 2.69e+11\n## 5   Oceania 1.88e+11"},{"path":"r-plyr-split.html","id":"plyr-challenge-one","chapter":"32 .  plyr로 데이터프레임을 쪼개고 합치기","heading":"32.2 도전과제 1","text":"대륙별로 평균 기대수명을 계산하라.\n어느 대륙이 가장 기대수명이 긴가?\n어느 대륙이 가장 기대수명이 짧은가?도전과제 1에 대한 해답오세아니아 대륙이 가장 길고 아프리카 대륙이 가장 짧다.출력 자료구조를 달리하면 어떨까?동일한 함수를 호출했지만, 두번째 문자만 l로 변경했다.\n그래서, 출력결과가 리스트로 반환됐다.다수 칼럼을 지정해서 그룹별로 group 할 수 있다:루프 자리에 람다 함수를 사용할 수 있다(대체로 더 빠르다):\n루프 몸통부분을 람다 함수에 작성하면 된다:꿀팁: 숫자 출력하기format 함수를 사용해서 메시지와 함께 숫자값을 “예쁘게” 출력할 수도 있다.","code":"\nddply(\n .data = gapminder,\n .variables = \"continent\",\n .fun = function(x) mean(x$lifeExp)\n)##   continent   V1\n## 1    Africa 48.9\n## 2  Americas 64.7\n## 3      Asia 60.1\n## 4    Europe 71.9\n## 5   Oceania 74.3\ndlply(\n .data = calcGDP(gapminder),\n .variables = \"continent\",\n .fun = function(x) mean(x$gdp)\n)## $Africa\n## [1] 2.09e+10\n## \n## $Americas\n## [1] 3.79e+11\n## \n## $Asia\n## [1] 2.27e+11\n## \n## $Europe\n## [1] 2.69e+11\n## \n## $Oceania\n## [1] 1.88e+11\n## \n## attr(,\"split_type\")\n## [1] \"data.frame\"\n## attr(,\"split_labels\")\n##   continent\n## 1    Africa\n## 2  Americas\n## 3      Asia\n## 4    Europe\n## 5   Oceania\nddply(\n .data = calcGDP(gapminder),\n .variables = c(\"continent\", \"year\"),\n .fun = function(x) mean(x$gdp)\n)##    continent year       V1\n## 1     Africa 1952 5.99e+09\n## 2     Africa 1957 7.36e+09\n## 3     Africa 1962 8.78e+09\n## 4     Africa 1967 1.14e+10\n## 5     Africa 1972 1.51e+10\n## 6     Africa 1977 1.87e+10\n## 7     Africa 1982 2.20e+10\n## 8     Africa 1987 2.41e+10\n## 9     Africa 1992 2.63e+10\n## 10    Africa 1997 3.00e+10\n## 11    Africa 2002 3.53e+10\n## 12    Africa 2007 4.58e+10\n## 13  Americas 1952 1.18e+11\n## 14  Americas 1957 1.41e+11\n## 15  Americas 1962 1.69e+11\n## 16  Americas 1967 2.18e+11\n## 17  Americas 1972 2.68e+11\n## 18  Americas 1977 3.24e+11\n## 19  Americas 1982 3.63e+11\n## 20  Americas 1987 4.39e+11\n## 21  Americas 1992 4.90e+11\n## 22  Americas 1997 5.83e+11\n## 23  Americas 2002 6.61e+11\n## 24  Americas 2007 7.77e+11\n## 25      Asia 1952 3.41e+10\n## 26      Asia 1957 4.73e+10\n## 27      Asia 1962 6.01e+10\n## 28      Asia 1967 8.46e+10\n## 29      Asia 1972 1.24e+11\n## 30      Asia 1977 1.60e+11\n## 31      Asia 1982 1.94e+11\n## 32      Asia 1987 2.42e+11\n## 33      Asia 1992 3.07e+11\n## 34      Asia 1997 3.88e+11\n## 35      Asia 2002 4.58e+11\n## 36      Asia 2007 6.28e+11\n## 37    Europe 1952 8.50e+10\n## 38    Europe 1957 1.10e+11\n## 39    Europe 1962 1.39e+11\n## 40    Europe 1967 1.73e+11\n## 41    Europe 1972 2.19e+11\n## 42    Europe 1977 2.55e+11\n## 43    Europe 1982 2.79e+11\n## 44    Europe 1987 3.17e+11\n## 45    Europe 1992 3.43e+11\n## 46    Europe 1997 3.84e+11\n## 47    Europe 2002 4.36e+11\n## 48    Europe 2007 4.93e+11\n## 49   Oceania 1952 5.42e+10\n## 50   Oceania 1957 6.68e+10\n## 51   Oceania 1962 8.23e+10\n## 52   Oceania 1967 1.06e+11\n## 53   Oceania 1972 1.34e+11\n## 54   Oceania 1977 1.55e+11\n## 55   Oceania 1982 1.76e+11\n## 56   Oceania 1987 2.09e+11\n## 57   Oceania 1992 2.36e+11\n## 58   Oceania 1997 2.89e+11\n## 59   Oceania 2002 3.45e+11\n## 60   Oceania 2007 4.04e+11\ndaply(\n .data = calcGDP(gapminder),\n .variables = c(\"continent\", \"year\"),\n .fun = function(x) mean(x$gdp)\n)##           year\n## continent      1952     1957     1962     1967     1972     1977     1982\n##   Africa   5.99e+09 7.36e+09 8.78e+09 1.14e+10 1.51e+10 1.87e+10 2.20e+10\n##   Americas 1.18e+11 1.41e+11 1.69e+11 2.18e+11 2.68e+11 3.24e+11 3.63e+11\n##   Asia     3.41e+10 4.73e+10 6.01e+10 8.46e+10 1.24e+11 1.60e+11 1.94e+11\n##   Europe   8.50e+10 1.10e+11 1.39e+11 1.73e+11 2.19e+11 2.55e+11 2.79e+11\n##   Oceania  5.42e+10 6.68e+10 8.23e+10 1.06e+11 1.34e+11 1.55e+11 1.76e+11\n##           year\n## continent      1987     1992     1997     2002     2007\n##   Africa   2.41e+10 2.63e+10 3.00e+10 3.53e+10 4.58e+10\n##   Americas 4.39e+11 4.90e+11 5.83e+11 6.61e+11 7.77e+11\n##   Asia     2.42e+11 3.07e+11 3.88e+11 4.58e+11 6.28e+11\n##   Europe   3.17e+11 3.43e+11 3.84e+11 4.36e+11 4.93e+11\n##   Oceania  2.09e+11 2.36e+11 2.89e+11 3.45e+11 4.04e+11\nd_ply(\n  .data=gapminder,\n  .variables = \"continent\",\n  .fun = function(x) {\n    meanGDPperCap <- mean(x$gdpPercap)\n    print(paste(\n      \"The mean GDP per capita for\", unique(x$continent),\n      \"is\", format(meanGDPperCap, big.mark=\",\")\n   ))\n  }\n)## [1] \"The mean GDP per capita for Africa is 2,194\"\n## [1] \"The mean GDP per capita for Americas is 7,136\"\n## [1] \"The mean GDP per capita for Asia is 7,902\"\n## [1] \"The mean GDP per capita for Europe is 14,469\"\n## [1] \"The mean GDP per capita for Oceania is 18,622\""},{"path":"r-plyr-split.html","id":"r-plyr-challenge-two","chapter":"32 .  plyr로 데이터프레임을 쪼개고 합치기","heading":"32.3 도전과제 2","text":"대륙과 연도별로 평균 기대수명을 계산하시오.\n2007년에 어느 것이 가장 짧고, 가장 긴가?\n1952년과 2007년 사이에 가장 커다란 변화는 어느 것인가?도전과제 2에 대한 해답오세아니아 대륙이 2007년 가장 긴 평균 기대수명을 갖는 반면 아프리카 대륙이\n가장 짧다.아시아 대륙이 가장 큰 차를 보이는 반면 오세아니아 대륙이 가장 적은 차를 보인다.","code":"\nsolution <- ddply(\n .data = gapminder,\n .variables = c(\"continent\", \"year\"),\n .fun = function(x) mean(x$lifeExp)\n)\nsolution_2007 <- solution[solution$year == 2007, ]\nsolution_2007##    continent year   V1\n## 12    Africa 2007 54.8\n## 24  Americas 2007 73.6\n## 36      Asia 2007 70.7\n## 48    Europe 2007 77.6\n## 60   Oceania 2007 80.7\nsolution_1952_2007 <- cbind(solution[solution$year == 1952, ], solution_2007)\ndifference_1952_2007 <- data.frame(continent = solution_1952_2007$continent,\n                                   year_1957 = solution_1952_2007[[3]],\n                                   year_2007 = solution_1952_2007[[6]],\n                                   difference = solution_1952_2007[[6]] - solution_1952_2007[[3]])\ndifference_1952_2007##   continent year_1957 year_2007 difference\n## 1    Africa      39.1      54.8       15.7\n## 2  Americas      53.3      73.6       20.3\n## 3      Asia      46.3      70.7       24.4\n## 4    Europe      64.4      77.6       13.2\n## 5   Oceania      69.3      80.7       11.5"},{"path":"r-plyr-split.html","id":"r-plyr-alternative","chapter":"32 .  plyr로 데이터프레임을 쪼개고 합치기","heading":"32.4 대안 도전과제","text":"실제로 실행하지 말고, 다음 중 어떤 코드가 대륙별 평균 기대수명을 계산하는가:도전과제에 대한 해답대륙별 평균 기대수명을 4번째 R 코드로 계산할 수 있다.","code":"\nddply(\n  .data = gapminder,\n  .variables = gapminder$continent,\n  .fun = function(dataGroup) {\n     mean(dataGroup$lifeExp)\n  }\n)\nddply(\n  .data = gapminder,\n  .variables = \"continent\",\n  .fun = mean(dataGroup$lifeExp)\n)\nddply(\n  .data = gapminder,\n  .variables = \"continent\",\n  .fun = function(dataGroup) {\n     mean(dataGroup$lifeExp)\n  }\n)\nadply(\n  .data = gapminder,\n  .variables = \"continent\",\n  .fun = function(dataGroup) {\n     mean(dataGroup$lifeExp)\n  }\n)"},{"path":"r-dplyr.html","id":"r-dplyr","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33 .  dplyr 솜씨있게 조작","text":"데이터프레임을 솜씨있게 조작하는 것은 많은 과학연구원에게 많은 것을 의미한다.\n특정 관측점(행) 혹은 변수(열)을 선택하거나,\n특정 변수(들)로 데이터를 집단으로 그룹짓거나, 요약 통계량을 계산하기도 한다.\n이런 연산작업에 정규 기본 베이스(Base) R 연산을 사용한다:하지만, 그다지 멋있지는 않은데, 이유는 상당한 반복이 상존하기 때문이다.\n여러분이 직접 반복하게 되면, 일단 여러분 시간을 지금 물론이고, 나중에 소중한 시간을 까먹게 되고,\n더나아가 잠재적으로 버그가 스며들 여지를 남기게 된다.","code":"\nmean(gapminder[gapminder$continent == \"Africa\", \"gdpPercap\"])## [1] 2194\nmean(gapminder[gapminder$continent == \"Americas\", \"gdpPercap\"])## [1] 7136\nmean(gapminder[gapminder$continent == \"Asia\", \"gdpPercap\"])## [1] 7902"},{"path":"r-dplyr.html","id":"r-dplyr-pkg","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.1 dplyr 팩키지","text":"운좋게도, dplyr 팩키지가\n데이터프레임을 솜씨있게 조작하는데 있어 유용한 함수를 많이 제공한다.\n이를 통해서, 위에서 언급된 반복을 줄이고, 실수를 범할 확률도 줄이고,\n심지어 타이핑하는 수고도 줄일 수 있다.\n보너스로, dplyr 문법은 훨씬 더 가독성도 높다.가장 흔히 사용되는 6가지 함수 뿐만 아니라,\n이런 함수를 조합하는데 사용되는 파이프 (%>%) 연산자 사용법도 다룬다.select()filter()group_by()summarize()mutate()이전 수업에서 팩키지를 설치하지 않았다면, 설치해서 직접 실습해보기 바란다:이제 팩키지를 불러와서 적재한다:","code":"\ninstall.packages('dplyr')\nlibrary(\"dplyr\")"},{"path":"r-dplyr.html","id":"r-dplyr-select","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.2 select() 사용","text":"예를 들어, 데이터프레임에서 변수 일부만 뽑아서 작업해 나가고자 한다면,\nselect() 함수를 사용한다.\n이 함수는 선택한 변수만 갖도록 지정한다.year_country_gdp 데이터프레임을 열게되면,\nyear, country, gdpPercap 변수만 담겨있는 것을 보게 된다.\n위에서는 정규 문법이 사용되었지만,\ndplyr 팩키지의 장점은 파이프를 사용해서 함수 다수를 조합하는데 있다.\n파이프 문법은 이전에 R에서 살펴봤던 것과는 사뭇 다르다.\n위에서 파이프를 사용했던 것을 다시 작성해본다.파이프를 사용해서 작성한 이유에 대한 이해를 돕기 위해서, 단계별로 살펴보자.\n먼저 gapminder 데이터프레임을 불러오고 나서,\n%>% 파이프 기호를 사용해서 다음 작업단계(select() 함수)로 전달했다.\n이번 경우에는 select() 함수에 데이터 객체를 명세하지 않았다.\n이유는 이전 파이프로부터 건네받았기 때문이다.\n재미난 사실: 유닉스 쉘 강의에서 이미 파이프를 접해봤을 것이다.\nR에서 파이프 기호가 %>%인 반면, 쉘에서는 |을 사용한다.\n하지만, 개념은 동일하다!","code":"\nyear_country_gdp <- select(gapminder,year,country,gdpPercap)\nyear_country_gdp <- gapminder %>% select(year,country,gdpPercap)"},{"path":"r-dplyr.html","id":"r-dplyr-filter","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.3 filter() 사용","text":"이제 앞선 작업을 바탕으로 앞으로 작업을 진척시켜 보자.\n유럽대륙만 갖고 작업하고자 한다. select 와 filter를 조합하면 된다.명령어를 하나 (여러 행에 걸칠 수 있고, 파이프도 포함한다) 작성하는데,\nlifeExp, country, year 변수에 대해서 아프리카 대륙(African)만 갖는 데이터프레임을 작성한다.\n하지만, 다른 대륙은 포함되면 안된다.\n데이터프레임 행의 갯수는 얼마나 되는가? 그리고 이유는 무엇인가?{: .solution}\n{: .challenge}지난번과 마찬가지로, gapminder 데이터프레임을 filter() 함수에 전달하고 나서,\n필터링된 gapminder 데이터프레임 버젼을 select() 함수에 전달한다.\n주의: 연산순서가 이번 경우에 무척 중요하다.\nselect() 함수를 먼저 실행하면, filter() 함수는 대륙 변수를 찾을 수 없는데,\n이유는 이전 단계에서 제거했기 때문이다.","code":"\nyear_country_gdp_euro <- gapminder %>%\n    filter(continent==\"Europe\") %>%\n    select(year,country,gdpPercap)\nyear_country_lifeExp_Africa <- gapminder %>%\n                           filter(continent==\"Africa\") %>%\n                           select(year,country,lifeExp)"},{"path":"r-dplyr.html","id":"r-dplyr-groupby-summarize","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.4 group_by()와 summarize() 사용","text":"이제, 기본 베이스(base) R로 작업함으로써 실수를 범하기 쉬운 반복작업을 줄일 것으로 생각했지만,\n현재까지 목표를 달성하지 못했다. 왜냐하면, 각 대륙마다 상기 작업을 반복해야 되기 때문이다.\nfilter() 대신에, group_by()를 사용한다.\nfilter()는 특정 기준을 만족하는 관측점만 넘겨준다(이번 경우: continent==\"Europe\").\ngroup_by()는 본질적으로, 필터에서 사용할 수 있는 모든 유일무이한 기준을 사용할 수 있다.group_by() 함수를 사용한 데이터프레임 구조(grouped_df)가 원래 gapminder 데이터프레임 구조(data.frame)와 같지 않음에 주목한다.\ngrouped_df는 list 리스트로 간주될 있는데, list에 각 항목은 data.frame으로,\n각 데이터프레임은 특정 대륙 continent에 대응되는 행만 담겨진다(적어도 상기 예제의 경우).","code":"\nstr(gapminder)## 'data.frame':    1704 obs. of  6 variables:\n##  $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n##  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n##  $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n##  $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n##  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n##  $ gdpPercap: num  779 821 853 836 740 ...\nstr(gapminder %>% group_by(continent))## grouped_df [1,704 × 6] (S3: grouped_df/tbl_df/tbl/data.frame)\n##  $ country  : chr [1:1704] \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n##  $ year     : int [1:1704] 1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n##  $ pop      : num [1:1704] 8425333 9240934 10267083 11537966 13079460 ...\n##  $ continent: chr [1:1704] \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n##  $ lifeExp  : num [1:1704] 28.8 30.3 32 34 36.1 ...\n##  $ gdpPercap: num [1:1704] 779 821 853 836 740 ...\n##  - attr(*, \"groups\")= tibble [5 × 2] (S3: tbl_df/tbl/data.frame)\n##   ..$ continent: chr [1:5] \"Africa\" \"Americas\" \"Asia\" \"Europe\" ...\n##   ..$ .rows    : list<int> [1:5] \n##   .. ..$ : int [1:624] 25 26 27 28 29 30 31 32 33 34 ...\n##   .. ..$ : int [1:300] 49 50 51 52 53 54 55 56 57 58 ...\n##   .. ..$ : int [1:396] 1 2 3 4 5 6 7 8 9 10 ...\n##   .. ..$ : int [1:360] 13 14 15 16 17 18 19 20 21 22 ...\n##   .. ..$ : int [1:24] 61 62 63 64 65 66 67 68 69 70 ...\n##   .. ..@ ptype: int(0) \n##   ..- attr(*, \".drop\")= logi TRUE"},{"path":"r-dplyr.html","id":"r-dplyr-summarize","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.5 summarize() 사용","text":"상기 예제는 그다지 특별한 점이 없다.\n왜냐하면 group_by() 함수는 summarize()와 함께할 때 훨씬 더 흥미롭다.\n두 함수를 조합하면 새로운 변수가 생성되는데,\n각 대륙별 데이터프레임에 대해 반복적인 함수 작업을 수행할 수 있다.\n다시 말해, group_by() 함수를 사용해서,\n최초 데이터프레임을 다수 조각으로 쪼개고 나서,\n각각에 대해 함수(예를 들어 mean() 혹은 sd())를 summarize() 내부에서 실행시키게 된다.상기 코드는 각 대륙별로 평균 gdpPercap를 계산할 수 있게 하지만, 훨씬 더 낫다.","code":"\ngdp_bycontinents <- gapminder %>%\n    group_by(continent) %>%\n    summarize(mean_gdpPercap=mean(gdpPercap))continent mean_gdpPercap\n     <fctr>          <dbl>\n1    Africa       2193.755\n2  Americas       7136.110\n3      Asia       7902.150\n4    Europe      14469.476\n5   Oceania      18621.609"},{"path":"r-dplyr.html","id":"r-dplyr-challenge-two","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.6 도전과제 2","text":"국가별로 평균 기대수명을 계산한다.\n어느 국가가 가장 평균 기대수명이 길고,\n어느 국가가 가장 평균 기대수명이 짧은가?도전과제 2에 대한 해답문제를 프는 또 다른 방식은 dplyr 팩키지 arrange() 함수를 사용하는 것이다.\narrange() 함수는 변수에 따라 데이터프레임을 행으로 정렬하는 기능을 갖고 있다.\ndplyr 팩키지 다른 함수처럼 유사한 구문을 갖추고 있다.\narrange() 함수 내부에 desc() 함수를 사용해서 내림차순으로 정렬할 수 있다.group_by() 훔수에 변수 다수를 사용해서 집단으로 그룹을 만들 수도 있다.\nyear 와 continent 변수로 그룹을 만들어 보자.이미 매우 막강한 기능이지만, 더 좋게 만들 수 있다!\nsummarize() 함수에 변수 하나를 정의하는 것에 한정되지 않고, 확장도 가능하다.","code":"\nlifeExp_bycountry <- gapminder %>%\n   group_by(country) %>%\n   summarize(mean_lifeExp=mean(lifeExp))\n\nlifeExp_bycountry %>%\n   filter(mean_lifeExp == min(mean_lifeExp) | mean_lifeExp == max(mean_lifeExp))## # A tibble: 2 × 2\n##   country      mean_lifeExp\n##   <chr>               <dbl>\n## 1 Iceland              76.5\n## 2 Sierra Leone         36.8\nlifeExp_bycountry %>%\n   arrange(mean_lifeExp) %>%\n   head(1)## # A tibble: 1 × 2\n##   country      mean_lifeExp\n##   <chr>               <dbl>\n## 1 Sierra Leone         36.8\nlifeExp_bycountry %>%\n   arrange(desc(mean_lifeExp)) %>%\n   head(1)## # A tibble: 1 × 2\n##   country mean_lifeExp\n##   <chr>          <dbl>\n## 1 Iceland         76.5\ngdp_bycontinents_byyear <- gapminder %>%\n    group_by(continent,year) %>%\n    summarize(mean_gdpPercap=mean(gdpPercap))\ngdp_pop_bycontinents_byyear <- gapminder %>%\n    group_by(continent,year) %>%\n    summarize(mean_gdpPercap=mean(gdpPercap),\n              sd_gdpPercap=sd(gdpPercap),\n              mean_pop=mean(pop),\n              sd_pop=sd(pop))"},{"path":"r-dplyr.html","id":"r-dplyr-count","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.7 count()와 n()","text":"매우 흔한 연산 중 하나는 각 그룹마다 관측점 수를 세는 것이다.\ndplyr 팩키지에 개수를 돕는 연관 함수가 2개 있다.예를 들어, 2002년 데이터셋에 포함된 국가수를 확인하고자 한다면,\ncount() 함수를 사용하는데, 관심있는 그룹을 포함하는 칼럼을 하나이상 지정할 수도 있다.\n선택사항으로 sort=TRUE를 인자로 추가하면 내림차순으로 결과를 정렬할 수 있다:계산과정에서 관측점 갯수를 파악할 필요가 있는 경우, n() 함수가 유용하다.\n예를 들어, 각 대륙별 기대수명 표준오차를 다음과 같이 구할 수도 있다:요약 연산을 몇개 엮어서 계산할 수도 있다;\n이 경우 각 대륙별 기대수명에 대한 minimum, maximum, mean, se 값을 다음과 같이 계산한다:","code":"\ngapminder %>%\n    filter(year == 2002) %>%\n    count(continent, sort = TRUE)##   continent  n\n## 1    Africa 52\n## 2      Asia 33\n## 3    Europe 30\n## 4  Americas 25\n## 5   Oceania  2\ngapminder %>%\n    group_by(continent) %>%\n    summarize(se_le = sd(lifeExp)/sqrt(n()))## # A tibble: 5 × 2\n##   continent se_le\n##   <chr>     <dbl>\n## 1 Africa    0.366\n## 2 Americas  0.540\n## 3 Asia      0.596\n## 4 Europe    0.286\n## 5 Oceania   0.775\ngapminder %>%\n    group_by(continent) %>%\n    summarize(\n      mean_le = mean(lifeExp),\n      min_le = min(lifeExp),\n      max_le = max(lifeExp),\n      se_le = sd(lifeExp)/sqrt(n()))## # A tibble: 5 × 5\n##   continent mean_le min_le max_le se_le\n##   <chr>       <dbl>  <dbl>  <dbl> <dbl>\n## 1 Africa       48.9   23.6   76.4 0.366\n## 2 Americas     64.7   37.6   80.7 0.540\n## 3 Asia         60.1   28.8   82.6 0.596\n## 4 Europe       71.9   43.6   81.8 0.286\n## 5 Oceania      74.3   69.1   81.2 0.775"},{"path":"r-dplyr.html","id":"r-dplyr-mutate","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.8 mutate() 사용","text":"mutate() 함수를 사용해서 정보를 요약하기 전에(혹은 후에도) 새로운 변수를 생성할 수 있다.","code":"\ngdp_pop_bycontinents_byyear <- gapminder %>%\n    mutate(gdp_billion=gdpPercap*pop/10^9) %>%\n    group_by(continent,year) %>%\n    summarize(mean_gdpPercap=mean(gdpPercap),\n              sd_gdpPercap=sd(gdpPercap),\n              mean_pop=mean(pop),\n              sd_pop=sd(pop),\n              mean_gdp_billion=mean(gdp_billion),\n              sd_gdp_billion=sd(gdp_billion))"},{"path":"r-dplyr.html","id":"r-dplyr-ifelse","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.9 mutate() 논리 필터 연결","text":"변수를 새로 만들 때, mutate() 함수를 논리 조건문과 엮을 수 있다.\nmutate() 와 ifelse()의 단순 조합을 통해서 필요한 것만 적절히 필터링할 수 있다: 즉, 새로운 무언가를 생성하는 순간에 말이다.\n이러한 가독성 높은 문장을 통해서 (데이터프레임 전체 차원을 변경시키지 않고도) 특정 데이터를 버리거나,\n조건에 따라 값을 갱신하는데 신속하고 강력한 방식을 제공할 수 있게 된다.","code":"\n## keeping all data but \"filtering\" after a certain condition\n# calculate GDP only for people with a life expectation above 25\ngdp_pop_bycontinents_byyear_above25 <- gapminder %>%\n    mutate(gdp_billion = ifelse(lifeExp > 25, gdpPercap * pop / 10^9, NA)) %>%\n    group_by(continent, year) %>%\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              sd_gdpPercap = sd(gdpPercap),\n              mean_pop = mean(pop),\n              sd_pop = sd(pop),\n              mean_gdp_billion = mean(gdp_billion),\n              sd_gdp_billion = sd(gdp_billion))\n\n## updating only if certain condition is fullfilled\n# for life expectations above 40 years, the gpd to be expected in the future is scaled\ngdp_future_bycontinents_byyear_high_lifeExp <- gapminder %>%\n    mutate(gdp_futureExpectation = ifelse(lifeExp > 40, gdpPercap * 1.5, gdpPercap)) %>%\n    group_by(continent, year) %>%\n    summarize(mean_gdpPercap = mean(gdpPercap),\n              mean_gdpPercap_expected = mean(gdp_futureExpectation))"},{"path":"r-dplyr.html","id":"r-dplyr-ggplot","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.10 dplyr와 ggplot2 조합","text":"ggplot2을 사용해서 퍼싯(facet) 패널 계층을 추가해서 작은 창에 그래프를 담아내는 방식을\n앞선 시각화 수업에서 확인했따. 다음에 앞서 사용한 코드가 나와 있다:상기 코드는 원하는 그래프를 만들어 주지만,\n다른 용도도 뚜렷이 없는 변수(starts., az.countries)도 생성시키게 된다.\n%>% 연산자를 사용해서 dplyr 함수를 엮어 데이터를 파이프에 흘러 보냈듯이,\nggplot() 함수에 데이터를 흘러 보낼 수 있다.\n%>% 파이프 연산자가 함수의 첫번째 인자를 대체하기 때문에,ggplot() 함수에 data = 인자를 명세할 필요는 없다.\ndplyr, ggplot2 함수를 조합하게 되면, 동일한 그래프를 생성하는데 있어\n변수를 새로 생성시키거나 데이터를 변경할 필요가 없어진다.dplyr 함수를 사용하게 되면 문제를 단순화할 수 있다. 예를 들어,\n첫 두단계를 다음과 같이 조합할 수도 있다:","code":"\n# Get the start letter of each country\nstarts.with <- substr(gapminder$country, start = 1, stop = 1)\n# Filter countries that start with \"A\" or \"Z\"\naz.countries <- gapminder[starts.with %in% c(\"A\", \"Z\"), ]\n# Make the plot\nggplot(data = az.countries, aes(x = year, y = lifeExp, color = continent)) +\n  geom_line() + facet_wrap( ~ country)\ngapminder %>%\n   # Get the start letter of each country\n   mutate(startsWith = substr(country, start = 1, stop = 1)) %>%\n   # Filter countries that start with \"A\" or \"Z\"\n   filter(startsWith %in% c(\"A\", \"Z\")) %>%\n   # Make the plot\n   ggplot(aes(x = year, y = lifeExp, color = continent)) +\n   geom_line() +\n   facet_wrap( ~ country)\ngapminder %>%\n    # Filter countries that start with \"A\" or \"Z\"\n    filter(substr(country, start = 1, stop = 1) %in% c(\"A\", \"Z\")) %>%\n    # Make the plot\n    ggplot(aes(x = year, y = lifeExp, color = continent)) +\n    geom_line() +\n    facet_wrap( ~ country)"},{"path":"r-dplyr.html","id":"r-dplyr-challenge-advanced","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.11 고급 도전과제","text":"각 대륙별로 국가를 두개 임의로 뽑아서 2002년 평균 기대수명을 계산해보자.\n그리고 나서, 역순으로 대륙명을 정렬한다.힌트: dplyr 팩키지 arrange(), sample_n() 함수를 사용한다.\n두 함수 모두 다른 dplyr 함수와 유사한 구문을 갖고 있다.고급 도전과제에 대한 해답","code":"\nlifeExp_2countries_bycontinents <- gapminder %>%\n   filter(year==2002) %>%\n   group_by(continent) %>%\n   sample_n(2) %>%\n   summarize(mean_lifeExp=mean(lifeExp)) %>%\n   arrange(desc(mean_lifeExp))"},{"path":"r-dplyr.html","id":"r-dplyr-advanced","chapter":"33 .  dplyr 솜씨있게 조작","heading":"33.12 추가 학습 교재","text":"R Data ScienceData Wrangling Cheat sheetIntroduction dplyrData wrangling R RStudio","code":""},{"path":"r-tidyr.html","id":"r-tidyr","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34 .  tidyr 솜씨있게 조작","text":"과학연구원들은 흔히 ‘wide’ 형식에서 ‘long’ 형식으로 혹은 역으로 데이터를 솜씨있게 조작해야 한다.\n‘long’ 형식은 다음과 같이 정의된다:각 칼럼이 변수.각 행이 관측점‘long’ 형식에서, 일반적으로 관측된 변수에 대해서 칼럼이 하나만 있고,\n다른 칼럼은 ID 변수다.‘wide’ 형식에서, 각 행은 흔히 관측점(site/subject/patient)이며,\n동일한 자료형을 담고 있는 다수 관측변수를 갖게 된다.\n시간이 경과함에 따라 반복되는 관측점이거나, 다수 변수의 관측점(혹은 둘이 혼합된 사례)일 수 있다.\n데이터 입력이 더 단순하거나 일부 다른 응용사례에서 ‘wide’ 형식을 선호할 수 있다.\n하지만, R 함수 다수는 ’long’형식을 가정하고 설계되었다.\n이번 학습을 통해서 원래 데이터 형식에 관계없이 데이터를 효율적으로 변환하는 방식을 학습한다.데이터 형식은 주로 가독성에 영향을 준다.\n사람에게, ‘wide’ 형식이 좀더 직관적인데, 이유는 데이터 형상으로 인해 화면에 더 많은 데이터를 볼 수 있기 때문이다.\n하지만, 컴퓨터에게 ‘long’ 형식이 더 가독성이 높고, 데이터베이스 형식에 훨씬 더 가깝다.\n데이터프레임에 ID 변수는 데이터베이스 필드(Field)와 유사하고, 관측변수는 데이터베이스 값(Value)와 유사하다.","code":""},{"path":"r-tidyr.html","id":"r-tidyr-start","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.1 시작하기","text":"(아마도 이전 학습에서 dplyr팩키지는 설치했을 것이다)\n먼저 설치하지 않았다면, 팩키지를 설치한다:팩키지를 불러와서 적재한다.먼저, gapminder 데이터프레임 자료구조를 살펴보자:","code":"\n#install.packages(\"tidyr\")\n#install.packages(\"dplyr\")\nlibrary(\"tidyr\")\nlibrary(\"dplyr\")\nstr(gapminder)## 'data.frame':    1704 obs. of  6 variables:\n##  $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n##  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n##  $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n##  $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n##  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n##  $ gdpPercap: num  779 821 853 836 740 ..."},{"path":"r-tidyr.html","id":"r-tidyr-challenge-one","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.2 도전과제 1","text":"gapminder는 순수하게 ‘long’ 형식인가, ‘wide’ 형식인가, 혹은 두가지 특징을 갖는 중간형식인가?도전과제 1 에 대한 해답원 gapminder 데이터프레임은 두가지 특징을 갖는 중간 형식이다.\n데이터프레임에 다수 관측변수 (pop,lifeExp,gdpPercap)가 있다는 점에서,\n순수한 긴형식은 아니라고 볼 수 있다.gapminder 데이터셋처럼, 관측된 데이터에 대한 다양한 자료형이 있다.\n대부분 순도 100% ‘long’ 혹은 순도 100% ‘wide’ 자료형식 사이 어딘가에 위치하게 된다.\ngapminder 데이터셋에는 “ID” 변수가 3개(continent, country, year), “관측변수”가 3개(pop,lifeExp,gdpPercap) 있다.\n저자는 일반적으로 대부분의 경우에 중간단계 형식 데이터를 선호한다.\n칼럼 1곳에 모든 관측점이 3가지 서로 다른 단위를 갖지 않음에도 불구하고 그렇다.\n데이터프레임을 좀더 늘리는 연산은 거의 없다(예를 들어, ID변수 4개, 관측변수 1개).흔히 벡터기반인 다수 R 함수를 사용할 때, 흔히 다른 단위를 갖는 값에 수학적 연산작업을 수행하지는 않느다.\n예를 들어, 순수 ‘long’ 형식을 사용할 때,\n인구, 기대수명, GDP의 모든 값에 대한 평균은 의미가 없는데,\n이유는 상호 호환되지 않는 3가지 단위를 갖는 평균값을 계산하여 반환하기 때문이다.\n해법은 먼저 집단으로 그룹지어서 데이터를 솜씨있게 다루거나 (dplyr 학습교재 참조),\n데이터프레임 구조를 변경시키는 것이다.\n주의: R에서 일부 도식화 함수는 ‘wide’ 형식 데이터에 더 잘 작동한다.","code":""},{"path":"r-tidyr.html","id":"r-tidyr-gather","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.3 gather()로 wide → long 전환","text":"지금까지, 깔끔한 형식을 갖는 원본 gapminder 데이터셋으로 작업을 했다.\n하지만, ‘실제’ 데이터(즉, 자체 연구 데이터)는 절대로 잘 구성되어 있지 못하다.\ngapminder 데이터셋에 대한 wide 형식 버젼을 갖고 시작해본다.이곳에서 ‘wide’ 형태를 갖는\ngapminder 데이터를 다운로드 받아서, 로컬 data 폴더에 저장시킨다.데이터 파일을 불러와서 살펴보자.\n주의: continent, country 칼럼이 요인형 자료형이 될 필요가 없다.\n따라서 read.csv() 함수 인자로 stringsAsFactors을 거짓(FALSE)으로 설정한다.깔끔한 중간 데이터 형식을 얻는 첫단추는 먼저 ‘wide’ 형식에서 ‘long’ 형식으로 변환하는 것이다.\ntidyr 팩키지 gather() 함수는 관측 변수를 모아서(gather) 단일 변수로 변환한다.위에서 파이프 구문을 사용했는데, 이전 수업에서 dplyr로 작업한 것과 유사하다.\n사실, dplyr과 tidyr은 상호 호환되어, 파이프 구문으로 dplyr과 tidyr 팩키지 함수를 섞어 사용한다.gather() 함수 내부에, 먼저 신규 ID 변수(obstype_year)에 대한 명칭,\n병합된 관측변수(obs_value)에 대한 명칭, 그리고 나서 이전 관측변수에 대한 명칭을 신규 칼럼명으로 부여한다.\n모든 관측변수를 타이핑했지만, select() 함수처럼(dplyr 수업 참조),\nstarts_with() 함수에 인자로 넣어, 원하는 문자열로 시작되는 모든 변수를 선택할 수도 있다.\ngather() 모을 필요없는 변수(예를 들어, ID 변수)를 식별하는데,\n- 기호를 사용하는 구문도 지원한다.이런 특수한 데이터프레임에는 별거 없어 보일 수도 있다.\n하지만, ID 변수 하나, 규칙없는 변수명 관측변수 40개를 갖는 경우가 있을 수 있다.\n이런 유연성은 시간을 상당히 절약해 준다!이제 obstype_year은 정보가 두조각으로 나뉜다: 관측 유형(pop,lifeExp, gdpPercap)과 연도(year).\nseparate() 함수를 사용해서 문자열을 다수 변수로 쪼갠다.","code":"\ngap_wide <- read.csv(\"data/gapminder_wide.csv\", stringsAsFactors = FALSE)\nstr(gap_wide)## 'data.frame':    142 obs. of  38 variables:\n##  $ continent     : chr  \"Africa\" \"Africa\" \"Africa\" \"Africa\" ...\n##  $ country       : chr  \"Algeria\" \"Angola\" \"Benin\" \"Botswana\" ...\n##  $ gdpPercap_1952: num  2449 3521 1063 851 543 ...\n##  $ gdpPercap_1957: num  3014 3828 960 918 617 ...\n##  $ gdpPercap_1962: num  2551 4269 949 984 723 ...\n##  $ gdpPercap_1967: num  3247 5523 1036 1215 795 ...\n##  $ gdpPercap_1972: num  4183 5473 1086 2264 855 ...\n##  $ gdpPercap_1977: num  4910 3009 1029 3215 743 ...\n##  $ gdpPercap_1982: num  5745 2757 1278 4551 807 ...\n##  $ gdpPercap_1987: num  5681 2430 1226 6206 912 ...\n##  $ gdpPercap_1992: num  5023 2628 1191 7954 932 ...\n##  $ gdpPercap_1997: num  4797 2277 1233 8647 946 ...\n##  $ gdpPercap_2002: num  5288 2773 1373 11004 1038 ...\n##  $ gdpPercap_2007: num  6223 4797 1441 12570 1217 ...\n##  $ lifeExp_1952  : num  43.1 30 38.2 47.6 32 ...\n##  $ lifeExp_1957  : num  45.7 32 40.4 49.6 34.9 ...\n##  $ lifeExp_1962  : num  48.3 34 42.6 51.5 37.8 ...\n##  $ lifeExp_1967  : num  51.4 36 44.9 53.3 40.7 ...\n##  $ lifeExp_1972  : num  54.5 37.9 47 56 43.6 ...\n##  $ lifeExp_1977  : num  58 39.5 49.2 59.3 46.1 ...\n##  $ lifeExp_1982  : num  61.4 39.9 50.9 61.5 48.1 ...\n##  $ lifeExp_1987  : num  65.8 39.9 52.3 63.6 49.6 ...\n##  $ lifeExp_1992  : num  67.7 40.6 53.9 62.7 50.3 ...\n##  $ lifeExp_1997  : num  69.2 41 54.8 52.6 50.3 ...\n##  $ lifeExp_2002  : num  71 41 54.4 46.6 50.6 ...\n##  $ lifeExp_2007  : num  72.3 42.7 56.7 50.7 52.3 ...\n##  $ pop_1952      : num  9279525 4232095 1738315 442308 4469979 ...\n##  $ pop_1957      : num  10270856 4561361 1925173 474639 4713416 ...\n##  $ pop_1962      : num  11000948 4826015 2151895 512764 4919632 ...\n##  $ pop_1967      : num  12760499 5247469 2427334 553541 5127935 ...\n##  $ pop_1972      : num  14760787 5894858 2761407 619351 5433886 ...\n##  $ pop_1977      : num  17152804 6162675 3168267 781472 5889574 ...\n##  $ pop_1982      : num  20033753 7016384 3641603 970347 6634596 ...\n##  $ pop_1987      : num  23254956 7874230 4243788 1151184 7586551 ...\n##  $ pop_1992      : num  26298373 8735988 4981671 1342614 8878303 ...\n##  $ pop_1997      : num  29072015 9875024 6066080 1536536 10352843 ...\n##  $ pop_2002      : int  31287142 10866106 7026113 1630347 12251209 7021078 15929988 4048013 8835739 614382 ...\n##  $ pop_2007      : int  33333216 12420476 8078314 1639131 14326203 8390505 17696293 4369038 10238807 710960 ...\ngap_long <- gap_wide %>%\n    gather(obstype_year, obs_values, starts_with('pop'),\n           starts_with('lifeExp'), starts_with('gdpPercap'))\nstr(gap_long)## 'data.frame':    5112 obs. of  4 variables:\n##  $ continent   : chr  \"Africa\" \"Africa\" \"Africa\" \"Africa\" ...\n##  $ country     : chr  \"Algeria\" \"Angola\" \"Benin\" \"Botswana\" ...\n##  $ obstype_year: chr  \"pop_1952\" \"pop_1952\" \"pop_1952\" \"pop_1952\" ...\n##  $ obs_values  : num  9279525 4232095 1738315 442308 4469979 ...\ngap_long <- gap_wide %>% gather(obstype_year,obs_values,-continent,-country)\nstr(gap_long)## 'data.frame':    5112 obs. of  4 variables:\n##  $ continent   : chr  \"Africa\" \"Africa\" \"Africa\" \"Africa\" ...\n##  $ country     : chr  \"Algeria\" \"Angola\" \"Benin\" \"Botswana\" ...\n##  $ obstype_year: chr  \"gdpPercap_1952\" \"gdpPercap_1952\" \"gdpPercap_1952\" \"gdpPercap_1952\" ...\n##  $ obs_values  : num  2449 3521 1063 851 543 ...\ngap_long <- gap_long %>% separate(obstype_year,into=c('obs_type','year'),sep=\"_\")\ngap_long$year <- as.integer(gap_long$year)"},{"path":"r-tidyr.html","id":"r-tidyr-challenge-two","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.4 도전 과제 2","text":"gap_long을 사용해서, 각 대륙별로 평균 기대수명, 인구, 1인당 GDP를 계산한다.\n힌트: dplyr 수업에서 학습한 group_by() 와 summarize() 함수를 사용한다.도전과제 2 에 대한 해답","code":"\ngap_long %>% group_by(continent,obs_type) %>%\n   summarize(means=mean(obs_values))## # A tibble: 15 × 3\n## # Groups:   continent [5]\n##   continent obs_type       means\n##   <chr>     <chr>          <dbl>\n## 1 Africa    gdpPercap     2194. \n## 2 Africa    lifeExp         48.9\n## 3 Africa    pop        9916003. \n## 4 Americas  gdpPercap     7136. \n## 5 Americas  lifeExp         64.7\n## 6 Americas  pop       24504795. \n## # … with 9 more rows"},{"path":"r-tidyr.html","id":"r-tidyr-wide","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.5 spread()로 ‘long’ 형식 변환","text":"이제 작업을 이중점검 하도록,\ngather() 역함수(적절히 작명된 spread())를 사용해서 관측변수를 다시 되돌린다.\n그리고 나면 gap_long을 원래 중간 형식 혹은 ‘wide’ 형식으로 퍼뜨린다.\n중간 형식에서부터 시작해보자.이제, 최초 데이터프레임 gapminder와 동일한 차원을 갖는 중간 데이터프레임 gap_normal이 있다.\n하지만, 변수 순서가 다르다. 순서를 수정하기 전에, .equal() 함수를 사용해서 동일한지 확인한다.거의 다 왔다. 최초 데이터프레임은 country, continent, year 순으로 정렬되었다.훌륭하다! ‘long’ 형식에서 다시 중간 형식으로 돌아갔지만, 코드에 어떤 오류도 스며들지 않았다.이제, ‘long’ 형식을 ‘wide’ 형식으로 변환하자.\n‘wide’ 형식에서, country 국가와 contienet 대륙을 ID 변수로 두고,\n관츠점을 3가지 측정값(pop,lifeExp,gdpPercap)과 시간(year)으로 쭉 뿌렸다.\n먼저, 모든 신규 변수(측정값 * 시간)에 대한 적절한 라벨을 생성할 필요가 있다.\n또한, ID변수를 합쳐서 gap_wide를 정의하는 과정을 단순화할 필요가 있다.unite()를 사용해서, continent,country를 묶는 ID변수가 하나 생겼고, 변수명을 정의했다.\n이제 파이프를 통해서 spread() 뿌린 준비를 마쳤다.","code":"\ngap_normal <- gap_long %>% spread(obs_type,obs_values)\ndim(gap_normal)## [1] 1704    6\ndim(gapminder)## [1] 1704    6\nnames(gap_normal)## [1] \"continent\" \"country\"   \"year\"      \"gdpPercap\" \"lifeExp\"   \"pop\"\nnames(gapminder)## [1] \"country\"   \"year\"      \"pop\"       \"continent\" \"lifeExp\"   \"gdpPercap\"\ngap_normal <- gap_normal[,names(gapminder)]\nall.equal(gap_normal,gapminder)## [1] \"Component \\\"country\\\": 1704 string mismatches\"          \n## [2] \"Component \\\"pop\\\": Mean relative difference: 1.63\"      \n## [3] \"Component \\\"continent\\\": 1212 string mismatches\"        \n## [4] \"Component \\\"lifeExp\\\": Mean relative difference: 0.204\" \n## [5] \"Component \\\"gdpPercap\\\": Mean relative difference: 1.16\"\nhead(gap_normal)##   country year      pop continent lifeExp gdpPercap\n## 1 Algeria 1952  9279525    Africa    43.1      2449\n## 2 Algeria 1957 10270856    Africa    45.7      3014\n## 3 Algeria 1962 11000948    Africa    48.3      2551\n## 4 Algeria 1967 12760499    Africa    51.4      3247\n## 5 Algeria 1972 14760787    Africa    54.5      4183\n## 6 Algeria 1977 17152804    Africa    58.0      4910\nhead(gapminder)##       country year      pop continent lifeExp gdpPercap\n## 1 Afghanistan 1952  8425333      Asia    28.8       779\n## 2 Afghanistan 1957  9240934      Asia    30.3       821\n## 3 Afghanistan 1962 10267083      Asia    32.0       853\n## 4 Afghanistan 1967 11537966      Asia    34.0       836\n## 5 Afghanistan 1972 13079460      Asia    36.1       740\n## 6 Afghanistan 1977 14880372      Asia    38.4       786\ngap_normal <- gap_normal %>% arrange(country,continent,year)\nall.equal(gap_normal,gapminder)## [1] TRUE\ngap_temp <- gap_long %>% unite(var_ID,continent,country,sep=\"_\")\nstr(gap_temp)## 'data.frame':    5112 obs. of  4 variables:\n##  $ var_ID    : chr  \"Africa_Algeria\" \"Africa_Angola\" \"Africa_Benin\" \"Africa_Botswana\" ...\n##  $ obs_type  : chr  \"gdpPercap\" \"gdpPercap\" \"gdpPercap\" \"gdpPercap\" ...\n##  $ year      : int  1952 1952 1952 1952 1952 1952 1952 1952 1952 1952 ...\n##  $ obs_values: num  2449 3521 1063 851 543 ...\ngap_temp <- gap_long %>%\n    unite(ID_var,continent,country,sep=\"_\") %>%\n    unite(var_names,obs_type,year,sep=\"_\")\nstr(gap_temp)## 'data.frame':    5112 obs. of  3 variables:\n##  $ ID_var    : chr  \"Africa_Algeria\" \"Africa_Angola\" \"Africa_Benin\" \"Africa_Botswana\" ...\n##  $ var_names : chr  \"gdpPercap_1952\" \"gdpPercap_1952\" \"gdpPercap_1952\" \"gdpPercap_1952\" ...\n##  $ obs_values: num  2449 3521 1063 851 543 ...\ngap_wide_new <- gap_long %>%\n    unite(ID_var,continent,country,sep=\"_\") %>%\n    unite(var_names,obs_type,year,sep=\"_\") %>%\n    spread(var_names,obs_values)\nstr(gap_wide_new)## 'data.frame':    142 obs. of  37 variables:\n##  $ ID_var        : chr  \"Africa_Algeria\" \"Africa_Angola\" \"Africa_Benin\" \"Africa_Botswana\" ...\n##  $ gdpPercap_1952: num  2449 3521 1063 851 543 ...\n##  $ gdpPercap_1957: num  3014 3828 960 918 617 ...\n##  $ gdpPercap_1962: num  2551 4269 949 984 723 ...\n##  $ gdpPercap_1967: num  3247 5523 1036 1215 795 ...\n##  $ gdpPercap_1972: num  4183 5473 1086 2264 855 ...\n##  $ gdpPercap_1977: num  4910 3009 1029 3215 743 ...\n##  $ gdpPercap_1982: num  5745 2757 1278 4551 807 ...\n##  $ gdpPercap_1987: num  5681 2430 1226 6206 912 ...\n##  $ gdpPercap_1992: num  5023 2628 1191 7954 932 ...\n##  $ gdpPercap_1997: num  4797 2277 1233 8647 946 ...\n##  $ gdpPercap_2002: num  5288 2773 1373 11004 1038 ...\n##  $ gdpPercap_2007: num  6223 4797 1441 12570 1217 ...\n##  $ lifeExp_1952  : num  43.1 30 38.2 47.6 32 ...\n##  $ lifeExp_1957  : num  45.7 32 40.4 49.6 34.9 ...\n##  $ lifeExp_1962  : num  48.3 34 42.6 51.5 37.8 ...\n##  $ lifeExp_1967  : num  51.4 36 44.9 53.3 40.7 ...\n##  $ lifeExp_1972  : num  54.5 37.9 47 56 43.6 ...\n##  $ lifeExp_1977  : num  58 39.5 49.2 59.3 46.1 ...\n##  $ lifeExp_1982  : num  61.4 39.9 50.9 61.5 48.1 ...\n##  $ lifeExp_1987  : num  65.8 39.9 52.3 63.6 49.6 ...\n##  $ lifeExp_1992  : num  67.7 40.6 53.9 62.7 50.3 ...\n##  $ lifeExp_1997  : num  69.2 41 54.8 52.6 50.3 ...\n##  $ lifeExp_2002  : num  71 41 54.4 46.6 50.6 ...\n##  $ lifeExp_2007  : num  72.3 42.7 56.7 50.7 52.3 ...\n##  $ pop_1952      : num  9279525 4232095 1738315 442308 4469979 ...\n##  $ pop_1957      : num  10270856 4561361 1925173 474639 4713416 ...\n##  $ pop_1962      : num  11000948 4826015 2151895 512764 4919632 ...\n##  $ pop_1967      : num  12760499 5247469 2427334 553541 5127935 ...\n##  $ pop_1972      : num  14760787 5894858 2761407 619351 5433886 ...\n##  $ pop_1977      : num  17152804 6162675 3168267 781472 5889574 ...\n##  $ pop_1982      : num  20033753 7016384 3641603 970347 6634596 ...\n##  $ pop_1987      : num  23254956 7874230 4243788 1151184 7586551 ...\n##  $ pop_1992      : num  26298373 8735988 4981671 1342614 8878303 ...\n##  $ pop_1997      : num  29072015 9875024 6066080 1536536 10352843 ...\n##  $ pop_2002      : num  31287142 10866106 7026113 1630347 12251209 ...\n##  $ pop_2007      : num  33333216 12420476 8078314 1639131 14326203 ..."},{"path":"r-tidyr.html","id":"r-tidyr-challenge-three","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.6 도전과제 3","text":"한 걸음 더 나아가, 국가, 연도, 측정값 3개를 쭉 뿌려 터무니 없는 gap_ludicrously_wide 형식 데이터를 생성한다.\n힌트: 신규 데이터프레임은 단지 행이 5개만 있다.도전과제 3 에 대한 해답이제, 엄청 ‘wide’ 형식 데이터프레임이 생겼다.\n하지만, ID_var 변수는 더 유용할 수 있다. separate() 함수로 변수 2개로 구분하자.다시 되돌아 왔다!","code":"\ngap_ludicrously_wide <- gap_long %>%\n   unite(var_names,obs_type,year,country,sep=\"_\") %>%\n   spread(var_names,obs_values)\ngap_wide_betterID <- separate(gap_wide_new,ID_var,c(\"continent\",\"country\"),sep=\"_\")\ngap_wide_betterID <- gap_long %>%\n    unite(ID_var, continent,country,sep=\"_\") %>%\n    unite(var_names, obs_type,year,sep=\"_\") %>%\n    spread(var_names, obs_values) %>%\n    separate(ID_var, c(\"continent\",\"country\"),sep=\"_\")\nstr(gap_wide_betterID)## 'data.frame':    142 obs. of  38 variables:\n##  $ continent     : chr  \"Africa\" \"Africa\" \"Africa\" \"Africa\" ...\n##  $ country       : chr  \"Algeria\" \"Angola\" \"Benin\" \"Botswana\" ...\n##  $ gdpPercap_1952: num  2449 3521 1063 851 543 ...\n##  $ gdpPercap_1957: num  3014 3828 960 918 617 ...\n##  $ gdpPercap_1962: num  2551 4269 949 984 723 ...\n##  $ gdpPercap_1967: num  3247 5523 1036 1215 795 ...\n##  $ gdpPercap_1972: num  4183 5473 1086 2264 855 ...\n##  $ gdpPercap_1977: num  4910 3009 1029 3215 743 ...\n##  $ gdpPercap_1982: num  5745 2757 1278 4551 807 ...\n##  $ gdpPercap_1987: num  5681 2430 1226 6206 912 ...\n##  $ gdpPercap_1992: num  5023 2628 1191 7954 932 ...\n##  $ gdpPercap_1997: num  4797 2277 1233 8647 946 ...\n##  $ gdpPercap_2002: num  5288 2773 1373 11004 1038 ...\n##  $ gdpPercap_2007: num  6223 4797 1441 12570 1217 ...\n##  $ lifeExp_1952  : num  43.1 30 38.2 47.6 32 ...\n##  $ lifeExp_1957  : num  45.7 32 40.4 49.6 34.9 ...\n##  $ lifeExp_1962  : num  48.3 34 42.6 51.5 37.8 ...\n##  $ lifeExp_1967  : num  51.4 36 44.9 53.3 40.7 ...\n##  $ lifeExp_1972  : num  54.5 37.9 47 56 43.6 ...\n##  $ lifeExp_1977  : num  58 39.5 49.2 59.3 46.1 ...\n##  $ lifeExp_1982  : num  61.4 39.9 50.9 61.5 48.1 ...\n##  $ lifeExp_1987  : num  65.8 39.9 52.3 63.6 49.6 ...\n##  $ lifeExp_1992  : num  67.7 40.6 53.9 62.7 50.3 ...\n##  $ lifeExp_1997  : num  69.2 41 54.8 52.6 50.3 ...\n##  $ lifeExp_2002  : num  71 41 54.4 46.6 50.6 ...\n##  $ lifeExp_2007  : num  72.3 42.7 56.7 50.7 52.3 ...\n##  $ pop_1952      : num  9279525 4232095 1738315 442308 4469979 ...\n##  $ pop_1957      : num  10270856 4561361 1925173 474639 4713416 ...\n##  $ pop_1962      : num  11000948 4826015 2151895 512764 4919632 ...\n##  $ pop_1967      : num  12760499 5247469 2427334 553541 5127935 ...\n##  $ pop_1972      : num  14760787 5894858 2761407 619351 5433886 ...\n##  $ pop_1977      : num  17152804 6162675 3168267 781472 5889574 ...\n##  $ pop_1982      : num  20033753 7016384 3641603 970347 6634596 ...\n##  $ pop_1987      : num  23254956 7874230 4243788 1151184 7586551 ...\n##  $ pop_1992      : num  26298373 8735988 4981671 1342614 8878303 ...\n##  $ pop_1997      : num  29072015 9875024 6066080 1536536 10352843 ...\n##  $ pop_2002      : num  31287142 10866106 7026113 1630347 12251209 ...\n##  $ pop_2007      : num  33333216 12420476 8078314 1639131 14326203 ...\nall.equal(gap_wide, gap_wide_betterID)## [1] TRUE"},{"path":"r-tidyr.html","id":"r-tidyr-points","chapter":"34 .  tidyr 솜씨있게 조작","heading":"34.7 추가 학습","text":"R Data ScienceData Wrangling Cheat sheetIntroduction tidyrData wrangling R RStudio","code":""},{"path":"r-knitr.html","id":"r-knitr","chapter":"35 .  knitr 보고서 생성","heading":"35 .  knitr 보고서 생성","text":"","code":""},{"path":"r-knitr.html","id":"r-knitr-report","chapter":"35 .  knitr 보고서 생성","heading":"35.1 데이터 분석 보고서","text":"데이터 분석가는 동료 혹은 향후 참고자료로 자신의 작업결과를 문서화하는데\n상당량의 보고서를 작성해서 분석과정과 출력결과를 기술한다.처음 작업을 시작할 때, 온전히 본인 작업을 위해서 R 스크립트를 작성한다.\n그리고 나서, 다양한 그래프가 첨부된 분석결과를 기술해서 동료에게 전자우편을 발송한다.\n분석결과를 논의하는 과정에서 어느 그래프를 지칭하지에 대해 혼란이 종종 수반된다.워드나 \\(\\LaTeX\\)으로 좀더 정형화된 보고서로 옮겨가도, 그림이 올바르게\n보이도록 만드는데 상당한 시간을 소비한다. 대부분 페이지 나누기가 문제가 된다.웹페이지(html 파일)를 생성하게 되면 모든 것이 훨씬 수월해진다.\n이유는 하나의 긴 흐름이 되기 때문이다. 따라서,\n한 페이지에 맞지 않는 긴 그림도 사용할 수 있게 된다.\n스크롤링이 딱맞는 친구다.","code":""},{"path":"r-knitr.html","id":"r-knitr-literate-programming","chapter":"35 .  knitr 보고서 생성","heading":"35.2 문학적 프로그래밍","text":"이상적으로 그런 분석 보고서가 재현가능한 문서가 된다:\n만약 오류가 발견되거나, 추가적인 분석주제가 데이터에 추가되면,\n다시 재컴파일 하게 되면, 신규 혹은 수정된 결과를 얻게 된다.\n(반대로, 워드나 한글 등 오피스로 작업하게 되면\n그림을 다시 생성하고나서 문서에 붙여넣고 수작업으로 상세결과를 편집해야 한다.)R에서 문학적 프로그래밍(literate programming)을 구현하는 주된 도구가 knitr다.\nknitr는 텍스트와 R 코드가 뒤썩인 문서를 생성할 수 있게 하는 역할을 수행한다.\n문서가 knitr로 처리되면, R 코드가 실행되어 그래프와 분석결과가 문서에 삽입된다.이런 유형의 아이디어를 문학적 프로그래밍(literate programming)이라고 부른다.knitr는 R코드 뿐만 아니라 다양한 프로그래밍 언어를 텍스트와 뒤섞을 수 있도록 하지만,\n기본적으로 R 마크다운을 추천한다. R 마크다운은 마크다운과 R코드를 섞어 쓸 수 있도록 한다.\n마크다운은 가벼운 마크업 언어로 웹페이지를 생성하는데 사용된다.","code":""},{"path":"r-knitr.html","id":"r-knitr-markdown","chapter":"35 .  knitr 보고서 생성","heading":"35.3 R 마크다운 파일 생성","text":"RStudio 에서 File → New File → R Markdown 을 클릭하면 다음과 같은 대화상자가 열린다:기본설정(HTML 출력)된 대로 사용할 수도 있지만, 제목을 줄 수도 있다.","code":""},{"path":"r-knitr.html","id":"r-knitr-markdown-components","chapter":"35 .  knitr 보고서 생성","heading":"35.4 R 마크다운 구성요소","text":"초기 설정된 텍스트 덩어리에 R에 대한 지시사항이 담겨있다:\n제목, 저자명, 날짜, html 출력물(다른 말로, 웹페이지)을 생성할지가 포함된다.원하지 않는 경우, 상기 필드를 임의로 삭제할 수 있다.\n엄밀히 말해서 인용부호는 상기 경우에 꼭 필요한 것은 아니다.\n제목에 콜론(:)이 포함되는 경우 대체로 인용부호가 필요하다.RStudio에 시작을 도와주도록 예제가 문서에 포함되어 있다.\n다음과 같은 R 코드 덩어리가 포함되어 있는 점을 주목한다:knitr로 실행되는 R 코드 덩어리로 R 코드 실행결과로 치환된다.\n뒤에서 더 다루게 된다.또한, 웹주소는 < > 꺾쇠 기호로 담아내고, **Knit**처럼 별표 두개를 사용하기도 한다.\n이것이 전형적인 Markdown 구문의 한 사례가 된다.","code":"---\ntitle: \"Initial R Markdown document\"\nauthor: \"Karl Broman\"\ndate: \"April 23, 2015\"\noutput: html_document\n---\n```{r}\nsummary(cars)\n```\n"},{"path":"r-knitr.html","id":"r-knitr-markdown-language","chapter":"35 .  knitr 보고서 생성","heading":"35.5 마크다운(Markdown)","text":"HTML 코드로 작성하는 대신에 전자우편에서 문서를 작성하는 것처럼\n텍스트에 마크업(markup)을 적용해서 웹페이지를 저작하는 시스템이 마크다운이다.\n마크업 텍스트는 적절한 HTML코드로 치환되는 과정을 거쳐서 최종 HTML로 변환된다.지금은 자동생성된 모든 코드를 삭제하고, 마크다운으로 저작을 시작해보자.별표 두개를 사용해서 굵게(bold)할 수 있는데 **굵게(bold)** 텍스트를 타이핑하면 된다.\n밑줄 혹은 별표 한개를 사용해서 이탤릭 도 구현가능한데, _이탤릭_ 텍스트를 타이핑하면 된다.다음과 같이 하이픈 혹은 별표를 적용해서 블릿 기호가 붙은 항목을 생성할 수 있다:혹은 다음과 같이도 가능하다:다음과 같이 웹페이지로 보여지게 된다:bold double-asterisksitalics underscorescode-type font backticks숫자를 사용하면 숫자가 붙은 항목도 생성이 가능하다.\n원하는만큼 동일한 숫자를 반복해서 적용하면 된다:다음과 같이 보이게 된다.bold double-asterisksitalics underscorescode-type font backticks# 기호를 각 라인 첫번째 적용하게 되면 다른 크기를 갖는\n섹션 제목을 만들 수 있다:좌측 상단에 “Knit HTML” 버튼을 클릭하면 R 마크다운 문서를 HTML 웹페이지로\n_컴파일_하게 된다. 바로 옆에 작은 물음표가 있음에 주목한다;\n클릭하게 되면 “Markdown Quick Reference” (마크다운 구문) 뿐만 아니라 RStudio IDE에서\nR 마크다운 문서도 참고할 수 있다.","code":"* bold with double-asterisks\n* italics with underscores\n* code-type font with backticks- bold with double-asterisks\n- italics with underscores\n- code-type font with backticks1. bold with double-asterisks\n1. italics with underscores\n1. code-type font with backticks# 아주 큰 제목(Title)\n## 큰 제목(Main section)\n### 작은 제목(Sub-section)\n#### 아주 작은 제목(Sub-sub section)"},{"path":"r-knitr.html","id":"r-knitr-challenge","chapter":"35 .  knitr 보고서 생성","heading":"35.6 도전과제","text":"R 마크다운 문서를 생성한다.\n모든 R 코드 덩어리를 삭제하고 마크다운 문서를 작성한다.\n(제목, 이탤릭 텍스트, 블릿 기호가 붙은 항목 등)\n문서를 웹페이지로 변환시킨다.도전과제에 대한 해답RStudio에서 File > New file > R Markdown...을 선택한다.\n누름틀(Placeholder) 텍스트를 삭제하고 다음과 같이 작성한다.","code":"# Introduction\n\n## Background on Data\n\nThis report uses the *gapminder* dataset, which has columns that include:\n\n* country\n* continent\n* year\n* lifeExp\n* pop\n* gdpPercap\n\n## Background on Methods"},{"path":"r-knitr.html","id":"r-knitr-markdown-more","chapter":"35 .  knitr 보고서 생성","heading":"35.7 마크다운 추가기능","text":"[text show](http://-web-page.com)처럼 하이퍼링크를 걸 수도 있다.![caption](http://url//file) 처럼 이미지를 삽입할 수도 있다.F2 처럼 아래 첨자를 F~2와 같이 넣을 수도 있도, F2 처럼\n윗첨자를 F^2^와 같이 넣을 수도 있다.수식 작성법은 LaTeX을 참조해서 작성할 수 있는데,\n$ $와 $$ $$을 사용해서 수식을 넣을 수 있다: $E = mc^2$.","code":"$$y = \\mu + \\sum_{i=1}^p \\beta_i x_i + \\epsilon$$"},{"path":"r-knitr.html","id":"r-knitr-markdown-code-chunk","chapter":"35 .  knitr 보고서 생성","heading":"35.8 R 코드 덩어리","text":"마크다운은 흥미롭고 유용하기도 하지만, 실제 진정한 힘은\n마크다운을 R 코드 덩어리와 뒤섞어 사용할 때 나온다. R 마크다운으로 말이다.\nR 마크다운이 처리되면서 R 코드도 실행된다;\n그림이 생성되는 경우, 최종 문서에 자동으로 그림이 삽입되어 들어간다.데이터를 불러오는 R 코드는 다음과 같이 생겼다:즉, ```{r chunk_name}와 ``` 사이에\nR 코드 덩어리를 위치한다.\nR 코드 덩어리에 명칭을 부여하는 것이 좋은데 이유는 오류 수정을 유용하게 하고,\n그래프가 생성되는 경우 파일명이 R 코드 덩어리에 지정한 명칭이 따라 붙기 때문이다.","code":"\n```{r load_data}\ngapminder \n즉, ```{r chunk_name}와 ``` 사이에\nR 코드 덩어리를 위치한다.\nR 코드 덩어리에 명칭을 부여하는 것이 좋은데 이유는 오류 수정을 유용하게 하고,\n그래프가 생성되는 경우 파일명이 R 코드 덩어리에 지정한 명칭이 따라 붙기 때문이다.\n"},{"path":"r-knitr.html","id":"r-knitr-challenge-two","chapter":"35 .  knitr 보고서 생성","heading":"35.9 도전과제","text":"다음 R 코드를 추가한다.ggplot2 팩키지 불러오는 코드gapminder 데이터를 불러오는 코드그래프를 생성하는 코드도전과제 해답","code":"```{r load-ggplot2}\nlibrary(\"ggplot2\")\n``````{r read-gapminder-data}\ngapminder <- read.csv(\"gapminder.csv\")\n``````{r make-plot}\nplot(lifeExp ~ year, data = gapminder)\n```"},{"path":"r-knitr.html","id":"r-knitr-compile","chapter":"35 .  knitr 보고서 생성","heading":"35.10 컴파일 작동방식","text":"“Knit HTML” 버튼을 생성하게 되면, knitr 프로그램이\nR 마크다운 문서를 처리해서, 일반 마크다운 문서가 생성된다(그림도 포함된다.):\nR 코드가 실행되면서 입력과 출력 모두에 대해 치환된다; 그림이 생성되는 경우,\n그림에 대한 링크도 포함된다.마크다운과 그림 문서는 pandoc 도구로 처리되어서,\n마크다운 파일을 그림이 내장된 HTML 파일로 탈바꿈하게 된다.","code":""},{"path":"r-knitr.html","id":"r-knitr-chunk-options","chapter":"35 .  knitr 보고서 생성","heading":"35.11 덩어리 선택옵션","text":"코드 덩어리(Chunk)가 어떻게 처리되는 방법에 대한 선택옵션이 다수 지원된다.echo=FALSE: R 코드가 출력되는 것을 방지results=\"hide\": 출력결과물이 문서에 뿌려지지 않도록 방지.eval=FALSE: 코드는 출력되지만, 평가되어 실행되는 것은 방지.warning=FALSE, message=FALSE: 경고와 메시지 출력을 숨김.fig.height, fig.width: 인치 단위로 그림 크기 높이와 폭을 지정.다음과 같이 작성할 수도 있다:전역 덩어리(chunk) 선택옵션을 사용하여 반복적으로 사용할 R마크다운 선택옵션을\n다음과 같이 지정하는 것도 가능하다:fig.path 선택옵션은 그림이 저장되는 장소를 지정하는데 사용한다.\n/이 중요한데 이유는 /을 지정하지 않으면 그림이 Figs으로 시작하는\n파일명으로 표준 저장소에 저장된다.작업 디렉토리에 R 마크다운 파일이 다수 존재하는 경우,\nfig.path를 사용해서 fig.path=\"Figs/cleaning-\", fig.path=\"Figs/analysis-\"처럼\n그림 파일명에 접두어를 달리 지정할 수도 있다.","code":"\n```{r load_libraries, echo=FALSE, message=FALSE}\nlibrary(\"dplyr\")\nlibrary(\"ggplot2\")\n```\n\n```{r global_options, echo=FALSE}\nknitr::opts_chunk$set(fig.path=\"Figs/\", message=FALSE, warning=FALSE,\n                      echo=FALSE, results=\"hide\", fig.width=11)\n```\n"},{"path":"r-knitr.html","id":"r-knitr-challenge-three","chapter":"35 .  knitr 보고서 생성","heading":"35.12 도전과제","text":"그림 크기를 변경하고, 코드를 출력에서 감추도록, R 코드 덩어리 선택옵션을 설정해 본다.도전과제 해답","code":"```{r echo = FALSE, fig.width = 3}\nplot(faithful)\n```"},{"path":"r-knitr.html","id":"인라인-r-코드","chapter":"35 .  knitr 보고서 생성","heading":"35.13 인라인 R 코드","text":"보고서의 모든 숫자를 재현가능하게 만들 수 있다.\n인라인 코드를 작성할 때 `r와 `을 사용한다.\n예를 들어, `r round(some_value, 2)`.\nR 코드가 실행되어 코드가 결과 값으로 치환된다.두줄이상에 걸처 인라인 코드 덩어리가 나눠지도록 작성하지는 말자.아마도, 조금 큰 코드 덩어리의 경우 include=FALSE(echo=FALSE와 results=\"hide\" 두가지 기능을 함께 보유)를 사용해서\n연산과 정의를 처리하는 것도 가능하다.이런 경우에 소수점 자리수에 대해서 2.0을 원하지만, round(2.03, 1)코드는 2가 된다.R/broman 팩키지에서\nmyround 함수가\n도움이 될 수 있다.","code":""},{"path":"r-knitr.html","id":"r-knitr-challenge-five","chapter":"35 .  knitr 보고서 생성","heading":"35.14 도전과제","text":"인라인 R 코드를 작성해 보자.도전과제 해답2 + 2 를 계산하는 인라인 R 코드: 2 + 2 = `r 2+2`.","code":""},{"path":"r-knitr.html","id":"r-knitr-others","chapter":"35 .  knitr 보고서 생성","heading":"35.15 기타 출력 선택옵션","text":"R 마크다운 문서를 PDF나 워드 문서로 변환할 수도 있다.\n“Knit HTML” 버튼 옆에 작은 삼각형을 클릭하면\n드롭다운 메뉴가 나타난다.\n혹은 R 마크다운 .Rmd 파일의 헤더부분에 pdf_document, word_document으로 설정하면 된다.꿀팁: PDF 문서 생성하기.pdf 문서를 생성하려면 추가로 소프트웨어를 설치해야 한다.\n소프트웨어 설치 없이 .pdf 문서를 생성하게 되면 오류 메시지에 자세한 사항이 기술되어 있다.TeX installers Windows.TeX installers macOS.","code":""},{"path":"r-knitr.html","id":"r-knitr-references","chapter":"35 .  knitr 보고서 생성","heading":"35.16 관련 자료","text":"Knitr knutshell tutorialDynamic Documents R knitr (book)R Markdown documentationR Markdown cheat sheetGetting started R MarkdownReproducible ReportingThe Ecosystem R MarkdownIntroducing Bookdown","code":""},{"path":"r-wrapup.html","id":"r-wrapup","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36 .  좋은 소프트웨어 작성법","text":"","code":""},{"path":"r-wrapup.html","id":"r-project","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.1 프로젝트 폴더 구조화","text":"작업 프로젝트 폴더를 구조하위 폴더를 코드, 매뉴얼, 데이터, 바이너리, 출력 그래프 등으로 구분하여 프로젝트 폴더를 구조화 시키고, 잘 조직화하고, 깔끔하게 한다.\n완전 수작업으로 할 수도 있고, RStudio New Project 기능을 활용하거나 ProjectTemplate 같은 팩키지를 사용한다.꿀팁: ProjectTemplate - 가능한 해결책프로젝트 관리를 자동화하는 한 방식은 제3자 팩키지, ProjectTemplate을 설치하는 것이다.\n해당 팩키지는 프로젝트 관리에 대한 이상적인 디렉토리 구조를 설정해 놓는다.\n팩키지가 자동으로 분석 파이브라인/작업흐름을 구성해서 구조화해 놓는다.\nRStudio 기본설정된 프로젝트 관리 기능과 Git을 섞어 사용하면, 작업을 기록할 뿐만 아니라,\n동료 연구원과 작업산출물 공유를 가능케 한다.ProjectTemplate을 설치한다.라이브러리를 불러 적재한다.프로젝트를 초기화한다.ProjectTemplate과 기능에 대한 자세한 사항은\nProjectTemplate 홈페이지를 방문한다.","code":"\ninstall.packages(\"ProjectTemplate\")\nlibrary(ProjectTemplate)\ncreate.project(\"../my_project\", merge.strategy = \"allow.non.conflict\")"},{"path":"r-wrapup.html","id":"r-project-code","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.2 가독성 높은 코드 생성","text":"코드 작성에 있어 가장 중요한 부분이 코드를 가독성 있고 이해가능하게 작성하는 것이다.\n누군가 여러분이 작성한 코드를 골라 무슨 작업을 수행하는지 이해할 수 있어야 한다:\n흔히 누군가는 6개월 후에 바로 당신이 될 수 있고, 만약 그렇게 작성하지 않았다면\n과거 자기 자신 본인을 분명히 저주할 것이다.","code":""},{"path":"r-wrapup.html","id":"r-project-document","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.3 문서화","text":"문서화에서 왜() 그리고 무엇()은 OK, 어떻게()는 .처음 코드를 작성할 때, 주석은 명령어가 무엇을 수행하는지 기술한다.\n왜냐하면, 여전히 학습중으로 개념을 명확히 하고, 나중에 다시 상기하는데 도움이 된다.\n하지만, 이러한 주석은 나중에 작성한 코드가 어떤 문제를 해결하고자 하는지\n기억을 하지 못하면 그다지 도움이 되지 못한다.\n왜() 문제를 해결하려고 하는지, 그리고 어떤() 문제인지 전달하는\n주석을 달려고 노력한다.\n어떻게()는 그 다음에 온다: 정말 걱정하지 말하야 되는 사항은 구체적인 구현이다.","code":""},{"path":"r-wrapup.html","id":"r-project-module","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.4 코드를 모듈화","text":"소프트웨어 카펜트리에서 추천하는 것은 작성한 함수를 분석 스크립트와\n구별해서 별도 파일에 저장시키는 것이다. 프로젝트 R세션을 열 때,\nsource 함수로 불러올 수 있게 별도 파일로 저장한다.분석 스크립트를 너저분하지 않게 하고, 유용한 함수 저장소를\n프로젝트 분석 스크립트에 적재할 수 있게 함으로써 이러한 접근법이 깔끔하다.\n또한 관련된 함수를 쉽게 무리지어 묶는다.","code":""},{"path":"r-wrapup.html","id":"r-project-split","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.5 문제를 잘게 쪼갠다","text":"문제를 한입크기 조각으로 쪼갠다.처음 시작할 때, 문제 해결과 함수 작성은 어마어마한 작업이고,\n코드를 쪼개는 것도 힘들다.\n문제를 소화가능한 덩어리로 쪼개고,\n나중에 구현에 관한 구체적인 사항을 걱정한다:\n해결책을 코드로 작성할 수 있는 지점까지\n문제를 더 작게 그리고 더 작은 함수로 계속 쪼개 나간다.\n그리고 나서 다시 거꾸로 빌드해서 만들어 낸다.","code":""},{"path":"r-wrapup.html","id":"r-project-run","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.6 작성 코드 정상 수행","text":"작성한 코드가 올바른 작업을 수행하도록 만든다.\n즉, 작성한 함수를 테스트해서 확실히 동작하게 만든다.","code":""},{"path":"r-wrapup.html","id":"r-project-dry","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.7 사람은 반복 금지","text":"함수는 프로젝트 내부에서 재사용을 쉽게 한다.\n프로젝트를 통해서 유사한 코드 라인 덩어리를 보게 되면,\n대체로 함수로 옮겨져야 되는 대상을 찾은 것이다.연산작업이 연속된 함수를 통해 실행되면,\n프로젝트는 모듈로 만들기 쉽고, 변경하기 쉽다.\n항상 특정한 입력값을 넣으면 특정한 출력값이 나오는 경우에 특히 그렇다.","code":""},{"path":"r-wrapup.html","id":"r-project-style","chapter":"36 .  좋은 소프트웨어 작성법","heading":"36.8 스타일 고집","text":"코드에 일관된 스타일을 지킨다.","code":""},{"path":"database-sql.html","id":"database-sql","chapter":"37 .  데이터베이스와 SQL 사용하기","heading":"37 .  데이터베이스와 SQL 사용하기","text":"거의 모든 사람이 스프레드쉬트(spreadsheet) 사용했고, 거의 모든 사람이 종국에는 한계에 맞닥뜨렸다.\n데이터셋이 더욱 복잡할수록, 데이터를 걸러내고, 다른 행과 열 사이에 관계를 표현하거나, 결측값을 다루기가 점점 어려워진다.데이터베이스는 스프레드쉬트가 멈춘 곳에서 다시 시작한다.\n만약 사용하고자 하는 것이 10여개의 숫자의 합이라면 데이터베이스는 사용하기가 간단하지는 않지만, 훨씬 큰 데이터셋에 훨씬 더 빨리 스프레드쉬트가 할 수 없는 많은 것을 수행할 수 있다.\n그리고, 설사 데이터베이스를 스스로 생성할 필요는 없지만,\n데이터베이스가 어떻게 동작하는지 파악하는 것은 우리가 사용하는 수 많은 시스템이 왜 그와 같은 방식으로 동작하는지 그리고 왜 특정한 방식으로 데이터를 구조화하려고 하는지도 이해를 준다.","code":""},{"path":"database-sqlite.html","id":"database-sqlite","chapter":"38 .  SQLite 설치","heading":"38 .  SQLite 설치","text":"이번 학습은 다음 장에서 사용되는 예제 데이터베이스를 어떻게 설치하는지 설명한다.\n다음의 지도사항을 따르기 위해서는 명령-라인을 사용하여 어떻게 디렉토리를 여기저기 이동하는지와 명령-라인에서 명령문을 어떻게 실행하는지 숙지할 필요가 있다.\n이런 주제와 친숙하지 않다면, 유닉스 쉘(Unix Shell) 학습을 참조하세요.\n이후의 장에서 데이터베이스를 어떻게 생성하고 데이터를 채우는지 배울 것이지만, 먼저 SQLite 데이터베이스가 어떻게 동작하는지 설명을 할 필요가 있어서\n데이터베이스를 선행하여 제공한다.","code":""},{"path":"database-sqlite.html","id":"sqlite-install","chapter":"38 .  SQLite 설치","heading":"38.1 설치","text":"인터랙티브하게 다음 학습을 수행하기 위해서는 설치 방법에 언급된 SQLite 를 참조하여 설치하세요.그리고 , 여러분이 선택한 위치에 “software_carpentry_sql” 디렉토리를 생성하세요.예를 들어명령 라인 터미널 윈도우를 여세요.명령 라인 터미널 윈도우를 여세요.다음과 같이 타이핑한다.다음과 같이 타이핑한다.생성한 디렉토리로 현재 작업 디렉토리를 변경한다.","code":"mkdir ~/swc/sqlcd ~/swc/sql"},{"path":"database-sqlite.html","id":"install-sqlite","chapter":"38 .  SQLite 설치","heading":"38.2 SQLite 설치 3","text":"SQLite Download Page에서 sqlite-tools-win32-x86-3200000.zip을 다운로드 받는다.\n압축을 풀면 황당하게 몇개 .exe 파일이 존재하는 황당함을 느낀다. 설치가 완료되었다.sqlite3.exe: sqlite 실행파일gen-survey-database.sql: survey.db sqlite 데이터베이스를 생성시키는데 사용되는 스크립트survey.db: sqlite3.exe 명령어를 실행해서 gen-survey-database.sql 스크립트를 통해 생성된 데이터베이스","code":"$ ls\ngen-survey-database.sql  sqlite3.exe           survey.db\nsqldiff.exe              sqlite3_analyzer.exe"},{"path":"database-sqlite.html","id":"download-database","chapter":"38 .  SQLite 설치","heading":"38.3 실습 데이터베이스 다운로드","text":"깃헙(GitHub)에서 gen-survey-database.sql 파일을 어떻게 다운로드 받을까요?~/swc/sql 디렉토리로 이동한 후에 그 디렉토리에서\nGitHub 사이트 https://github.com/swcarpentry/bc/blob/master/novice/sql/gen-survey-database.sqlSQL에\n위치한 SQL 파일(“gen-survey-database.sql”)을 다운로드한다.파일이 GitHub 저장소 내에 위치하고 있어서, 전체 Git 저장소(git repo)를 복제(cloning)하지 않고 단일 파일만 로컬로 가져온다.\n이 목적을 달성하기 위해서,\nHTTP, HTTPS, FTP 프로토콜을 지원하는 명령-라인 웹크롤러(web-crawler) 소프트웨어 GNU Wget 혹은,\n다양한 프로토콜을 사용하여 데이터를 전송하는데 사용되는 라이브러리이며 명령-라인 도구인 cURL을 사용한다.\n두가지 도구 모두 크로스 플랫폼(cross platform)으로 다양한 운영체제를 지원한다.Wget 혹은 cURL을 로컬에 설치한 후에, 터미널에서 다음 명령어를 실행한다.Tip: 만약 cURL을 선호한다면, 다음 명령문에서 “wget”을 curl -O로 대체하세요.상기 명령문으로 Wget은 HTTP 요청을 생성해서 github 저장소의 “gen-survey-database.sql” 원파일만 현재 작업 디렉토리로 가져온다.성공적으로 완료되면 터미널은 다음 출력결과를 화면에 표시한다.이제 성공적으로 단일 SQL 파일을 가져와서,\nsurvey.db 데이터베이스를 생성하고\ngen-survey-database.sql 에 저장된 지시방법에 따라서 데이터를 채워넣는다.명령-라인 터미널에서 SQLite3 프로그램을 호출하기 위해서, 다음 명령문을 실행한다.","code":"root@hangul:~/swc/sql$ wget https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql--2014-09-02 18:31:43--  https://raw.githubusercontent.com/swcarpentry/bc/master/novice/sql/gen-survey-database.sql\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 103.245.222.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|103.245.222.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3297 (3.2K) [text/plain]\nSaving to: ‘gen-survey-database.sql’\n\n100%[=========================================================================================================================&gt;] 3,297       --.-K/s   in 0.01s   \n\n2014-09-02 18:31:45 (264 KB/s) - ‘gen-survey-database.sql’ saved [3297/3297]root@hangul:~/swc/sql$ sqlite3 survey.db < gen-survey-database.sql"},{"path":"database-sqlite.html","id":"connect-sqlite","chapter":"38 .  SQLite 설치","heading":"38.4 SQLite DB 연결/설치 테스트","text":"생성된 데이터베이스에 연결하기 위해서,\n데이터베이스를 생성한 디렉토리 안에서 SQLite를 시작한다.\n그래서 ~/swc/sql 디렉토리에서 다음과 같이 타이핑한다.sqlite3 survey.db 명령문이 데이터베이스를 열고 데이터베이스 명령-라인 프롬프트로 안내한다.\nSQLite에서 데이터베이스는 플랫 파일(flat file)로 명시적으로 열 필요가 있다.\n그리고 나서 SQLite 시작되고 sqlite로 명령-라인 프롬프트가 다음과 같이 변경되어 표시된다.다음 출력결과가 보여주듯이 .databases 명령문으로 소속된 데이터베이스 이름과 파일 목록을 확인한다.다음과 같이 타이핑해서 필요한 “Person”, “Survey”, “Site” “Visited” 테이블이 존재하는 것을 확인한다.\n.table의 출력결과는 다음과 같다.","code":"root@hangul:~/swc/sql$ sqlite3 survey.dbSQLite version 3.20.0 2017-08-01 13:24:15\nEnter \".help\" for usage hints.\nConnected to a transient in-memory database.\nUse \".open FILENAME\" to reopen on a persistent database.\nsqlite>  sqlite> .databases\nseq  name             file                                                      \n---  ---------------  ----------------------------------------------------------\n0    main             ~/novice/sql/survey.dbsqlite> .tables\nPerson   Site     Survey   Visited"},{"path":"database-sqlite.html","id":"sqlite-escape","chapter":"38 .  SQLite 설치","heading":"38.5 SQLite DB 나오는 법","text":"SQLite3 DB 명령-라인 인터페이스(CLI)를 어떻게 빠져나올까요?SQLite3를 빠져나오기 위해서, 다음과 같이 타이핑한다.","code":"sqlite> .quit"},{"path":"database-select.html","id":"database-select","chapter":"39 .  변수/칼럼 선택하기","heading":"39 .  변수/칼럼 선택하기","text":"1920년 후반, 1930년 초반 William Dyer, Frank Pabodie,Valentina Roerich는 남태평양 도달불가능한 극(Pole Inaccessibility)과 이어서 남극 대륙을 탐험했다.\n2년 전에 이들의 탐험 기록이 Miskatonic 대학 창고 사물함에서 발견됐다.\n기록을 스캔해서 OCR로 저장했고, 이제는 검색가능하고 분석이 용히한 방식으로 정보를 저장하고자 한다.기본적으로 3가지 선택 옵션(텍스트 파일, 스프레드쉬트, 데이터베이스)이 있다.\n텍스트 파일은 생성하기 가장 쉽고 버젼 제어와 궁합이 맞지만, 검색과 분석 도구를 별도로 구축해야한다.\n스프레드쉬트는 단순한 분석에는 적합하지만, 크고 복잡한 데이터셋을 매우 잘 다루지는 못한다.\n그래서 데이터를 데이터베이스에 넣어서 어떻게 검색과 분석을 하는지 이번 학습에서 배울 것이다.","code":""},{"path":"database-select.html","id":"db-selection-definition","chapter":"39 .  변수/칼럼 선택하기","heading":"39.1 정의 몇가지","text":"관계형 데이터베이스(relational database)는\n테이블(tables)로 정렬된 정보를 저장하고 다루는 방식이다.\n각 테이블은 데이터를 기술하는 필드(fields)로도 알려진 열(column)과\n데이터를 담고 있는 레코드(records)로 알려진 행(row)으로 구성된다.스프레드쉬트를 사용할 때, 이전 값에 기초하여 새로운 값을 계산할 때 공식을 셀(cell)에 넣어서 구한다.\n데이터베이스를 사용할 때는 쿼리(queries, 질의)로 불리는 명령문을\n데이터베이스 관리자(database manager)에게 보낸다.\n데이터베이스 관리자는 사용자를 대신해서 데이터베이스를 다루는 프로그램이다.\n데이터베이스 관리자는 쿼리가 명기하는 임의의 조회와 계산을 수행하고 다음 쿼리의 시작점으로 사용될 수 있는\n테이블 형식으로 결과값을 반환한다.모든 데이터베이스 관리자(IBM DB2, PostgreSQL, MySQL, Microsoft Access, SQLite)는\n서로 다른 고유한 방식으로 데이터를 저장해서 한곳에서 생성된 데이터베이스는 다른 곳의 데이터베이스에서\n직접적으로 사용될 수 없다. 하지만, 모든 데이터베이스 관리자는 데이터를 다양한 형식으로 가져오기(import)와 내보내기(export)를 지원한다.\n그래서 한 곳에서 다른 곳으로 정보를 이동하는 것이 가능하다.쿼리는 SQL로 불리는 언어로 작성된다.\nSQL 은 “Structured Query Language”(구조적 질의 언어)의 약자다.\nSQL은 데이터를 분석하고 다시 조합할 수 있는 수백개의 다른 방식을 제공한다.\n학습에서 일부를 살펴볼 것이지만, 이 일부가 과학자가 수행하는 일의 대부분을 처리할 것이다.다음 테이블은 예제로 사용할 데이터베이스를 보여준다.Person: 판독한 사람.Site: 판독한 장소.Visited: 특정 사이트에서 판독한 시점.Survey: 실제 판독.3개 항목 (Visited 테이블에서 1개, Survey 테이블에서 2개) 은 붉은색으로 표기한 것을 주목하라.\n왜냐하면 어떠한 값도 담고 있지 않아서 그렇다. 결측값(missing)은 추후 다룰 것이다.\n지금으로서는 과학자의 이름을 화면에 표시하는 SQL을 작성하자.\nSQL select 문을 사용해서 원하는 칼럼이름과 원하는 테이블이름을 준다.\n쿼리와 결과는 다음과 같다.표 39.1: 첫번째 SQL 쿼리쿼리 끝에 세미콜론(;)은 쿼리가 완료되어 실행준비 되었다고 데이터베이스 관리자에게 알려준다.\n명령문과 칼럼 이름을 모두 소문자로 작성했고, 테이블 이름은 타이틀 케이스(Title Case, 단어의 첫 문자를 대문자로 표기)로 작성했다.\n하지만 그렇게 반듯이 할 필요는 없다. 아래 예제가 보여주듯이, SQL은 대소문자 구분하지 않는다표 39.2: SQL 쿼리문은 대소문자 구분하지 않음모두 소문자, 타이틀 케이스, 소문자 낙타 대문자(Lower Camel Case)를 선택하든지 관계없이 일관성을 가져라.\n랜덤 대문자를 추가적으로 인지하지 않더라고 복잡한 쿼리는 충분히 그 자체로 이해하기 어렵다.쿼리로 돌아가서, 데이터베이스 테이블의 행과 열이 특정한 순서로 저장되지 않는다는 것을 이해하는 것이 중요하다.\n어떤 순서로 항상 표시되지만, 다양한 방식으로 제어할 수 있다.\n예를 들어, 쿼리를 다음과 같이 작성해서 칼럼을 교환할 수 있다.표 39.3: 칼럼 교환혹은 심지어 칼럼을 반복할 수도 있다.표 39.4: 칼럼명 중복 선택손쉬운 방법으로, *을 사용해서 테이블의 모든 칼럼을 선택할 수도 있다.표 39.5: 모든 칼럼 선택","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>SELECT family, personal from Person;SeLeCt FaMiLy, PeRsOnAl FrOm PeRsOn;SELECT personal, family from Person;select ident, ident, ident from Person;select * from Person;"},{"path":"database-select.html","id":"db-select-challenge","chapter":"39 .  변수/칼럼 선택하기","heading":"39.2 도전 과제","text":"Site 테이블에서 사이트 이름만 선택하는 쿼리를 작성하세요.Site 테이블에서 사이트 이름만 선택하는 쿼리를 작성하세요.많은 사람들이 쿼리를 다음과 같은 형식으로 작성한다.\nSELECT personal, family person;\n혹은 다음과 같이도 작성한다.\nselect Personal, Family PERSON;\n읽기 쉽기 쉬운 스타일은 어느 것인가요? 이유는 무엇일까요?많은 사람들이 쿼리를 다음과 같은 형식으로 작성한다.혹은 다음과 같이도 작성한다.읽기 쉽기 쉬운 스타일은 어느 것인가요? 이유는 무엇일까요?","code":"SELECT personal, family FROM person;select Personal, Family from PERSON;"},{"path":"database-select.html","id":"db-select-points","chapter":"39 .  변수/칼럼 선택하기","heading":"39.3 주요점","text":"관계형 데이터베이스는 정보를 테이블로 저장한다. 고정된 숫자의 칼럼과 변하기 쉬운 숫자의 레코드로 구성된다.데이터베이스 관리자는 데이터베이스에 저장된 정보를 다루는 프로그램이다.데이터베이스에서 정보를 추출하는데 SQL이라고 불리는 특화된 언어로 쿼리를 작성한다.SQL은 대소문자를 구별하지 않는다.","code":""},{"path":"database-sort.html","id":"database-sort","chapter":"40 .  정렬, 중복 제거","heading":"40 .  정렬, 중복 제거","text":"데이터는 종종 잉여가 있어서, 쿼리도 종종 과잉 정보를 반환한다.\n예를 들어, survey 테이블에서 측정된 수량 정보를 선택하면, 다음을 얻게된다.표 40.1: SQL select 쿼리문결과를 좀더 읽을 수 있게 만들기 위해서 쿼리에 distinct 키워드를 추가해서 중복된 출력을 제거한다.표 40.2: 중복 제거 쿼리문하나 이상의 칼럼(예를 들어 survey 사이트 ID와 측정된 수량)을 선택한다면, 별개로 구별된 값의 쌍이 반환된다.표 40.3: 칼럼 두개 중복 제거양쪽 경우에 설사 데이터베이스 내에서 서로 인접하지 않더라도 모두 중복이 제거된 것을 주목하세요.\n다시 한번, 행은 실제로 정렬되지는 않았다는 것을 기억하세요. 단지 정렬된 것으로 화면에 출력된다.","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>select quant from Survey;select distinct quant from Survey;select distinct taken, quant from Survey;"},{"path":"database-sort.html","id":"db-sort-challenge","chapter":"40 .  정렬, 중복 제거","heading":"40.1 도전 과제","text":"Site 테이블에서 별개로 구별되는 날짜를 선택하는 쿼리를 작성하세요.앞서 언급했듯이, 데이터베이스 레코드는 특별한 순서로 저장되지 않는다. 이것이 의미하는 바는 쿼리 결과가 반드시 정렬되어 있지 않다는 것이다.\n설사 정렬이 되어 있더라도, 종종 다른 방식으로 정렬하고 싶을 것이다.\n예를 들어 과학자의 이름 대신에 프로젝트 이름으로 정렬할 수도 있다. SQL에서 쿼리에 order 절을 추가해서 간단하게 구현할 수 있다.표 40.4: ident 칼럼 기준 정렬디폴트로, 결과는 오름차순으로 정렬되어야 한다. (즉, 가장 적은 값에서 가장 큰 값 순으로 정렬된다.)\ndesc (“descending”)를 사용해서 역순으로도 정렬할 수 있다.표 40.5: ident 칼럼 기준 역정렬(그리고, desc 대신에 asc를 사용해서 오름차순으로 정렬하고 있다는 것을 명시적으로 표현할 수도 있다.)한번에 여러 필드를 정렬할 수도 있다. 예를 들어, 다음 쿼리는 taken 필드를 오름차순으로 그리고 동일 그룹의 taken 값 내에서는\nperson으로 내림차순으로 결과를 정렬한다.표 40.6: 칼럼 기준 순정렬, 역정렬만약 중복을 제거한다면 이해하기가 더 쉽다.표 40.7: 중복제거 칼럼 기준 순정렬, 역정렬","code":"select * from Person order by ident;select * from person order by ident desc;select taken, person from Survey order by taken asc, person desc;select distinct taken, person from Survey order by taken asc, person desc;"},{"path":"database-sort.html","id":"db-sort-challenge-two","chapter":"40 .  정렬, 중복 제거","heading":"40.2 도전 과제","text":"Visited 테이블에서 별개로 구별되는 날짜를 반환하는 쿼리를 작성하세요.Visited 테이블에서 별개로 구별되는 날짜를 반환하는 쿼리를 작성하세요.성(family name)으로 정렬된 Person 테이블에 과학자의 성명 전부를 화면에 출력하는 쿼리를 작성하세요.성(family name)으로 정렬된 Person 테이블에 과학자의 성명 전부를 화면에 출력하는 쿼리를 작성하세요.","code":""},{"path":"database-sort.html","id":"db-sort-main-points","chapter":"40 .  정렬, 중복 제거","heading":"40.3 주요점","text":"데이터베이스 테이블의 레코드는 본질적으로 정렬되지 않는다.\n만약 특정 순서로 정렬하여 표시하려면, 명시적으로 정렬을 명기하여야 한다.데이터베이스의 값이 유일(unique)함을 보장하지는 않는다.\n만약 중복을 제거하고자 한다면, 명시적으로 유일함을 명기하여야 한다.","code":""},{"path":"database-filter.html","id":"database-filter","chapter":"41 .  필터링 (Filtering)","heading":"41 .  필터링 (Filtering)","text":"데이터베이스의 가장 강력한 기능중 하나는 데이터를 필터(filter)하는 능력이다.\n즉, 특정 기준에 맞는 레코드만 선택한다. 예를 들어, 특정 사이트를 언제 방문했는지 확인한다고 가정하자.\n쿼리에 절을 사용해서 Visited 테이블로부터 레코드를 뽑아낼 수 있다.표 41.1: SQL 필터 쿼리문데이터베이스 관리자는 두 단계로 나누어 쿼리를 실행한다.\n첫번째로, 절을 만족하는 것이 있는지 확인하기 위해서\nVisited 테이블의 각 행을 점검한다.\n그리고 나서 무슨 칼럼을 표시할지 결정하기 위해서 select 키워드 다음에 있는 칼럼 이름을 사용한다.이러한 처리 순서가 의미하는 바는 화면에 표시되지 않는 칼럼 값에 기반해서도 절을 사용해서 레코드를 필터링할 수 있다는 것이다.표 41.2: SQL 칼럼 선택과 결합된 필터 쿼리문SQL 필터 쿼리문 적용 과정데이터를 필터링하는데 불 연산자(Boolean Operators)를 사용할 수 있다. 예를 들어, 1930년 이후로 DR-1 사이트에서 수집된 모든 정보를 요청할 수도 있다.표 41.3: SQL 필터 부울연산 반영쿼리문(각 테스트 주위의 괄호는 엄밀히 말해 필요하지는 않지만 쿼리를 좀더 읽기 쉽게 한다.)대부분의 데이터베이스 관리자는 날짜에 대한 특별한 데이터 형식을 가진다.\n사실 많이 있지만 두가지 형식으로 볼 수 있다. 날짜 데이터 형식의 하나는 “May 31, 1971”와 같은 것이고,\n다른 하나는 “31 days” 같은 기간에 대한 것이다.\nSQLite는 구분하지는 않는다. 대신에 SQLite는 날짜를 텍스트 (ISO-8601 표준 형식 “YYYY-MM-DD HH:MM:SS.SSSS”), 혹은\n실수 (November 24, 4714 BCE 이후 지나간 일수), 혹은 정수 (1970년 1월 1일 자정 이후 초)로만 저장한다.\n만약 복잡하게 들린다면, 그럴수도 있다 하지만 스웨덴의 역사적인 날짜(historical dates Sweden)를\n이해하는 것만큼 복잡하는지는 않다.Lake 혹은 Roerich가 무슨 측정을 했는지 알아내고자 한다면, or를 사용하여 이름에 테스트를 조합할 수 있다.표 41.4: SQL 필터 부울 선택() 연산자 반영쿼리문다른 방식으로, in을 사용하여 특정 집합에 값이 있는지 확인할 수 있다.표 41.5: SQL 필터 가독성 높은 부울 선택() 연산 쿼리문and와 or를 조합할 수는 있지만, 어느 연산자가 먼저 수행되는지 주의할 필요가 있다.\n만약 괄호를 사용하지 않는다면, 다음을 얻게 된다.표 41.6: SQL 필터 부울 선택() 연산 적용순서상기 결과는 Lake가 측정한 염분량과 Roerich가 측정한 임의 측정값이다.\n대신에 아마도 다음과 같은 결과를 얻고자 했을 것이다.표 41.7: SQL 필터 괄호적용 부울 선택() 연산 적용순서마지막으로 distinct와 where를 사용하여 두번째 수준의 필터링을 한다.표 41.8: SQL 중복제거 선택문과 결합된 필터 부울 선택() 연산하지만, 기억하라. distinct는 처리될 때 선택된 칼럼에 표시되는 값에만 적용되고 전체 행에는 적용되지 않는다.방금전까지 수행하는 것은 대부분의 사람들이 어떻게 SQL 쿼리를 증가시키는지 살펴봤다.\n의도한 것의 일부를 수행하는 단순한 것에서부터 시작했다.\n그리고 절을 하나씩 하나씩 추가하면서 효과를 테스트했다. 좋은 전략이다. 사실 복잡한 쿼리를 작성할 때, 종종 유일한 전략이다.\n하지만 이 전략은 빠른 회전(turnaround)시간에 달려있고 사용자에게는 정답을 얻게되면 인지하는 것에 달려있다.\n빠른 회전시간을 달성하는 최선의 방법은 임시 데이터베이스에 데이터의 일부를 저장하고 쿼리를 실행하거나 혹은\n합성된 레코드로 작은 데이터베이스를 채워놓고 작업을 하는 것이다.\n예를 들어, 2천만 호주사람의 실제 데이터베이스에 쿼리를 작업하지 말고,\n1만명 샘플을 뽑아 쿼리를 돌리거나 작은 프로그램을 작성해서 랜덤으로 혹은 그럴듯한 1만명 레코드를 생성해서 사용한다.","code":"select * from Visited where site='DR-1';select ident from Visited where site='DR-1';select * from Visited where (site='DR-1') and (dated>='1930-00-00');select * from Survey where person='lake' or person='roe';select * from Survey where person in ('lake', 'roe');select * from Survey where quant='sal' and person='lake' or person='roe';select * from Survey where quant='sal' and (person='lake' or person='roe');select distinct person, quant from Survey where person='lake' or person='roe';"},{"path":"database-filter.html","id":"db-filter-challenge","chapter":"41 .  필터링 (Filtering)","heading":"41.1 도전 과제","text":"극에서 30&deg보다 고위도에 위치한 모든 사이트를 선택하고자 한다고 가정하자.\n작성한 첫번째 쿼리는 다음과 같다.\nselect * Site (lat > -60) (lat < 60);\n왜 이 쿼리가 잘못된 것인지 설명하세요.\n그리고 쿼리를 다시 작성해서 올바르게 동작하게 만드세요.극에서 30&deg보다 고위도에 위치한 모든 사이트를 선택하고자 한다고 가정하자.\n작성한 첫번째 쿼리는 다음과 같다.왜 이 쿼리가 잘못된 것인지 설명하세요.\n그리고 쿼리를 다시 작성해서 올바르게 동작하게 만드세요.정규화된 염분 수치는 0.0에서 1.0 사이에 있어야 한다.\n상기 범위 밖에 있는 염분수치를 가진 모든 레코드를 Survey 테이블에서 선택하는 쿼리를 작성하세요.정규화된 염분 수치는 0.0에서 1.0 사이에 있어야 한다.\n상기 범위 밖에 있는 염분수치를 가진 모든 레코드를 Survey 테이블에서 선택하는 쿼리를 작성하세요.만약 명명된 칼럼의 값이 주어진 패턴과 일치한다면 SQL 테스트 *column-name* like *pattern*은 참이다.\n“0 혹은 그 이상의 문자와 매칭”된다는 것을 의미하기 위해서 ’%’문자를 패턴에 임의 숫자 횟수에 사용한다.\n\n표현식\n\n\n값\n\n\n‘’ like ‘’\n\n\nTrue\n\n\n‘’ like ‘%’\n\n\nTrue\n\n\n‘b’ like ‘%’\n\n\nFalse\n\n\n‘alpha’ like ‘%’\n\n\nTrue\n\n\n‘alpha’ like ‘%p%’\n\n\nTrue\n\n표현식 *column-name* like *pattern*은 테스트를 거꾸로 한다.\nlike를 사용하여 사이트에서 ’DR-something’으로 라벨이 붙지 않은 모든 레코드를 Visited에서 찾는 쿼리를 작성하세요.만약 명명된 칼럼의 값이 주어진 패턴과 일치한다면 SQL 테스트 *column-name* like *pattern*은 참이다.\n“0 혹은 그 이상의 문자와 매칭”된다는 것을 의미하기 위해서 ’%’문자를 패턴에 임의 숫자 횟수에 사용한다.표현식값‘’ like ‘’True‘’ like ‘%’True‘b’ like ‘%’False‘alpha’ like ‘%’True‘alpha’ like ‘%p%’True표현식 *column-name* like *pattern*은 테스트를 거꾸로 한다.\nlike를 사용하여 사이트에서 ’DR-something’으로 라벨이 붙지 않은 모든 레코드를 Visited에서 찾는 쿼리를 작성하세요.","code":"select * from Site where (lat > -60) or (lat < 60);"},{"path":"database-filter.html","id":"db-filter-points","chapter":"41 .  필터링 (Filtering)","heading":"41.2 주요점","text":"where를 사용해서 불 조건(Boolean conditions)에 따라 레코드를 필터링한다.필터링이 전체 레코드에 적용되어서, 조건을 실제로 표시되지 않는 필드에 사용할 수 있다.","code":""},{"path":"database-calc.html","id":"database-calc","chapter":"42 .  새로운 값 계산하기","heading":"42 .  새로운 값 계산하기","text":"주의깊이 탐험 기록을 다시 정독한 뒤에, 탐험대가 보고한 방사선 측정치가 5%만큼 상향되어 수정될 필요가 있다는 것을 깨달았다.\n저장된 데이터를 변형하기 보다는 쿼리의 일부분으로서 즉석에서 계산을 수행할 수 있다.표 42.1: 신규 칼럼 생성 쿼리문쿼리를 실행하면, 표현식 1.05 * reading이 각 행마다 평가된다.\n표현식에는 임의의 필드, 통상 많이 사용되는 연산자, 그리고 다양한 함수를 사용한다.\n(정확하게는 어느 데이터베이스 관리자를 사용되느냐에 따라 의존성을 띄게된다.)\n예를 들어, 온도 측정치를 화씨에서 섭씨로 소수점 아래 두자리에서 반올림하여 변환할 수 있다.표 42.2: 신규 칼럼 반올림 적용 쿼리문다른 필드의 값을 조합할 수도 있다. 예를 들어, 문자열 접합 연산자 (string concatenation operator, ||)를 사용한다.표 42.3: 접합연산자 적용 신규 칼럼 생성 쿼리문first와 last 대신에 필드 이름으로 personal과 family를 사용하는 것이 이상해 보일지 모른다.\n하지만, 문화적 차이를 다루기 위한 필요한 첫번째 단계다. 예를 들어, 다음 규칙을 고려해보자.분명하게, 심지어 두부분 “personal”과 “family”으로 나누는 것도 충분하지 않다.","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>select 1.05 * reading from Survey where quant='rad';select taken, round(5*(reading-32)/9, 2) from Survey where quant='temp';select personal || ' ' || family from Person;"},{"path":"database-calc.html","id":"db-calc-challenge","chapter":"42 .  새로운 값 계산하기","heading":"42.1 도전 과제","text":"좀더 조사한 뒤에, Valentina Roerich는 염도를 퍼센티지(%)로 작성한 것을 알게되었다.\nSurvey 테이블에서 값을 100으로 나누어서 모든 염도 측정치를 반환하는 쿼리를 작성하세요.좀더 조사한 뒤에, Valentina Roerich는 염도를 퍼센티지(%)로 작성한 것을 알게되었다.\nSurvey 테이블에서 값을 100으로 나누어서 모든 염도 측정치를 반환하는 쿼리를 작성하세요.union 연산자는 두 쿼리의 결과를 조합한다.union 연산자는 두 쿼리의 결과를 조합한다.표 42.4: union 연산자 적용 쿼리 두개 결합 결과union을 사용하여 앞선 도전과제에서 기술되어 수정된 Roerich가 측정한, Roerich만 측정한 염도 측정치의 통합 리스트를 생성하세요.\n출력결과는 다음과 같아야 한다.Visited 테이블에 사이트 식별자는 ’-’으로 구분되는 두 부분으로 구성되어 있다.몇몇 주요 사이트 식별자는 두 문자길이를 가지고 몇몇은 3문자길이를 가진다.\n“string” 함수 instr(X, Y)은 X 문자열에 문자열 Y가 첫번째 출현의 1-기반 인덱스를 반환하거나\nY가 X에 존재하지 않으면 0 을 반환한다.\n부분 문자열 함수 substr(X, )은 인덱스 I에서 시작하는 문자열 X의 부분문자열을 반환한다.\n상기 두 함수를 사용해서 유일한 주요 사이트 식별자를 생성하세요. (이 데이터에 대해서 작업된 리스트는\n“DR”과 “MSK”만 포함해야 한다.)","code":"select * from Person where ident='dyer' union select * from Person where ident='roe';select distinct site from Visited;"},{"path":"database-calc.html","id":"db-calc-points","chapter":"42 .  새로운 값 계산하기","heading":"42.2 주요점","text":"SQL은 쿼리의 일부로서 레코드의 값을 사용한 계산을 수행한다.","code":""},{"path":"database-null.html","id":"database-null","chapter":"43 .  결측 데이터 (Missing Data)","heading":"43 .  결측 데이터 (Missing Data)","text":"현실 세계 데이터는 결코 완전하지 않고 구멍은 항상 있다.\nnull로 불리는 특별한 값을 사용하여 데이터베이스는 구멍을 표현한다.\nnull는 0, False, 혹은 빈 문자열도 아니다.”아무것도 없음(nothing )“을 의미하는 특별한 값이다.\nnull을 다루는 것은 약간 특별한 기교와 신중한 생각을 요구한다.시작으로 Visited 테이블을 살펴보자. 레코드가 8개 있지만 #752은 날짜가 없다. 혹은 더 정확히 말하면 날짜가 null이다.표 43.1: 결측값을 갖는 테이블Null 다른 값과는 다르게 동작한다.\n만약 1930년 이전 레코드를 선택한다면,표 43.2: 1930년 이전 레코드 선택결과 2개를 얻게 되고, 만약 1930년 동안 혹은 이후 레코드를 선택한다면,표 43.3: 1930년 이후 레코드 선택결과를 5개 얻게되지만, 레코드 #752은 결과값 어디에도 존재하지 않는다.\n이유는 null<'1930-00-00' 평가결과가 참도 거짓도 아니기 때문이다.\nnull 이 의미하는 것은 “알수가 없다”는 것이다.\n그리고 만약 비교 평가식의 왼쪽편 값을 알지 못한다면, 비교도 참인지 거짓인지 알수가 없다.\n데이터베이스는 “알 수 없음”을 null로 표현하기 때문에, null<'1930-00-00'의 값도 사실 null이다.\nnull>='1930-00-00'도 또한 null인데 왜냐하면 질문에 답을 할 수 없기 때문이다.\n그리고, where절에 레코드는 테스트가 참인 것만 있기 때문에 레코드 #752은 어느 결과값에도 포함되지 않게 된다.평가식만 null값을 이와 같은 방식으로 다루는 연산자는 아니다.\n1+null도 null이고,\n5*null도 null이고,\nlog(null)도 null이 된다.\n특히, 무언가를 = 과 != 으로 null과 비교하는 것도 null이 된다.표 43.4: NULL 값 갖는 레코드 선택표 43.5: NULL 값 갖지 않는 레코드 선택null 인지 아닌지를 점검하기 위해서, 특별한 테스트 null을 사용해야 한다.표 43.6: NULL 사용 NULL 값 갖는 레코드 선택혹은, 역으로는 null을 사용한다.표 43.7: NULL 사용 NULL 값 갖지 않는 레코드 선택null 값은 나타나는 곳마다 두통을 일으킨다.\n예를 들어, Dyer가 측정하지 않은 모든 염분 정보를 찾는다고 가정하자.\n다음과 같이 쿼리를 작성하는 것은 당연하다.표 43.8: NULL 값이 갖는 문제하지만, 상기 쿼리 필터는 누가 측정을 했는지 모르는 레코드는 빠뜨린다.\n다시 한번, 이유는 person이 null일 때, !=비교는 null값을 만들어서\n레코드가 결과값에 있지 않게 된다. 만약 이런 레코드도 유지하려고 한다면,\n명시적으로 검사를 추가할 필요가 있다.표 43.9: NULL 값 갖는 문제 명시적 해결여전히 이러한 접근법이 맞는 것인지 아닌 것인지 판단할 필요가 있다.\n만약 절대적으로 결과에 Lake가 측정한 어떠한 값도 포함하지 않는다고 확신한다면,\n누가 작업을 한 것인지 모르는 모든 레코드를 제외할 필요가 있다.","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>select * from Visited;select * from Visited where dated<'1930-00-00';select * from Visited where dated>='1930-00-00';select * from Visited where dated=NULL;select * from Visited where dated!=NULL;select * from Visited where dated is NULL;select * from Visited where dated is not NULL;select * from Survey where quant='sal' and person!='lake';select * from Survey where quant='sal' and (person!='lake' or person is null);"},{"path":"database-null.html","id":"db-null-challenge","chapter":"43 .  결측 데이터 (Missing Data)","heading":"43.1 도전 과제","text":"날짜가 알려지지 않은 (즉 null) 항목은 빼고, 날짜 순으로 Visited 테이블에 있는 레코드를 정렬한 쿼리를 작성하세요.날짜가 알려지지 않은 (즉 null) 항목은 빼고, 날짜 순으로 Visited 테이블에 있는 레코드를 정렬한 쿼리를 작성하세요.다음 쿼리가 무슨 결과를 할까요?\nselect * Visited dated ('1927-02-08', null);\n상기 쿼리가 실질적으로 무엇을 생기게 할까요?다음 쿼리가 무슨 결과를 할까요?상기 쿼리가 실질적으로 무엇을 생기게 할까요?몇몇 데이터베이스 디자이너는 null 보다 결측 데이터를 표기하기 위해서 보초값(sentinel value)를 사용한다.\n예를 들어, 결측 날짜를 표기하기 위해서 “0000-00-00” 날짜를 사용하거나 결측 염분치 혹은 결측 방사선 측정값을 표기하기 위해서 -1.0을 사용한다.\n(왜냐하면 실제 측정값이 음수가 될 수 없기 때문이다.)\n이러한 접근법은 무엇을 단순화할까요? 이러한 접근법이 어떤 부담과 위험을 가져올까요?몇몇 데이터베이스 디자이너는 null 보다 결측 데이터를 표기하기 위해서 보초값(sentinel value)를 사용한다.\n예를 들어, 결측 날짜를 표기하기 위해서 “0000-00-00” 날짜를 사용하거나 결측 염분치 혹은 결측 방사선 측정값을 표기하기 위해서 -1.0을 사용한다.\n(왜냐하면 실제 측정값이 음수가 될 수 없기 때문이다.)\n이러한 접근법은 무엇을 단순화할까요? 이러한 접근법이 어떤 부담과 위험을 가져올까요?","code":"select * from Visited where dated in ('1927-02-08', null);"},{"path":"database-null.html","id":"db-null-points","chapter":"43 .  결측 데이터 (Missing Data)","heading":"43.2 주요점","text":"데이터베이스는 결측 정보를 표현하기 위해서 null을 사용한다.null이 관계되는 산술 혹은 불 연산 결과도 null이다.null과 함께 안전하세 사용될 수 있는 유일한 연산자는 null과 null이다.","code":""},{"path":"database-agg.html","id":"database-agg","chapter":"44 .  집합(Aggregation)","heading":"44 .  집합(Aggregation)","text":"이제 데이터의 평균과 범위를 계산하고자 한다. Visited 테이블에서 모든 날짜 정보를 어떻게 선택하는지 알고 있다.표 44.1: SQL select 쿼리문하지만 조합하기 위해서는 min 혹은 max 같은 집합 함수(aggregation function)를 사용해야만 한다.\n각 함수는 입력으로 레코드 집합을 받고 출력으로 단일 레코드를 만든다.표 44.2: 최소값 집합 함수 적용 쿼리문SQL 집합함수 최소값(min) 찾는 과정표 44.3: 최대값 집합 함수 적용 쿼리문min과 max는 SQL에 내장된 단지 두개의 집합 함수다.\n다른 세개는 avg, count, sum이 있다.표 44.4: 평균값 집합 함수 적용 쿼리문표 44.5: 개수 집합 함수 적용 쿼리문표 44.6: 합계 집합 함수 적용 쿼리문여기서 count(reading)을 사용했다. 하지만 quant를 단순히 쉽게 세거나 테이블의 다른 어떤 필드도 셀 수 있고 심지어 count(*)을 사용하기도 한다.\n왜냐하면 count()함수가 값 자체보다는 얼마나 많은 값이 있는지에만 관심을 두기 때문이다.SQL이 여러개의 집합연산도 한번에 수행한다. 예를 들어, 염분측정치의 범위도 알 수 있다.표 44.7: 최소, 최대값 집합 함수 적용 쿼리문출력결과가 놀라움을 줄 수도 있지만, 원 결과값과 집합 결과를 조합할 수도 있다.표 44.8: 원 결과값과 집합 함수를 적용한 쿼리문왜 Roerich 혹은 Dyer가 아닌 Lake의 이름이 나타날까요?\n답은 필드를 집합하지만 어떻게 집합하는지 말을 하지 않기 때문에 데이터베이스 관리자가 입력에서 실제 값을 고른다.\n처음 처리된 것, 마지막에 처리된 것, 혹은 완전히 다른 무언가를 사용할 수도 있다.또다른 중요한 사실은 집합할 어떠한 값도 없을 때, 집합 결과는 0 혹은 다른 임의의 값 보다 “알지 못한다(don’t know)”가 된다.표 44.9: NULL 값이 포함된 원데이터에 집합 함수를 적용한 쿼리문집합 함수의 마지막 중요한 한가지 기능은 매우 유용한 방식으로 나머지 SQL과는 일관되지 않다는 것이다.\n만약 두 값을 더하는데 그중 하나가 null이면 결과는 null이다.\n확장해서, 만약 한 집합의 모든 값을 더하기 위해서 sum을 사용하고 이들 중 임의의 값이 null이면,\n결과도 또한 null이어야 한다. 하지만 집합함수가 null 값을 무시하고 단지 non-null 값만을 조합한다면 훨씬 더 유용하다.\n명시적으로 항상 필터해야하는 대신에 이것의 결과 쿼리를 다음과 같이 작성할 수 있게 한다.표 44.10: NULL 값이 포함된 원데이터를 명시적으로 처리한 후 집합 함수를 적용한 쿼리문명시적으로 항상 다음과 같이 필터하는 쿼리를 작성할 필요가 없다.표 44.11: NULL 값이 포함된 원데이터를 명시적으로 처리하지 않는 집합 함수를 적용한 쿼리문한번에 모든 레코드를 집합하는 것이 항상 타당하지는 않다.\n예를 들어, Gina가 데이터에 체계적인 편의(bias)가 있어서 다른 과학자의 방사선 측정치가 다른 사람의 것과 비교하여 높다고 의심한다고 가정하자.\n다음 쿼리가 의도를 반영하여 동작하지 않는다는 것은 알고 있다.표 44.12: 주의깊이 살펴볼 쿼리문왜냐하면 데이터베이스 관리자가 각 과학자별로 구분된 집합하기 보다는 임의의 한명의 과학자 이름만 선택하기 때문이다.\n단지 5명의 과학자만 있기 때문에, 다음과 같은 형식의 5개 쿼리를 작성할 수 있다.표 44.13: 사람별로 작성한 쿼리문 문제 예제하지만, 이러한 접근법은 성가시고, 만약 50명 혹은 500명의 과학자를 가진 데이터셋을 분석한다면,\n모든 쿼리를 올바르게 작성할 가능성은 작다.필요한 것은 데이터베이스 관리자가 group by절을 사용해서 각 과학자별로 시간을 집합하도록 지시하는 것이다.표 44.14: group 문을 사용해서 사람별로 작성한 쿼리문 예제group by는 이름이 의미하는 것과 동일한 것을 정확하게 수행한다.\n지정된 필드에 동일한 값을 가진 모든 레코드를 그룹으로 묶어서 집합을 각 배치별로 처리한다.\n각 배치에 모든 레코드는 person에 동일한 값을 가지고 있기 때문에,\n데이터베이스 관리자가 임의의 값을 잡아서 집합된 reading 값과 함께 표시하는지는 더 이상 문제가 되지 않는다.한번에 다중 기준으로 정렬하듯이 다중 기준으로 묶어 그룹화할 수 있다.\n예를 들어 과학자와 측정 수량에 따라 평균 측정값을 얻기 위해서,\ngroup 절에 또다른 필드만 추가한다.표 44.15: group 문을 확장하여 적용한 쿼리문 사례그렇지 않으면 결과가 의미가 없기 때문에, person을 표시되는 필드 리스트에 추가한 것을 주목하라.한단계 더나아가 누가 측정을 했는지 알지 못하는 모든 항목을 제거하자.표 44.16: 사람별로 측정값을 정렬한 쿼리문 사례좀더 면밀하게 살펴보면, 이 쿼리는,Survey테이블에서 person 필드가 null이 아닌 레코드를 선택한다.Survey테이블에서 person 필드가 null이 아닌 레코드를 선택한다.상기 레코드를 부분집합으로 그룹지어서 각 부분집합의 person과 quant의 값은 같다.상기 레코드를 부분집합으로 그룹지어서 각 부분집합의 person과 quant의 값은 같다.먼저 person으로 부분집합을 정렬하고나서 quant로 각 하위 그룹내에서도 정렬한다.먼저 person으로 부분집합을 정렬하고나서 quant로 각 하위 그룹내에서도 정렬한다.각 부분집합의 레코드 숫자를 세고, 각각 reading 평균을 계산하고, 각각 person과 quant 값을 선택한다.\n(모두 동등하기 때문에 어느 것인지는 문제가 되지 않는다.)각 부분집합의 레코드 숫자를 세고, 각각 reading 평균을 계산하고, 각각 person과 quant 값을 선택한다.\n(모두 동등하기 때문에 어느 것인지는 문제가 되지 않는다.)","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>select dated from Visited;select min(dated) from Visited;select max(dated) from Visited;select avg(reading) from Survey where quant='sal';select count(reading) from Survey where quant='sal';select sum(reading) from Survey where quant='sal';select min(reading), max(reading) from Survey where quant='sal' and reading<=1.0;select person, count(*) from Survey where quant='sal' and reading<=1.0;select person, count(*) from Survey where quant='sal' and reading<=1.0;select min(dated) from Visited;select min(dated) from Visited where dated is not null;select person, count(reading), round(avg(reading), 2)\nfrom  Survey\nwhere quant='rad';select person, count(reading), round(avg(reading), 2)\nfrom  Survey\nwhere quant='rad'\nand   person='dyer';select   person, count(reading), round(avg(reading), 2)\nfrom     Survey\nwhere    quant='rad'\ngroup by person;select   person, quant, count(reading), round(avg(reading), 2)\nfrom     Survey\ngroup by person, quant;select   person, quant, count(reading), round(avg(reading), 2)\nfrom     Survey\nwhere    person is not null\ngroup by person, quant\norder by person, quant;"},{"path":"database-agg.html","id":"db-agg-challenge","chapter":"44 .  집합(Aggregation)","heading":"44.1 도전 과제","text":"Frank Pabodie는 얼마 많이 온도 측정치를 기록했고 평균 값은 얼마인가요?Frank Pabodie는 얼마 많이 온도 측정치를 기록했고 평균 값은 얼마인가요?집합 값의 평균은 값을 합한 것을 값의 갯수로 나눈 것이다.\n값이 1.0, null, 5.0 으로 주어졌을 때, avg 함수는 2.0 혹은 3.0을 반환하는 것을 의미하나요?집합 값의 평균은 값을 합한 것을 값의 갯수로 나눈 것이다.\n값이 1.0, null, 5.0 으로 주어졌을 때, avg 함수는 2.0 혹은 3.0을 반환하는 것을 의미하나요?각 개별 방사선 측정값과 평균값 사이의 차이를 계산하고자 한다. 쿼리를 다음과 같이 작성한다.\nselect reading - avg(reading) Survey quant='rad';\n상기 쿼리가 무엇을 만드나요? 그리고 왜 그런가요?각 개별 방사선 측정값과 평균값 사이의 차이를 계산하고자 한다. 쿼리를 다음과 같이 작성한다.상기 쿼리가 무엇을 만드나요? 그리고 왜 그런가요?group_concat(field, separator) 함수는 지정된 구분 문자(혹은 만약 구분자가 지정되지 않는다면 ‘,’)를 사용하여 필드의 모든 값을 결합한다.\n이 함수르 사용해서 과학자의 이름을 한줄 리스트로 다음과 같이 만드세요.\nWilliam Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank Danforth\n성씨(surname)으로 리스트를 정렬하는 방법을 제시할 수 있나요?group_concat(field, separator) 함수는 지정된 구분 문자(혹은 만약 구분자가 지정되지 않는다면 ‘,’)를 사용하여 필드의 모든 값을 결합한다.\n이 함수르 사용해서 과학자의 이름을 한줄 리스트로 다음과 같이 만드세요.성씨(surname)으로 리스트를 정렬하는 방법을 제시할 수 있나요?","code":"select reading - avg(reading) from Survey where quant='rad';William Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank Danforth"},{"path":"database-agg.html","id":"db-agg-points","chapter":"44 .  집합(Aggregation)","heading":"44.2 주요점","text":"집합 함수는 많은 값을 조합해서 하나의 새로운 값을 만든다.집합 함수는 null 값을 무시한다.필터링 다음에 집합이 일어난다.","code":""},{"path":"database-table-join.html","id":"database-table-join","chapter":"45 .  데이터 결합하기","heading":"45 .  데이터 결합하기","text":"과거 기상 자료를 집계하는 웹사이트에 데이터를 제출해야 되어서,\nGina는 위도, 경도, 날짜, 수량, 측정값 형식으로 자료를 체계적으로 만들 필요가 있다.\n하지만, 위도와 경도 정보는 Site 테이블에 있는 반면에 측정 날짜 정보는 Visited 테이블에 있고,\n측정값 자체는 Survey 테이블에 있다.\n어떤 방식이든지 상기 테이블을 조합할 필요가 있다.이러한 작업을 하는 SQL 명령어가 join이다. 어떻게 동작하는지 확인하기 위해서,\nSite와 Visited 테이블을 조인하면서 출발해보자.표 45.1: SQL join 쿼리문join은 두 테이블을 벡터곱(cross product)한다.\n즉, 모든 가능한 조합을 표현하려고 한 테이블의 레코드 각각마다 다른 테이블의 각 레코드와 조인한다.\nSite 테이블에 3개 레코드가 있고, Visited 테이블에 8개 레코드가 있어서,\n조인된 결과는 24개 레코드가 된다. 그리고, 각 테이블이 3개 필드가 있어서 출력은 6개의 필드가 된다.조인이 수행하지 않은 것은 조인되는 레코드가 서로 관계가 있는지를 파악하는 것이다.\n어떻게 조인할지 명시할 때까지 레코드가 서로 관계가 있는지 없는지 알 수 있는 방법은 없다.\n이를 위해서 동일한 사이트 이름을 가진 조합에만 관심있다는 것을 명시하는 절(clause)을 추가한다.표 45.2: 키값을 명시한 SQL join 쿼리문on 은 where와 같은 역할을 한다. 특정 테스트를 통과한 레코드만 간직한다.\n(on과 where의 차이점은 on은 레코드가 생성될 때 레코드를 필터링하는 반면에, where는 조인작업이 완료될 때까지 기다리고 난 뒤에 필터링을 한다.)\n쿼리에 레코드를 추가하자 마자 데이터베이스 관리자는 두 다른 사이트에 관한 조합된 정보는 사용한 뒤에 버려버리고, 원하는 레코드만 남겨둔다.조인 결과에 필드이름을 명기하기 위해서 table.field를 사용한 것에 주목하세요.\n이렇게 하는 이유는 테이블이 동일한 이름을 가질 수 있고 어느 필드를 언급하는지 좀더 구체성을 띌 필요가 있다.\n예를 들어, person과 visited 테이블을 조인한다면, 결과는 각각의 원래 테이블에서 ident로 불리는 필드를 상속한다.이제는 조인에서 원하는 3개의 칼럼을 선택하려고 점 표기법(dotted notation)을 사용할 수 있다.표 45.3: 점표기법을 적용한 SQL join 쿼리문만약 두개의 테이블을 조인하는 것이 좋은 경우에, 많은 데이블을 조인하는 것은 더 좋아야한다.\n더 많은 join 절과 의미없는 레코드 조합을 필터링해서 제거하는 더 많은 테스트를 단순히 추가해서 사실 쿼리에 임의 갯수의 테이블을 조인할 수 있다.표 45.4: 다수 테이블을 확장하여 결합한 SQL join 쿼리문Site, Visited, Survey 테이블의 어느 레코드가 서로 대응되지는 분간할 수 있는데 이유는 각 테이블이\n기본키(primary keys)와 외래키(foreign keys)를 가지고 있기 때문이다..\n기본키는 하나의 값 혹은 여러 값의 조합으로 테이블의 각 레코드를 유일하게 식별한다.\n외래키는 또 다른 테이블에 있는 유일하게 레코드를 식별하는 하나의 값(혹은 여러 값의 조합)이다.\n다르게 표현하면, 외래캐는 다른 테이블에 존재하는 테이블의 기본키다.\n예제 데이터베이스에서 Person.ident는 Person 테이블의 기본키인 반면에,\nSurvey.person은 외래키로 Survey 테이블의 항목과 Person 테이블의 항목을 연결한다.대부분의 데이터베이스 디자이너는 모든 테이블은 잘 정의된 기본키가 있어야된다고 믿는다.\n또한 이 키는 데이터와 떨어져서 만약 데이터를 변경할 필요가 있다면, 한 곳의 변경이 한 곳에만 변경을 만들어야만 한다.\n이를 위한 쉬운 방법은 데이터베이스에 레코드를 추가할 때 임의의 유일한 ID를 각 레코드마다 추가하는 것이다.\n실제로 이방법은 매우 흔하게 사용된다. “student numbers”, “patient numbers” 같은 이름을 ID로 사용하고,\n몇몇 데이터베이스 시스템 혹은 다른 곳에서 원래 고유 레코드 식별자로 거의 항상 판명된다.\n다음 쿼리가 시범으로 보여주듯이, 테이블에 레코드가 추가됨에 따라 SQLite는 자동으로 레코드에 숫자를 붙이고, 쿼리에서 이렇게 붙여진 레코드 숫자를 사용한다.표 45.5: 행ID(rowid) 쿼리문","code":"$ sqlite3 survey.db\nSQLite version 3.35.4 2021-04-02 15:20:15\nEnter \".help\" for usage hints.\nsqlite>select * from Site join Visited;select * from Site join Visited on Site.name = Visited.site;select Site.lat, Site.long, Visited.dated\nfrom   Site join Visited\non     Site.name=Visited.site;select Site.lat, Site.long, Visited.dated, Survey.quant, Survey.reading\nfrom   Site join Visited join Survey\non     Site.name=Visited.site\nand    Visited.ident=Survey.taken\nand    Visited.dated is not null;select rowid, * from Person;"},{"path":"database-table-join.html","id":"db-join-hygiene","chapter":"45 .  데이터 결합하기","heading":"45.1 데이터 위생 (Data Hygiene)","text":"지금까지 조인이 어떻게 동작하는지 살펴봤으니, 왜 관계형 모델이 그렇게 유용한지 그리고 어떻게 가장 잘 사용할 수 있는지 살펴보자.\n첫번째 규칙은 모든 값은 독립 요소로 분해될 수 없는 원자(atomic)적 속성을 지녀야 한다.\n즉, 구별해서 작업하고자 하는 부분을 포함해서는 안된다. 하나의 칼럼에 전체 이름을 넣는 대신에\n별도로 구별되는 칼럼에 이름과 성을 저장해서 이름 컴포넌트를 뽑아내는 부분 문자열 연산(substring operation)을 사용할 필요가 없다.\n좀더 중요하게는, 별도로 이름을 두 부분으로 저장한다. 왜냐하면, 공백으로 쪼개는 것은 신뢰성이 약하다.\n“Eloise St. Cyr” 혹은 “Jan Mikkel Steubart” 같은 이름을 생각하면 쉽게 알 수 있다.두번째 규칙은 모든 레코드는 유일한 기본키를 가져야한다. 내재적인 의미가 전혀없는 일련번호가 될 수 있고, 레코드의 값중의 하나\n(Person 테이블의 ident 필드), 혹은 Survey 테이블에서 심지어 모든 측정값을 유일하게 식별하는 (taken, person, quant) 삼중값의 조합도 될 수 있다.세번째 규칙은 불필요한 정보가 없어야 한다. 예를 들어, Site테이블을 제거하고 다음과 같이 Visited 테이블을 다시 작성할 수 있다.사실, 스프레드쉬트와 마찬가지로 각 행에 각 측정값에 관한 모든 정보를 기록하는 하나의 테이블을 사용할 수도 있다.\n문제는 이와 같은 방식으로 조직된 데이터를 일관성있게 관리하는 것은 매우 어렵다.\n만약 특정한 사이트의 특정한 방문 날짜가 잘못된다면, 데이터베이스에 다수의 레코드를 변경해야한다.\n더 안좋은 것은 다른 사이트도 그 날짜에 방문되었기 때문에 어느 레코드를 변경할지 추정해야하는 것이다.네번째 규칙은 모든 값의 단위는 명시적으로 저장되어야한다. 예제 데이터베이스는 그렇지 못해서 문제다.Roerich의 염분치는 다른 사람의 측정치보다 수천배 크다. 하지만, 천단위 대신에 백만 단위를 사용하고 있는지 혹은 1932년\n그 사이트에 염분에 이상 실제로 있었는지 알지못한다.한걸음 물러나서 생각하자, 데이터와 저장하는데 사용되는 도구는 공생관계다. 테이블과 조인은 데이터가 특정 방식으로 잘 조직되었다면 매우 효과적이다.\n하지만, 만약 특정 형태로 되어 있다면 효과적으로 다룰 수 있는 도구가 있기 때문에 데이터를 그와 같은 방식으로 조직하기도 한다.\n인류학자가 말했듯이, 도구는 도구를 만드는 손을 만든다. (tool shapes hand shapes tool)","code":""},{"path":"database-table-join.html","id":"db-table-join-chellenge","chapter":"45 .  데이터 결합하기","heading":"45.2 도전 과제","text":"DR-1 사이트의 모든 방사선 측정치를 출력하는 쿼리를 작성하세요.DR-1 사이트의 모든 방사선 측정치를 출력하는 쿼리를 작성하세요.“Frank” 가 방문한 모든 사이트를 출력하는 쿼리를 작성하세요.“Frank” 가 방문한 모든 사이트를 출력하는 쿼리를 작성하세요.다음 쿼리가 무슨 결과를 산출하는지 말로 기술하세요.\nselect Site.name Site join Visited\nSite.lat<-49.0 Site.name=Visited.site Visited.dated>='1932-00-00';다음 쿼리가 무슨 결과를 산출하는지 말로 기술하세요.","code":"select Site.name from Site join Visited\non Site.lat<-49.0 and Site.name=Visited.site and Visited.dated>='1932-00-00';"},{"path":"database-table-join.html","id":"db-table-join-points","chapter":"45 .  데이터 결합하기","heading":"45.3 주요점","text":"모든 사실은 데이터베이스에서 정확하게 한번만 표현되어야 한다.조인은 한 테이블의 레코드와 다른 테이블의 레코드를 모두 조합한 결과를 출력한다.기본키는 테이블의 레코드를 유일하게 식별하는 필드값(혹은 필드의 집합)이다.외래키는 또 다른 테이블의 기본키가되는 필드값(혹은 필드의 집합)이다.테이블사이에 기본키와 외래키를 매칭해서 의미없는 레코드의 조합을 제거할 수 있다.조인을 좀더 단순하고 효율적으로 만들기 위해서 키(key)는 원자값(atomic value)이 되어야 한다.","code":""},{"path":"database-data-create.html","id":"database-data-create","chapter":"46 .  데이터 생성과 변형","heading":"46 .  데이터 생성과 변형","text":"지금까지 어떻게 데이터베이스에서 정보를 추출하는지만 살펴봤다.\n왜냐하면, 정보를 추가하는 것보다 정보를 조회하는 것이 더 자주 있는 일이기도 하고, 다른 연산자는 쿼리가 이해되어야만 의미가 통하기 때문이다.\n만약 데이터를 생성하고 변형하고자 한다면, 다른 두짝의 명령어를 공부할 필요가 있다.첫번째 짝은 create table과 drop table이다.\n두 단어로 작성되지만, 사실 하나의 단일 명령어다.\n첫번째 명령어는 새로운 테이블을 생성한다. 인자는 테이블 칼럼의 이름과 형식이다.\n예를 들어, 다음 문장은 survey 데이터베이스에 테이블 4개를 생성한다.다음 명령어를 사용하여 테이블 중의 하나를 제거할 수도 있다.데이블을 제거할 때 매우 주의하라. 대부분의 데이터베이이스는 변경사항을 되돌리는 기능을 제공하지만, 이러한 기능에 의존하지 않는 것이 더 낫다.다른 데이터베이스 시스템은 테이블 칼럼의 다른 데이터 형식도 지원하지만,\n대부분은 다음을 다음을 제공한다.대부분의 데이터베이스는 불(boolean)과 날짜/시간 값도 지원한다.\nSQLite는 불값을 정수 0 과 1 을 사용하고 날짜/시간은 앞선(earlier) 학습방식으로 표현한다.\n점점 더 많은 데이터베이스가 위도와 경도 같은 지리정보 데이터 형식도 지원한다.\n특정 시스템이 무슨 기능을 제공하고 제공하지 않는지 그리고 어떤 이름을 다른 데이터 형식에\n부여하는지를 계속 파악하는 것은 끝없는 시스템 이식성에 대한 골치거리다.테이블을 생성할 때, 칼럼에 몇가지 제약사항을 지정할 수 있다.\n예를 들어, Survey 테이블에 대한 좀더 좋은 정의는 다음과 같이 될 것이다.다시 한번, 정확하게 무슨 제약사항이 이용가능하고 어떻게 호출되는지는 어떤 데이터베이스 관리자를 사용하는야에 달려있다.테이블이 생성되자마자, 다른 명령어 짝 insert와 delete를 사용하여 레코드를 추가하고 제거할 수 있다.\ninsert 문의 가장 간단한 형식은 순서대로 값을 목록으로 나열하는 것이다.또한, 다른 테이블에서 직접 값을 테이블에 삽입할 수도 있다.레코드를 삭제하는 것은 약간 난이도가 있다.\n왜냐하면, 데이터베이스가 내부적으로 일관성을 보장할 필요가 있기 때문이다.\n만약 하나의 단독 테이블만 관심을 둔다면, 삭제하고자 하는 레코드와 매칭되는\nwhere절과 delete문을 함께 사용한다.\n예를 들어, Frank Danforth가 어떤 측정도 하지 않았다는 것을 인지하자마자,\n다음과 같이 Person 테이블에서 Frank Danforth를 제거할 수 있다.하지만 대신에 Anderson Lake를 실수로 제거했다면 어떨까요?\nSurvey 테이블은 Anderson Lake이 수행한 7개의 측정 레코드를 담고 있지만,\n이것은 결코 일어나지 말아야 된다.\nSurvey.person은 Person 테이블에 외래키이고,\n모든 쿼리는 전자의 모든 값을 매칭하는 후자의 행이 있을 거라고 가정한다.이러한 문제를 참조 무결성(referential integrity)이라고 부른다. 테이블 사이의 모든 참조는 항상 제대로 해결될 수 있도록 확인할 필요가 있다.\n참조 무결성을 보증하는 한 방법은 기본키로 사용하는 레코드를 삭제하기 전에 외래키로\n'lake'를 사용하는 모든 레코드를 삭제하는 것이다.\n만약 데이터베이스 관리자가 이 기능을 지원한다면,\n연쇄적인 삭제(cascading delete)를 사용해서 자동화할 수 있다.\n하지만, 이 기법은 여기서 다루는 학습 영역밖이다.모든 것을 데이터베이스에 저장하는 대신 많은 응용프로그램은\n하이브리드 저장 모델을 사용한다.\n천체 이미지 같은 실제 데이터는 파일에 저장되는 반면에, 파일 이름, 변경된 날짜,\n커버하는 하늘의 영역, 스펙트럼 특성, 등등 정보는 데이터베이스에 저장한다.\n대부분의 음악 재생기(MP3 플레이어) 소프트웨어가 작성되는 방식이기도 하다.\n응용프로그램 내부 데이터베이스는 MP3 파일을 기억하고 있지만, MP3 파일 자체는 디스크에 있다.","code":"create table Person(ident text, personal text, family text);\ncreate table Site(name text, lat real, long real);\ncreate table Visited(ident integer, site text, dated text);\ncreate table Survey(taken integer, person text, quant real, reading real);drop table Survey;create table Survey(\n    taken   integer not null, -- where reading taken\n    person  text,             -- may not know who took it\n    quant   real not null,    -- the quantity measured\n    reading real not null,    -- the actual reading\n    primary key(taken, quant),\n    foreign key(taken) references Visited(ident),\n    foreign key(person) references Person(ident)\n);insert into Site values('DR-1', -49.85, -128.57);\ninsert into Site values('DR-3', -47.15, -126.72);\ninsert into Site values('MSK-4', -48.87, -123.40);create table JustLatLong(lat text, long text);\ninsert into JustLatLong select lat, long from site;delete from Person where ident = \"danforth\";"},{"path":"database-data-create.html","id":"db-database-create-challenge","chapter":"46 .  데이터 생성과 변형","heading":"46.1 도전 과제","text":"Survey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요.Survey.person의 null인 모든 사용자를 문자열 'unknown'으로 대체하는 SQL문을 작성하세요.동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의\nCSV 파일을 보내왔다.\nTaken,Temp\n619,-21.5\n622,-15.5\nsurvey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는\n작은 파이썬 프로그램을 작성하세요.\nPerson 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다.\n반복적으로 프로그램을 테스트하려면, SQL insert replace 문을 자세히 살펴볼 필요도 있다.동료중의 한명이 Robert Olmstead가 측정한 온도 측정치를 포함하는 다음과 같은 형식의\nCSV 파일을 보내왔다.survey 데이터베이스에 레코드로 추가하려고 CSV 파일을 읽고 SQL insert문을 출력하는\n작은 파이썬 프로그램을 작성하세요.\nPerson 테이블에 Olmstead 항목을 추가할 필요가 있을 것이다.\n반복적으로 프로그램을 테스트하려면, SQL insert replace 문을 자세히 살펴볼 필요도 있다.SQLite는 SQL 표준이 아닌 몇개 관리 명령어가 있다.\n그중의 하나가 .dump로 데이터베이스를 다시 생성하는데 필요한 SQL 명령문을 출력한다.\n또다른 것은 .load로 .dump에서 생성된 파일을 읽어서 데이터베이스를 복원한다.\n여러분의 동료중의 한명이 텍스트인 dump 파일을 버젼 제어 시스템에 저장하는 것이\n데이터베이스 변경사항을 추적하고 관리하는 좋은 방법이라고 생각한다.\n이러한 접근법의 장점과 단점은 무엇일까요? (힌트: 레코드는 어느 특정한 순서로 저장되지 않는다.)SQLite는 SQL 표준이 아닌 몇개 관리 명령어가 있다.\n그중의 하나가 .dump로 데이터베이스를 다시 생성하는데 필요한 SQL 명령문을 출력한다.\n또다른 것은 .load로 .dump에서 생성된 파일을 읽어서 데이터베이스를 복원한다.\n여러분의 동료중의 한명이 텍스트인 dump 파일을 버젼 제어 시스템에 저장하는 것이\n데이터베이스 변경사항을 추적하고 관리하는 좋은 방법이라고 생각한다.\n이러한 접근법의 장점과 단점은 무엇일까요? (힌트: 레코드는 어느 특정한 순서로 저장되지 않는다.)","code":"Taken,Temp\n619,-21.5\n622,-15.5"},{"path":"database-data-create.html","id":"db-database-create-points","chapter":"46 .  데이터 생성과 변형","heading":"46.2 주요점","text":"데이터베이스 테이블은 테이블 이름과 필드의 이름과 특성을 명시하는 쿼리를 사용해서 생성된다.쿼리를 사용해서 레코드는 삽입, 갱신, 삭제될 수 있다.모든 레코드가 유일한 기본키를 가질 때 데이터를 변경하는 것이 더 간단하고 안전하다.","code":""},{"path":"참고문헌.html","id":"참고문헌","chapter":"참고문헌","heading":"참고문헌","text":"","code":""},{"path":"make-automation-intro.html","id":"make-automation-intro","chapter":"47 .  자동화와 Make","heading":"47 .  자동화와 Make","text":"Make는 파일을 읽어들이고, 특정 방식으로 읽어들인 파일을 처리하고, 처리결과를 파일에 적을 수 있는 명령어를 실행하는 도구다.\n예를 들어, 소프트웨어 개발에서, Make를 사용해서 소스 코드를 컴파일하고 실행가능한 프로그램 혹은 라이브러리로 만들 수 있다.\n하지만, Make를 사용해서 다음도 할 수 있다:원데이터를 요악햐는 분석용 데이터 파일을 얻는데, 원데이터 파일에 분석 스크립트를 실행한다.그래프를 그려 도식화하는데, 필요한 데이터 파일에 시각화 스크립트를 실행한다.텍스트 파일과 그림을 파싱하고 조합해서 논문을 자동 생성한다.Make를 빌드 도구라고 부른다 — Make는 데이터 파일, 그래프, 논문, 프로그램 혹은 라이브러리를 빌드(build)한다.\n원한다면, 기존에 존재하는 파일도 갱신할 수 있다.Make는 Make가 생성한 파일과 이를 생성하는데 사용된 파일에 대한 의존성을 추적한다.\n만약 원본 파일 (예를 들어, 데이터 파일) 중 하나가 변경되면, Make는 알아서 원본파일에 의존성을 갖는 파일(예를 들어, 그래프)을\n재생성하고 갱신한다.현재 빌드 도구는 많이 있다. 하지만, 시장에 나온 모든 빌드 도구는 Make와 같은 개념에 기초하고 있다.유닉스 쉘에서 나온 make를 사용한다. 따라서,\n쉘을 사용해서 디렉토리 목록을 살펴보고, 파일과 디렉토리를 생성, 복사, 삭제, 조회할 수 있고,\n간단한 스크립트를 실행해본 이전 경혐이 일부 필요하다.","code":""},{"path":"make-automation-intro.html","id":"make-setup","chapter":"47 .  자동화와 Make","heading":"47.1 사전 준비","text":"이번 학습을 따라가는데 다음 파일을 다운로드한다:make-lesson.zip 파일을 다운로드한다.make-lesson.zip 파일을 배쉬 쉘(bash shell)을 경우해서 접근할 수 있는 디렉토리로 이동한다.배쉬 쉘 윈도우를 연다.파일을 다운로드한 디렉토리로 이동한다.make-lesson.zip 압축 파일을 다음 명령어로 푼다:작업 디렉토리를 make-lesson 디렉토리로 변경한다:","code":"$ unzip make-lesson.zip$ cd make-lesson"},{"path":"make-automation.html","id":"make-automation","chapter":"48 .  들어가며","heading":"48 .  들어가며","text":"소장하고 있는 책 중 지프의 법칙이 맞는지 관심이 있다고 가정해보자.가장 자주 출현하는 단어는 두번째 가장 자주 출현하는 단어보다 거의 두배 나타난다.\n이를 지프의 법칙,\nZipf’s Law이라고 부른다.원데이터(책과 파이썬 스크립트)는 준비를 마쳤고 head books/isles.txt 명령어로\n소장하고 있는 책중 하나를 빠르게 살펴보자.\n작업할 파이썬 스크립트와 데이터 파일은 다음과 같은 구조를 갖고 있다.텍스트 파일을 읽어 들이고,\n텍스트에 단어갯수를 세고, 출력을 데이터 파일에 저장하는\ncountwords.py 스크립트로 작성이 되어 있어 먼저 책의 단어 빈도수를 살펴보자.head 명령어를 사용해서 데이터 파일 첫 5행을 살펴본다면,isles.dat 파일이 단어마다 한줄씩 구성된 것을 볼 수 있다.각 행은, 단어 자체, 해당 단어 출현횟수, 출현횟수를 텍스트 파일에 전체 단어 갯수에 대한\n백분율로 나타낸다. 또다른 예제로:결과를 시각화하자.\nplotcounts.py 스크립트는 데이터 파일을 읽어들여, 가장 자주 출현하는 10 단어를 도식화한다:plotcounts.py 아스키가 아닌 그래프로 결과를 볼 수도 있다.윈도우를 닫아 그래프를 빠져나온다.plotcounts.py로 그래프를 이미지(예, PNG 파일)로 저장할 수도 있다:마지막으로 지프의 법칙을 앞서 분석한 책에 대해 실행해보자.상기 스크립트를 합하면, 작업흐름은 다음을 구현한 것이 된다:데이터 파일을 읽어들인다.해당 데이터 파일에 분석을 실시한다.분석 결과를 신규 파일에 저장한다.분석 결과에 대한 그래프를 그려 도식화한다.이미지 파일로 그래프를 저장해서, 논문에 삽입할 수 있게 된다.분석요약표를 제작한다.지금까지 작업을 수행한 것처럼,\n쉘 프롬프트에서 countwords.py 와 plotcounts.py 스크립트를 파일 한둘에 작업하는 것은 문제 없다.\n하지만, 텍스트 파일이 5개, 10개, 20개가 된다면, 파이프라인에 작업량이 늘어나게 되면\n어마어미한 작업량이 된다. 여기에 더해서 어느 누구도 심지어 30초 가량 소요된다고\n하더라도 앉아서 명령이 종료되기를 원하지 않는다.지루한 데이터 프로세싱 작업의 가장 일반적인 해법은 시작부터 종료까지\n전체 작업과정을 담은 쉘스크립트를 작성하는 것이다.예를 들어 나노(nano) 같은 텍스트 편집기를 사용해서 run_pipeline.sh 파일에\n다음 사항을 추가한다.쉘 스크립트를 돌려 확인한다. 출력결과는 앞선 결과와 동일하다.쉘 스크립트를 작성하게 되면 재현성 관련 몇가지 문제를 해결해준다.명시적으로 파이프라인을 문서화해서 (미래 자신을 포함해서) 동료와\n좀더 효율적으로 커뮤니케이션할 수 있게 돕는다.bash run_pipeline.sh 명령어 하나를 타이핑함으로써 전체 분석을 재현할 수 있게 만들었다.따라서 반복적인 오탈자와 실수를 방지한다. 처음에는 제대로 동작하지 않을 수 있지만,\n버그나 오류를 수정하고 나면 제대로 동작된 상태로 지속된다.이와 같은 장점에도 불구하고 여전히 몇가지 단점도 존재한다.plotcounts.py 파일로 생성되는 막대그래프 폭을 조정하는 경우를 상정해보자.plotcounts.py 파일을 편집해서 막대 폭을 1.0 대신 0.8로 조정하다.\nplot_word_counts 함수 정의를 찾아 width = 1.0 을 width = 0.8으로 바꾼다.이제 그래프를 다시 제작할 수 있다. bash run_pipeline.sh 스크립트만 다시\n실행시키기만 하면 된다. 제대로 동작하기 때문에 큰 문제는 없지만,\n단어 빈도수를 계산하는 부분이 실행에 오래 걸린다면 큰 문제가 아닐 수 없다.\n단어 빈도수를 계산하는 루틴은 변경된 것이 없다; 따라서, 해당 로직을 다시 돌릴\n필요는 없다.대안으로 수작업으로 빈도수가 계산된 파일만 대상으로 그래프를 따로 제작한다.하지만 이런 접근방법은 쉘 스크립트를 도입한 장점이 상당수 훼손되었다.또다른 일반적인 방식은 run_pipeline.sh 스크립트 일부를 주석처리하여 실행되지\n않게 하는 것이다.이렇게 작성하고 나서 bash run_pipeline.sh 명령어를 사용해서 수정한 쉘 스크립트를\n돌려 원하는 결과를 얻어낸다.하지만, 쉘 스크립트 일부를 주석처리해서 돌리고 나중에 다시 원복하는 방식은\n번거럽고 데이터 처리 파이프라인이 복잡할 경우 오류가 발생할 개연성을 충분히 담게 된다.Make(GNU Make로도 알려짐)는\n빠르고, 자유롭게 사용가능하고, 무료이며, 문서화가 잘된 빌드 관리자(build manager)다.\nMake는 1977년 벨 연구소 여름 인턴으로 근무한 Stuart Feldman에 의해 개발되었고,\n오늘날까지 널리 사용되고 있다.\nMake는 분석을 실행하고, 결과를 도식화하는데 필요한 명령어를 실행한다.\n쉘스크립트처럼, 단일 쉘 명령어를 통해, 복잡한 순서 명령어를 실행할 수 있다.\n쉘스크립트와 달리, 명시적으로 파일 사이에 존재하는 의존성을 기록해서,\n텍스트 파일이 변경될 때, 데이터 파일 혹은 이미지 파일을 언제 다시 재생성할지 결정할 수 있다.\n새로운 파일을 생성하는데, 파일을 처리하는 일반적인 패턴을 따르는 어떤 명령어에도 Make를 사용할 수 있다.\n예를 들어:원데이터 파일에 분석 스크립트를 실행해서, 원 데이터를 요약하는 데이터를 생성한다.상기 데이터에 시각화 스크립트를 실행해서, 그래프를 생성한다.텍스트와 그래프를 파싱하고 조합해서 논문을 생성한다.소스코드를 컴파일해서 실행 프로그램 혹은 라이브러리를 생성한다.시중에 이용가능한 빌드 도구가 많이 있다.\n예를 들어, Apache ANT, doit,\n윈도우용 nmake가 있다.\n이런 빌드 도구를 사용하는 스크립트를 빌드하는 빌드 도구도 있다.\n예를 들어, GNU Autoconf와\nCMake가 있다.\n어떤 도구가 최선인지는 요구사항, 사용 의도, 운영체제에 달려있다.\n하지만, 거의 모든 빌드 도구는 Make와 동일한 기본 개념을 공유하고 있다.거의 40살이 된 Make를 왜 사용할까?오늘날, 고성능 컴퓨팅에 매우 일반적인 언어인\nC 혹은 포트란 레거시 코드를 갖고 작업한 연구원은 아마도 Make를 접해봤을 것 같다.재현가능한 연구 작업흐름을 구현하거나,\n(R 혹은 파이썬을 사용해서) 자료분석과 시각화 작업을 자동화하거나,\n텍스트를 가지고 표와 그래프를 조합해서 데출판을 위한 보고서와 논문을 작업하는데,\nMake를 사용했을 것이다.Make의 기본적인 개념은 거의 모든 빌드도구에 공통이다.GNU Make는\n빠르고, 자유롭게 사용가능하고, 무료이며, 문서화가 잘 정비되어 있고,\n매우 인기가 있고, Make 를 구현한 것 중 하나를 매우 잘 확장하고 있다.\n이제부터, GNU Make에 집중한다. 따라서,\nMake를 언급하면, GNU Make를 의미한다.","code":"|- books\n|  |- abyss.txt\n|  |- isles.txt\n|  |- last.txt\n|  |- LICENSE_TEXTS.md\n|  |- sierra.txt\n|- plotcounts.py\n|- countwords.py\n|- testzipf.py$ python countwords.py books/isles.txt isles.dat$ head -5 isles.datthe 3822 6.7371760973\nof 2460 4.33632998414\nand 1723 3.03719372466\nto 1479 2.60708619778\na 1308 2.30565838181$ python countwords.py books/abyss.txt abyss.dat\n$ head -5 abyss.datthe 4044 6.35449402891\nand 2807 4.41074795726\nof 1907 2.99654305468\na 1594 2.50471401634\nto 1515 2.38057825267$ python plotcounts.py isles.dat ascii\n\nthe   ########################################################################\nof    ##############################################\nand   ################################\nto    ############################\na     #########################\nin    ###################\nis    #################\nthat  ############\nby    ###########\nit    ###########$ python plotcounts.py isles.dat show$ python plotcounts.py isles.dat isles.png$ python testzipf.py abyss.dat isles.dat\n\nBook    First   Second  Ratio\nabyss   4044    2807    1.44\nisles   3822    2460    1.55# USAGE: bash run_pipeline.sh\n# to produce plots for isles and abyss\n# and the summary table for the Zipf's law tests\n\npython countwords.py books/isles.txt isles.dat\npython countwords.py books/abyss.txt abyss.dat\n\npython plotcounts.py isles.dat isles.png\npython plotcounts.py abyss.dat abyss.png\n\n# Generate summary table\npython testzipf.py abyss.dat isles.dat > results.txt$ bash run_pipeline.sh\n$ cat results.txtfor book in abyss isles; do\n    python plotcounts.py $book.dat $book.png\ndone# USAGE: bash run_pipeline.sh\n# to produce plots for isles and abyss\n# and the summary table for the Zipf's law tests.\n\n# These lines are commented out because they don't need to be rerun.\n#python countwords.py books/isles.txt isles.dat\n#python countwords.py books/abyss.txt abyss.dat\n\npython plotcounts.py isles.dat isles.png\npython plotcounts.py abyss.dat abyss.png\n\n# Generate summary table\n# This line is also commented out because it doesn't need to be rerun.\n#python testzipf.py abyss.dat isles.dat > results.txt"},{"path":"make-makefiles-chapter.html","id":"make-makefiles-chapter","chapter":"49 .  Makefiles","heading":"49 .  Makefiles","text":"다음 내용을 갖는 Makefile로 불리는 파일을 생성한다:간단한 빌드 파일로,\nMake를 사용할 때 Makefile로 불리우며 -\nMake가 실행하는 파일이다. 순차적으로 각 라인을 찬찬히 살펴보자:# 은 주석을 나타낸다. # 시작되는 어떤 텍스트나 끝 줄까지 Make가 무시한다.isles.dat 는 대상(target)으로, 생성되거나 빌드되는 파일이다.books/isles.txt 파일은 의존성(dependency)으로,\n대상을 빌드하거나 갱신하는데 필요한 파일이 된다. 대상은 의존성을 0 혹은 여러개 갖을 수 있다.: 은 구분자로 대상과 의존성을 구별한다.python countwords.py books/isles.txt isles.dat 은 동작(action)으로, 의존성을 사용해서 대상을 빌드하거나 갱신하는데 실행되는 명령어가 된다. 대상은 의존성을 0 혹은 여러개 갖을 수 있다.동작은 공백 8자가 아니라, 탭(TAB) 문자를 사용해서 들여쓰기 한다. 1970년부터\n사용된 Make 유산이다.대상, 의존성, 동작이 모여 규칙(rule)을 구성하게 된다.상기 규칙은 python countwords.py 동작과 books/isles.txt 의존성을 사용해서\nisles.dat 대상을 빌드하는 방식을 기술하고 있다.아무것도 없는 처음 상태에서 시작하도록, 생성했던 .dat 와 .png 확장자를 갖는 파일을 삭제한다:기본 디폴트 설정으로, Make는 Makefile로 불리는 Makefile을 찾는다.\n그리고, Make를 다음과 같이 실행한다.Make는 실행하는 동작을 화면에 출력한다:만약 다음 메시지를 보게 되면,동작 중 하나를 들여쓰는데 탭 문자 대신에 공백을 사용했기 때문이다.기대한 결과가 나왔는지 확인해보자.isles.dat 파일 첫 5행이 이전 실행결과와 정확하게 동일해야 된다.Makefile을 Makefile로 호명할 필요는 없다. 하지만,\n그밖의 다른 것으로 호명하려면, Make가 어디서 찾을 수 있는지 일러줄 필요가 있다.\n-f 플래그를 사용해서 파일명을 지정할 수 있다. 예를 들어:Makefile을 재실하면, Make가 다음과 같이 정보를 준다:상기와 같이 출력되는 이유는 대상 isles.dat 파일이 이제 생성되어서,\nMake가 다시 생성하기 않기 때문이다.\n작동 방식을 살펴보기 위해서, 텍스트 파일 중 하나를 갱신한 척 해보자.\n편집기에서 파일을 여는 대신에, 쉘 touch 명령어를 사용해서 시간도장(timestamp)을 갱신한다.\n시간도장 갱신은 파일을 편집하면 발생되게 된다:books/isles.txt 파일과 isles.dat 파일 시간도장(timestamp)을 비교하면,대상 isles.dat 파일이 의존성 books/isles.txt 파일보다 더 이전 파일임을 알게 된다:Make를 다시 실행하면,isles.dat 파일을 다시 생성시킨다:대상을 빌드하도록 Make가 요청받을 때,\nMake는 대상과 의존성 모두의 ’최종 변경 시간’을 검사한다.\n만약 대상과 비교해서 의존성에 갱신된 것이 있다면, 대상을 갱신하도록 동작을 다시 실행한다.\n이러한 접근법을 사용해서 Make는 직간접적으로 변경된 파일만 다시 빌드작업을 수행한다.\n이것을 증분 빌드(incremental build)라고 한다.문서로 Makefiles파일간 의존성과 함께 분석 단계 입력과 출력을 명시적으로 기록함으로써,\nMakefiles은 일종의 문서(documentation)로 역할을 수행하여 작업자가 기억해야 되는\n것을 대폭줄여준다.Makefile 파일 후미에 또다른 규칙을 추가하자:Make를 실행하면,다음 결과를 얻게 된다:아무일도 발생하지 않는데, 이유는 Make가 Makefile에서 찾게되는 첫번째 대상만\n빌드하려고 하기 때문이다. 첫번째 대상이 기본 디폴트 설정 대상(default target)으로\nisles.dat 파일이 되는데 이미 최신 상태다.\n명시적으로 Make에게 abyss.dat 파일을 빌드한다는 의도를 일러줄 필요가 있다:이제 다음 결과를 얻게 된다:“Date” vs “Nothing Done”Make가 이미 존재하고 가장 최신(date) 파일을 빌드하는 경우\nMake는 다음 사항을 알려준다.Make가 이미 존재하지만 Makefile에 규칙(rule)이 없는 경우는,\n다음 메시지를 Make가 알려준다.date 가 의미하는 바는 Makefile에 파일(혹은 디렉토리)과\n연관된 액션을 갖는 규칙이 있지만 파일이 가장 최신 상태임을 반증한다.\nNothing done은 파일이 존재는 하지만 다음 사항을 나타내고 있다.Makefile이 해당 규칙이 없다.Makefile이 규칙은 있으나 액션을 갖고 있지 않다.작업한 모든 파일을 제거하고 나서 명시적으로 전부 재생성할 수 있다.\n이 작업으로 새로운 대상과 연관된 규칙 clean을 도입한다:\n.dat 파일처럼 자동생성된 파일을 제거하는 일반적인 명칭이다.상기 규칙예제가 의존성을 갖지 않는 사례다.\nclean은 어떤 .dat 파일에 대해서도 의존성이 없다. 왜냐하면,\n금방 삭제될 파일을 다시 생성하는 것이 무의미하기 때문이다.\n파일이 존재하든 존재하지 않던 데이터 파일을 제거하고자 한다.\n대상을 명세하고 Make를 실행하면,다음 결과를 얻게 된다:clean으로 실제로 어떤 것도 빌드되지는 않는다.\n오히려, 유용한 연속 동작을 실행하는데 사용하는 약칭이 된다.\n매우 유용하지만, 이런 대상이 문제를 불러 일으킬 수 있다.\n예를 들어, 데이터 파일을 다시 생성하고, clean 이라는 디렉토리를 생성하고 나서,\nMake를 실행한다:다음 결과를 얻게 된다:Make가 clean이라는 파일(혹은 디렉토리)을 찾는다.\nclean 규칙에는 어떤 의존성도 없기 때문에,\nclean 이 빌드되어서 최신 상태라고 가정하게 된다.\n그래서, 규칙에 나온 동작을 하나도 실행하지 않는다.\nclean을 약칭으로 사용할 때, make clean 명령어를 실행하면,\n항상 해당 규칙을 Make가 실행하도록 일러줄 필요가 있다.\nMake에게 어떤 것도 빌드하지 않는 가짜 대상(phony target)이라고\n일러줘서 이 문제를 해결한다. 대상을 .PHONY로 표식해서 해당 작업을 수행한다:Make를 실행하면,다음 결과를 얻는다:모든 데이터 파일을 생성하도록 유사한 명령어를 추가할 수도 있다:상기 규칙예제가 다른 규칙에 대상이 되는 의존성을 갖는 규칙이다.\nMake를 실행하면, 의존성이 존재하는지 검사하고, 만약 의존성이 없다면,\n해당 파일을 생성하는 규칙이 있는지를 살펴본다.\n만약 그런 규칙이 존재하면, 먼저 동작시키게 되고, 그렇지 않다면 Make가 오류를 발생시킨다.의존성(Dependencies)의존성을 다시 빌드하는 순서는 무작위다.\n목록에 기입된 순서로 빌드된다고 가정하지 말아야 된다.의존성은 방향성 있는 주기가 없는 그래프(directed acyclic graph) 형태를 띈다.\n대상이 본인 혹은 의존성을 갖는 하나가 대상에 의존성을 갖을 수 없다.동작을 갖지 않는 규칙의 한 사례이기도 하다.\n필요한 경우, 순전히 의존성 빌드를 촉발하는데 사용되기도 하다.만약 상기 규칙을 실행하면,Make가 data 파일을 생성하게 된다:dats를 다시 실행하면,Make가 데이터 파일이 존재하는 것을 알게 된다:이제 최종 Makefile은 다음과 같다:dats에 명기된 대상을 빌드하는데 관여된 의존성을 도식화했는데,\nMakefile에서 구현된 사항이 다음 그림에 나와 있다:Makefile 내부에 표현된 의존성","code":"# 단어 갯수를 센다.\nisles.dat : books/isles.txt\n        python wordcount.py books/isles.txt isles.dat$ rm *.dat *.png$ makepython countwords.py books/isles.txt isles.datMakefile:3: *** missing separator.  Stop.head -5 isles.dat\nthe 3822 6.737176097303014\nof 2460 4.336329984135378\nand 1723 3.0371937246606735\nto 1479 2.607086197778953\na 1308 2.305658381808567$ make -f MyOtherMakefilemake: `isles.dat' is up to date.$ touch books/isles.txt$ ls -l books/isles.txt isles.dat-rw-r--r--    1 mjj      Administ   323972 Jun 12 10:35 books/isles.txt\n-rw-r--r--    1 mjj      Administ   182273 Jun 12 09:58 isles.dat$ makepython countwords.py books/isles.txt isles.databyss.dat : books/abyss.txt\n        python wordcount.py books/abyss.txt abyss.dat$ makemake: `isles.dat' is up to date.$ make abyss.datpython countwords.py books/abyss.txt abyss.datmake: `isles.dat' is up to date.$ make countwords.py\n\nmake: Nothing to be done for `countwords.py'.clean : \n        rm -f *.dat$ make cleanrm -f *.dat$ make isles.dat abyss.dat\n$ mkdir clean\n$ make cleanmake: `clean' is up to date..PHONY : clean\nclean : \n        rm -f *.dat$ make cleanrm -f *.dat.PHONY : dats\ndats : isles.dat abyss.dat$ make datspython wordcount.py books/isles.txt isles.dat\npython wordcount.py books/abyss.txt abyss.dat$ make datsmake: Nothing to be done for `dats'.# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat\n\nisles.dat : books/isles.txt\n        python wordcount.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt\n        python wordcount.py books/abyss.txt abyss.dat\n\n.PHONY : clean\nclean :\n        rm -f *.dat"},{"path":"make-makefiles-chapter.html","id":"make-challenge-one","chapter":"49 .  Makefiles","heading":"49.1 신규 규칙 두개 작성","text":"last.dat 파일에 대한 새로운 규칙을 작성하는데, books/last.txt 파일에서 생성된다.dats 규칙을 상기 대상을 포함하도록 갱신하라.analysis.tar.gz 에 대한 새로운 규칙을 작성하는데,\n데이터 파일을 보관하도록 압축파일이 생성된다.\n규칙은 다음 작업이 필요하다:세가지 .dat 파일 각각에 의존성을 갖는다.python testzipf.py abyss.dat isles.dat last.dat > results.txt 동작을 호출한다.Makefile 상단에 규칙을 두어 디폴트기본 타겟이 되게 한다.results.txt 파일을 제거하도록 clean을 갱신한다.시작 Makefile은 다음과 같다.도전과제에 대한 해답results.txt에 명기된 대상을 빌드하는데 관여된 의존성을 도식화했는데,\nMakefile에서 구현된 사항이 다음 그림에 나와 있다:Makefile 내부에 표현된 results.txt 의존성","code":"# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat\n\nisles.dat : books/isles.txt\n    python countwords.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt\n    python countwords.py books/abyss.txt abyss.dat\n\n.PHONY : clean\nclean : \n    rm -f *.dat# Generate summary table.\nresults.txt : isles.dat abyss.dat last.dat\n  python testzipf.py abyss.dat isles.dat last.dat > results.txt\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt\n  python countwords.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt\n  python countwords.py books/abyss.txt abyss.dat\n\nlast.dat : books/last.txt\n  python countwords.py books/last.txt last.dat\n\n.PHONY : clean\nclean :\n  rm -f *.dat\n  rm -f results.txt"},{"path":"make-makefiles.html","id":"make-makefiles","chapter":"50 .  자동 변수","heading":"50 .  자동 변수","text":"앞선 수업 말미 연습문제를 푼 후, Makefile 은 다음과 같아 보인다:Makefile에 중복이 엄청 많다.\n예를 들어, 텍스트 파일과 데이터 파일 명칭이 Makefile 전역에 걸쳐 여러 곳에서 반복되고 있다.\nMakefile은 코드의 한 형태로, 어떤 코드에서나 그렇듯이 반복되는 코드는 문제가 될 소지가 있다.\n예를 들어, Makefile의 일부에서 데이터 파일 명칭을 바꾸고 나서 다른 곳에 명칭을 바꾸는 것을 잊곤 한다.D.R.Y.(Don’t Repeat )대다수 프로그래밍 언어에서 프로그래머가 긴 연산과정 루틴을 간결하고 표현력있고\n아름다운 코드로 기술할 수 있는 기능을 지원한다.\nR, 파이썬, 자바 언어에 사용자 정의 변수와 함수 기능이 유용한데 이유는\n구체적인 모든 사항을 반복해서 작성할 필요가 없기 때문이다.\n단지 한번만 작성하는 이러한 좋은 프로그래밍 습관이 D.R.Y.(Don’t Repeat )\n원칙으로 알려져 있다. 우리나라 말로 복붙, 삽질 하지말자 정도가 체감상 맞을 듯 싶다.Makefile 에서 반복되는 코드를 제거해 나가자.\nresults.txt 규칙에서, 데이터 파일과 파일 저장소 아카이브 명칭이 중복된다:먼저 문서저장소 아카이브 명칭을 살펴보면,\n동작에 나온 문서저장소 명칭을 $@으로 교체할 수 있다:$@은 Make 자동 변수(automatic variable)로,\n’현재 규칙에 대한 대상’을 의미한다.\nMake가 실행되면, Make가 해당 변수를 대상 명칭으로 교체한다.동작에 나온 의존성을 $^으로 교체할 수 있다:$^은 또다른 자동변수로, ’현재 규칙에 대한 모든 의존성’을 의미한다.\n다시 한번, Make가 실행될 때, Make가 해당 변수를 의존성으로 교체한다.텍스트 파일을 갱신하고, 위에서 작성한 규칙을 재실행한다:다음에 산출 결과가 나와 있다:","code":"# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt\n        python wordcount.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt\n        python wordcount.py books/abyss.txt abyss.dat\n\nlast.dat : books/last.txt\n        python wordcount.py books/last.txt last.dat\n\n# Generate archive file.\nanalysis.tar.gz : isles.dat abyss.dat last.dat\n        tar -czf analysis.tar.gz isles.dat abyss.dat last.dat\n\n.PHONY : clean\nclean :\n        rm -f *.dat\n        rm -f analysis.tar.gzresults.txt : isles.dat abyss.dat last.dat\n    python testzipf.py abyss.dat isles.dat last.dat > results.txtresults.txt : isles.dat abyss.dat last.dat\n  python testzipf.py abyss.dat isles.dat last.dat > $@results.txt : isles.dat abyss.dat last.dat\n    python testzipf.py $^ > $@$ touch books/*.txt\n$ make results.txtpython countwords.py books/isles.txt isles.dat\npython countwords.py books/abyss.txt abyss.dat\npython countwords.py books/last.txt last.dat\npython testzipf.py isles.dat abyss.dat last.dat > results.txt"},{"path":"make-makefiles.html","id":"make-dependency-challenge","chapter":"50 .  자동 변수","heading":"50.1 의존성 갱신하기","text":"지금 다음을 실행하면 어떤 일이 발생할까:아무 일도 없다.모든 파일이 다시 생성된다.단지 .dat 파일만 다시 생성된다.단지 results.txt만 다시 생성된다.도전과제 해법\n4. 단지 results.txt만 다시 생성된다.*.dat에 대한 규칙은 실행되지 않는데 이유는 해당되는 .txt 파일 변경이\n일어나지 않아서 그렇다.다음을 실행하게 되면.dat 파일과 results.txt 파일이 다시 생성된 것을 확인할 수 있다.위에서 살펴봤듯이, $^은 ’현재 규칙에 대한 모든 의존성’을 의미한다.\nresults.txt 파일에 대해서는 잘 동작하는데,\n이유는 해당 동작이 모든 의존성을 testzipf.py에 입력처럼 동일하게 처리하기 때문이다.하지만, 일부 규칙에 대해, 첫째 의존성을 다르게 처리하고 싶을 수 있다.\n예를 들어, .dat 파일에 대한 규칙은 첫째 의존성(만을) 사용해서 wordcount.py 에\n입력 파일로 적용코져 한다.\n만약 추가적인 의존성을 추가하면(곧 그렇듯이), countwords.py에 입력 파일로 전달되면 안된다.\n왜냐하면, 호출될 때 입력 파일만 호명되길 기대하기 때문이다.Make는 이런 목적을 위한 자동변수가 있는데 $<으로,\n’현재 규칙에 대한 첫째 의존성’을 의미한다.","code":"$ touch *.dat\n$ make analysis.tar.gz$ touch books/*.txt\n$ make results.txt"},{"path":"make-makefiles.html","id":"make-automatic-challenge","chapter":"50 .  자동 변수","heading":"50.2 자동변수 규칙 작성","text":"자동 변수를 사용하도록 .dat 규칙을 다시 작성하시오.자동 변수 $@(‘현재 규칙에 대한 대상’)와 $< (‘현재 규칙에 대한 첫째 의존성’)을 사용하도록 .dat 규칙을 다시 작성하시오.자동변수 적용 해답","code":"# Generate summary table.\nresults.txt : *.dat\n    python testzipf.py $^ > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt\n    python countwords.py books/isles.txt isles.dat\n\nabyss.dat : books/abyss.txt\n    python countwords.py books/abyss.txt abyss.dat\n\nlast.dat : books/last.txt\n    python countwords.py books/last.txt last.dat\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txt# Generate summary table.\nresults.txt : isles.dat abyss.dat last.dat\n  python testzipf.py $^ > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt\n  python countwords.py $< $@\n\nabyss.dat : books/abyss.txt\n  python countwords.py $< $@\n\nlast.dat : books/last.txt\n  python countwords.py $< $@\n\n.PHONY : clean\nclean :\n  rm -f *.dat\n  rm -f results.txt"},{"path":"make-makefiles.html","id":"make-autovariable-points","chapter":"50 .  자동 변수","heading":"50.3 자동변수 요약","text":"Make 자동변수를 사용해서 Makefile에 중복을 제거한다.$@을 사용해서 현재 규칙에 있는 대상을 참조한다.$^을 사용해서 현재 규칙에 있는 의존성을 참조한다.$<을 사용해서 현재 규칙에 있는 첫째 의존성을 참조한다.","code":""},{"path":"make-dependencies.html","id":"make-dependencies","chapter":"51 .  데이터와 코드 의존성","heading":"51 .  데이터와 코드 의존성","text":"지금까지 작성한 Makefile은 다음과 같다:데이터 파일은 텍스트 파일에 대한 제품이기도 하지만,\n텍스트 파일을 처리하고 데이터 파일을 생성하는 countwords.py, 스크립트에 대한 제품이기도 하다.\ncountwords.py 파일 수정(예를 들어 요약 데이터 신규 칼럼 추가 혹은 기존 요약결과 제거 등)은\n출력결과를 .dat 파일변경에도 일조를 하게 된다.\n따라서, touch 명령어를 사용해서 countwords.py 파일을 수정한 것처럼 하고\nMake를 다시 실행시키자.아무런 일도 발생하지 않았다!\ncountwords.py 파일을 수정했지만, 데이터 파일을 갱신하지 않아서\n.dat 파일 생성에 관여하는 규칙이 countwords.py 파일 의존성을 기록하지 못했다.또한, countwords.py 파일을 데이터 파일에 대한 의존성으로 추가해야만 된다:wordcount.py 프로그램을 편집한 척하고, Make를 재실행하면,다음 결과를 얻게 된다:시운전 (Dry Run)make 명령어를 실행할 때 -n 플래그를 사용하게 되면\n실제 명령을 실행하지 않고 실행할 명령어를 보여준다.-n 플래그 없이 화면에 동일한 출력결과를 보여주지만,\n실제 명령은 실행되지 않는다. ‘dry-run’ 모드를 사용해서\n실제 돌리지 건에 Makefile이 제대로 설정되었는지 사전\n확인할 수 있다.countwords.py와 testzipf.py 파일을 .dat 파일에 의존성으로 추가한 후,\nresults.txt에 명기된 대상을 빌드하는데 관여된 의존성을 도식화했는데,\nMakefile에서 구현된 사항이 다음 그림에 나와 있다:countwords.py와 testzipf.py 파일을 의존성으로 추가한 후에, results.txt 의존성.txt 파일은 wordcount.py 파일에 의존성을 갖지 않는가?.txt 파일은 입력 파일이며 어떤 의존성도 갖지 않는다.\n입력파일이 wordcount.py 파일에 의존성을 만드려면,\n거짓 의존성(false dependency)\n도입이 필요하다.직관적으로 results.txt 파일에 의존성을 countwords.py 파일에 추가해야 한다.\n.dat 파일을 다시 만드는데 최종표가 빌드되야 하기 때문이다.\n하지만 그럴필요가 없다는 것이 밝혀졌다. countwords.py 파일을 갱신할 때\nresults.txt 파일에 생긴 일을 살펴보자.상기 명령을 실행하면 다음을 얻게 된다.results.txt 파일 파일 포함해서 전체 파이프라인이 촉발되어 실행되었다.\n이 과정을 이해하기 위해 의존성 그래프에 따르면 results.txt 파일은\n.dat 파일에 의존성을 갖는다.\ncountwords.py 파일을 갱신하게 되면 .dat 파일 갱신을 촉발시킨다.\n따라서, make가 .dat 파일 의존성이 results.txt 타겟 파일보다\n신규 상태임을 인식하게 되어 results.txt 파일을 다시 만들어낸다.\n이것이 make의 강력함을 보여주는 한 사례다: 파이프라인의 일부 파일이 갱신되면\n적절한 후속 단계를 자동 실행시킨다.","code":"# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt\n    python wordcount.py $< $@\n\nabyss.dat : books/abyss.txt\n    python wordcount.py $< $@\n\nlast.dat : books/last.txt\n    python wordcount.py $< $@\n\n# Generate archive file.\nanalysis.tar.gz : *.dat\n    tar -czf $@ $^\n\n.PHONY : clean\nclean :\n        rm -f *.dat\n        rm -f analysis.tar.gz$ make dats\n$ touch countwords.py\n$ make datsisles.dat : books/isles.txt countwords.py\n    python countwords.py $< $@\n\nabyss.dat : books/abyss.txt countwords.py\n    python countwords.py $< $@\n\nlast.dat : books/last.txt countwords.py\n    python countwords.py $< $@$ touch wordcount.py\n$ make datspython countwords.py books/isles.txt isles.dat\npython countwords.py books/abyss.txt abyss.dat\npython countwords.py books/last.txt last.dat$ touch countwords.py\n$ make -n dats$ touch countwords.py\n$ make results.txtpython countwords.py books/abyss.txt abyss.dat\npython countwords.py books/isles.txt isles.dat\npython countwords.py books/last.txt last.dat\npython testzipf.py abyss.dat isles.dat last.dat > results.txt"},{"path":"make-dependencies.html","id":"make-one-file","chapter":"51 .  데이터와 코드 의존성","heading":"51.1 입력파일 갱신","text":"다음 명령을 실행시키게 되면 어떤 결과가 나오게 될까?last.dat 파일만 다시 생성된다.모든 .dat확장자를 갖는 파일이 다시 생성된다.last.dat, results.txt 파일만 다시 생성된다.모든 .dat, results.txt 파일만 다시 생성된다.해답\n3. last.dat, results.txt 파일만 다시 생성된다.의존성 나무그래프를 따라가면 정답이 명확하게 이해된다.","code":"$ touch books/last.txt\n$ make results.txt"},{"path":"make-dependencies.html","id":"make-testzipf","chapter":"51 .  데이터와 코드 의존성","heading":"51.2 results.txt 의존성 testzipf.py","text":"results.txt 파일 의존성에 testzipf.py 파일을 추가하면 어떻게 될까?\n그리고 이유는 무엇일까?해답다음과 같이 results.txt 파일에 규칙을 추가하게 되면testzipf.py 는 $^의 일부가 되어 명령어는 사실 다음과 같이 된다.testzipf.py 파일에서 .dat 파일처럼 스크립트를 파싱하게 되어 오류가 발생한다.\n오류가 나온 것을 실제로 돌려 확인해보자.다음과 같은 결과가 나오게 된다.results.txt 파일에 대한 의존성에 testzipf.py 스크립트를 반영해야 된다.\n앞선 사례를 통해 $^ 규칙을 사용할 수는 없다는 것이 확인되었다.\n하지만, testzipf.py 파일을 첫번째 의존성으로 이동하고 나서\n$<을 사용해서 참조하면 된다. .dat 파일을 지칭하는데는\n임시로 *.dat를 사용한다.(추후 더 좋은 해법을 다룰 것이다.)현재까지 다룬 Makefile","code":"results.txt : isles.dat abyss.dat last.dat testzipf.py\n        python testzipf.py $^ > $@python testzipf.py abyss.dat isles.dat last.dat testzipf.py > results.txt$ make results.txtpython testzipf.py abyss.dat isles.dat last.dat testzipf.py > results.txt\nTraceback (most recent call last):\n  File \"testzipf.py\", line 19, in <module>\n    counts = load_word_counts(input_file)\n  File \"path/to/testzipf.py\", line 39, in load_word_counts\n    counts.append((fields[0], int(fields[1]), float(fields[2])))\nIndexError: list index out of range\nmake: *** [results.txt] Error 1results.txt : testzipf.py isles.dat abyss.dat last.dat\n    python $< *.dat > $@# Generate summary table.\nresults.txt : testzipf.py isles.dat abyss.dat last.dat\n    python $< *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\nisles.dat : books/isles.txt countwords.py\n    python countwords.py $< $@\n\nabyss.dat : books/abyss.txt countwords.py\n    python countwords.py $< $@\n\nlast.dat : books/last.txt countwords.py\n    python countwords.py $< $@\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txt"},{"path":"make-patterns.html","id":"make-patterns","chapter":"52 .  패턴 규칙","heading":"52 .  패턴 규칙","text":"Makefile에는 여전히 반복되는 콘텐츠가 있다.\n텍스트 파일과 데이터 파일 명칭을 제외하고 각 .dat 파일에 대한 규칙은 동일한다.\n이러한 규칙을 단일 패턴 규칙(pattern rule)으로\n교체할 수 있는데, 패턴 규칙을 사용해서 books/ 디렉토리에 .txt 파일을 임의 .dat 파일로\n빌드한다:%는 Make 와일드-카드(wild-card)다.\n$*은 특수 변수로, 특수변수가 스템(stem)4을 규칙이 매칭하는 것으로 치환한다.상기 규칙은 다음과 같이 해석할 수 있다: [something].dat 타켓을 갖는 파일을\n빌드하는데 books/[something].txt 의존성을 갖는 파일을 찾아\ncountwords.py [dependency] [target] 명령을 실행한다.만약 Make를 다시 실행하면,다음 결과를 얻게 된다:이전과 마찬가지로 개별 .dat 타겟을 빌드하는데 Make를 여전히 사용할 수 있다.\n어떤 스템이 매칭되더라도 신규 규칙은 여전히 정상동작한다.Make 와일드-카드 사용하기Make % 와일드-카드는 대상과 해당 의존성에만 사용될 수 있다.\n동작에는 사용될 수가 없다.하지만, 동작에서 $*을 사용할 수 있는데, 스템이 규칙이 매칭하는 것으로 치환한다.Makefile은 이제 훨씬 더 짧아졌고, 깨끗해졌다:현재까지 다룬 Makefile패턴 규칙을 소개했고 dat 규칙에 $*을 사용해서 사용법을 설명했다.\n좀더 깔끔한 해법은 $@을 사용해서 현재 규칙의 타겟을 명세하는 것이지만\n그러면 $*을 학습할 이유는 없을 것이다.","code":"%.dat : books/%.txt countwords.py\n    python countwords.py $< $*.dat$ make clean\n$ make datspython wordcount.py books/isles.txt isles.dat\npython wordcount.py books/abyss.txt abyss.dat\npython wordcount.py books/last.txt last.dat# Generate summary table.\nresults.txt : testzipf.py isles.dat abyss.dat last.dat\n    python $< *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\n%.dat : books/%.txt countwords.py\n    python countwords.py $< $*.dat\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txt# Generate summary table.\nresults.txt : testzipf.py isles.dat abyss.dat last.dat\n    python $< *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\n%.dat : books/%.txt countwords.py\n    python countwords.py $< $*.dat\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txt\n%.dat : books/%.txt countwords.py\n    python countwords.py $< $@"},{"path":"make-patterns.html","id":"make-patterns-points","chapter":"52 .  패턴 규칙","heading":"52.1 패턴 규칙 주요점","text":"Make 와일드-카드 %를 대상과 의존성에 사용한다.Make 특수 변수 $*을 동작에 사용한다.규칙에는 Make 와일드-카드 사용을 회피한다.","code":""},{"path":"make-variable.html","id":"make-variable","chapter":"53 .  변수","heading":"53 .  변수","text":"지금까지의 노력에도 불구하고, Makefile에는 여전히 중복된 콘텐트, 즉 countwords.py\n스크립트 명칭과 스크립트를 실행하는데 동원된 프로그램 python이 존재한다.\n해당 스크립트의 이름을 바꾸면, 여러 곳에서 Makefile을 갱신해야만 된다.스크립트 명칭을 보관하는 Make 변수(variable) (Make 일부 버젼에서는 매크로(macro)라고도 불림)를 소개한다:변수 할당(assignment)하는 예제가 위에 나와 있다 -\nCOUNT_SRC 변수에 countwords.py 값이 할당되었다.countwords.py는 스크립트로, 파이썬(python)에 전달되어 호출된다.\n또다른 변수를 도입해서 스크립트 실행을 표현한다:Make가 실행될 때, $(...)는 Make에게 변수를 해당 값으로 치환하도록 일러준다.\n이것이 변수 참조(reference)다.\n변수값을 사용하고자 하는 어떤 곳에서도, 이런 방식으로 작성하고 참조한다.여기서는 COUNT_SRC 변수를 참조한다.\nMake로 하여금 COUNT_SRC 변수를 countwords.py 값으로 치환하게 한다.\nMake가 실행될 때, COUNT_EXE에 값으로 python countwords.py를 할당한다.이런 방식으로 COUNT_EXE 변수를 정의하면 스크립트 실행방식을 쉽게 변경할 수 있게 된다\n(예를 들어, 스크립트 구현 언어를 파이썬에서 R로 변경하게 되면).변수 사용하기Makefile를 갱신해서, %.dat 규칙이\nCOUNT_SRC 와 COUNT_EXE 변수를 참조하게 한다.\n그리고 나서 ZIPF_SRC 와 ZIPF_EXE 변수명을 사용해서\ntestzipf.py 스크립트와 results.txt 규칙에 대해서도 동일하게 작업한다.해답Makefile 상단에 변수를 위치시키게 되면, 찾고 변경하기 쉽게 한다는 의미가 된다.\n대안으로, 변수 정보만 간직하는 Makefile을 새로 만들어 넣을 수 있다.\nconfig.mk 파일을 생성하자:다음 명령어를 사용해서, config.mk 파일을 Makefile 내부로 Makefile을 가져올 수 있다:Make를 재실행해서, 모든 것이 여전히 잘 동작하는지 살펴보자:Makefile 구성정보와 작업을 수행하는 부분, 즉 규칙을 구분했다.\n스크립트 명칭 혹은 실행방식을 변경하려면,\nMakefile에 있는 소스코드가 아니라, 단지 구성파일만 편집하면 된다.\n이런 방식으로 코드를 구성과 결합시키지 않는 것이 좋은 프로그래밍 관례다.\n더 모듈화 되고, 유연해지며, 재사용가능한 코드가 되기 때문이다.현재까지 다룬 Makefile새로 추가된 config 파일","code":"COUNT_SRC=countwords.pyLANGUAGE=python\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)LANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)\n\n# Generate summary table.\nresults.txt : $(ZIPF_SRC) isles.dat abyss.dat last.dat\n  $(ZIPF_EXE) *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\n%.dat : books/%.txt $(COUNT_SRC)\n  $(COUNT_EXE) $< $*.dat\n\n.PHONY : clean\nclean :\n  rm -f *.dat\n  rm -f results.txt# Count words script.\nLANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\n\n# Test Zipf's rule\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)include config.mk$ make clean\n$ make dats\n$ make results.txtinclude config.mk\n\n# Generate summary table.\nresults.txt : $(ZIPF_SRC) isles.dat abyss.dat last.dat\n    $(ZIPF_EXE) *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\n%.dat : books/%.txt $(COUNT_SRC)\n    $(COUNT_EXE) $< $*.dat\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txt\n# Count words script.\nLANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\n\n# Test Zipf's rule\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)"},{"path":"make-function.html","id":"make-function","chapter":"54 .  함수","heading":"54 .  함수","text":"현재 시점엣, Makefile은 다음과 같다:Make에는 많은 함수(functions)가 지원되어 더 복잡한 규칙을 작성할 수 있다. 한 사례가 wildcard다. wildcard는 특정 패턴과 매칭되는 파일 목록을 얻어와서,\n변수에 저장할 수 있다. 예를 들어, 모든 텍스트 파일(.txt로 끝나는 파일) 목록을 불러와서\nMakefile 시작부분에 변수에 불러온 값을 저장한다:변수의 값을 보여주도록 .PHONY 대상과 규칙으로 추가한다:(echo?)Make는 동작을 실행할 때 동작을 화면에 출력한다.\n동작 시작부에 @을 사용하면 Make로 하여금 동작을 출력하지 않게 한다.\n그래서, echo 대신에 @echo을 사용함으로써,\necho 실행 결과(변수값을 출력)를 볼 수 있지만, echo 명령어 자체는 볼 수 없게 된다.Make를 실행하면:다음 결과를 얻게 된다:이제 sierra.txt도 포함된 것에 주목한다.함수를 도입한 후, analysis.tar.gz에 명기된 대상을 빌드하는데 관여된 의존성을 도식화했는데,\nMakefile에서 구현된 사항이 다음 그림에 나와 있다:patsubst (‘pattern substitution’, 패턴 치환)은 패턴, 대체 문자열, 명칭 목록을 순서대로 받는다;\n목록에 나와 있는 패턴과 매칭되는 명칭은 대체 문자열로 치환된다. 다시, 결과는 변수에 저장한다.\n예를 들어, 텍스트 파일 목록을 데이터 파일 목록(.dat로 끝나는 파일)으로 다시 작성하고 해당 결과를 변수에 저장한다:variables을 연장해서 DAT_FILES 값을 보여준다:Make를 실행하면,다음 결과를 얻게 된다:이제, sierra.txt 파일도 처리된다.이것을 갖고, clean 과 dats 파일을 다시 작성한다:검사해 봅시다:다음 결과를 얻게된다:results.txt 도 다시 작성할 수 있다:Make를 다시 실행하면:다음 결과를 얻게 된다:results.txt 파일 실행결과를 확인해보자.가장 빈도수가 높은 두 단어 출현비율이 지프의 법칙에서 예측했듯이 대략 2 근처다.다음에 최종 Makefile이 나와 있다:config.mk 파일에 다음이 포함되어 있음을 기억하라:Makefile 내부에 results.txt 타겟을 제작하는데 구현된 의존성을 다음 그래프가 보여주고 있다.\n이를 통해 함수도 소개했다.함수를 도입한 후에 results.txt 의존성","code":"include config.mk\n\n# Generate summary table.\nresults.txt : $(ZIPF_SRC) isles.dat abyss.dat last.dat\n    $(ZIPF_EXE) *.dat > $@\n\n# Count words.\n.PHONY : dats\ndats : isles.dat abyss.dat last.dat\n\n%.dat : books/%.txt $(COUNT_SRC)\n    $(COUNT_EXE) $< $*.dat\n\n.PHONY : clean\nclean :\n    rm -f *.dat\n    rm -f results.txtTXT_FILES=$(wildcard books/*.txt).PHONY : variables\nvariables:\n    @echo TXT_FILES: $(TXT_FILES)$ make variablesTXT_FILES: books/abyss.txt books/isles.txt books/last.txt books/sierra.txtDAT_FILES=$(patsubst books/%.txt, %.dat, $(TXT_FILES)).PHONY : variables\nvariables:\n    @echo TXT_FILES: $(TXT_FILES)\n    @echo DAT_FILES: $(DAT_FILES)$ make variablesTXT_FILES: books/abyss.txt books/isles.txt books/last.txt books/sierra.txt\nDAT_FILES: abyss.dat isles.dat last.dat sierra.dat.PHONY : clean\nclean :\n        rm -f $(DAT_FILES)\n        rm -f analysis.tar.gz\n\n.PHONY : dats\ndats : $(DAT_FILES)$ make clean\n$ make datspython countwords.py books/abyss.txt abyss.dat\npython countwords.py books/isles.txt isles.dat\npython countwords.py books/last.txt last.dat\npython countwords.py books/sierra.txt sierra.datresults.txt : $(ZIPF_SRC) $(DAT_FILES)\n    $(ZIPF_EXE) $(DAT_FILES) > $@$ make clean\n$ make results.txtpython countwords.py books/abyss.txt abyss.dat\npython countwords.py books/isles.txt isles.dat\npython countwords.py books/last.txt last.dat\npython countwords.py books/sierra.txt sierra.dat\npython testzipf.py  last.dat  isles.dat  abyss.dat  sierra.dat > results.txt$ cat results.txt\n\nBook    First   Second  Ratio\nabyss   4044    2807    1.44\nisles   3822    2460    1.55\nlast    12244   5566    2.20\nsierra  4242    2469    1.72include config.mk\n\nTXT_FILES=$(wildcard books/*.txt)\nDAT_FILES=$(patsubst books/%.txt, %.dat, $(TXT_FILES))\n\n# Generate summary table.\nresults.txt : $(ZIPF_SRC) $(DAT_FILES)\n    $(ZIPF_EXE) $(DAT_FILES) > $@\n\n# Count words.\n.PHONY : dats\ndats : $(DAT_FILES)\n\n%.dat : books/%.txt $(COUNT_SRC)\n    $(COUNT_EXE) $< $@\n\n.PHONY : clean\nclean :\n    rm -f $(DAT_FILES)\n    rm -f results.txt\n\n.PHONY : variables\nvariables:\n    @echo TXT_FILES: $(TXT_FILES)\n    @echo DAT_FILES: $(DAT_FILES)# Count words script.\nLANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\n\n# Test Zipf's rule\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)"},{"path":"make-function.html","id":"make-function-points","chapter":"54 .  함수","heading":"54.1 함수 요약","text":"Make wildcard 함수를 사용해서 패턴과 매칭되는 파일 목록을 얻어온다.Make patsubst 함수를 사용해서 파일명을 다시 작성한다.","code":""},{"path":"make-self-doc.html","id":"make-self-doc","chapter":"55 .  문서화 Makefile","heading":"55 .  문서화 Makefile","text":"배쉬 내부에 실행되는 프로그램과\n개발자가 작성한 프로그램 포함하여 내장 배쉬 명령어는\n--help 플래그를 사용해서 프로그램과 명령어 사용법에 대한 정보를 전달하고 있다.\n이런 연장선상에서 help 타겟을 Makefiles 내부에 작성해서 전달하는 것이\n본인은 물론 다른 개발자에게도 도움이 된다.\n이렇게 함으로써 주요 타겟에 대한 요약 정보와 동작방식에 대한 이해를 빠르게 높임으로써\n꼭 필요하지 않는 경우 Makefile을 볼 필요는 없게 된다.\nhelp 타겟을 실행하게 되면 다음이 출력된다.그렇다면 구현하는 방법은 어떻게 될까? 다음과 같이 규칙을 작성하면 된다:하지만 규칙을 매번 추가하거나 삭제, 혹은 규칙에 대한 설명을 변경할 때마다\n이런 규칙도 수정해서 최신화시켜놔야 한다.\n규칙 자체에 규칙에 대한 기술도 함께 유지하고 자동으로 추출하게 된다면\n정말 멋진 일이 될 것이다.배쉬 쉘이 여기서 우리를 구원해줄 수 있다.\nsed 명령어를 사용한다. sed는 stream editor 줄임말이다.\nsed는 텍스트를 읽어 필터링하고 필터된 결과를 텍스트로 저장한다.따라서, 규칙에 대한 주석도 함께 작성해서 나중에\nsed가 탐지할 수 있도록 표식을 남겨둔다.\nMake는 #을 주석으로 사용하기 때문에 sed가 탐지할 수 있도록\n## 표식을 대신 사용한다. 예를 들어,## 표식을 사용해서 자동으로 sed가 필터하는 주석과 다른 규칙이 기술하는 주석을\n구별한다.Makefile 파일에 sed를 적용한 help 타겟을 작성한다:상기 규칙은 Makefile 자체에 의존한다.\nMakefile에 적힌 첫번째 의존성으로 sed를 실행하고 sed에게 명령하여\n##으로 시작되는 모든 행을 추출해서 sed가 출력하게 지정한다.다음을 실행하게 되면다음을 얻게 된다.타겟이나 규칙을 추가, 변경, 제거하게 되면\n해당 규칙에 인접한 주석을 추가, 갱신, 제거하는 것만 기억하면 된다.\n해당 작업에 대한 주석으로 ## 관례만 존중하면 help 규칙이 자동으로 탐지하여\n출력 도움말을 만들어낸다.현재까지 다룬 Makefileconfig.mk 파일","code":"$ make help\n\nresults.txt : Generate Zipf summary table.\ndats        : Count words in text files.\nclean       : Remove auto-generated files..PHONY : help\nhelp :\n    @echo \"results.txt : Generate Zipf summary table.\"\n    @echo \"dats        : Count words in text files.\"\n    @echo \"clean       : Remove auto-generated files.\"## results.txt : Generate Zipf summary table.\nresults.txt : $(ZIPF_SRC) $(DAT_FILES)\n    $(ZIPF_EXE) $(DAT_FILES) > $@\n\n## dats        : Count words in text files.\n.PHONY : dats\ndats : $(DAT_FILES)\n\n%.dat : books/%.txt $(COUNT_SRC)\n    $(COUNT_EXE) $< $@\n\n## clean       : Remove auto-generated files.\n.PHONY : clean\nclean :\n    rm -f $(DAT_FILES)\n    rm -f results.txt\n\n## variables   : Print variables.\n.PHONY : variables\nvariables:\n    @echo TXT_FILES: $(TXT_FILES)\n    @echo DAT_FILES: $(DAT_FILES).PHONY : help\nhelp : Makefile\n    @sed -n 's/^##//p' $<$ make help results.txt : Generate Zipf summary table.\n dats        : Count words in text files.\n clean       : Remove auto-generated files.\n variables   : Print variables.include config.mk\n\nTXT_FILES=$(wildcard books/*.txt)\nDAT_FILES=$(patsubst books/%.txt, %.dat, $(TXT_FILES))\n\n## results.txt : Generate Zipf summary table.\nresults.txt : $(ZIPF_SRC) $(DAT_FILES)\n    $(ZIPF_EXE) $(DAT_FILES) > $@\n\n## dats        : Count words in text files.\n.PHONY : dats\ndats : $(DAT_FILES)\n\n%.dat : books/%.txt $(COUNT_SRC)\n    $(COUNT_EXE) $< $@\n\n## clean       : Remove auto-generated files.\n.PHONY : clean\nclean :\n    rm -f $(DAT_FILES)\n    rm -f results.txt\n\n## variables   : Print variables.\n.PHONY : variables\nvariables:\n    @echo TXT_FILES: $(TXT_FILES)\n    @echo DAT_FILES: $(DAT_FILES)\n\n.PHONY : help\nhelp : Makefile\n    @sed -n 's/^##//p' $<\n\n# Count words script.\nLANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\n\n# Test Zipf's rule\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)\n"},{"path":"make-conclusion.html","id":"make-conclusion","chapter":"56 .  결론","heading":"56 .  결론","text":"Make 같은 자동 빌드 도구는 여러가지 방식으로 도움을 줄 수 있다.\n반복되는 명령어를 자동화해서, 명령어를 수작업으로 실행할 때,\n범하게 되는 오류위험을 줄여 주고, 시간을 절약해서 도움이 된다.생성할 파일이 어떤 방식으로 변경될 때,\n자동적으로 생성되는 산출물(데이터 파일 혹은 그래프)만 다시 생성하게 함으로써\n시간을 절약해준다.대상, 의존성, 동작 개념을 통해,\n코드, 스크립트, 도구, 구성(configuration), 원데이터,\n파생된 데이터, 그래프, 논문 사이 의존성을 기록하는 문서화 형태로 역할을 수행한다.","code":""},{"path":"make-conclusion.html","id":"make-conclusion-png","chapter":"56 .  결론","heading":"56.1 PNG 생성하기","text":"새로운 규칙을 추가하고, 기존 규칙을 갱신하고, 매크로를 새로 추가하여 다음 작업을 수행한다:plotcounts.py 프로그램을 사용해서 .dat 파일에서 .png 파일을 생성한다.자동생성된 모든 파일(.dat, .jpg, results.txt)을 제거한다.대다수 Makefile은 첫번째 타겟으로 디폴트 기본 포니 타겟을 정의한다.\n타겟을 이번 경우 .png 파일과 results.txt 파일을 빌드하는 작업을 수행한다.\nMakefile은 관례를 따라 타겟을 지원한다.\n따라서, make results.txt 실행하는 대신 make 혹은 더 줄여 make 명령어를\n실행해야 된다. 기본디폴트 설정으로 Makefile에서 첫번째 타겟을 찾아 실행하게 만든다.\n이번 경우 타겟이다.Makefileconfig.mk이미지가 추가된 후 타겟 의존성","code":"include config.mk\n\nTXT_FILES=$(wildcard books/*.txt)\nDAT_FILES=$(patsubst books/%.txt, %.dat, $(TXT_FILES))\nPNG_FILES=$(patsubst books/%.txt, %.png, $(TXT_FILES))\n\n## all         : Generate Zipf summary table and plots of word counts.\n.PHONY : all\nall : results.txt $(PNG_FILES)\n\n## results.txt : Generate Zipf summary table.\nresults.txt : $(ZIPF_SRC) $(DAT_FILES)\n  $(ZIPF_EXE) $(DAT_FILES) > $@\n\n## dats        : Count words in text files.\n.PHONY : dats\ndats : $(DAT_FILES)\n\n%.dat : books/%.txt $(COUNT_SRC)\n  $(COUNT_EXE) $< $@\n\n## pngs        : Plot word counts.\n.PHONY : pngs\npngs : $(PNG_FILES)\n\n%.png : %.dat $(PLOT_SRC)\n  $(PLOT_EXE) $< $@\n\n## clean       : Remove auto-generated files.\n.PHONY : clean\nclean :\n  rm -f $(DAT_FILES)\n  rm -f $(PNG_FILES)\n  rm -f results.txt\n\n## variables   : Print variables.\n.PHONY : variables\nvariables:\n  @echo TXT_FILES: $(TXT_FILES)\n  @echo DAT_FILES: $(DAT_FILES)\n  @echo PNG_FILES: $(PNG_FILES)\n\n.PHONY : help\nhelp : Makefile\n  @sed -n 's/^##//p' $<\n# Count words script.\nLANGUAGE=python\nCOUNT_SRC=countwords.py\nCOUNT_EXE=$(LANGUAGE) $(COUNT_SRC)\n\n# Plot word counts script.\nPLOT_SRC=plotcounts.py\nPLOT_EXE=$(LANGUAGE) $(PLOT_SRC)\n\n# Test Zipf's rule\nZIPF_SRC=testzipf.py\nZIPF_EXE=$(LANGUAGE) $(ZIPF_SRC)\n"}]
